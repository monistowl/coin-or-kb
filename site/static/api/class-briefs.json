{
  "CoinPresolveZeros": {
    "brief": "Drop and reintroduce explicit zero coefficients",
    "file": "CoinPresolveZeros",
    "library": "CoinUtils",
    "layer": "layer-0",
    "header": "src/CoinPresolveZeros.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "CoinBronKerbosch": {
    "brief": "Bron-Kerbosch Algorithm for maximal clique enumeration",
    "file": "CoinBronKerbosch",
    "library": "CoinUtils",
    "layer": "layer-0",
    "header": "src/CoinBronKerbosch.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "CoinCliqueList": {
    "brief": "Sequential storage for cliques found in conflict graphs",
    "file": "CoinCliqueList",
    "library": "CoinUtils",
    "layer": "layer-0",
    "header": "src/CoinCliqueList.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "CoinPresolveSubst": {
    "brief": "Variable substitution from equality constraints",
    "file": "CoinPresolveSubst",
    "library": "CoinUtils",
    "layer": "layer-0",
    "header": "src/CoinPresolveSubst.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "CoinDynamicConflictGraph": {
    "brief": "CoinConflictGraph implementation which supports modifications.",
    "file": "CoinDynamicConflictGraph",
    "library": "CoinUtils",
    "layer": "layer-0",
    "header": "src/CoinDynamicConflictGraph.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "CoinDistance": {
    "brief": "Platform-independent iterator distance utilities\n\nProvides wrapper functions around std::distance to ensure consistent\nbehavior across different compilers and platforms. These utilities are\nused throughout COIN-OR for iterator-based calculations.",
    "file": "CoinDistance",
    "library": "CoinUtils",
    "layer": "layer-0",
    "header": "src/CoinDistance.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "CoinUtility": {
    "brief": "Factory functions for CoinPair and CoinTriple\n\nProvides convenience functions for creating CoinPair and CoinTriple objects\nwith automatic template argument deduction, similar to std::make_pair.",
    "file": "CoinUtility",
    "library": "CoinUtils",
    "layer": "layer-0",
    "header": "src/CoinUtility.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "CoinCliqueSet": {
    "brief": "Set of cliques",
    "file": "CoinCliqueSet",
    "library": "CoinUtils",
    "layer": "layer-0",
    "header": "src/CoinCliqueSet.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "CoinLpIO": {
    "brief": "LP file format reader/writer for linear programming problems\n\nReads/writes CPLEX LP format with Min/Max objective, constraints,\nbounds, and integer/binary variable declarations.",
    "file": "CoinLpIO",
    "library": "CoinUtils",
    "layer": "layer-0",
    "header": "src/CoinLpIO.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "CoinPragma": {
    "brief": "Compiler-specific pragma settings (mainly MSVC warnings)",
    "file": "CoinPragma",
    "library": "CoinUtils",
    "layer": "layer-0",
    "header": "src/CoinPragma.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "CoinNodeHeap": {
    "brief": "Monotone min-heap for Dijkstra's algorithm",
    "file": "CoinNodeHeap",
    "library": "CoinUtils",
    "layer": "layer-0",
    "header": "src/CoinNodeHeap.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "CoinPresolveFixed": {
    "brief": "Remove fixed variables and make variables fixed",
    "file": "CoinPresolveFixed",
    "library": "CoinUtils",
    "layer": "layer-0",
    "header": "src/CoinPresolveFixed.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "CoinMessageHandler": {
    "brief": ".NET wrapper for CoinMessageHandler (logging)\n\nC++/CLI wrapper for COIN-OR logging infrastructure.\nCoinMessageHandlerProxy bridges .NET virtual methods to native callbacks.\nCoinOneMessage and CoinMessages for custom message definitions.",
    "file": "CoinMessageHandler",
    "library": "Sonnet",
    "layer": "layer-4",
    "header": "src/SonnetWrapper/CoinMessageHandler.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "CoinAlloc": {
    "brief": "Memory pool allocator for small fixed-size blocks\n\nOptional memory pool that reduces malloc overhead for small allocations.\nConfigure with COINUTILS_MEMPOOL_MAXPOOLED and COINUTILS_MEMPOOL_ALIGNMENT.",
    "file": "CoinAlloc",
    "library": "CoinUtils",
    "layer": "layer-0",
    "header": "src/CoinAlloc.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "CoinWarmStart": {
    "brief": "Abstract interfaces for warm start information in optimization solvers",
    "file": "CoinWarmStart",
    "library": "CoinUtils",
    "layer": "layer-0",
    "header": "src/CoinWarmStart.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "CoinTime": {
    "brief": "Cross-platform timing utilities (CPU and wall clock)\n\nProvides CoinCpuTime() and CoinWallclockTime() that work on\nWindows, Mac, and Unix/Linux platforms.",
    "file": "CoinTime",
    "library": "CoinUtils",
    "layer": "layer-0",
    "header": "src/CoinTime.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "CoinSimpFactorization": {
    "brief": "Simple LU factorization for LP basis matrices\n\nStraightforward LU factorization implementation. Less optimized than\nCoinFactorization but simpler and useful as reference implementation.",
    "file": "CoinSimpFactorization",
    "library": "CoinUtils",
    "layer": "layer-0",
    "header": "src/CoinSimpFactorization.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "CoinFactorization": {
    "brief": "LU factorization of sparse basis matrix for simplex\n\nImplements LU factorization with hyper-sparse handling for efficient\nFTRAN/BTRAN operations. Supports rank-one updates during pivoting.",
    "file": "CoinFactorization",
    "library": "CoinUtils",
    "layer": "layer-0",
    "header": "src/CoinFactorization.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "CoinPresolveMonitor": {
    "brief": "Monitor rows/columns for debugging presolve transforms",
    "file": "CoinPresolveMonitor",
    "library": "CoinUtils",
    "layer": "layer-0",
    "header": "src/CoinPresolveMonitor.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "CoinMpsIO": {
    "brief": ".NET wrapper for CoinMpsIO (MPS file I/O)\n\nC++/CLI wrapper for reading LP problems from MPS format files.\nExposes row/column bounds, objective coefficients, and matrix data.",
    "file": "CoinMpsIO",
    "library": "Sonnet",
    "layer": "layer-4",
    "header": "src/SonnetWrapper/CoinMpsIO.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "CoinFinite": {
    "brief": "Numeric limit constants and floating-point validation functions\n\nProvides platform-independent definitions for numeric limits (COIN_DBL_MAX,\nCOIN_INT_MAX, etc.) and functions to check for special floating-point values\n(infinity, NaN). These are fundamental utilities used throughout COIN-OR\nfor bounds checking and numerical validation.",
    "file": "CoinFinite",
    "library": "CoinUtils",
    "layer": "layer-0",
    "header": "src/CoinFinite.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "CoinModelUseful": {
    "brief": "Helper classes for CoinModel (Link, LinkedList, Hash)",
    "file": "CoinModelUseful",
    "library": "CoinUtils",
    "layer": "layer-0",
    "header": "src/CoinModelUseful.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "CoinBuild": {
    "brief": "Efficient row-by-row or column-by-column model construction\n\nCoinBuild accumulates rows or columns for batch addition to a model.\nMore efficient than adding one row/column at a time to CoinPackedMatrix.",
    "file": "CoinBuild",
    "library": "CoinUtils",
    "layer": "layer-0",
    "header": "src/CoinBuild.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "CoinPackedMatrix": {
    "brief": ".NET wrapper for CoinPackedMatrix (sparse matrix)\n\nC++/CLI wrapper exposing CoinUtils sparse matrix to .NET languages.",
    "file": "CoinPackedMatrix",
    "library": "Sonnet",
    "layer": "layer-4",
    "header": "src/SonnetWrapper/CoinPackedMatrix.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "CoinPresolveMatrix": {
    "brief": "Core presolve data structures and action base class\n\nDefines CoinPrePostsolveMatrix (common base), CoinPresolveMatrix (for\npresolve), CoinPostsolveMatrix (for postsolve), and CoinPresolveAction\n(base class for all presolve transformations).",
    "file": "CoinPresolveMatrix",
    "library": "CoinUtils",
    "layer": "layer-0",
    "header": "src/CoinPresolveMatrix.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "CoinWarmStartVector": {
    "brief": "Template warm start storing a single typed vector",
    "file": "CoinWarmStartVector",
    "library": "CoinUtils",
    "layer": "layer-0",
    "header": "src/CoinWarmStartVector.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "CoinShallowPackedVector": {
    "brief": "Non-owning sparse vector reference (view into external storage)\n\nCoinShallowPackedVector provides read-only access to sparse vector data\nstored elsewhere. It maintains only pointers, not copies. Use when you\nneed a lightweight view into a row/column of a CoinPackedMatrix.",
    "file": "CoinShallowPackedVector",
    "library": "CoinUtils",
    "layer": "layer-0",
    "header": "src/CoinShallowPackedVector.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "CoinSmartPtr": {
    "brief": "Intrusive reference-counted smart pointer",
    "file": "CoinSmartPtr",
    "library": "CoinUtils",
    "layer": "layer-0",
    "header": "src/CoinSmartPtr.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "CoinRational": {
    "brief": "Rational number representation with double-to-rational conversion\n\nProvides a simple rational number class that can convert floating-point\nvalues to rational approximations. Useful in optimization for converting\nfloating-point coefficients to exact rational form when needed.",
    "file": "CoinRational",
    "library": "CoinUtils",
    "layer": "layer-0",
    "header": "src/CoinRational.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "CoinSignal": {
    "brief": "Cross-platform signal handler typedef (CoinSighandler_t)",
    "file": "CoinSignal",
    "library": "CoinUtils",
    "layer": "layer-0",
    "header": "src/CoinSignal.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "CoinPresolveTripleton": {
    "brief": "Tripleton row presolve: three-variable equation substitution",
    "file": "CoinPresolveTripleton",
    "library": "CoinUtils",
    "layer": "layer-0",
    "header": "src/CoinPresolveTripleton.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "CoinPackedVectorBase": {
    "brief": "Abstract base class for read-only sparse vector access\n\nProvides the read-only interface for sparse vectors stored as parallel\nindex/value arrays. This is the base class for CoinPackedVector (owning)\nand CoinShallowPackedVector (non-owning reference).",
    "file": "CoinPackedVectorBase",
    "library": "CoinUtils",
    "layer": "layer-0",
    "header": "src/CoinPackedVectorBase.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "CoinDenseVector": {
    "brief": "Dense vector template with element-wise arithmetic operations\n\nCoinDenseVector<T> stores all elements in a contiguous array.\nUnlike sparse vectors, every position has storage. Supports\narithmetic operators (+, -, *, /) with other dense vectors.",
    "file": "CoinDenseVector",
    "library": "CoinUtils",
    "layer": "layer-0",
    "header": "src/CoinDenseVector.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "CoinPresolveIsolated": {
    "brief": "Handle isolated constraints (connected only by free variables)",
    "file": "CoinPresolveIsolated",
    "library": "CoinUtils",
    "layer": "layer-0",
    "header": "src/CoinPresolveIsolated.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "CoinConflictGraph": {
    "brief": "Conflict graph for binary variable incompatibilities in MIP",
    "file": "CoinConflictGraph",
    "library": "CoinUtils",
    "layer": "layer-0",
    "header": "src/CoinConflictGraph.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "CoinSnapshot": {
    "brief": "Lightweight read-only snapshot of problem state at a B&B node\n\nCoinSnapshot captures problem data for cut generators and branching code.\nMay own or reference external arrays (see owned_ flag). Designed for\npassing problem state without copying full solver structures.",
    "file": "CoinSnapshot",
    "library": "CoinUtils",
    "layer": "layer-0",
    "header": "src/CoinSnapshot.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "CoinPresolveDoubleton": {
    "brief": "Doubleton row presolve: substitute y from ax+by=c",
    "file": "CoinPresolveDoubleton",
    "library": "CoinUtils",
    "layer": "layer-0",
    "header": "src/CoinPresolveDoubleton.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "CoinOslFactorization": {
    "brief": "LU factorization derived from IBM OSL (Optimization Subroutine Library)\n\nPort of OSL's factorization code. Provides alternative to CoinFactorization\nwith different numerical characteristics and update strategies.",
    "file": "CoinOslFactorization",
    "library": "CoinUtils",
    "layer": "layer-0",
    "header": "src/CoinOslFactorization.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "CoinPresolveDual": {
    "brief": "Fix variables using dual bounds and reduced cost analysis",
    "file": "CoinPresolveDual",
    "library": "CoinUtils",
    "layer": "layer-0",
    "header": "src/CoinPresolveDual.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "CoinIndexedVector": {
    "brief": "Sparse vector with dense backing array for O(1) element access\n\nCoinIndexedVector combines sparse index storage with a dense values array,\nenabling O(1) random access while tracking which positions are non-zero.\nDesigned for simplex operations where sparse updates need fast access.\nHas optional \"packed\" mode that behaves more like CoinPackedVector.",
    "file": "CoinIndexedVector",
    "library": "CoinUtils",
    "layer": "layer-0",
    "header": "src/CoinIndexedVector.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "CoinHelperFunctions": {
    "brief": "Low-level utility functions for array manipulation, copying, and comparison\n\nProvides optimized template functions for common array operations used throughout\nCOIN-OR: copying (with Duff's device optimization), filling, zeroing, sorting checks,\niota generation, and element deletion. Also includes random number generation and\nfile I/O utilities.\n\nMany functions offer ~2x speedup over naive loops via loop unrolling and\nDuff's device techniques.",
    "file": "CoinHelperFunctions",
    "library": "CoinUtils",
    "layer": "layer-0",
    "header": "src/CoinHelperFunctions.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "CoinPresolveSingleton": {
    "brief": "Singleton row/column presolve transforms",
    "file": "CoinPresolveSingleton",
    "library": "CoinUtils",
    "layer": "layer-0",
    "header": "src/CoinPresolveSingleton.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "CoinPresolveUseless": {
    "brief": "Remove useless (redundant) constraints",
    "file": "CoinPresolveUseless",
    "library": "CoinUtils",
    "layer": "layer-0",
    "header": "src/CoinPresolveUseless.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "CoinFileIO": {
    "brief": "Abstract file I/O with automatic compression detection\n\nProvides CoinFileInput and CoinFileOutput base classes with factory\nmethods that auto-detect gzip/bzip2 compression. Used by CoinMpsIO\nand CoinLpIO for reading/writing problem files.",
    "file": "CoinFileIO",
    "library": "CoinUtils",
    "layer": "layer-0",
    "header": "src/CoinFileIO.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "CoinDenseFactorization": {
    "brief": "Dense matrix factorization and CoinOtherFactorization base class\n\nProvides CoinOtherFactorization abstract base class for alternative\nfactorization methods, plus CoinDenseFactorization for small dense\nproblems using LAPACK-style LU.",
    "file": "CoinDenseFactorization",
    "library": "CoinUtils",
    "layer": "layer-0",
    "header": "src/CoinDenseFactorization.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "CoinParam": {
    "brief": "Command line parameter parsing with keyword matching\n\nProvides base class for 'keyword value' parameters with support for\ninteger, double, string, and keyword-set values. Includes partial\nkeyword matching, range validation, and help text.",
    "file": "CoinParam",
    "library": "CoinUtils",
    "layer": "layer-0",
    "header": "src/CoinParam.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "CoinPresolveForcing": {
    "brief": "Forcing and useless constraint detection",
    "file": "CoinPresolveForcing",
    "library": "CoinUtils",
    "layer": "layer-0",
    "header": "src/CoinPresolveForcing.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "CoinSort": {
    "brief": "Sorting utilities for pairs, triples, and parallel arrays\n\nProvides CoinPair, CoinTriple, and sort functions for sorting\nmultiple related arrays together (e.g., indices and values).",
    "file": "CoinSort",
    "library": "CoinUtils",
    "layer": "layer-0",
    "header": "src/CoinSort.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "CoinPresolvePsdebug": {
    "brief": "Debug and consistency checking for presolve\n\nEnable with PRESOLVE_DEBUG and PRESOLVE_CONSISTENCY defines.",
    "file": "CoinPresolvePsdebug",
    "library": "CoinUtils",
    "layer": "layer-0",
    "header": "src/CoinPresolvePsdebug.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "CoinPresolveImpliedFree": {
    "brief": "Detect and process implied free variables",
    "file": "CoinPresolveImpliedFree",
    "library": "CoinUtils",
    "layer": "layer-0",
    "header": "src/CoinPresolveImpliedFree.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "CoinPresolveTighten": {
    "brief": "Tighten variable bounds using constraint propagation",
    "file": "CoinPresolveTighten",
    "library": "CoinUtils",
    "layer": "layer-0",
    "header": "src/CoinPresolveTighten.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "CoinWarmStartPrimalDual": {
    "brief": "Warm start using both primal and dual variable values\n\nStores both primal (column) and dual (row) solution vectors.\nUseful for interior point methods. Includes diff capability.",
    "file": "CoinWarmStartPrimalDual",
    "library": "CoinUtils",
    "layer": "layer-0",
    "header": "src/CoinWarmStartPrimalDual.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "CoinFloatEqual": {
    "brief": "Function objects for testing equality of real numbers\n\nTwo objects are provided; one tests for equality to an absolute tolerance,\none to a scaled tolerance. The tests will handle IEEE floating point, but\nnote that infinity == infinity. Mathematicians are rolling in their graves,\nbut this matches the behaviour for the common practice of using\n<code>DBL_MAX</code> (<code>numeric_limits<double>::max()</code>, or similar\nlarge finite number) as infinity.",
    "file": "CoinFloatEqual",
    "library": "CoinUtils",
    "layer": "layer-0",
    "header": "src/CoinFloatEqual.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "CoinModel": {
    "brief": "High-level model building with string names and expressions\n\nCoinModel provides a flexible interface for constructing LP/MIP models.\nSupports row/column names, string-based expressions, and incremental\nbuilding. Convert to CoinPackedMatrix for solver use.",
    "file": "CoinModel",
    "library": "CoinUtils",
    "layer": "layer-0",
    "header": "src/CoinModel.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "CoinCutPool": {
    "brief": "Class for storing a pool of cuts",
    "file": "CoinCutPool",
    "library": "CoinUtils",
    "layer": "layer-0",
    "header": "src/CoinCutPool.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "CoinSearchTree": {
    "brief": "Search tree data structures for branch-and-bound\n\nProvides tree node management with various comparison strategies\n(best-first, depth-first, breadth-first).",
    "file": "CoinSearchTree",
    "library": "CoinUtils",
    "layer": "layer-0",
    "header": "src/CoinSearchTree.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "CoinMessage": {
    "brief": "Standard COIN-OR message definitions (enum and preloaded set)\n\nDefines COIN_Message enum for standard messages (MPS errors, presolve\ninfo, etc.) and CoinMessage class that preloads these into a handler.",
    "file": "CoinMessage",
    "library": "CoinUtils",
    "layer": "layer-0",
    "header": "src/CoinMessage.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "CoinStaticConflictGraph": {
    "brief": "static CoinConflictGraph implementation with fast queries",
    "file": "CoinStaticConflictGraph",
    "library": "CoinUtils",
    "layer": "layer-0",
    "header": "src/CoinStaticConflictGraph.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "CoinWarmStartBasis": {
    "brief": "Simplex basis warm start with variable status (basic/nonbasic)\n\nStores status of each variable (structural and artificial) using\n2 bits per variable. Includes diff capability for branch-and-bound.",
    "file": "CoinWarmStartBasis",
    "library": "CoinUtils",
    "layer": "layer-0",
    "header": "src/CoinWarmStartBasis.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "CoinCliqueExtender": {
    "brief": "Clique extender",
    "file": "CoinCliqueExtender",
    "library": "CoinUtils",
    "layer": "layer-0",
    "header": "src/CoinCliqueExtender.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "CoinPackedVector": {
    "brief": "Sparse vector that owns its index/value storage\n\nCoinPackedVector stores a sparse vector as parallel arrays of indices\nand values. Unlike CoinShallowPackedVector, this class owns its storage\nand supports modification operations.",
    "file": "CoinPackedVector",
    "library": "CoinUtils",
    "layer": "layer-0",
    "header": "src/CoinPackedVector.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "CoinPresolveEmpty": {
    "brief": "Drop and reinsert empty rows/columns\n\nShould be last presolve step. Physical removal of empty entities.",
    "file": "CoinPresolveEmpty",
    "library": "CoinUtils",
    "layer": "layer-0",
    "header": "src/CoinPresolveEmpty.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "CoinAdjacencyVector": {
    "brief": "Vector of growable vectors",
    "file": "CoinAdjacencyVector",
    "library": "CoinUtils",
    "layer": "layer-0",
    "header": "src/CoinAdjacencyVector.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "CoinError": {
    "brief": "Exception class and assertion macros for COIN-OR error handling\n\nProvides CoinError, a rich exception class that captures context about\nwhere and why an error occurred, plus assertion macros that can optionally\nthrow CoinError instead of calling abort().",
    "file": "CoinError",
    "library": "CoinUtils",
    "layer": "layer-0",
    "header": "src/CoinError.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "CoinWarmStartDual": {
    "brief": "Warm start using dual variable values only\n\nStores dual solution vector for warm starting interior point methods\nor dual simplex. Includes diff capability for branch-and-bound.",
    "file": "CoinWarmStartDual",
    "library": "CoinUtils",
    "layer": "layer-0",
    "header": "src/CoinWarmStartDual.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "CoinOddWheelSeparator": {
    "brief": "Odd-wheel cut separator",
    "file": "CoinOddWheelSeparator",
    "library": "CoinUtils",
    "layer": "layer-0",
    "header": "src/CoinOddWheelSeparator.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "CoinStructuredModel": {
    "brief": "Block-structured model composed of CoinModel blocks",
    "file": "CoinStructuredModel",
    "library": "CoinUtils",
    "layer": "layer-0",
    "header": "src/CoinStructuredModel.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "CoinPresolveDupcol": {
    "brief": "Detect and remove duplicate columns and rows",
    "file": "CoinPresolveDupcol",
    "library": "CoinUtils",
    "layer": "layer-0",
    "header": "src/CoinPresolveDupcol.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "mongoose_mex": {
    "brief": "MATLAB MEX interface for Mongoose graph partitioning\nCopyright (C) 2017-2018, Scott P. Kolodziej, Nuri S. Yeralan,\nTimothy A. Davis, William W. Hager. GPL-3.0-only license.\n\nMATLAB interface utilities: conversion between MATLAB sparse matrices\nand Mongoose cs/Graph structures, option struct marshalling, result\nconversion to MATLAB arrays. Enables 'mongoose' MEX function for\ngraph partitioning from MATLAB.",
    "file": "mongoose_mex",
    "library": "SuiteSparse",
    "layer": "layer-0",
    "header": "Mongoose/MATLAB/mongoose_mex.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "Mongoose_QPNapUp": {
    "brief": "Upward lambda search in napsack solver\nCopyright (C) 2017-2023, Scott P. Kolodziej, Nuri S. Yeralan,\nTimothy A. Davis, William W. Hager. GPL-3.0-only license.\n\nQPNapUp searches for lambda in increasing direction when current\nsolution violates upper balance bound (b > hi). Processes breakpoints\nvia heaps until constraint is satisfied, returning optimal lambda.",
    "file": "Mongoose_QPNapUp",
    "library": "SuiteSparse",
    "layer": "layer-0",
    "header": "Mongoose/Include/Mongoose_QPNapUp.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "Mongoose_Refinement": {
    "brief": "Partition projection during uncoarsening phase\nCopyright (C) 2017-2023, Scott P. Kolodziej, Nuri S. Yeralan,\nTimothy A. Davis, William W. Hager. GPL-3.0-only license.\n\nRefinement projects partition from coarse to fine graph during\nuncoarsening. Maps coarse partition to fine vertices via inverse\nmatchmap, then applies FM/QP improvement (waterdance) at each level\nfor high-quality final partition.",
    "file": "Mongoose_Refinement",
    "library": "SuiteSparse",
    "layer": "layer-0",
    "header": "Mongoose/Include/Mongoose_Refinement.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "Mongoose_QPGradProj": {
    "brief": "Projected gradient descent for QP partition optimization\nCopyright (C) 2017-2023, Scott P. Kolodziej, Nuri S. Yeralan,\nTimothy A. Davis, William W. Hager. GPL-3.0-only license.\n\nQPGradProj implements gradient projection for bound-constrained QP:\nminimizes quadratic cut objective subject to box constraints [0,1]\nand balance constraint (lo <= a'x <= hi). Projects gradient onto\nfeasible region, iterates until convergence or iteration limit.",
    "file": "Mongoose_QPGradProj",
    "library": "SuiteSparse",
    "layer": "layer-0",
    "header": "Mongoose/Include/Mongoose_QPGradProj.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "Mongoose_QPMaxHeap": {
    "brief": "Max-heap for QP napsack breakpoint processing\nCopyright (C) 2017-2023, Scott P. Kolodziej, Nuri S. Yeralan,\nTimothy A. Davis, William W. Hager. GPL-3.0-only license.\n\nQPMaxHeap provides max-heap operations (build, delete, add, heapify)\nfor efficient breakpoint processing in napsack solver. Extracts\nbreakpoints in descending order, complementing min-heap for\nbidirectional lambda search.",
    "file": "Mongoose_QPMaxHeap",
    "library": "SuiteSparse",
    "layer": "layer-0",
    "header": "Mongoose/Include/Mongoose_QPMaxHeap.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "Mongoose_ImproveQP": {
    "brief": "Quadratic programming partition improvement via continuous relaxation\nCopyright (C) 2017-2023, Scott P. Kolodziej, Nuri S. Yeralan,\nTimothy A. Davis, William W. Hager. GPL-3.0-only license.\n\nQP improvement relaxes discrete partition to continuous [0,1] variables,\noptimizes via gradient projection with balance constraints, then rounds\nto discrete partition. Complements FM by exploring continuous solution\nspace; combined in waterdance for best results.",
    "file": "Mongoose_ImproveQP",
    "library": "SuiteSparse",
    "layer": "layer-0",
    "header": "Mongoose/Include/Mongoose_ImproveQP.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "Mongoose_ImproveFM": {
    "brief": "Fiduccia-Mattheyses partition refinement algorithm\nCopyright (C) 2017-2023, Scott P. Kolodziej, Nuri S. Yeralan,\nTimothy A. Davis, William W. Hager. GPL-3.0-only license.\n\nFM algorithm improves partitions via gain-based vertex swapping.\nSwapCandidate tracks vertex, partition side, weight, gain, and heap\nposition. Algorithm maintains boundary heaps, selects highest-gain\nboundary vertex, swaps, and updates neighbor gains. Allows non-positive\nmoves within search_depth to escape local minima.",
    "file": "Mongoose_ImproveFM",
    "library": "SuiteSparse",
    "layer": "layer-0",
    "header": "Mongoose/Include/Mongoose_ImproveFM.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "Mongoose_Internal": {
    "brief": "Internal type definitions and enumerations for Mongoose\nCopyright (C) 2017-2023, Scott P. Kolodziej, Nuri S. Yeralan,\nTimothy A. Davis, William W. Hager. GPL-3.0-only license.\n\nDefines Int type (int64_t), matching strategies (Random, HEM, HEMSR,\nHEMSRdeg), initial cut types (QP, Random, NaturalOrder), and match\ntypes (Orphan, Standard, Brotherly, Community) used throughout Mongoose.",
    "file": "Mongoose_Internal",
    "library": "SuiteSparse",
    "layer": "layer-0",
    "header": "Mongoose/Include/Mongoose_Internal.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "Mongoose_QPMinHeap": {
    "brief": "Min-heap for QP napsack breakpoint processing\nCopyright (C) 2017-2023, Scott P. Kolodziej, Nuri S. Yeralan,\nTimothy A. Davis, William W. Hager. GPL-3.0-only license.\n\nQPMinHeap provides min-heap operations (build, delete, add, heapify)\nfor efficient breakpoint processing in napsack solver. Extracts\nbreakpoints in ascending order to find optimal lambda for balance\nconstraint satisfaction.",
    "file": "Mongoose_QPMinHeap",
    "library": "SuiteSparse",
    "layer": "layer-0",
    "header": "Mongoose/Include/Mongoose_QPMinHeap.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "Mongoose_QPLinks": {
    "brief": "QP free set rounding and partition conversion\nCopyright (C) 2017-2023, Scott P. Kolodziej, Nuri S. Yeralan,\nTimothy A. Davis, William W. Hager. GPL-3.0-only license.\n\nQPLinks converts continuous QP solution to discrete partition by\nrounding fractional variables and updating free set. Handles the\ninterface between continuous relaxation and discrete partition\nrepresentation in the waterdance refinement cycle.",
    "file": "Mongoose_QPLinks",
    "library": "SuiteSparse",
    "layer": "layer-0",
    "header": "Mongoose/Include/Mongoose_QPLinks.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "Mongoose_Sanitize": {
    "brief": "Matrix preprocessing for graph partitioning\nCopyright (C) 2017-2023, Scott P. Kolodziej, Nuri S. Yeralan,\nTimothy A. Davis, William W. Hager. GPL-3.0-only license.\n\nMatrix sanitization prepares input for partitioning: sanitizeMatrix\nhandles symmetry and binary weights, removeDiagonal strips self-loops,\nmirrorTriangular expands triangular to symmetric. Ensures valid\nundirected graph representation for algorithms.",
    "file": "Mongoose_Sanitize",
    "library": "SuiteSparse",
    "layer": "layer-0",
    "header": "Mongoose/Include/Mongoose_Sanitize.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "Mongoose_EdgeCut": {
    "brief": "Edge cut result structure and partitioning entry points\nCopyright (C) 2017-2023, Scott P. Kolodziej, Nuri S. Yeralan,\nTimothy A. Davis, William W. Hager. GPL-3.0-only license.\n\nEdgeCut struct holds partitioning results: boolean partition array,\ncut_cost (edge weight sum), cut_size (edge count), partition weights\n(w0, w1), and imbalance metric. edge_cut() functions are main entry\npoints for computing graph partitions.",
    "file": "Mongoose_EdgeCut",
    "library": "SuiteSparse",
    "layer": "layer-0",
    "header": "Mongoose/Include/Mongoose_EdgeCut.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "Mongoose_QPBoundary": {
    "brief": "QP boundary initialization from graph partition\nCopyright (C) 2017-2023, Scott P. Kolodziej, Nuri S. Yeralan,\nTimothy A. Davis, William W. Hager. GPL-3.0-only license.\n\nQPBoundary initializes QP state from discrete partition, setting\nx values based on partition assignment and identifying boundary\nvertices (those with neighbors in opposite partition) as the\nactive set for optimization.",
    "file": "Mongoose_QPBoundary",
    "library": "SuiteSparse",
    "layer": "layer-0",
    "header": "Mongoose/Include/Mongoose_QPBoundary.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "Mongoose": {
    "brief": "Main public API for Mongoose graph partitioning library\nCopyright (C) 2017-2018, Scott P. Kolodziej, Nuri S. Yeralan,\nTimothy A. Davis, William W. Hager. GPL-3.0-only license.\n\nMongoose: High-quality graph partitioning via multilevel coarsening\nwith Fiduccia-Mattheyses and quadratic programming refinement.\nPublic interface includes Graph, EdgeCut, EdgeCut_Options classes\nand read_graph/edge_cut functions for partitioning workflows.",
    "file": "Mongoose",
    "library": "SuiteSparse",
    "layer": "layer-0",
    "header": "Mongoose/Include/Mongoose.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "Mongoose_Logger": {
    "brief": "Debug logging and performance timing utilities\nCopyright (C) 2017-2023, Scott P. Kolodziej, Nuri S. Yeralan,\nTimothy A. Davis, William W. Hager. GPL-3.0-only license.\n\nLogger class provides runtime debug level control and tic/toc timing\nfor algorithm phases: Matching, Coarsening, Refinement, FM, QP, IO.\nLogError/Warn/Info/Test macros for conditional output. Timing tracks\ncumulative time per phase for profiling.",
    "file": "Mongoose_Logger",
    "library": "SuiteSparse",
    "layer": "layer-0",
    "header": "Mongoose/Include/Mongoose_Logger.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "Mongoose_IO": {
    "brief": "Matrix Market file I/O for graphs and matrices\nCopyright (C) 2017-2023, Scott P. Kolodziej, Nuri S. Yeralan,\nTimothy A. Davis, William W. Hager. GPL-3.0-only license.\n\nFile I/O for Mongoose: read_graph creates Graph from Matrix Market file,\nread_matrix creates cs struct. Handles symmetrization (A+A')/2 for\nasymmetric matrices, extracts largest connected component, removes\ndiagonal. Accepts C string or std::string filenames.",
    "file": "Mongoose_IO",
    "library": "SuiteSparse",
    "layer": "layer-0",
    "header": "Mongoose/Include/Mongoose_IO.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "Mongoose_Graph": {
    "brief": "Graph data structure for Mongoose partitioning\nCopyright (C) 2017-2023, Scott P. Kolodziej, Nuri S. Yeralan,\nTimothy A. Davis, William W. Hager. GPL-3.0-only license.\n\nGraph class stores adjacency in CSC format (p, i arrays) with optional\nedge weights (x) and vertex weights (w). Factory methods create from\nraw arrays or CSparse matrices. Shallow copy flags track ownership.",
    "file": "Mongoose_Graph",
    "library": "SuiteSparse",
    "layer": "layer-0",
    "header": "Mongoose/Include/Mongoose_Graph.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "Mongoose_CSparse": {
    "brief": "Sparse matrix operations subset from CSparse library\nCopyright (C) 2017-2023, Scott P. Kolodziej, Nuri S. Yeralan,\nTimothy A. Davis, William W. Hager. GPL-3.0-only license.\n\nProvides CSparse subset for sparse matrix operations: cs struct\n(compressed column/triplet format), cs_add (matrix addition),\ncs_transpose, cs_compress (triplet to CSC), and allocation.\nUses int64_t (csi) matching Mongoose's Int type.",
    "file": "Mongoose_CSparse",
    "library": "SuiteSparse",
    "layer": "layer-0",
    "header": "Mongoose/Include/Mongoose_CSparse.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "Mongoose_QPDelta": {
    "brief": "QP solver state: solution, gradient, free set, and workspace\nCopyright (C) 2017-2023, Scott P. Kolodziej, Nuri S. Yeralan,\nTimothy A. Davis, William W. Hager. GPL-3.0-only license.\n\nQPDelta stores iterative QP solver state: current solution x, gradient,\nfree set (variables not at bounds), balance constraint bounds (lo/hi),\nLagrange multiplier lambda, and workspace arrays. FreeSet_status tracks\nwhether each x_i is at 0, 1, or strictly between (free).",
    "file": "Mongoose_QPDelta",
    "library": "SuiteSparse",
    "layer": "layer-0",
    "header": "Mongoose/Include/Mongoose_QPDelta.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "Mongoose_Debug": {
    "brief": "Debug macros, assertions, and diagnostic print functions\nCopyright (C) 2017-2023, Scott P. Kolodziej, Nuri S. Yeralan,\nTimothy A. Davis, William W. Hager. GPL-3.0-only license.\n\nDebug infrastructure: ASSERT/DEBUG macros (disabled by NDEBUG),\nPR macro for printf debugging, IMPLIES/IFF logic macros. Print\nfunctions for cs matrices, EdgeCutProblem graphs, and QP state.\nEnable debugging by uncommenting #undef NDEBUG (very slow).",
    "file": "Mongoose_Debug",
    "library": "SuiteSparse",
    "layer": "layer-0",
    "header": "Mongoose/Include/Mongoose_Debug.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "Mongoose_CutCost": {
    "brief": "Partition quality metrics structure\nCopyright (C) 2017-2023, Scott P. Kolodziej, Nuri S. Yeralan,\nTimothy A. Davis, William W. Hager. GPL-3.0-only license.\n\nCutCost struct holds partition quality metrics: heuCost (cut + balance\npenalty), cutCost (edge weight sum), W[2] (partition weights), and\nimbalance (deviation from target split). Used internally to evaluate\nand compare partitions during refinement.",
    "file": "Mongoose_CutCost",
    "library": "SuiteSparse",
    "layer": "layer-0",
    "header": "Mongoose/Include/Mongoose_CutCost.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "Mongoose_GuessCut": {
    "brief": "Initial partition generation at coarsest level\nCopyright (C) 2017-2023, Scott P. Kolodziej, Nuri S. Yeralan,\nTimothy A. Davis, William W. Hager. GPL-3.0-only license.\n\nGuessCut creates initial partition for coarsest graph before refinement\nbegins. Strategies include QP relaxation, random assignment, or natural\nvertex order. Quality of initial guess affects final partition quality\ndespite refinement. Selected via initial_cut_type option.",
    "file": "Mongoose_GuessCut",
    "library": "SuiteSparse",
    "layer": "layer-0",
    "header": "Mongoose/Include/Mongoose_GuessCut.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "Mongoose_BoundaryHeap": {
    "brief": "Boundary vertex heap for FM partition refinement\nCopyright (C) 2017-2023, Scott P. Kolodziej, Nuri S. Yeralan,\nTimothy A. Davis, William W. Hager. GPL-3.0-only license.\n\nManages heaps of boundary vertices (those with edges crossing cut)\nfor FM algorithm. Two heaps (one per partition) ordered by vertex\ngain. Operations: load, clear, insert, remove, heapifyUp/Down.\nCritical for efficient O(n log n) FM refinement.",
    "file": "Mongoose_BoundaryHeap",
    "library": "SuiteSparse",
    "layer": "layer-0",
    "header": "Mongoose/Include/Mongoose_BoundaryHeap.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "Mongoose_EdgeCutOptions": {
    "brief": "Configuration options for edge cut partitioning algorithms\nCopyright (C) 2017-2023, Scott P. Kolodziej, Nuri S. Yeralan,\nTimothy A. Davis, William W. Hager. GPL-3.0-only license.\n\nEdgeCut_Options controls all algorithm parameters: coarsening (limit,\nmatching strategy, community detection), initial cut type (QP/random),\nFiduccia-Mattheyses (search depth, refinement count), QP gradient\nprojection (tolerance, iteration limit), and partition targets\n(split ratio, balance tolerance).",
    "file": "Mongoose_EdgeCutOptions",
    "library": "SuiteSparse",
    "layer": "layer-0",
    "header": "Mongoose/Include/Mongoose_EdgeCutOptions.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "Mongoose_QPNapDown": {
    "brief": "Downward lambda search in napsack solver\nCopyright (C) 2017-2023, Scott P. Kolodziej, Nuri S. Yeralan,\nTimothy A. Davis, William W. Hager. GPL-3.0-only license.\n\nQPNapDown searches for lambda in decreasing direction when current\nsolution violates lower balance bound (b < lo). Processes breakpoints\nvia heaps until constraint is satisfied, returning optimal lambda.",
    "file": "Mongoose_QPNapDown",
    "library": "SuiteSparse",
    "layer": "layer-0",
    "header": "Mongoose/Include/Mongoose_QPNapDown.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "Mongoose_EdgeCutProblem": {
    "brief": "Extended graph with matching and partition state for algorithms\nCopyright (C) 2017-2023, Scott P. Kolodziej, Nuri S. Yeralan,\nTimothy A. Davis, William W. Hager. GPL-3.0-only license.\n\nEdgeCutProblem extends Graph with algorithm state: partition array,\nvertex gains, external degrees, boundary heaps, cut metrics. Also\nstores matching data (matchmap, invmatchmap, matchtype) for multilevel\nhierarchy. Provides inline helpers for boundary heap and mark array.",
    "file": "Mongoose_EdgeCutProblem",
    "library": "SuiteSparse",
    "layer": "layer-0",
    "header": "Mongoose/Include/Mongoose_EdgeCutProblem.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "Mongoose_Waterdance": {
    "brief": "Alternating FM/QP refinement passes for partition improvement\nCopyright (C) 2017-2023, Scott P. Kolodziej, Nuri S. Yeralan,\nTimothy A. Davis, William W. Hager. GPL-3.0-only license.\n\nWaterdance alternates between FM (discrete swaps) and QP (continuous\noptimization) refinement passes. The interplay (\"dance\") between methods\nescapes local minima that either method alone would get stuck in.\nNumber of dances controlled by num_dances option.",
    "file": "Mongoose_Waterdance",
    "library": "SuiteSparse",
    "layer": "layer-0",
    "header": "Mongoose/Include/Mongoose_Waterdance.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "Mongoose_Coarsening": {
    "brief": "Graph coarsening via vertex matching for multilevel partitioning\nCopyright (C) 2017-2023, Scott P. Kolodziej, Nuri S. Yeralan,\nTimothy A. Davis, William W. Hager. GPL-3.0-only license.\n\nCoarsening reduces graph size while preserving structure by contracting\nmatched vertices. Given a matching (HEM, random, etc.), creates coarser\ngraph with merged vertices and aggregated edge weights. Essential for\nmultilevel partitioning to handle large graphs efficiently.",
    "file": "Mongoose_Coarsening",
    "library": "SuiteSparse",
    "layer": "layer-0",
    "header": "Mongoose/Include/Mongoose_Coarsening.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "Mongoose_Matching": {
    "brief": "Vertex matching algorithms for graph coarsening\nCopyright (C) 2017-2023, Scott P. Kolodziej, Nuri S. Yeralan,\nTimothy A. Davis, William W. Hager. GPL-3.0-only license.\n\nImplements matching strategies: Random (random neighbor), HEM (heavy\nedge matching), SR/SRdeg (sorted/degree-sorted heavy edge). Matching\npairs vertices for coarsening; heavier edges are preferred to preserve\ngraph structure. Cleanup handles unmatched (orphan) vertices.",
    "file": "Mongoose_Matching",
    "library": "SuiteSparse",
    "layer": "layer-0",
    "header": "Mongoose/Include/Mongoose_Matching.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "Mongoose_Random": {
    "brief": "Random number generation for Mongoose algorithms\nCopyright (C) 2017-2023, Scott P. Kolodziej, Nuri S. Yeralan,\nTimothy A. Davis, William W. Hager. GPL-3.0-only license.\n\nSimple random number interface: random() returns Int, setRandomSeed()\ninitializes generator. Used by random matching, random initial cuts,\nand tie-breaking in algorithms. Seed set via EdgeCut_Options::random_seed.",
    "file": "Mongoose_Random",
    "library": "SuiteSparse",
    "layer": "layer-0",
    "header": "Mongoose/Include/Mongoose_Random.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "Mongoose_QPNapsack": {
    "brief": "Napsack subproblem solver for QP balance constraint\nCopyright (C) 2017-2023, Scott P. Kolodziej, Nuri S. Yeralan,\nTimothy A. Davis, William W. Hager. GPL-3.0-only license.\n\nQPNapsack solves the napsack subproblem: find lambda such that the\nprojected solution satisfies balance constraint lo <= a'x <= hi.\nUses breakpoint method with heaps to efficiently find optimal lambda.\nCore subroutine in QP gradient projection.",
    "file": "Mongoose_QPNapsack",
    "library": "SuiteSparse",
    "layer": "layer-0",
    "header": "Mongoose/Include/Mongoose_QPNapsack.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "SuiteSparseQR": {
    "brief": "User C++ API for sparse multifrontal QR factorization\nCopyright (c) 2008-2023, Timothy A Davis. GPL-2.0+ license.\n\nMain user interface for SPQR: SuiteSparseQR overloads for [Q,R,E]=qr(A),\nX=A\\B, qmult. Structures: spqr_symbolic (pattern analysis), spqr_numeric\n(R values, Householder H), spqr_gpu (GPU staging). Expert functions:\nSuiteSparseQR_factorize, _solve, _min2norm, _symbolic, _numeric for\nfactorization reuse. Supports real/complex, int32/int64.",
    "file": "SuiteSparseQR",
    "library": "SuiteSparse",
    "layer": "layer-0",
    "header": "SPQR/Include/SuiteSparseQR.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "spqr": {
    "brief": "Internal SPQR implementation functions and data structures\nCopyright (c) 2008-2023, Timothy A Davis. GPL-2.0+ license.\n\nNon-user-callable routines: spqr_analyze (symbolic), spqr_factorize (numeric),\nspqr_kernel (parallel front factorization), spqr_assemble/cpack/rhpack (front\nassembly). Support: spqr_tol, stranspose1/2, larftb (block reflectors),\nhapply, panel, 1colamd, 1fixed. Helper structs: spqr_work, spqr_blob.\nMacros: FLIP/UNFLIP for marking, INDEX for column-major.",
    "file": "spqr",
    "library": "SuiteSparse",
    "layer": "layer-0",
    "header": "SPQR/Include/spqr.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "spqr_cholmod_wrappers": {
    "brief": "Template wrappers for CHOLMOD functions with int32/int64 support\nCopyright (c) 2008-2023, Timothy A Davis. GPL-2.0+ license.\n\nTemplate wrappers enabling SPQR to use CHOLMOD with either int32_t or int64_t\nindices. Functions: spqr_start/finish (init), memory (malloc/calloc/free/realloc),\nsparse matrix ops (allocate_sparse, free_sparse, transpose, copy), dense\n(allocate_dense, zeros, ones), ordering (amd, metis, colamd, postorder),\nutility (norm_sparse/dense, sdmult, ssmult, ssadd). Each has explicit\ntemplate specializations for int32_t and int64_t.",
    "file": "spqr_cholmod_wrappers",
    "library": "SuiteSparse",
    "layer": "layer-0",
    "header": "SPQR/Include/spqr_cholmod_wrappers.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "spqrgpu": {
    "brief": "GPU kernel interfaces for SPQR sparse QR factorization\nCopyright (c) 2008-2023, Timothy A Davis. GPL-2.0+ license.\n\nGPU acceleration entry points: spqrgpu_kernel (processes spqr_blob on GPU),\nspqrgpu_computeFrontStaging (plans front staging by GPU memory capacity),\nspqrgpu_buildAssemblyMaps (constructs Rimap/Rjmap for contribution assembly).\nTemplates for double/Complex Entry types. Requires GPUQREngine_SuiteSparse.hpp.",
    "file": "spqrgpu",
    "library": "SuiteSparse",
    "layer": "layer-0",
    "header": "SPQR/Include/spqrgpu.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "GPUQREngine_SEntry": {
    "brief": "Sparse entry tuple for GPU front assembly\nCopyright (c) 2013, Timothy A Davis, Sencer Nuri Yeralan,\nand Sanjay Ranka. GPL-2.0+ license.\n\nSEntry struct: (findex, value) tuple for placing sparse matrix values\ninto dense frontal matrices. findex is linear index into front, value\nis numeric entry. Used in S assembly phase (ASSEMBLE_S state) to transfer\ninput matrix to GPU fronts via cpuS/gpuS arrays in SparseMeta.",
    "file": "GPUQREngine_SEntry",
    "library": "SuiteSparse",
    "layer": "layer-0",
    "header": "SPQR/GPUQREngine/Include/GPUQREngine_SEntry.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "GPUQREngine_Stats": {
    "brief": "Performance statistics for GPU QR factorization\nCopyright (c) 2013, Timothy A Davis, Sencer Nuri Yeralan,\nand Sanjay Ranka. GPL-2.0+ license.\n\nQREngineStats template struct: kernelTime (total GPU kernel time across\nlaunches), numLaunches (kernel invocation count), flopsActual (total\nfloating-point operations). Optional output parameter for GPUQREngine_Internal.",
    "file": "GPUQREngine_Stats",
    "library": "SuiteSparse",
    "layer": "layer-0",
    "header": "SPQR/GPUQREngine/Include/GPUQREngine_Stats.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "GPUQREngine_BucketList": {
    "brief": "Tile bucket management and GPU task generation\nCopyright (c) 2013, Timothy A Davis, Sencer Nuri Yeralan,\nand Sanjay Ranka. GPL-2.0+ license.\n\nBucketList manages LLBundles in doubly-linked lists organized by column\nbucket. Tracks idle tiles (head/next/prev), generates Factorize/Apply\ntasks. Wavefront advances through buckets. VT block allocation via\nwsMongoVT workspace. Methods: Initialize, AdvanceBundles, CreateBundles,\nFillWorkQueue. Supports staircase exploitation for sparse factorization.",
    "file": "GPUQREngine_BucketList",
    "library": "SuiteSparse",
    "layer": "layer-0",
    "header": "SPQR/GPUQREngine/Include/GPUQREngine_BucketList.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "GPUQREngine_Front": {
    "brief": "Frontal matrix class for GPU QR factorization\nCopyright (c) 2013, Timothy A Davis, Sencer Nuri Yeralan,\nand Sanjay Ranka. GPL-2.0+ license.\n\nFront class encapsulates frontal matrix metadata: dimensions (fm\u00d7fn),\nCPU/GPU pointers (F, gpuF, cpuR), factorization state, staircase for\nexploiting block zeros. SparseMeta member extends for multifrontal\nsparse factorization. State machine tracks: ALLOCATE_WAIT \u2192 FACTORIZE \u2192 DONE.",
    "file": "GPUQREngine_Front",
    "library": "SuiteSparse",
    "layer": "layer-0",
    "header": "SPQR/GPUQREngine/Include/GPUQREngine_Front.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "GPUQREngine_GraphVizHelper": {
    "brief": "Debug visualization for bucket list state\nCopyright (c) 2013, Timothy A Davis, Sencer Nuri Yeralan,\nand Sanjay Ranka. GPL-2.0+ license.\n\nGPUQREngine_RenderBuckets function generates GraphViz output for\nBucketList visualization. Only compiled when GPUQRENGINE_RENDER defined.\nUsed for debugging factorization scheduling and tile progression.",
    "file": "GPUQREngine_GraphVizHelper",
    "library": "SuiteSparse",
    "layer": "layer-0",
    "header": "SPQR/GPUQREngine/Include/GPUQREngine_GraphVizHelper.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "GPUQREngine": {
    "brief": "Version information for GPUQREngine CUDA library\nCopyright (c) 2013, Timothy A Davis, Sencer Nuri Yeralan,\nand Sanjay Ranka. GPL-2.0+ license.\n\nVersion macros for GPUQREngine GPU-accelerated QR factorization.\nCurrent version 4.3.4 (June 2024). Part of SuiteSparse SPQR.",
    "file": "GPUQREngine",
    "library": "SuiteSparse",
    "layer": "layer-0",
    "header": "SPQR/GPUQREngine/Include/GPUQREngine.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "GPUQREngine_LLBundle": {
    "brief": "Bundle of row tiles for GPU factorization tasks\nCopyright (c) 2013, Timothy A Davis, Sencer Nuri Yeralan,\nand Sanjay Ranka. GPL-2.0+ license.\n\nLLBundle groups row tiles for Factorize/Apply tasks. Tracks: First (smallest\nrowtile, made triangular), Shadow (memento of factorized First), Last,\nDelta (pipelining), Max. VT[2] pointers for Householder vectors. Methods:\nAddTileToSlots, Advance, gpuPack. CurrentTask indicates GenericFactorize/Apply.\nManaged by BucketList in doubly-linked structure.",
    "file": "GPUQREngine_LLBundle",
    "library": "SuiteSparse",
    "layer": "layer-0",
    "header": "SPQR/GPUQREngine/Include/GPUQREngine_LLBundle.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "GPUQREngine_TaskDescriptor": {
    "brief": "GPU task types and metadata for QR kernel dispatch\nCopyright (c) 2013, Timothy A Davis, Sencer Nuri Yeralan,\nand Sanjay Ranka. GPL-2.0+ license.\n\nTaskType enum: Factorize variants (3x1, 2x1, 1x1, edge cases), Apply\nvariants (Apply3/2/1), Assembly (SAssembly, PackAssembly). TaskDescriptor\nstruct contains F pointer, AuxAddress[4] (VT blocks, maps), dimensions,\nextra[10] (tile indices, ranges). Used by UberKernel for dispatch.\ngetFlops/getWeightedFlops for work queue balancing.",
    "file": "GPUQREngine_TaskDescriptor",
    "library": "SuiteSparse",
    "layer": "layer-0",
    "header": "SPQR/GPUQREngine/Include/GPUQREngine_TaskDescriptor.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "GPUQREngine_Common": {
    "brief": "GPU thread geometry, tile constants, and common macros\nCopyright (c) 2013, Timothy A Davis, Sencer Nuri Yeralan,\nand Sanjay Ranka. GPL-2.0+ license.\n\nCore constants: TILESIZE=32 (tile dimension), PANELSIZE=3 (tiles per\npanel), NUMTHREADS=384 (threads per kernel), PADDING=1 (bank conflicts).\nCommon macros: CEIL, MIN, MAX, EMPTY sentinel. Optional GPUQRENGINE_RENDER\nfor GraphViz visualization, experimental GPUQRENGINE_PIPELINING.",
    "file": "GPUQREngine_Common",
    "library": "SuiteSparse",
    "layer": "layer-0",
    "header": "SPQR/GPUQREngine/Include/GPUQREngine_Common.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "GPUQREngine_FrontState": {
    "brief": "Finite state machine for front factorization lifecycle\nCopyright (c) 2013, Timothy A Davis, Sencer Nuri Yeralan,\nand Sanjay Ranka. GPL-2.0+ license.\n\nFrontState enum defines 9-state FSM: ALLOCATE_WAIT (0) \u2192 ASSEMBLE_S (1) \u2192\nCHILD_WAIT (2) \u2192 FACTORIZE (3) \u2192 FACTORIZE_COMPLETE (4) \u2192 PARENT_WAIT (5) \u2192\nPUSH_ASSEMBLE (6) \u2192 CLEANUP (7) \u2192 DONE (8). Transitions driven by\nFillWorkQueue and PostProcessing. Scheduler uses states to coordinate work.",
    "file": "GPUQREngine_FrontState",
    "library": "SuiteSparse",
    "layer": "layer-0",
    "header": "SPQR/GPUQREngine/Include/GPUQREngine_FrontState.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "GPUQREngine_Scheduler": {
    "brief": "Central coordinator for GPU QR factorization tasks\nCopyright (c) 2013, Timothy A Davis, Sencer Nuri Yeralan,\nand Sanjay Ranka. GPL-2.0+ license.\n\nScheduler manages fronts and GPU resources: frontList with numFronts,\nbucketLists for task generation, workQueues (double-buffered), CUDA\nstreams (kernelStreams[2], memoryStreamH2D/D2H). Main loop: fillWorkQueue \u2192\nlaunchKernel \u2192 postProcess. Tracks completion via FrontDataPulled events.",
    "file": "GPUQREngine_Scheduler",
    "library": "SuiteSparse",
    "layer": "layer-0",
    "header": "SPQR/GPUQREngine/Include/GPUQREngine_Scheduler.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "GPUQREngine_SparseMeta": {
    "brief": "Sparse multifrontal factorization metadata\nCopyright (c) 2013, Timothy A Davis, Sencer Nuri Yeralan,\nand Sanjay Ranka. GPL-2.0+ license.\n\nSparseMeta extends Front for sparse factorization: fp (pivotal columns),\nnc (remaining children), isStaged/pushOnly flags for staging. S assembly\nmetadata (cpuS/gpuS SEntry arrays, Scount). Pack assembly: contribution\nblock dimensions (cm\u00d7cn), parent info (pn, gpuP), row/col maps (gpuRimap/gpuRjmap).",
    "file": "GPUQREngine_SparseMeta",
    "library": "SuiteSparse",
    "layer": "layer-0",
    "header": "SPQR/GPUQREngine/Include/GPUQREngine_SparseMeta.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "GPUQREngine_SuiteSparse": {
    "brief": "Public SuiteSparse API for GPU QR factorization\nCopyright (c) 2013, Timothy A Davis, Sencer Nuri Yeralan,\nand Sanjay Ranka. GPL-2.0+ license.\n\nMain entry point for SPQR GPU support. QREngineResultCode enum: SUCCESS,\nOUTOFMEMORY, GPUERROR. GPUQREngine template functions: dense (fronts only)\nand sparse (with Parent/Childp/Child tree). GPUQREngine_FindStaircase\ncomputes staircase for block zero exploitation.",
    "file": "GPUQREngine_SuiteSparse",
    "library": "SuiteSparse",
    "layer": "layer-0",
    "header": "SPQR/GPUQREngine/Include/GPUQREngine_SuiteSparse.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "GPUQREngine_Timing": {
    "brief": "CUDA event-based timing macros for kernel profiling\nCopyright (c) 2013, Timothy A Davis, Sencer Nuri Yeralan,\nand Sanjay Ranka. GPL-2.0+ license.\n\nTiming macros enabled by TIMING define: TIMER_INIT (create cudaEvents),\nTIMER_START (record start), TIMER_STOP (synchronize and get elapsed),\nTIMER_FINISH (destroy events). Compiles to no-ops when TIMING undefined.\nUsed for kernel performance measurement and optimization.",
    "file": "GPUQREngine_Timing",
    "library": "SuiteSparse",
    "layer": "layer-0",
    "header": "SPQR/GPUQREngine/Include/GPUQREngine_Timing.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "GPUQREngine_Internal": {
    "brief": "Internal API and UberKernel declaration\nCopyright (c) 2013, Timothy A Davis, Sencer Nuri Yeralan,\nand Sanjay Ranka. GPL-2.0+ license.\n\nInternal includes (Common, TaskDescriptor, Front, Stats, SuiteSparse).\nGPUQREngine_UberKernel: launches GPU kernel on stream with work queue.\nGPUQREngine_Internal: main factorization entry with Parent/Child arrays\nfor multifrontal tree traversal. Returns QREngineResultCode.",
    "file": "GPUQREngine_Internal",
    "library": "SuiteSparse",
    "layer": "layer-0",
    "header": "SPQR/GPUQREngine/Include/GPUQREngine_Internal.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "sharedMemory": {
    "brief": "GPU shared memory layout for QR kernel operations\nCopyright (c) 2013, Timothy A Davis, Sencer Nuri Yeralan,\nand Sanjay Ranka. GPL-2.0+ license.\n\nSharedMemory union overlays three kernel types: factorize (A, T, Z tiles\nfor Householder), apply (V, C matrices for block update), packassemble\n(Rimap/Rjmap for contribution assembly). Global __shared__ shMemory,\nmyTask (current task), IsApplyFactorize flag. Sized for PANELSIZE\u00d7TILESIZE.",
    "file": "sharedMemory",
    "library": "SuiteSparse",
    "layer": "layer-0",
    "header": "SPQR/GPUQREngine/Include/Kernel/sharedMemory.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "params_apply": {
    "brief": "Apply kernel parameters, macros, and function declarations\nCopyright (c) 2013, Timothy A Davis, Sencer Nuri Yeralan,\nand Sanjay Ranka. GPL-2.0+ license.\n\nConstants: MAX_ROW_TILES=3, MAX_COL_TILES=2. Shared memory accessors:\nshV, shC, SHV(t,i,j), SHA(i,j), ST(i,j). Global memory: GLVT, GLF,\nIFRONT. Thread indexing: iv, jv, VCHUNKSIZE, NVCHUNKS. Device functions:\nblock_apply_3/2/1, block_apply_3_by_1/2_by_1/1_by_1 variants.",
    "file": "params_apply",
    "library": "SuiteSparse",
    "layer": "layer-0",
    "header": "SPQR/GPUQREngine/Include/Kernel/Apply/params_apply.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "SuiteSparse_GPURuntime": {
    "brief": "Version information for SuiteSparse GPU runtime library\nCopyright (c) 2013-2016, Timothy A Davis, Sencer Nuri Yeralan,\nand Sanjay Ranka. GPL-2.0+ license.\n\nVersion macros for SuiteSparse_GPURuntime shared GPU infrastructure.\nCurrent version 4.3.4 (June 2024). Provides common GPU utilities used\nby GPUQREngine and other SuiteSparse GPU components.",
    "file": "SuiteSparse_GPURuntime",
    "library": "SuiteSparse",
    "layer": "layer-0",
    "header": "SPQR/GPURuntime/Include/SuiteSparse_GPURuntime.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "SuiteSparseGPU_workspace_macros": {
    "brief": "Convenience macros for accessing Workspace CPU/GPU pointers\nCopyright (c) 2013-2016, Timothy A Davis, Sencer Nuri Yeralan,\nand Sanjay Ranka. GPL-2.0+ license.\n\nGPU_REFERENCE(ws, TYPE): safely get GPU pointer from Workspace with NULL check.\nCPU_REFERENCE(ws, TYPE): safely get CPU pointer from Workspace with NULL check.\nBoth cast to TYPE and handle NULL workspace gracefully.",
    "file": "SuiteSparseGPU_workspace_macros",
    "library": "SuiteSparse",
    "layer": "layer-0",
    "header": "SPQR/GPURuntime/Include/SuiteSparseGPU_workspace_macros.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "SuiteSparseGPU_Workspace": {
    "brief": "Unified CPU/GPU memory workspace management class\nCopyright (c) 2013-2016, Timothy A Davis, Sencer Nuri Yeralan,\nand Sanjay Ranka. GPL-2.0+ license.\n\nWorkspace class manages paired CPU/GPU memory allocations: nitems \u00d7 size_of_item\nbytes on both devices. Static methods: cpu_malloc/calloc/free, gpu_malloc/calloc/free.\nInstance methods: allocate (with cpu/gpu/pageLocked flags), destroy, transfer\n(cudaMemcpyKind with sync option). Accessors: cpu(), gpu(), getCount(), getStride().",
    "file": "SuiteSparseGPU_Workspace",
    "library": "SuiteSparse",
    "layer": "layer-0",
    "header": "SPQR/GPURuntime/Include/SuiteSparseGPU_Workspace.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "SuiteSparseGPU_internal": {
    "brief": "Internal includes for SuiteSparse GPU runtime\nCopyright (c) 2013-2016, Timothy A Davis, Sencer Nuri Yeralan,\nand Sanjay Ranka. GPL-2.0+ license.\n\nConditionally includes CUDA runtime when SPQR_HAS_CUDA defined. Forward\ndeclares Workspace class. Includes SuiteSparse_config.h, macros, and\nWorkspace header. Also includes version header unconditionally.",
    "file": "SuiteSparseGPU_internal",
    "library": "SuiteSparse",
    "layer": "layer-0",
    "header": "SPQR/GPURuntime/Include/SuiteSparseGPU_internal.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "SuiteSparseGPU_macros": {
    "brief": "Common macros for SuiteSparse GPU components\nCopyright (c) 2013-2016, Timothy A Davis, Sencer Nuri Yeralan,\nand Sanjay Ranka. GPL-2.0+ license.\n\nIMPLIES(p,q) logical implication macro: true unless p is true and q is false.\nIncludes debug level macros and workspace accessor macros. Used throughout\nGPURuntime and GPUQREngine.",
    "file": "SuiteSparseGPU_macros",
    "library": "SuiteSparse",
    "layer": "layer-0",
    "header": "SPQR/GPURuntime/Include/SuiteSparseGPU_macros.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "SuiteSparseGPU_debug": {
    "brief": "Debug verbosity levels for SuiteSparse GPU runtime\nCopyright (c) 2013-2016, Timothy A Davis, Sencer Nuri Yeralan,\nand Sanjay Ranka. GPL-2.0+ license.\n\nDebug levels: OFF (0), ERRORONLY (1), CASUAL (2), VERBOSE (3), EXTREME (4).\nGPURUNTIME_DLEVEL set based on NDEBUG: CASUAL when debugging, OFF otherwise.\nConvenience macros: DEBUG_ATLEAST_ERRORONLY/CASUAL/VERBOSE/EXTREME.\nGPURUNTIME_LOGFILE_PATH defaults to \"SuiteSparse_GPURuntime-logfile.txt\".",
    "file": "SuiteSparseGPU_debug",
    "library": "SuiteSparse",
    "layer": "layer-0",
    "header": "SPQR/GPURuntime/Include/SuiteSparseGPU_debug.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "paru_cov": {
    "brief": "Test coverage utilities for ParU sparse LU\nCopyright (c) 2022-2025, Mohsen Aznaveh and Timothy A. Davis.\nGPL-3.0-or-later license.\n\nTesting infrastructure: TEST_PASSES (success exit), TEST_ASSERT/TEST_ASSERT_INFO\n(abort on failure). paru_backward for residual computation. BRUTAL_ALLOC_TEST\nmacro: iteratively runs method with increasing malloc failure counts to test\nall allocation paths. Enabled by PARU_ALLOC_TESTING define.",
    "file": "paru_cov",
    "library": "SuiteSparse",
    "layer": "layer-0",
    "header": "ParU/Tcov/paru_cov.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "paru_omp": {
    "brief": "OpenMP abstraction layer for ParU parallel LU\nCopyright (c) 2022-2025, Mohsen Aznaveh and Timothy A. Davis.\nGPL-3.0-or-later license.\n\nPortable OpenMP wrappers: PARU_omp_get_wtime, get_max_threads, get_num_threads,\nset_num_threads, get/set_dynamic, get_active_level, get_max_active_levels,\nget_thread_num. When _OPENMP undefined, provides stub implementations returning\nsequential defaults (1 thread, 0 wtime). Defines PARU_1TASK when no OpenMP.",
    "file": "paru_omp",
    "library": "SuiteSparse",
    "layer": "layer-0",
    "header": "ParU/Source/paru_omp.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "paru_internal": {
    "brief": "Internal data structures and functions for ParU sparse LU\nCopyright (c) 2022-2025, Mohsen Aznaveh and Timothy A. Davis.\nGPL-3.0-or-later license.\n\nCore ParU structures: ParU_Symbolic_struct (row-form S, singletons, fronts,\ntask tree), ParU_Numeric_struct (LU factors, permutations, scaling),\nParU_Control_struct (tolerances, threading). paru_element (contribution\nblock), paru_work (workspace), paru_tuple (element lists). Internal\nfunctions: front assembly/factorization, heap management, BLAS threading.\nIncludes UMFPACK SymbolicType/SWType for singleton detection.",
    "file": "paru_internal",
    "library": "SuiteSparse",
    "layer": "layer-0",
    "header": "ParU/Source/paru_internal.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "GB_cuda_apply": {
    "brief": "CUDA JIT kernel launchers for GraphBLAS apply operations\nSPDX-License-Identifier: Apache-2.0\n\nGPU apply operations: GB_cuda_apply_unop_jit (unary operator with optional\nflipij), GB_cuda_apply_bind1st_jit (binary op with scalar bound to first),\nGB_cuda_apply_bind2nd_jit (scalar bound to second). All take stream, grid\nand block size parameters for kernel launch.",
    "file": "GB_cuda_apply",
    "library": "SuiteSparse",
    "layer": "layer-0",
    "header": "GraphBLAS/CUDA/GB_cuda_apply.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "GB_cuda_ewise": {
    "brief": "CUDA JIT kernel launchers for GraphBLAS element-wise operations\nSPDX-License-Identifier: Apache-2.0\n\nGPU element-wise scaling: GB_cuda_rowscale_jit (C = D.*B row scaling),\nGB_cuda_colscale_jit (C = A.*D column scaling). Both support flipxy for\noperand order and take stream/grid/block parameters.",
    "file": "GB_cuda_ewise",
    "library": "SuiteSparse",
    "layer": "layer-0",
    "header": "GraphBLAS/CUDA/GB_cuda_ewise.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "GB_cuda_AxB": {
    "brief": "CUDA JIT kernel launcher for GraphBLAS matrix multiplication\nCopyright (c) 2017-2025, Timothy A. Davis. Apache-2.0 license.\n\nGB_cuda_AxB_dot3_jit: GPU sparse matrix-matrix multiply C=A*B using dot\nproduct method (dot3). Supports masked operation (M, Mask_struct), semiring\nselection, and flipxy. Takes device and number_of_sms for launch config.",
    "file": "GB_cuda_AxB",
    "library": "SuiteSparse",
    "layer": "layer-0",
    "header": "GraphBLAS/CUDA/GB_cuda_AxB.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "GB_cuda_reduce": {
    "brief": "CUDA JIT kernel launcher for GraphBLAS reductions\nCopyright (c) 2017-2025, Timothy A. Davis. Apache-2.0 license.\n\nGB_cuda_reduce_to_scalar_jit: GPU reduction of matrix A to scalar z using\nmonoid. Output to z (scalar) or V (1\u00d71 matrix) based on has_cheeseburger\nflag. Takes stream/grid/block parameters for kernel launch.",
    "file": "GB_cuda_reduce",
    "library": "SuiteSparse",
    "layer": "layer-0",
    "header": "GraphBLAS/CUDA/GB_cuda_reduce.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "GB_cuda": {
    "brief": "Host-side CUDA utilities for GraphBLAS GPU operations\nCopyright (c) 2017-2025, Timothy A. Davis. Apache-2.0 license.\nNVIDIA CORPORATION contributions (c) 2024-2025.\n\nHost CUDA includes and utilities (not for JIT kernels). Matrix prefetch\nfunctions with component flags (P/H/Y/B/I/X for pointers/hyperstart/y/bitmap/\nindices/values). GB_cuda_upscale_identity for monoid identity. Stream pool\nacquire/release for CUDA stream management.",
    "file": "GB_cuda",
    "library": "SuiteSparse",
    "layer": "layer-0",
    "header": "GraphBLAS/CUDA/GB_cuda.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "GB_cuda_select": {
    "brief": "CUDA JIT kernel launchers for GraphBLAS select operations\nSPDX-License-Identifier: Apache-2.0\n\nGPU select operations: GB_cuda_select_bitmap_jit (bitmap format input),\nGB_cuda_select_sparse_jit (sparse format input). Both apply IndexUnaryOp\nwith optional flipij and ythunk scalar. Returns selected entries in C.",
    "file": "GB_cuda_select",
    "library": "SuiteSparse",
    "layer": "layer-0",
    "header": "GraphBLAS/CUDA/GB_cuda_select.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "rmm_wrap": {
    "brief": "RMM (RAPIDS Memory Manager) wrapper types for GraphBLAS GPU memory\nSPDX-License-Identifier: Apache-2.0\n\nType aliases for RMM memory resources: host_mr (new/delete), pinned_mr\n(pinned host), device_mr (CUDA malloc), managed_mr (unified memory).\nPool variants: host_pool_mr, host_pinned_pool_mr, device_pool_mr,\nmanaged_pool_mr. Stream types: cuda_stream_pool, cuda_stream_view.",
    "file": "rmm_wrap",
    "library": "SuiteSparse",
    "layer": "layer-0",
    "header": "GraphBLAS/rmm_wrap/rmm_wrap.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "GB_cuda_error": {
    "brief": "CUDA error checking macro for GraphBLAS GPU operations\nCopyright (c) 2017-2025, Timothy A. Davis. Apache-2.0 license.\n\nCUDA_OK macro: wraps CUDA API calls with error checking. On failure,\nmaps cudaErrorMemoryAllocation to GrB_OUT_OF_MEMORY, other errors to\nGxB_GPU_ERROR. Prints error info via printf and GBURBLE, calls GB_FREE_ALL.",
    "file": "GB_cuda_error",
    "library": "SuiteSparse",
    "layer": "layer-0",
    "header": "GraphBLAS/CUDA/include/GB_cuda_error.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "GB_cuda_timer": {
    "brief": "CUDA event-based GPU timer class\nCopyright (c) 2017-2025, Timothy A. Davis. Apache-2.0 license.\nNVIDIA CORPORATION contributions (c) 2024-2025.\n\nGpuTimer class: Start() records start event, Stop() records stop event,\nElapsed() synchronizes and returns milliseconds between. Uses cudaEvent_t\nfor precise GPU timing. Useful for kernel performance measurement.",
    "file": "GB_cuda_timer",
    "library": "SuiteSparse",
    "layer": "layer-0",
    "header": "GraphBLAS/CUDA/include/GB_cuda_timer.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "GB_cuda_geometry": {
    "brief": "CUDA kernel launch geometry constants\nCopyright (c) 2017-2025, Timothy A. Davis.\n\nBlock and chunk size constants for CUDA kernels, used by host and JIT.\nSelect sparse: BLOCKDIM1=512, CHUNKSIZE1=4096; BLOCKDIM2=256, CHUNKSIZE2=1024.\nSelect bitmap: BLOCKDIM=512. Includes log2 variants for bit shifts.",
    "file": "GB_cuda_geometry",
    "library": "SuiteSparse",
    "layer": "layer-0",
    "header": "GraphBLAS/CUDA/include/GB_cuda_geometry.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "GraphBLAS_cuda": {
    "brief": "Main GraphBLAS CUDA include with C++ complex type definitions\nCopyright (c) 2017-2025, Timothy A. Davis. Apache-2.0 license.\n\nCUDA-compatible GraphBLAS header. Defines C++ complex types: GxB_FC32_t\n(std::complex<float>), GxB_FC64_t (std::complex<double>). Macros GxB_CMPLXF,\nGxB_CMPLX for construction. Includes GB_cuda_geometry.hpp. Used by JIT\nkernels requiring complex arithmetic.",
    "file": "GraphBLAS_cuda",
    "library": "SuiteSparse",
    "layer": "layer-0",
    "header": "GraphBLAS/CUDA/include/GraphBLAS_cuda.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "SuiteSparse_config": {
    "brief": "Central configuration and utility header for all SuiteSparse libraries\n\nThis file provides the shared foundation for the entire SuiteSparse\ncollection of sparse matrix algorithms. Key features include:\n\n- Compiler and platform detection (GCC, Clang, MSVC, ICC, NVCC)\n- Configurable memory management with replaceable malloc/calloc/realloc/free\n- Portable BLAS/LAPACK interface handling Fortran name mangling and integer sizes\n- OpenMP detection and thread-safe timing utilities\n- Complex number type definitions for C/C++ interoperability\n\n@note Applications can customize memory allocation by calling the\n      SuiteSparse_config_*_set functions before using any SuiteSparse library.",
    "file": "SuiteSparse_config",
    "library": "SuiteSparse",
    "layer": "layer-0",
    "header": "SuiteSparse_config/SuiteSparse_config.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": true
  },
  "amd": {
    "brief": "Approximate Minimum Degree ordering for sparse matrix factorization\n\nAMD computes a fill-reducing permutation P for sparse Cholesky or LU\nfactorization. Given a symmetric matrix A (or A+A' if A is unsymmetric),\nAMD finds P such that P*A*P' has fewer nonzeros in its Cholesky factor\nthan A would.",
    "file": "amd",
    "library": "SuiteSparse",
    "layer": "layer-0",
    "header": "AMD/Include/amd.h",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "amd_internal": {
    "brief": "Internal definitions for AMD (Approximate Minimum Degree) ordering\nCopyright (c) 1996-2023, Timothy A. Davis, Patrick R. Amestoy,\nand Iain S. Duff. BSD-3-clause license.\n\nAMD computes fill-reducing orderings for sparse matrix factorization.\nUses approximate minimum degree heuristic with quotient graph representation\nfor efficient O(|A|) ordering of symmetric matrices (or A'A for unsymmetric).",
    "file": "amd_internal",
    "library": "SuiteSparse",
    "layer": "layer-0",
    "header": "AMD/Include/amd_internal.h",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "RBio": {
    "brief": "Rutherford-Boeing sparse matrix I/O library\nCopyright (c) 2009-2023, Timothy A. Davis. GPL-2.0+ license.\n\nRBio reads and writes sparse matrices in Rutherford-Boeing format,\na standard format for exchanging sparse matrices. Supports real, complex,\ninteger, and pattern-only matrices in assembled or elemental forms.",
    "file": "RBio",
    "library": "SuiteSparse",
    "layer": "layer-0",
    "header": "RBio/Include/RBio.h",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "cs": {
    "brief": "Concise Sparse matrix library - teaching implementation of sparse algorithms\n\nCSparse provides a minimal, readable implementation of core sparse matrix\noperations. It serves as both a standalone library and educational reference\nfor sparse linear algebra algorithms.\n\nKey features:\n- Sparse matrix in triplet or compressed-column (CSC) format\n- Sparse Cholesky (cs_chol), LU (cs_lu), and QR (cs_qr) factorization\n- Fill-reducing orderings via AMD\n- Direct solvers: cs_cholsol, cs_lusol, cs_qrsol\n- Dulmage-Mendelsohn decomposition (cs_dmperm)",
    "file": "cs",
    "library": "SuiteSparse",
    "layer": "layer-0",
    "header": "CSparse/Include/cs.h",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "camd": {
    "brief": "Constrained Approximate Minimum Degree ordering for symmetric matrices\nCopyright (c) 1996-2024, Timothy A. Davis, Yanqing Chen,\nPatrick R. Amestoy, and Iain S. Duff. BSD-3-clause license.\n\nCAMD computes fill-reducing orderings for sparse Cholesky factorization\nwith user-specified constraints. Extends AMD to support constraint sets\nthat force certain nodes to be ordered before others.",
    "file": "camd",
    "library": "SuiteSparse",
    "layer": "layer-0",
    "header": "CAMD/Include/camd.h",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "ccolamd": {
    "brief": "Constrained Column Approximate Minimum Degree ordering\nCopyright (c) 1996-2024, Timothy A. Davis, Sivasankaran Rajamanickam,\nand Stefan Larimore. BSD-3-clause license.\n\nCCOLAMD computes column orderings for sparse QR and LU factorization with\nuser-specified constraints. Extends COLAMD with constraint sets that force\ncertain columns to appear before or after others in the ordering.",
    "file": "ccolamd",
    "library": "SuiteSparse",
    "layer": "layer-0",
    "header": "CCOLAMD/Include/ccolamd.h",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "LAGraphX": {
    "brief": "",
    "file": "LAGraphX",
    "library": "SuiteSparse",
    "layer": "layer-0",
    "header": "LAGraph/include/LAGraphX.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "umfpack": {
    "brief": "Multifrontal sparse LU factorization for unsymmetric matrices\n\nUMFPACK computes a sparse LU factorization of a general (unsymmetric)\nsquare matrix A:\n  P*R*A*Q = L*U\nwhere P and Q are permutation matrices, R is diagonal scaling, L is\nunit lower triangular, and U is upper triangular.\n\nKey features:\n- Multifrontal algorithm with BLAS-3 dense kernels\n- Automatic strategy selection (symmetric vs unsymmetric)\n- Fill-reducing orderings: AMD (symmetric), COLAMD (unsymmetric)\n- Real and complex matrices (double precision)\n- Row scaling for numerical stability\n\nTypical workflow:\n1. umfpack_di_symbolic: Symbolic analysis (ordering, memory estimates)\n2. umfpack_di_numeric: Numerical LU factorization\n3. umfpack_di_solve: Solve Ax = b, A'x = b, etc.\n4. umfpack_di_free_symbolic, umfpack_di_free_numeric: Free memory",
    "file": "umfpack",
    "library": "SuiteSparse",
    "layer": "layer-0",
    "header": "UMFPACK/Include/umfpack.h",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "umf_internal": {
    "brief": "Internal definitions for UMFPACK sparse LU factorization\nCopyright (c) 2005-2023, Timothy A. Davis. GPL-2.0+ license.\n\nUMFPACK is an unsymmetric multifrontal sparse LU factorization package.\nComputes P\u00b7A\u00b7Q = L\u00b7U via supernodal factorization with partial pivoting.\nHandles real and complex matrices in single and double precision.",
    "file": "umf_internal",
    "library": "SuiteSparse",
    "layer": "layer-0",
    "header": "UMFPACK/Source/umf_internal.h",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "btf": {
    "brief": "Block Triangular Form permutation for sparse matrices\n\nBTF computes permutations to transform a sparse matrix into block upper\ntriangular form (BTF). This decomposes the matrix into independent blocks\nthat can be processed separately, improving efficiency for factorization.\n\nThree main routines:\n- btf_maxtrans: Maximum transversal (zero-free diagonal matching)\n- btf_strongcomp: Strongly connected components (block decomposition)\n- btf_order: Combined BTF ordering (calls both above)",
    "file": "btf",
    "library": "SuiteSparse",
    "layer": "layer-0",
    "header": "BTF/Include/btf.h",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "btf_internal": {
    "brief": "Internal definitions for BTF (Block Triangular Form) permutation\nCopyright (c) 2004-2023, University of Florida. LGPL-2.1+ license.\n\nBTF finds permutation matrices P and Q such that P\u00b7A\u00b7Q has block upper\ntriangular form with square diagonal blocks that are irreducible\n(strongly connected components). Essential preprocessing for sparse LU.",
    "file": "btf_internal",
    "library": "SuiteSparse",
    "layer": "layer-0",
    "header": "BTF/Include/btf_internal.h",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "klu": {
    "brief": "Sparse LU factorization optimized for circuit simulation matrices\n\nKLU computes a sparse LU factorization of a square matrix A:\n  P*A*Q = L*U\nwhere P and Q are permutation matrices, L is unit lower triangular,\nand U is upper triangular.\n\nKLU is specifically designed for matrices arising from circuit simulation,\nwhich tend to be sparse and nearly block-triangular. The factorization\nproceeds in three phases:\n1. klu_analyze: BTF pre-ordering + fill-reducing ordering (AMD/COLAMD)\n2. klu_factor: Numerical LU factorization (left-looking, column-by-column)\n3. klu_solve: Forward/back substitution to solve Ax = b",
    "file": "klu",
    "library": "SuiteSparse",
    "layer": "layer-0",
    "header": "KLU/Include/klu.h",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "klu_internal": {
    "brief": "Internal definitions for KLU sparse LU factorization\nCopyright (c) 2004-2023, University of Florida. LGPL-2.1+ license.\n\nKLU is a sparse LU factorization package designed for circuit simulation\nmatrices, which are typically highly sparse with near-diagonal structure.\nUses BTF (Block Triangular Form) permutation to exploit structure.",
    "file": "klu_internal",
    "library": "SuiteSparse",
    "layer": "layer-0",
    "header": "KLU/Include/klu_internal.h",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "cholmod_internal": {
    "brief": "Internal definitions for CHOLMOD sparse Cholesky factorization\nCopyright (C) 2005-2023, Timothy A. Davis. Apache-2.0 license.\n\nCHOLMOD is a comprehensive sparse Cholesky factorization package supporting\nsupernodal and simplicial methods, update/downdate, and multiple orderings.\nHandles symmetric positive definite systems A\u00b7x = b via L\u00b7L' = A.",
    "file": "cholmod_internal",
    "library": "SuiteSparse",
    "layer": "layer-0",
    "header": "CHOLMOD/Include/cholmod_internal.h",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "cholmod": {
    "brief": "Comprehensive sparse Cholesky factorization library\n\nCHOLMOD provides high-performance sparse Cholesky factorization for\nsymmetric positive definite (SPD) and symmetric positive semi-definite\nmatrices. It supports:\n\nKey features:\n- Supernodal and simplicial Cholesky (LL' and LDL')\n- Fill-reducing orderings: AMD, COLAMD, METIS, CAMD\n- Real, complex, and pattern-only matrices\n- Single and double precision (float/double)\n- Row/column updates and downdates\n- GPU acceleration (NVIDIA CUDA)\n\nTypical workflow:\n1. cholmod_start: Initialize Common workspace\n2. cholmod_analyze: Symbolic analysis (fill-reducing ordering)\n3. cholmod_factorize: Numerical Cholesky factorization\n4. cholmod_solve: Solve Ax = b using the factors\n5. cholmod_finish: Free workspace",
    "file": "cholmod",
    "library": "SuiteSparse",
    "layer": "layer-0",
    "header": "CHOLMOD/Include/cholmod.h",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "ldl": {
    "brief": "Simple sparse LDL' factorization for symmetric matrices\n\nLDL computes a sparse LDL' factorization of a symmetric matrix A:\n  A = L * D * L'\nwhere L is unit lower triangular and D is diagonal. This factorization\nworks for symmetric indefinite matrices (D may have negative entries).\n\nThe factorization is performed in two phases:\n1. ldl_symbolic: Compute elimination tree and allocate storage\n2. ldl_numeric: Compute numerical values of L and D\n\nTriangular solves (ldl_lsolve, ldl_dsolve, ldl_ltsolve) complete the\nsolution of Ax = b.",
    "file": "ldl",
    "library": "SuiteSparse",
    "layer": "layer-0",
    "header": "LDL/Include/ldl.h",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "colamd": {
    "brief": "Column Approximate Minimum Degree ordering for sparse LU factorization\n\nCOLAMD computes a column permutation Q that reduces fill-in during LU\nfactorization of an unsymmetric matrix A. The ordering minimizes the\nfill-in of A*Q when factored as LU.\n\nSYMAMD computes a symmetric ordering for a symmetric matrix, using COLAMD\non the matrix's structure. Both are related to the minimum degree family\nof algorithms.",
    "file": "colamd",
    "library": "SuiteSparse",
    "layer": "layer-0",
    "header": "COLAMD/Include/colamd.h",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "ParU": {
    "brief": "Parallel unsymmetric multifrontal sparse LU factorization\nCopyright (c) 2022-2025, Mohsen Aznaveh and Timothy A. Davis. GPL-3.0-or-later.\n\nParU is a parallel sparse direct solver using OpenMP tasking for task-based\nparallelism combined with parallel BLAS (nested parallelism). Solves Ax = b\nfor sparse A via LU factorization with partial pivoting.",
    "file": "ParU",
    "library": "SuiteSparse",
    "layer": "layer-0",
    "header": "ParU/Include/ParU.h",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "zstd_ldm": {
    "brief": "",
    "file": "zstd_ldm",
    "library": "SuiteSparse",
    "layer": "layer-0",
    "header": "GraphBLAS/zstd/zstd_subset/compress/zstd_ldm.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "zstd_compress_internal": {
    "brief": "",
    "file": "zstd_compress_internal",
    "library": "SuiteSparse",
    "layer": "layer-0",
    "header": "GraphBLAS/zstd/zstd_subset/compress/zstd_compress_internal.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "huf": {
    "brief": "",
    "file": "huf",
    "library": "SuiteSparse",
    "layer": "layer-0",
    "header": "GraphBLAS/zstd/zstd_subset/common/huf.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "zstd_trace": {
    "brief": "",
    "file": "zstd_trace",
    "library": "SuiteSparse",
    "layer": "layer-0",
    "header": "GraphBLAS/zstd/zstd_subset/common/zstd_trace.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "AbcDualRowSteepest": {
    "brief": "Steepest edge pivot selection for ABC dual simplex",
    "file": "AbcDualRowSteepest",
    "library": "Clp",
    "layer": "layer-1",
    "header": "src/AbcDualRowSteepest.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "ClpModelParameters": {
    "brief": "Enumeration types for ClpModel parameter access\n\nDefines typed parameter indices for ClpModel's get/set methods:\n\nClpIntParam - Integer parameters:\n- ClpMaxNumIteration: Maximum simplex iterations\n- ClpMaxNumIterationHotStart: Hot start iteration limit\n- ClpNameDiscipline: Row/column naming mode (0=auto, 1=lazy, 2=full)\n\nClpDblParam - Double parameters:\n- ClpDualObjectiveLimit: Stop when dual objective exceeds\n- ClpPrimalObjectiveLimit: Stop when primal objective exceeds\n- ClpDualTolerance: Dual feasibility tolerance\n- ClpPrimalTolerance: Primal feasibility tolerance\n- ClpObjOffset: Constant term in objective\n- ClpMaxSeconds/ClpMaxWallSeconds: Time limits\n- ClpPresolveTolerance: Presolve zero tolerance\n\nClpStrParam - String parameters:\n- ClpProbName: Problem name from MPS file\n\nUtility templates for array operations:\n- ClpDisjointCopyN(), ClpFillN(), ClpCopyOfArray(): Non-COIN versions\n\nClpTrustedData: Opaque structure for passing user data to trusted code.",
    "file": "ClpModelParameters",
    "library": "Clp",
    "layer": "layer-1",
    "header": "src/ClpModelParameters.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "ClpGubMatrix": {
    "brief": "Generalized Upper Bound (GUB) matrix for special LP structure\n\nImplements GUB constraints - sets of variables where exactly one (or at\nmost one) must be in the basis. This structure appears in problems like\nassignment, crew scheduling, and set partitioning.",
    "file": "ClpGubMatrix",
    "library": "Clp",
    "layer": "layer-1",
    "header": "src/ClpGubMatrix.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "ClpLsqr": {
    "brief": "LSQR iterative solver for sparse least-squares problems\n\nImplements the LSQR algorithm of Paige and Saunders (1982) for solving:\n- Ax = b (exact solve)\n- min ||b - Ax||_2 (least squares)\n- min ||(b) - (A    )x||_2 (damped/regularized)\n      ||(0)   (damp*I)  ||",
    "file": "ClpLsqr",
    "library": "Clp",
    "layer": "layer-1",
    "header": "src/ClpLsqr.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "ClpSimplexDual": {
    "brief": "Dual simplex algorithm implementation",
    "file": "ClpSimplexDual",
    "library": "Clp",
    "layer": "layer-1",
    "header": "src/ClpSimplexDual.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "ClpNonLinearCost": {
    "brief": "Piecewise linear cost handling and bound infeasibility tracking\n\nManages piecewise linear objective functions and tracks bound violations\nduring primal simplex. When variables move outside their bounds, this class\ncomputes the appropriate infeasibility penalty costs.",
    "file": "ClpNonLinearCost",
    "library": "Clp",
    "layer": "layer-1",
    "header": "src/ClpNonLinearCost.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "ClpCholeskyPardiso": {
    "brief": "Intel MKL Pardiso sparse direct solver for Cholesky factorization\n\nWraps Intel's Pardiso solver from the Math Kernel Library (MKL) for\nCholesky factorization of normal equations in interior point methods.",
    "file": "ClpCholeskyPardiso",
    "library": "Clp",
    "layer": "layer-1",
    "header": "src/ClpCholeskyPardiso.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "AbcSimplex": {
    "brief": "AVX/SIMD-optimized simplex solver (\"A Better Clp\")",
    "file": "AbcSimplex",
    "library": "Clp",
    "layer": "layer-1",
    "header": "src/AbcSimplex.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "ClpLinearObjective": {
    "brief": "Standard linear objective function (c'x)",
    "file": "ClpLinearObjective",
    "library": "Clp",
    "layer": "layer-1",
    "header": "src/ClpLinearObjective.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "ClpNode": {
    "brief": "Node representation for branch-and-bound fathoming\n\nSupport classes for Clp's fathom capability - solving subproblems\nin a branch-and-bound tree. Used when Clp is embedded in CBC.",
    "file": "ClpNode",
    "library": "Clp",
    "layer": "layer-1",
    "header": "src/ClpNode.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "AbcMatrix": {
    "brief": "Cache-optimized matrix for ABC simplex with multiple copies",
    "file": "AbcMatrix",
    "library": "Clp",
    "layer": "layer-1",
    "header": "src/AbcMatrix.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "ClpCholeskyUfl": {
    "brief": "SuiteSparse CHOLMOD interface for Cholesky factorization\n\nWraps the CHOLMOD library from SuiteSparse (University of Florida) for\nCholesky factorization of normal equations in interior point methods.",
    "file": "ClpCholeskyUfl",
    "library": "Clp",
    "layer": "layer-1",
    "header": "src/ClpCholeskyUfl.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "ClpDualRowSteepest": {
    "brief": "Steepest edge pivot selection for dual simplex",
    "file": "ClpDualRowSteepest",
    "library": "Clp",
    "layer": "layer-1",
    "header": "src/ClpDualRowSteepest.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "AbcSimplexPrimal": {
    "brief": "AVX-optimized primal simplex algorithm",
    "file": "AbcSimplexPrimal",
    "library": "Clp",
    "layer": "layer-1",
    "header": "src/AbcSimplexPrimal.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "ClpNetworkMatrix": {
    "brief": "Specialized matrix for pure network LP problems\n\nImplements efficient storage for network flow problems where each column\n(arc) has exactly two nonzeros: +1 at the head node and -1 at the tail node.\nThis representation requires only O(n) storage for row indices vs O(2n) for\na general sparse matrix.",
    "file": "ClpNetworkMatrix",
    "library": "Clp",
    "layer": "layer-1",
    "header": "src/ClpNetworkMatrix.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "ClpConstraintLinear": {
    "brief": "Linear constraint implementation for nonlinear extensions\n\nImplements ClpConstraint for a linear constraint: sum(a_j * x_j) = b.\nUsed with ClpSimplexNonlinear when linear constraints appear alongside\nnonlinear objective or other nonlinear constraints.",
    "file": "ClpConstraintLinear",
    "library": "Clp",
    "layer": "layer-1",
    "header": "src/ClpConstraintLinear.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "ClpFactorization": {
    "brief": "Wrapper around CoinFactorization for use within Clp simplex",
    "file": "ClpFactorization",
    "library": "Clp",
    "layer": "layer-1",
    "header": "src/ClpFactorization.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "ClpPEPrimalColumnDantzig": {
    "brief": "Positive Edge enhanced Dantzig pricing for primal simplex",
    "file": "ClpPEPrimalColumnDantzig",
    "library": "Clp",
    "layer": "layer-1",
    "header": "src/ClpPEPrimalColumnDantzig.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "MyEventHandler": {
    "brief": "Example event handler demonstrating callback customization\n\nSample implementation of ClpEventHandler showing how users can\nintercept simplex events for custom processing. Used in unit tests.\n\nTo create your own handler:\n1. Inherit from ClpEventHandler\n2. Override event() method\n3. Return 0 to continue, non-zero to stop\n4. Attach via ClpSimplex::passInEventHandler()\n\nAvailable events (see ClpEventHandler::Event):\n- endOfIteration: After each pivot\n- endOfFactorization: After basis refactorization\n- endOfValuesPass: After crash/values pass\n- node: During B&B (if used with Cbc)\n\nThe model_ pointer gives access to full solver state including\ncurrent solution, basis, and objective value.",
    "file": "MyEventHandler",
    "library": "Clp",
    "layer": "layer-1",
    "header": "src/MyEventHandler.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "ClpParamUtils": {
    "brief": "Parameter handler callback functions for ClpParam",
    "file": "ClpParamUtils",
    "library": "Clp",
    "layer": "layer-1",
    "header": "src/ClpParamUtils.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "ClpPrimalColumnSteepest": {
    "brief": "Steepest edge and Devex pivot selection for primal simplex",
    "file": "ClpPrimalColumnSteepest",
    "library": "Clp",
    "layer": "layer-1",
    "header": "src/ClpPrimalColumnSteepest.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "ClpDummyMatrix": {
    "brief": "Placeholder matrix with dimensions but no data\n\nImplements ClpMatrixBase with only dimensions (rows, columns, elements)\nbut no actual matrix data. Used primarily with ClpPdco where the user\nprovides custom matrix-vector products via callbacks.",
    "file": "ClpDummyMatrix",
    "library": "Clp",
    "layer": "layer-1",
    "header": "src/ClpDummyMatrix.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "ClpSimplex": {
    "brief": "Main simplex solver class - orchestrates primal and dual simplex algorithms",
    "file": "ClpSimplex",
    "library": "Clp",
    "layer": "layer-1",
    "header": "src/ClpSimplex.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "ClpPEPrimalColumnSteepest": {
    "brief": "Positive Edge enhanced steepest edge for primal simplex",
    "file": "ClpPEPrimalColumnSteepest",
    "library": "Clp",
    "layer": "layer-1",
    "header": "src/ClpPEPrimalColumnSteepest.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "ClpSolve": {
    "brief": "Algorithm selection and configuration for ClpSimplex::initialSolve()",
    "file": "ClpSolve",
    "library": "Clp",
    "layer": "layer-1",
    "header": "src/ClpSolve.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "AbcWarmStart": {
    "brief": "Extended warm start with factorization caching for ABC",
    "file": "AbcWarmStart",
    "library": "Clp",
    "layer": "layer-1",
    "header": "src/AbcWarmStart.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "Idiot": {
    "brief": "Heuristic crash procedure for finding initial LP solutions\n\nThe \"Idiot\" algorithm is a simple heuristic that finds approximate primal\nsolutions quickly. Despite its self-deprecating name (which is copylefted!),\nit serves as an effective \"crash\" procedure to warm-start the simplex method.",
    "file": "Idiot",
    "library": "Clp",
    "layer": "layer-1",
    "header": "src/Idiot.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "AbcNonLinearCost": {
    "brief": "Piecewise linear cost and infeasibility tracking for ABC",
    "file": "AbcNonLinearCost",
    "library": "Clp",
    "layer": "layer-1",
    "header": "src/AbcNonLinearCost.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "ClpInterior": {
    "brief": "Interior point (barrier) method for LP",
    "file": "ClpInterior",
    "library": "Clp",
    "layer": "layer-1",
    "header": "src/ClpInterior.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "ClpCholeskyDense": {
    "brief": "Dense Cholesky factorization for interior point methods\n\nImplements Cholesky factorization when A*D*A' becomes effectively dense.\nUses blocked recursive algorithms for cache efficiency and supports\nparallel execution via ClpCholeskySpawn.",
    "file": "ClpCholeskyDense",
    "library": "Clp",
    "layer": "layer-1",
    "header": "src/ClpCholeskyDense.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "CoinAbcCommon": {
    "brief": "Common definitions for ABC (A Better Coin) optimized simplex",
    "file": "CoinAbcCommon",
    "library": "Clp",
    "layer": "layer-1",
    "header": "src/CoinAbcCommon.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "ClpCholeskyTaucs": {
    "brief": "TAUCS sparse solver interface for Cholesky factorization\n\nWraps Sivan Toledo's TAUCS library for Cholesky factorization of normal\nequations in interior point methods.",
    "file": "ClpCholeskyTaucs",
    "library": "Clp",
    "layer": "layer-1",
    "header": "src/ClpCholeskyTaucs.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "ClpDualRowDantzig": {
    "brief": "Dantzig's rule for dual simplex pivot selection\n\nImplements the simplest pivot row selection: choose the basic variable\nwith the largest primal infeasibility. Simple and fast per iteration,\nbut may require many more iterations than steepest edge on degenerate\nor difficult problems.\n\nThis is Dantzig's original 1947 rule applied to dual simplex.\nUse ClpDualRowSteepest for better performance on most problems.",
    "file": "ClpDualRowDantzig",
    "library": "Clp",
    "layer": "layer-1",
    "header": "src/ClpDualRowDantzig.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "ClpMatrixBase": {
    "brief": "Abstract base class for constraint matrices in Clp\n\nDefines the interface that all matrix types must implement for use with\nClp algorithms. The abstraction allows specialized matrix formats that\nexploit structure (network, GUB, \u00b11 matrices) while providing a uniform\ninterface to the simplex solver.",
    "file": "ClpMatrixBase",
    "library": "Clp",
    "layer": "layer-1",
    "header": "src/ClpMatrixBase.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "ClpCholeskyWssmpKKT": {
    "brief": "WSSMP solver for KKT system (augmented system) formulation\n\nVariant of ClpCholeskyWssmp that solves the KKT/augmented system directly\ninstead of forming and factoring the normal equations A*D*A'.",
    "file": "ClpCholeskyWssmpKKT",
    "library": "Clp",
    "layer": "layer-1",
    "header": "src/ClpCholeskyWssmpKKT.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "ClpCholeskyMumps": {
    "brief": "MUMPS sparse direct solver interface for Cholesky factorization\n\nWraps the MUMPS (MUltifrontal Massively Parallel sparse direct Solver)\nlibrary for Cholesky factorization of normal equations in interior point.",
    "file": "ClpCholeskyMumps",
    "library": "Clp",
    "layer": "layer-1",
    "header": "src/ClpCholeskyMumps.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "AbcCommon": {
    "brief": "Configuration macros for ABC (A Better Clp) build modes",
    "file": "AbcCommon",
    "library": "Clp",
    "layer": "layer-1",
    "header": "src/AbcCommon.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "ClpConstraint": {
    "brief": "Abstract base class for nonlinear constraints\n\nDefines the interface for general (potentially nonlinear) constraints\nused in nonlinear programming extensions. The standard LP constraints\n(Ax \u2264 b) are handled directly by ClpModel; this class is for more\ngeneral constraint forms g(x) \u2264 0.",
    "file": "ClpConstraint",
    "library": "Clp",
    "layer": "layer-1",
    "header": "src/ClpConstraint.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "ClpPackedMatrix": {
    "brief": "Standard sparse matrix implementation for Clp (wraps CoinPackedMatrix)\n\nThe default matrix type for Clp, implementing ClpMatrixBase using\nCoinPackedMatrix for sparse storage. This is appropriate for general\nsparse LP matrices without special structure.",
    "file": "ClpPackedMatrix",
    "library": "Clp",
    "layer": "layer-1",
    "header": "src/ClpPackedMatrix.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "ClpPdcoBase": {
    "brief": "Abstract base class for PDCO problem customization\n\nStrategy pattern interface for defining custom convex objectives in PDCO.",
    "file": "ClpPdcoBase",
    "library": "Clp",
    "layer": "layer-1",
    "header": "src/ClpPdcoBase.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "ClpPresolve": {
    "brief": "Clp interface to CoinPresolve for LP preprocessing",
    "file": "ClpPresolve",
    "library": "Clp",
    "layer": "layer-1",
    "header": "src/ClpPresolve.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "ClpObjective": {
    "brief": "Abstract base class for objective functions",
    "file": "ClpObjective",
    "library": "Clp",
    "layer": "layer-1",
    "header": "src/ClpObjective.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "ClpPlusMinusOneMatrix": {
    "brief": "Specialized matrix where all nonzeros are +1 or -1\n\nEfficient storage for constraint matrices where every coefficient is either\n+1 or -1. Common in set partitioning, covering, and assignment problems.\nNo element values are stored - only row indices, with separate start arrays\nfor positive and negative entries in each column.",
    "file": "ClpPlusMinusOneMatrix",
    "library": "Clp",
    "layer": "layer-1",
    "header": "src/ClpPlusMinusOneMatrix.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "ClpHelperFunctions": {
    "brief": "BLAS-1 style dense vector operations for Clp",
    "file": "ClpHelperFunctions",
    "library": "Clp",
    "layer": "layer-1",
    "header": "src/ClpHelperFunctions.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "ClpQuadraticObjective": {
    "brief": "Quadratic objective function for convex QP (x'Qx/2 + c'x)\n\nImplements convex quadratic objectives for quadratic programming.\nThe quadratic term is stored as a CoinPackedMatrix Q, supporting\nboth full symmetric and half (lower triangular) storage.",
    "file": "ClpQuadraticObjective",
    "library": "Clp",
    "layer": "layer-1",
    "header": "src/ClpQuadraticObjective.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "ClpEventHandler": {
    "brief": "Callback interface for handling solver events during optimization\n\nProvides a mechanism for user code to receive callbacks during the solve\nprocess. Users derive from ClpEventHandler and override event() to handle\nevents like end of iteration, factorization, or presolve stages.",
    "file": "ClpEventHandler",
    "library": "Clp",
    "layer": "layer-1",
    "header": "src/ClpEventHandler.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "ClpPredictorCorrector": {
    "brief": "Mehrotra's predictor-corrector interior point algorithm",
    "file": "ClpPredictorCorrector",
    "library": "Clp",
    "layer": "layer-1",
    "header": "src/ClpPredictorCorrector.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "ClpSimplexPrimal": {
    "brief": "Primal simplex algorithm implementation",
    "file": "ClpSimplexPrimal",
    "library": "Clp",
    "layer": "layer-1",
    "header": "src/ClpSimplexPrimal.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "ClpPdco": {
    "brief": "PDCO (Primal-Dual interior point for Convex Objectives) algorithm",
    "file": "ClpPdco",
    "library": "Clp",
    "layer": "layer-1",
    "header": "src/ClpPdco.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "AbcSimplexDual": {
    "brief": "AVX-optimized dual simplex algorithm",
    "file": "AbcSimplexDual",
    "library": "Clp",
    "layer": "layer-1",
    "header": "src/AbcSimplexDual.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "ClpSolver": {
    "brief": "Standalone Clp solver driver and command-line interface",
    "file": "ClpSolver",
    "library": "Clp",
    "layer": "layer-1",
    "header": "src/ClpSolver.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "AbcPrimalColumnDantzig": {
    "brief": "Dantzig's rule for ABC primal simplex pivot selection",
    "file": "AbcPrimalColumnDantzig",
    "library": "Clp",
    "layer": "layer-1",
    "header": "src/AbcPrimalColumnDantzig.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "ClpSimplexOther": {
    "brief": "Auxiliary simplex operations: ranging, parametrics, and utilities",
    "file": "ClpSimplexOther",
    "library": "Clp",
    "layer": "layer-1",
    "header": "src/ClpSimplexOther.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "AbcPrimalColumnSteepest": {
    "brief": "Steepest edge and Devex for ABC primal simplex",
    "file": "AbcPrimalColumnSteepest",
    "library": "Clp",
    "layer": "layer-1",
    "header": "src/AbcPrimalColumnSteepest.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "ClpParam": {
    "brief": "Parameter type enums for Clp and CBC command-line interface (legacy)\nCopyright (C) 2002, International Business Machines Corporation.\nEPL-1.0 license.\n\nClpParameterType enum: ranges 1-100 (double), 101-200 (int), 201-300\n(Clp string), 301-400 (Cbc string), 401-500 (Clp actions), 501-600 (Cbc\nactions). Parameters for tolerances, limits, scaling, algorithms, output.\nThis file is in Attic (deprecated) - see ClpParameters.hpp for current version.\n\n@deprecated Replaced by ClpParameters.hpp",
    "file": "ClpParam",
    "library": "Clp",
    "layer": "layer-1",
    "header": "src/Attic/ClpParam.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "CbcOrClpParam": {
    "brief": "Shared parameter codes for Cbc and Clp solvers\n\nLegacy parameter handling shared between Cbc (branch-and-cut) and Clp\n(linear programming). This file is intentionally duplicated between\nCbc/Test and Clp/Test for simplicity.\n\nParameter code ranges (CbcOrClpParameterType):\n- 1-100: Double parameters (CLP_PARAM_DBL_*, CBC_PARAM_DBL_*)\n- 101-200: Integer parameters (CLP_PARAM_INT_*, CBC_PARAM_INT_*)\n- 201-300: Clp string parameters\n- 301-400: Cbc string parameters\n- 401-500: Clp actions (mostly)\n- 501-600: Cbc actions (mostly)\n\nConditional compilation:\n- COIN_HAS_CBC: Include Cbc-specific parameters\n- COIN_HAS_CLP: Include Clp-specific parameters\n\nNote: Being superseded by ClpParam/CbcParam for cleaner separation.",
    "file": "CbcOrClpParam",
    "library": "Clp",
    "layer": "layer-1",
    "header": "src/CbcOrClpParam.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "ClpSimplexNonlinear": {
    "brief": "Nonlinear LP solver using reduced gradient and SLP methods",
    "file": "ClpSimplexNonlinear",
    "library": "Clp",
    "layer": "layer-1",
    "header": "src/ClpSimplexNonlinear.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "AbcDualRowDantzig": {
    "brief": "Dantzig's rule for ABC dual simplex pivot selection",
    "file": "AbcDualRowDantzig",
    "library": "Clp",
    "layer": "layer-1",
    "header": "src/AbcDualRowDantzig.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "ClpParameters": {
    "brief": "Command-line and runtime parameter management",
    "file": "ClpParameters",
    "library": "Clp",
    "layer": "layer-1",
    "header": "src/ClpParameters.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "ClpNetworkBasis": {
    "brief": "Specialized factorization for pure network problems",
    "file": "ClpNetworkBasis",
    "library": "Clp",
    "layer": "layer-1",
    "header": "src/ClpNetworkBasis.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "ClpModel": {
    "brief": ".NET wrapper for ClpModel (COIN-OR LP solver)\n\nC++/CLI wrapper exposing CLP simplex solver to .NET languages.\nSupports quadratic objectives via loadQuadraticObjective().",
    "file": "ClpModel",
    "library": "Sonnet",
    "layer": "layer-4",
    "header": "src/SonnetWrapper/ClpModel.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "ClpPrimalQuadraticDantzig": {
    "brief": "Dantzig-style pricing for quadratic programming\n\nExtends ClpPrimalColumnPivot for QP problems where the reduced cost\ndepends on the current solution (due to the quadratic objective).",
    "file": "ClpPrimalQuadraticDantzig",
    "library": "Clp",
    "layer": "layer-1",
    "header": "src/ClpPrimalQuadraticDantzig.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "AbcSimplexFactorization": {
    "brief": "LU factorization wrapper for ABC simplex",
    "file": "AbcSimplexFactorization",
    "library": "Clp",
    "layer": "layer-1",
    "header": "src/AbcSimplexFactorization.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "AbcDualRowPivot": {
    "brief": "Abstract base class for dual pivot row selection in ABC",
    "file": "AbcDualRowPivot",
    "library": "Clp",
    "layer": "layer-1",
    "header": "src/AbcDualRowPivot.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "ClpMessage": {
    "brief": "Message codes and localization for Clp solver output\n\nDefines the CLP_Message enum with all status and diagnostic message codes\nused by Clp during optimization. Messages are organized by solver phase:\n- CLP_SIMPLEX_*: General simplex status (finished, infeasible, etc.)\n- CLP_DUAL_*: Dual simplex specific messages\n- CLP_PRIMAL_*: Primal simplex specific messages\n- CLP_BARRIER_*: Interior point method messages\n\nClpMessage inherits from CoinMessages to provide localized message text.\nControl output verbosity via ClpSimplex::setLogLevel().",
    "file": "ClpMessage",
    "library": "Clp",
    "layer": "layer-1",
    "header": "src/ClpMessage.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "ClpConstraintQuadratic": {
    "brief": "Quadratic constraint implementation: x'Qx + c'x \u2264 b\n\nImplements ClpConstraint for quadratic constraints. The constraint\nfunction is: 0.5 * sum_{ij}(Q_ij * x_i * x_j) + sum_j(c_j * x_j) \u2264 b",
    "file": "ClpConstraintQuadratic",
    "library": "Clp",
    "layer": "layer-1",
    "header": "src/ClpConstraintQuadratic.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "ClpPrimalColumnPivot": {
    "brief": "Abstract base class for primal simplex pivot column selection\n\nIn primal simplex, the pivot column (entering variable) is chosen based on\nreduced cost. This class defines the interface for different selection\nstrategies. Derived classes implement specific rules.\n\nKey methods:\n- pivotColumn(): Select which column (variable) enters the basis\n- updateWeights(): Maintain pricing information after pivots\n- saveWeights(): Preserve weights across refactorizations",
    "file": "ClpPrimalColumnPivot",
    "library": "Clp",
    "layer": "layer-1",
    "header": "src/ClpPrimalColumnPivot.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "CoinAbcHelperFunctions": {
    "brief": "SIMD-optimized scatter/gather operations for ABC factorization\n\nHigh-performance kernels for sparse matrix operations using:\n- Manual loop unrolling (UNROLL_SCATTER, UNROLL_GATHER)\n- AVX/AVX2 intrinsics when available\n- Cilk parallel loops with configurable grainsize\n- Prefetching hints (coin_prefetch macros)\n\nKey operations:\n- CoinAbcScatterUpdate: region[index[j]] -= value[j] * pivot\n- CoinAbcGatherUpdate: dot product over sparse indices\n- Memory utilities: CoinAbcMemcpyLong, CoinAbcMemset0Long\n\nIncludes specialized ScatterUpdateN functions for N=1..8 and 4N variants\nusing function pointer dispatch (scatterStruct) for optimal performance.",
    "file": "CoinAbcHelperFunctions",
    "library": "Clp",
    "layer": "layer-1",
    "header": "src/CoinAbcHelperFunctions.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "MyMessageHandler": {
    "brief": "Example message handler demonstrating custom logging\n\nSample implementation of CoinMessageHandler showing how users can\ncustomize message output. Used in unit tests to demonstrate\ncapturing solver progress and collecting feasible extreme points.\n\nFeatures demonstrated:\n- Override print() to intercept all solver messages\n- Access to model_ for querying current solution\n- Collection of feasible extreme points during solve\n- Custom file output via FILE* pointer\n\nUse case - Feasible point enumeration:\nDuring optimization, each time the solver finds a new feasible\nextreme point (basic feasible solution), the handler captures it.\nUseful for problems where alternative optima matter.\n\nTo create your own handler:\n1. Inherit from CoinMessageHandler\n2. Override print() method\n3. Attach via ClpSimplex::passInMessageHandler()",
    "file": "MyMessageHandler",
    "library": "Clp",
    "layer": "layer-1",
    "header": "src/MyMessageHandler.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "ClpDualRowPivot": {
    "brief": "Abstract base class for dual simplex pivot row selection\n\nIn dual simplex, the pivot row (leaving variable) is chosen based on\nprimal infeasibility. This class defines the interface for different\nselection strategies. Derived classes implement specific rules.\n\nKey methods:\n- pivotRow(): Select which row (basic variable) leaves the basis\n- updateWeights(): Maintain pricing information after pivots\n- updatePrimalSolution(): Update solution after basis change",
    "file": "ClpDualRowPivot",
    "library": "Clp",
    "layer": "layer-1",
    "header": "src/ClpDualRowPivot.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "ClpPrimalColumnDantzig": {
    "brief": "Dantzig's rule for primal simplex pivot selection\n\nImplements the simplest pivot column selection: choose the nonbasic variable\nwith the most negative reduced cost (for minimization). This is Dantzig's\noriginal 1947 rule.\n\nSimple and fast per iteration, but typically requires more iterations than\nsteepest edge methods on degenerate or difficult problems. Use\nClpPrimalColumnSteepest for better performance on most problems.",
    "file": "ClpPrimalColumnDantzig",
    "library": "Clp",
    "layer": "layer-1",
    "header": "src/ClpPrimalColumnDantzig.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "CoinAbcDenseFactorization": {
    "brief": "Abstract base class for ABC factorization and dense submatrix handling",
    "file": "CoinAbcDenseFactorization",
    "library": "Clp",
    "layer": "layer-1",
    "header": "src/CoinAbcDenseFactorization.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "ClpCholeskyBase": {
    "brief": "Cholesky factorization base class for interior point methods\n\nProvides Cholesky factorization of the normal equations matrix A*D*A'\nused in predictor-corrector interior point methods. The factorization\nuses AMD ordering to reduce fill-in.\n\nThe base class provides a simple sparse Cholesky implementation with\nsupernodal dense blocks. Derived classes can interface to more\nsophisticated factorizations (MUMPS, Pardiso, TAUCS, etc.).\n\nKey methods:\n- order(): Compute fill-reducing ordering (AMD by default)\n- symbolic(): Set up sparsity structure of factor\n- factorize(): Numeric factorization of A*D*A'\n- solve(): Solve system using computed factors",
    "file": "ClpCholeskyBase",
    "library": "Clp",
    "layer": "layer-1",
    "header": "src/ClpCholeskyBase.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "ClpPEDualRowDantzig": {
    "brief": "Positive Edge enhanced Dantzig pricing for dual simplex",
    "file": "ClpPEDualRowDantzig",
    "library": "Clp",
    "layer": "layer-1",
    "header": "src/ClpPEDualRowDantzig.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "ClpGubDynamicMatrix": {
    "brief": "Dynamic column generation with Generalized Upper Bound structure\n\nCombines GUB constraints with dynamic column generation. Columns are\npartitioned into GUB sets where at most one column per set can be basic.",
    "file": "ClpGubDynamicMatrix",
    "library": "Clp",
    "layer": "layer-1",
    "header": "src/ClpGubDynamicMatrix.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "ClpCholeskyWssmp": {
    "brief": "WSSMP sparse direct solver interface for Cholesky factorization\n\nWraps IBM's Watson Sparse Matrix Package (WSSMP) for Cholesky factorization\nof normal equations in interior point methods.",
    "file": "ClpCholeskyWssmp",
    "library": "Clp",
    "layer": "layer-1",
    "header": "src/ClpCholeskyWssmp.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "ClpPEDualRowSteepest": {
    "brief": "Positive Edge enhanced steepest edge for dual simplex",
    "file": "ClpPEDualRowSteepest",
    "library": "Clp",
    "layer": "layer-1",
    "header": "src/ClpPEDualRowSteepest.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "CoinAbcFactorization": {
    "brief": "ABC optimized LU factorization variants",
    "file": "CoinAbcFactorization",
    "library": "Clp",
    "layer": "layer-1",
    "header": "src/CoinAbcFactorization.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "ClpPESimplex": {
    "brief": "Positive Edge anti-degeneracy framework for simplex",
    "file": "ClpPESimplex",
    "library": "Clp",
    "layer": "layer-1",
    "header": "src/ClpPESimplex.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "AbcPrimalColumnPivot": {
    "brief": "Abstract base class for primal pivot column selection in ABC",
    "file": "AbcPrimalColumnPivot",
    "library": "Clp",
    "layer": "layer-1",
    "header": "src/AbcPrimalColumnPivot.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "CoinAbcBaseFactorization": {
    "brief": "Core ABC SIMD-optimized LU factorization implementation",
    "file": "CoinAbcBaseFactorization",
    "library": "Clp",
    "layer": "layer-1",
    "header": "src/CoinAbcBaseFactorization.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "ClpDynamicMatrix": {
    "brief": "Dynamic column generation matrix with GUB structure\n\nSupports column generation by maintaining a pool of potential columns\nand dynamically adding promising ones to the active working matrix.\nBuilt on GUB structure where each \"set\" can generate multiple columns.",
    "file": "ClpDynamicMatrix",
    "library": "Clp",
    "layer": "layer-1",
    "header": "src/ClpDynamicMatrix.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "CoinAbcCommonFactorization": {
    "brief": "Common infrastructure for ABC SIMD-optimized factorization",
    "file": "CoinAbcCommonFactorization",
    "library": "Clp",
    "layer": "layer-1",
    "header": "src/CoinAbcCommonFactorization.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "OsiClpSolverInterface": {
    "brief": ".NET wrapper for OsiClpSolverInterface (CLP via OSI)\n\nC++/CLI wrapper exposing CLP solver through OSI interface to .NET.\nIncludes matrix access methods and optional CPLEX/Gurobi support.",
    "file": "OsiClpSolverInterface",
    "library": "Sonnet",
    "layer": "layer-4",
    "header": "src/SonnetWrapper/OsiClpSolverInterface.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "Clp_C_Interface": {
    "brief": "C language interface to Clp solver\n\nPure C API for embedding Clp in C programs or creating language bindings.\nDesign follows OSL V3 conventions for familiarity.\n\nOpaque handles:\n- Clp_Simplex: Pointer to internal ClpSimplex object\n- Clp_Solve: Pointer to ClpSolve options object\n\nNaming convention: C++ method foo() becomes Clp_foo(model, ...)\nwhere model is the first parameter.\n\nKey function groups:\n- Construction: Clp_newModel(), Clp_deleteModel()\n- Problem setup: Clp_loadProblem(), Clp_readMps()\n- Solving: Clp_dual(), Clp_primal(), Clp_initialSolve()\n- Solution access: Clp_getColSolution(), Clp_getRowActivity()\n- Parameters: Clp_setLogLevel(), Clp_setMaximumIterations()\n\nCallback support: clp_callback typedef for user message handling.\n\nThread safety: Each Clp_Simplex is independent; do not share across threads.",
    "file": "Clp_C_Interface",
    "library": "Clp",
    "layer": "layer-1",
    "header": "src/Clp_C_Interface.h",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "ClpConfig": {
    "brief": "Clp configuration and platform detection\n\nHandles build configuration for cross-platform compatibility:\n- HAVE_CONFIG_H: Uses autoconf-generated config.h\n- CLPLIB_BUILD: Building the library vs. using it\n- DLL_EXPORT: Windows DLL export declarations\n- GCC visibility: Hidden visibility with explicit exports\n\nDefines CLPLIB_EXPORT macro for public API symbols.\n\nConfiguration precedence:\n1. config.h (autoconf) when HAVE_CONFIG_H defined\n2. config_clp.h for configured installations\n3. config_clp_default.h for manual builds",
    "file": "ClpConfig",
    "library": "Clp",
    "layer": "layer-1",
    "header": "src/ClpConfig.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "atomic_xam": {
    "brief": "CppAD: atomic xam",
    "file": "atomic_xam",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "val_graph/atomic_xam.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "exp_eps": {
    "brief": "CppAD: exp eps",
    "file": "exp_eps",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "introduction/exp_eps.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "exp_2": {
    "brief": "CppAD: exp 2",
    "file": "exp_2",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "introduction/exp_2.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "cppad_ipopt_nlp": {
    "brief": "Ipopt interface: cppad_ipopt_nlp",
    "file": "cppad_ipopt_nlp",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "cppad_ipopt/src/cppad_ipopt_nlp.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "utility": {
    "brief": "CppAD utility: utility",
    "file": "utility",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/utility.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "cppad": {
    "brief": "Contains all variables and functions defined by CppAD package",
    "file": "cppad",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/cppad.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "base_require": {
    "brief": "CppAD: base require",
    "file": "base_require",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/base_require.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "wno_conversion": {
    "brief": "CppAD: wno conversion",
    "file": "wno_conversion",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/wno_conversion.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "solve": {
    "brief": "GPU-accelerated LP and MIP solving functions\n\nMain entry points for linear programming optimization on GPU.\n\n**LP Solving (PDLP):**\n- solve_lp(): GPU-accelerated first-order LP solver\n- Uses Primal-Dual Hybrid Gradient (PDHG) algorithm\n- Supports warm starting from previous solutions\n\n**MIP Solving:**\n- solve_mip(): Mixed-integer programming with GPU B&B\n- Branch-and-bound with LP relaxations\n\n**Input Formats:**\n- optimization_problem_t: Native cuOpt problem representation\n- mps_data_model_t: MPS file format parser output",
    "file": "solve",
    "library": "cuopt",
    "layer": "layer-4",
    "header": "cpp/include/cuopt/linear_programming/solve.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "ad_tape": {
    "brief": "Internal implementation: ad_tape",
    "file": "ad_tape",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/local/ad_tape.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "op_code_dyn": {
    "brief": "Internal implementation: op_code_dyn",
    "file": "op_code_dyn",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/local/op_code_dyn.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "atomic_index": {
    "brief": "Internal implementation: atomic_index",
    "file": "atomic_index",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/local/atomic_index.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "op_code_var": {
    "brief": "Internal implementation: op_code_var",
    "file": "op_code_var",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/local/op_code_var.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "is_pod": {
    "brief": "Internal implementation: is_pod",
    "file": "is_pod",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/local/is_pod.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "set_get_in_parallel": {
    "brief": "Internal implementation: set_get_in_parallel",
    "file": "set_get_in_parallel",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/local/set_get_in_parallel.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "atom_state": {
    "brief": "Internal implementation: atom_state",
    "file": "atom_state",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/local/atom_state.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "temp_file": {
    "brief": "Internal implementation: temp_file",
    "file": "temp_file",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/local/temp_file.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "pod_vector": {
    "brief": "Internal implementation: pod_vector",
    "file": "pod_vector",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/local/pod_vector.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "sparse_jac": {
    "brief": "Sparse Jacobian computation using graph coloring",
    "file": "sparse_jac",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/core/sparse_jac.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "sparse": {
    "brief": "Sparse LP data structures for Creme solver\n\nCore data structure (sparseLP) for randomized LP solving.\nStores constraint matrix in sparse row format with bounds.",
    "file": "sparse",
    "library": "Creme",
    "layer": "layer-4",
    "header": "Creme/src/Base/sparse.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "dependent": {
    "brief": "Core AD functionality: dependent",
    "file": "dependent",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/core/dependent.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "optimize": {
    "brief": "Core AD functionality: optimize",
    "file": "optimize",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/core/optimize.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "bool_fun": {
    "brief": "Core AD functionality: bool fun",
    "file": "bool_fun",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/core/bool_fun.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "sparse_jacobian": {
    "brief": "Core AD functionality: sparse jacobian",
    "file": "sparse_jacobian",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/core/sparse_jacobian.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "user_ad": {
    "brief": "Core AD functionality: user ad",
    "file": "user_ad",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/core/user_ad.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "rev_jac_sparsity": {
    "brief": "Core AD functionality: rev jac sparsity",
    "file": "rev_jac_sparsity",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/core/rev_jac_sparsity.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "unary_plus": {
    "brief": "Core AD functionality: unary plus",
    "file": "unary_plus",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/core/unary_plus.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "con_dyn_var": {
    "brief": "Core AD functionality: con dyn var",
    "file": "con_dyn_var",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/core/con_dyn_var.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "for_jac_sparsity": {
    "brief": "Core AD functionality: for jac sparsity",
    "file": "for_jac_sparsity",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/core/for_jac_sparsity.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "reverse": {
    "brief": "Core AD functionality: reverse",
    "file": "reverse",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/core/atomic/four/reverse.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "convert": {
    "brief": "Core AD functionality: convert",
    "file": "convert",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/core/convert.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "sub_eq": {
    "brief": "Core AD functionality: sub eq",
    "file": "sub_eq",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/core/sub_eq.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "fun_eval": {
    "brief": "Core AD functionality: fun eval",
    "file": "fun_eval",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/core/fun_eval.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "sign": {
    "brief": "Core AD functionality: sign",
    "file": "sign",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/core/sign.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "subgraph_jac_rev": {
    "brief": "Core AD functionality: subgraph jac rev",
    "file": "subgraph_jac_rev",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/core/subgraph_jac_rev.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "epsilon": {
    "brief": "Core AD functionality: epsilon",
    "file": "epsilon",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/core/epsilon.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "ad_valued": {
    "brief": "Core AD functionality: ad valued",
    "file": "ad_valued",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/core/ad_valued.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "drivers": {
    "brief": "Lie derivative computation for nonlinear control systems\n\nComputes Lie derivatives used in nonlinear control theory for:\n- Observability analysis (lie_scalar, lie_gradient)\n- Controllability analysis (lie_covector, lie_bracket)\n\n**Mathematical background:**\nGiven vector field f(x) and scalar function h(x), the Lie derivative is:\n  L_f h = \u2207h \u00b7 f = \u03a3 (\u2202h/\u2202x_i) f_i(x)\n\nHigher-order Lie derivatives (L_f^k h) reveal observability structure.\nLie brackets [f,g] = \u2202g/\u2202x\u00b7f - \u2202f/\u2202x\u00b7g reveal controllability structure.\n\n**Functions:**\n- lie_scalar(): Compute L_f^k h (scalar Lie derivatives)\n- lie_gradient(): Compute \u2207(L_f^k h) (gradients of Lie derivatives)\n- lie_covector(): Compute covector fields\n- lie_bracket(): Compute Lie bracket [f,g]",
    "file": "drivers",
    "library": "ADOL-C",
    "layer": "layer-2",
    "header": "ADOL-C/include/adolc/lie/drivers.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "abort_recording": {
    "brief": "Core AD functionality: abort recording",
    "file": "abort_recording",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/core/abort_recording.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "for_one": {
    "brief": "Core AD functionality: for one",
    "file": "for_one",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/core/for_one.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "div": {
    "brief": "Core AD functionality: div",
    "file": "div",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/core/div.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "mul_eq": {
    "brief": "Core AD functionality: mul eq",
    "file": "mul_eq",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/core/mul_eq.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "opt_val_hes": {
    "brief": "Core AD functionality: opt val hes",
    "file": "opt_val_hes",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/core/opt_val_hes.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "compound_assign": {
    "brief": "Core AD functionality: compound assign",
    "file": "compound_assign",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/core/compound_assign.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "integer": {
    "brief": "Core AD functionality: integer",
    "file": "integer",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/core/integer.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "compare": {
    "brief": "Core AD functionality: compare",
    "file": "compare",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/core/compare.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "ad_fun": {
    "brief": "ADFun class - function object storing recorded AD operations\n\nADFun<Base> stores a recorded sequence of operations and provides\nmethods to evaluate the function and its derivatives.\n\nKey methods:\n- **Forward(p, x)**: p-th order forward mode Taylor coefficient\n- **Reverse(q, w)**: q-th order reverse mode derivative\n- **Jacobian(x)**: Full Jacobian matrix\n- **Hessian(x, w)**: Weighted Hessian matrix\n- **SparseJacobian/SparseHessian**: Sparse derivative computation",
    "file": "ad_fun",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/core/ad_fun.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "value": {
    "brief": "Core AD functionality: value",
    "file": "value",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/core/value.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "unary_minus": {
    "brief": "Core AD functionality: unary minus",
    "file": "unary_minus",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/core/unary_minus.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "ad_io": {
    "brief": "Core AD functionality: ad io",
    "file": "ad_io",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/core/ad_io.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "arithmetic": {
    "brief": "Core AD functionality: arithmetic",
    "file": "arithmetic",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/core/arithmetic.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "subgraph_sparsity": {
    "brief": "Core AD functionality: subgraph sparsity",
    "file": "subgraph_sparsity",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/core/subgraph_sparsity.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "pow": {
    "brief": "Core AD functionality: pow",
    "file": "pow",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/core/pow.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "num_skip": {
    "brief": "Core AD functionality: num skip",
    "file": "num_skip",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/core/num_skip.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "base_double": {
    "brief": "Core AD functionality: base double",
    "file": "base_double",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/core/base_double.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "ad_to_string": {
    "brief": "Core AD functionality: ad to string",
    "file": "ad_to_string",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/core/ad_to_string.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "sparse_hessian": {
    "brief": "Core AD functionality: sparse hessian",
    "file": "sparse_hessian",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/core/sparse_hessian.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "for_two": {
    "brief": "Core AD functionality: for two",
    "file": "for_two",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/core/for_two.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "ad": {
    "brief": "Core AD<Base> automatic differentiation scalar type\n\nAD<Base> is the fundamental type for automatic differentiation.\nOperations on AD<Base> values are recorded on a \"tape\" which can\nlater be used to compute derivatives.",
    "file": "ad",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/core/ad.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "sub": {
    "brief": "Core AD functionality: sub",
    "file": "sub",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/core/sub.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "for_sparse_hes": {
    "brief": "Core AD functionality: for sparse hes",
    "file": "for_sparse_hes",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/core/atomic/two/for_sparse_hes.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "fun_construct": {
    "brief": "Core AD functionality: fun construct",
    "file": "fun_construct",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/core/fun_construct.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "capacity_order": {
    "brief": "Core AD functionality: capacity order",
    "file": "capacity_order",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/core/capacity_order.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "mul": {
    "brief": "Core AD functionality: mul",
    "file": "mul",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/core/mul.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "std_math_11": {
    "brief": "Core AD functionality: std math 11",
    "file": "std_math_11",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/core/std_math_11.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "new_dynamic": {
    "brief": "Core AD functionality: new dynamic",
    "file": "new_dynamic",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/core/new_dynamic.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "base_std_math": {
    "brief": "Core AD functionality: base std math",
    "file": "base_std_math",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/core/base_std_math.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "parallel_ad": {
    "brief": "Core AD functionality: parallel ad",
    "file": "parallel_ad",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/core/parallel_ad.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "base_hash": {
    "brief": "Core AD functionality: base hash",
    "file": "base_hash",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/core/base_hash.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "rev_hes_sparsity": {
    "brief": "Core AD functionality: rev hes sparsity",
    "file": "rev_hes_sparsity",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/core/rev_hes_sparsity.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "rev_one": {
    "brief": "Core AD functionality: rev one",
    "file": "rev_one",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/core/rev_one.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "var2par": {
    "brief": "Core AD functionality: var2par",
    "file": "var2par",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/core/var2par.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "abs": {
    "brief": "Core AD functionality: abs",
    "file": "abs",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/core/abs.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "numeric_limits": {
    "brief": "Core AD functionality: numeric limits",
    "file": "numeric_limits",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/core/numeric_limits.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "print_for": {
    "brief": "Core AD functionality: print for",
    "file": "print_for",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/core/print_for.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "base_float": {
    "brief": "Core AD functionality: base float",
    "file": "base_float",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/core/base_float.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "undef": {
    "brief": "Core AD functionality: undef",
    "file": "undef",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/core/undef.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "cond_exp": {
    "brief": "Operation recording: cond_exp",
    "file": "cond_exp",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/local/record/cond_exp.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "jacobian": {
    "brief": "Core AD functionality: jacobian",
    "file": "jacobian",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/core/jacobian.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "bender_quad": {
    "brief": "Core AD functionality: bender quad",
    "file": "bender_quad",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/core/bender_quad.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "fun_check": {
    "brief": "Core AD functionality: fun check",
    "file": "fun_check",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/core/fun_check.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "rev_two": {
    "brief": "Core AD functionality: rev two",
    "file": "rev_two",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/core/rev_two.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "bool_valued": {
    "brief": "Core AD functionality: bool valued",
    "file": "bool_valued",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/core/bool_valued.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "standard_math": {
    "brief": "Core AD functionality: standard math",
    "file": "standard_math",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/core/standard_math.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "rev_sparse_jac": {
    "brief": "Core AD functionality: rev sparse jac",
    "file": "rev_sparse_jac",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/core/atomic/two/rev_sparse_jac.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "add": {
    "brief": "Core AD functionality: add",
    "file": "add",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/core/add.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "sparse_hes": {
    "brief": "Sparse Hessian computation using automatic differentiation",
    "file": "sparse_hes",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/core/sparse_hes.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "equal_op_seq": {
    "brief": "Core AD functionality: equal op seq",
    "file": "equal_op_seq",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/core/equal_op_seq.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "base_complex": {
    "brief": "Core AD functionality: base complex",
    "file": "base_complex",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/core/base_complex.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "lu_ratio": {
    "brief": "Core AD functionality: lu ratio",
    "file": "lu_ratio",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/core/lu_ratio.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "add_eq": {
    "brief": "Core AD functionality: add eq",
    "file": "add_eq",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/core/add_eq.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "near_equal_ext": {
    "brief": "Core AD functionality: near equal ext",
    "file": "near_equal_ext",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/core/near_equal_ext.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "for_sparse_jac": {
    "brief": "Core AD functionality: for sparse jac",
    "file": "for_sparse_jac",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/core/atomic/two/for_sparse_jac.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "check_for_nan": {
    "brief": "Core AD functionality: check for nan",
    "file": "check_for_nan",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/core/check_for_nan.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "base_cond_exp": {
    "brief": "Core AD functionality: base cond exp",
    "file": "base_cond_exp",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/core/base_cond_exp.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "ad_binary": {
    "brief": "Core AD functionality: ad binary",
    "file": "ad_binary",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/core/ad_binary.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "base_to_string": {
    "brief": "Core AD functionality: base to string",
    "file": "base_to_string",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/core/base_to_string.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "hessian": {
    "brief": "Core AD functionality: hessian",
    "file": "hessian",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/core/hessian.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "rev_sparse_hes": {
    "brief": "Core AD functionality: rev sparse hes",
    "file": "rev_sparse_hes",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/core/atomic/two/rev_sparse_hes.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "zdouble": {
    "brief": "Core AD functionality: zdouble",
    "file": "zdouble",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/core/zdouble.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "abs_normal_fun": {
    "brief": "Core AD functionality: abs normal fun",
    "file": "abs_normal_fun",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/core/abs_normal_fun.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "azmul": {
    "brief": "Core AD functionality: azmul",
    "file": "azmul",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/core/azmul.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "base_limits": {
    "brief": "Core AD functionality: base limits",
    "file": "base_limits",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/core/base_limits.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "for_hes_sparsity": {
    "brief": "Core AD functionality: for hes sparsity",
    "file": "for_hes_sparsity",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/core/for_hes_sparsity.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "atan2": {
    "brief": "Core AD functionality: atan2",
    "file": "atan2",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/core/atan2.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "omp_max_thread": {
    "brief": "Core AD functionality: omp max thread",
    "file": "omp_max_thread",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/core/omp_max_thread.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "ad_type": {
    "brief": "Core AD functionality: ad type",
    "file": "ad_type",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/core/ad_type.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "subgraph_reverse": {
    "brief": "Core AD functionality: subgraph reverse",
    "file": "subgraph_reverse",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/core/subgraph_reverse.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "div_eq": {
    "brief": "Core AD functionality: div eq",
    "file": "div_eq",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/core/div_eq.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "to_csrc": {
    "brief": "Core AD functionality: to csrc",
    "file": "to_csrc",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/core/to_csrc.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "det_by_minor": {
    "brief": "Speed testing: det_by_minor",
    "file": "det_by_minor",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/speed/det_by_minor.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "sparse_jac_fun": {
    "brief": "Speed testing: sparse_jac_fun",
    "file": "sparse_jac_fun",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/speed/sparse_jac_fun.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "mat_sum_sq": {
    "brief": "Speed testing: mat_sum_sq",
    "file": "mat_sum_sq",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/speed/mat_sum_sq.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "ode_evaluate": {
    "brief": "Speed testing: ode_evaluate",
    "file": "ode_evaluate",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/speed/ode_evaluate.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "uniform_01": {
    "brief": "Speed testing: uniform_01",
    "file": "uniform_01",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/speed/uniform_01.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "det_by_lu": {
    "brief": "Speed testing: det_by_lu",
    "file": "det_by_lu",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/speed/det_by_lu.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "det_grad_33": {
    "brief": "Speed testing: det_grad_33",
    "file": "det_grad_33",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/speed/det_grad_33.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "det_of_minor": {
    "brief": "Speed testing: det_of_minor",
    "file": "det_of_minor",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/speed/det_of_minor.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "det_33": {
    "brief": "Speed testing: det_33",
    "file": "det_33",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/speed/det_33.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "sparse_hes_fun": {
    "brief": "Speed testing: sparse_hes_fun",
    "file": "sparse_hes_fun",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/speed/sparse_hes_fun.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "memory_leak": {
    "brief": "CppAD utility: memory leak",
    "file": "memory_leak",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/utility/memory_leak.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "rosen_34": {
    "brief": "CppAD utility: rosen 34",
    "file": "rosen_34",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/utility/rosen_34.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "ode_gear_control": {
    "brief": "CppAD utility: ode gear control",
    "file": "ode_gear_control",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/utility/ode_gear_control.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "ode_err_control": {
    "brief": "CppAD utility: ode err control",
    "file": "ode_err_control",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/utility/ode_err_control.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "near_equal": {
    "brief": "CppAD utility: near equal",
    "file": "near_equal",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/utility/near_equal.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "ode_gear": {
    "brief": "CppAD utility: ode gear",
    "file": "ode_gear",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/utility/ode_gear.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "pow_int": {
    "brief": "CppAD utility: pow int",
    "file": "pow_int",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/utility/pow_int.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "runge_45": {
    "brief": "CppAD utility: runge 45",
    "file": "runge_45",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/utility/runge_45.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "poly": {
    "brief": "Polynomial term representations (linear, quadratic, polynomial)\n\nTerm classes for building polynomial expressions.\n\n**lterm (Linear Term):**\n- _coef: Coefficient (constant or param)\n- _p: Variable/parameter pointer\n- _sign: True if positive, false if negative\n- Represents: \u00b1coef \u00d7 p\n\n**qterm (Quadratic Term):**\n- _coef: Coefficient\n- _p1, _p2: Two variable/parameter pointers\n- _sign: Sign flag\n- Represents: \u00b1coef \u00d7 p1 \u00d7 p2\n\n**pterm (Polynomial Term):**\n- _coef: Coefficient\n- _l: List of (param, power) pairs\n- Represents: coef \u00d7 \u220f(p\u1d62^k\u1d62)\n\n**Usage in Functions:**\n```cpp\nfunc.add_lterm(coef, x);      // coef*x\nfunc.add_qterm(coef, x, y);   // coef*x*y\n```",
    "file": "poly",
    "library": "Gravity",
    "layer": "layer-4",
    "header": "include/gravity/poly.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "lu_solve": {
    "brief": "CppAD utility: lu solve",
    "file": "lu_solve",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/utility/lu_solve.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "vector": {
    "brief": "CppAD utility: vector",
    "file": "vector",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/utility/vector.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "track_new_del": {
    "brief": "CppAD utility: track new del",
    "file": "track_new_del",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/utility/track_new_del.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "lu_factor": {
    "brief": "CppAD utility: lu factor",
    "file": "lu_factor",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/utility/lu_factor.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "omp_alloc": {
    "brief": "CppAD utility: omp alloc",
    "file": "omp_alloc",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/utility/omp_alloc.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "nan": {
    "brief": "CppAD utility: nan",
    "file": "nan",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/utility/nan.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "set_union": {
    "brief": "CppAD utility: set union",
    "file": "set_union",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/utility/set_union.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "sparse2eigen": {
    "brief": "CppAD utility: sparse2eigen",
    "file": "sparse2eigen",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/utility/sparse2eigen.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "error_handler": {
    "brief": "CppAD utility: error handler",
    "file": "error_handler",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/utility/error_handler.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "link_dll_lib": {
    "brief": "CppAD utility: link dll lib",
    "file": "link_dll_lib",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/utility/link_dll_lib.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "to_string": {
    "brief": "CppAD utility: to string",
    "file": "to_string",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/utility/to_string.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "lu_invert": {
    "brief": "CppAD utility: lu invert",
    "file": "lu_invert",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/utility/lu_invert.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "create_dll_lib": {
    "brief": "CppAD utility: create dll lib",
    "file": "create_dll_lib",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/utility/create_dll_lib.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "check_simple_vector": {
    "brief": "CppAD utility: check simple vector",
    "file": "check_simple_vector",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/utility/check_simple_vector.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "sparse_rc": {
    "brief": "CppAD utility: sparse rc",
    "file": "sparse_rc",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/utility/sparse_rc.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "elapsed_seconds": {
    "brief": "CppAD utility: elapsed seconds",
    "file": "elapsed_seconds",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/utility/elapsed_seconds.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "romberg_one": {
    "brief": "CppAD utility: romberg one",
    "file": "romberg_one",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/utility/romberg_one.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "check_numeric_type": {
    "brief": "CppAD utility: check numeric type",
    "file": "check_numeric_type",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/utility/check_numeric_type.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "sparse_rcv": {
    "brief": "CppAD utility: sparse rcv",
    "file": "sparse_rcv",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/utility/sparse_rcv.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "vector_bool": {
    "brief": "CppAD utility: vector bool",
    "file": "vector_bool",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/local/utility/vector_bool.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "romberg_mul": {
    "brief": "CppAD utility: romberg mul",
    "file": "romberg_mul",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/utility/romberg_mul.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "pack_setvec": {
    "brief": "Internal implementation: pack_setvec",
    "file": "pack_setvec",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/local/sparse/pack_setvec.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "list_setvec": {
    "brief": "Internal implementation: list_setvec",
    "file": "list_setvec",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/local/sparse/list_setvec.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "size_setvec": {
    "brief": "Internal implementation: size_setvec",
    "file": "size_setvec",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/local/sparse/size_setvec.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "val_type": {
    "brief": "Value graph: val_type",
    "file": "val_type",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/local/val_graph/val_type.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "record_new": {
    "brief": "Value graph: record_new",
    "file": "record_new",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/local/val_graph/record_new.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "rev_depend": {
    "brief": "Core AD functionality: rev depend",
    "file": "rev_depend",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/core/atomic/four/rev_depend.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "renumber": {
    "brief": "Value graph: renumber",
    "file": "renumber",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/local/val_graph/renumber.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "vector_op": {
    "brief": "Value graph: vector_op",
    "file": "vector_op",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/local/val_graph/vector_op.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "op2arg_index": {
    "brief": "Value graph: op2arg_index",
    "file": "op2arg_index",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/local/val_graph/op2arg_index.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "compress": {
    "brief": "Value graph: compress",
    "file": "compress",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/local/val_graph/compress.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "val2fun": {
    "brief": "Value graph: val2fun",
    "file": "val2fun",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/local/val_graph/val2fun.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "op_hash_table": {
    "brief": "Value graph: op_hash_table",
    "file": "op_hash_table",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/local/val_graph/op_hash_table.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "val_optimize": {
    "brief": "Value graph: val_optimize",
    "file": "val_optimize",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/local/val_graph/val_optimize.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "cumulative": {
    "brief": "Value graph: cumulative",
    "file": "cumulative",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/local/val_graph/cumulative.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "enable_parallel": {
    "brief": "Value graph: enable_parallel",
    "file": "enable_parallel",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/local/val_graph/enable_parallel.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "pri_op": {
    "brief": "Internal implementation: pri_op",
    "file": "pri_op",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/local/var_op/pri_op.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "option": {
    "brief": "Core AD functionality: option",
    "file": "option",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/core/atomic/two/option.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "csum_op": {
    "brief": "Internal implementation: csum_op",
    "file": "csum_op",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/local/var_op/csum_op.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "print_op": {
    "brief": "Value graph: print_op",
    "file": "print_op",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/local/val_graph/print_op.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "record": {
    "brief": "Value graph: record",
    "file": "record",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/local/val_graph/record.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "op_iterator": {
    "brief": "Value graph: op_iterator",
    "file": "op_iterator",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/local/val_graph/op_iterator.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "dead_code": {
    "brief": "Value graph: dead_code",
    "file": "dead_code",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/local/val_graph/dead_code.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "tape": {
    "brief": "Value graph: tape",
    "file": "tape",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/local/val_graph/tape.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "unary_op": {
    "brief": "Value graph: unary_op",
    "file": "unary_op",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/local/val_graph/unary_op.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "call_op": {
    "brief": "Value graph: call_op",
    "file": "call_op",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/local/val_graph/call_op.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "con_op": {
    "brief": "Value graph: con_op",
    "file": "con_op",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/local/val_graph/con_op.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "base_op": {
    "brief": "Value graph: base_op",
    "file": "base_op",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/local/val_graph/base_op.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "fun2val": {
    "brief": "Value graph: fun2val",
    "file": "fun2val",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/local/val_graph/fun2val.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "comp_op": {
    "brief": "Operation recording: comp_op",
    "file": "comp_op",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/local/record/comp_op.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "op_enum2class": {
    "brief": "Value graph: op_enum2class",
    "file": "op_enum2class",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/local/val_graph/op_enum2class.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "summation": {
    "brief": "Value graph: summation",
    "file": "summation",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/local/val_graph/summation.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "binary_op": {
    "brief": "Value graph: binary_op",
    "file": "binary_op",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/local/val_graph/binary_op.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "cexp_op": {
    "brief": "Internal implementation: cexp_op",
    "file": "cexp_op",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/local/var_op/cexp_op.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "call_atomic": {
    "brief": "Internal sweep implementation: call_atomic",
    "file": "call_atomic",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/local/sweep/call_atomic.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "fold_con": {
    "brief": "Value graph: fold_con",
    "file": "fold_con",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/local/val_graph/fold_con.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "var_type": {
    "brief": "Value graph: var_type",
    "file": "var_type",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/local/val_graph/var_type.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "dis_op": {
    "brief": "Internal implementation: dis_op",
    "file": "dis_op",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/local/var_op/dis_op.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "dyn_type": {
    "brief": "Value graph: dyn_type",
    "file": "dyn_type",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/local/val_graph/dyn_type.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "cskip_op": {
    "brief": "Internal implementation: cskip_op",
    "file": "cskip_op",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/local/var_op/cskip_op.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "add_op": {
    "brief": "Internal implementation: add_op",
    "file": "add_op",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/local/var_op/add_op.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "two_var": {
    "brief": "Internal implementation: two_var",
    "file": "two_var",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/local/var_op/two_var.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "zmul_op": {
    "brief": "Internal implementation: zmul_op",
    "file": "zmul_op",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/local/var_op/zmul_op.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "par_op": {
    "brief": "Internal implementation: par_op",
    "file": "par_op",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/local/var_op/par_op.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "store_op": {
    "brief": "Internal implementation: store_op",
    "file": "store_op",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/local/var_op/store_op.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "sqrt_op": {
    "brief": "Internal implementation: sqrt_op",
    "file": "sqrt_op",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/local/var_op/sqrt_op.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "acosh_op": {
    "brief": "Internal implementation: acosh_op",
    "file": "acosh_op",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/local/var_op/acosh_op.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "sinh_op": {
    "brief": "Internal implementation: sinh_op",
    "file": "sinh_op",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/local/var_op/sinh_op.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "tanh_op": {
    "brief": "Internal implementation: tanh_op",
    "file": "tanh_op",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/local/var_op/tanh_op.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "sin_op": {
    "brief": "Internal implementation: sin_op",
    "file": "sin_op",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/local/var_op/sin_op.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "var_op": {
    "brief": "Internal implementation: var_op",
    "file": "var_op",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/local/var_op/var_op.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "atanh_op": {
    "brief": "Internal implementation: atanh_op",
    "file": "atanh_op",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/local/var_op/atanh_op.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "cosh_op": {
    "brief": "Internal implementation: cosh_op",
    "file": "cosh_op",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/local/var_op/cosh_op.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "compare_op": {
    "brief": "Internal implementation: compare_op",
    "file": "compare_op",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/local/var_op/compare_op.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "mul_op": {
    "brief": "Internal implementation: mul_op",
    "file": "mul_op",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/local/var_op/mul_op.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "exp_op": {
    "brief": "Internal implementation: exp_op",
    "file": "exp_op",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/local/var_op/exp_op.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "asinh_op": {
    "brief": "Internal implementation: asinh_op",
    "file": "asinh_op",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/local/var_op/asinh_op.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "atomic_op": {
    "brief": "Internal implementation: atomic_op",
    "file": "atomic_op",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/local/var_op/atomic_op.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "sub_op": {
    "brief": "Internal implementation: sub_op",
    "file": "sub_op",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/local/var_op/sub_op.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "log_op": {
    "brief": "Internal implementation: log_op",
    "file": "log_op",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/local/var_op/log_op.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "asin_op": {
    "brief": "Internal implementation: asin_op",
    "file": "asin_op",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/local/var_op/asin_op.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "expm1_op": {
    "brief": "Internal implementation: expm1_op",
    "file": "expm1_op",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/local/var_op/expm1_op.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "tan_op": {
    "brief": "Internal implementation: tan_op",
    "file": "tan_op",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/local/var_op/tan_op.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "load_op": {
    "brief": "Internal implementation: load_op",
    "file": "load_op",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/local/var_op/load_op.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "neg_op": {
    "brief": "Internal implementation: neg_op",
    "file": "neg_op",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/local/var_op/neg_op.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "atan_op": {
    "brief": "Internal implementation: atan_op",
    "file": "atan_op",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/local/var_op/atan_op.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "sign_op": {
    "brief": "Internal implementation: sign_op",
    "file": "sign_op",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/local/var_op/sign_op.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "log1p_op": {
    "brief": "Internal implementation: log1p_op",
    "file": "log1p_op",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/local/var_op/log1p_op.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "div_op": {
    "brief": "Internal implementation: div_op",
    "file": "div_op",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/local/var_op/div_op.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "one_var": {
    "brief": "Internal implementation: one_var",
    "file": "one_var",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/local/var_op/one_var.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "cos_op": {
    "brief": "Internal implementation: cos_op",
    "file": "cos_op",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/local/var_op/cos_op.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "abs_op": {
    "brief": "Internal implementation: abs_op",
    "file": "abs_op",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/local/var_op/abs_op.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "acos_op": {
    "brief": "Internal implementation: acos_op",
    "file": "acos_op",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/local/var_op/acos_op.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "get_op_usage": {
    "brief": "Tape optimization: get_op_usage",
    "file": "get_op_usage",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/local/optimize/get_op_usage.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "usage": {
    "brief": "Tape optimization: usage",
    "file": "usage",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/local/optimize/usage.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "record_csum": {
    "brief": "Tape optimization: record_csum",
    "file": "record_csum",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/local/optimize/record_csum.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "get_op_previous": {
    "brief": "Tape optimization: get_op_previous",
    "file": "get_op_previous",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/local/optimize/get_op_previous.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "match_op": {
    "brief": "Tape optimization: match_op",
    "file": "match_op",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/local/optimize/match_op.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "optimize_run": {
    "brief": "Tape optimization: optimize_run",
    "file": "optimize_run",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/local/optimize/optimize_run.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "cexp_info": {
    "brief": "Tape optimization: cexp_info",
    "file": "cexp_info",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/local/optimize/cexp_info.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "extract_option": {
    "brief": "Tape optimization: extract_option",
    "file": "extract_option",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/local/optimize/extract_option.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "get_cexp_info": {
    "brief": "Tape optimization: get_cexp_info",
    "file": "get_cexp_info",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/local/optimize/get_cexp_info.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "dyn_player": {
    "brief": "Tape playback: dyn_player",
    "file": "dyn_player",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/local/play/dyn_player.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "cppad_vector_itr": {
    "brief": "CppAD utility: cppad vector itr",
    "file": "cppad_vector_itr",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/local/utility/cppad_vector_itr.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "recorder": {
    "brief": "Operation recording: recorder",
    "file": "recorder",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/local/record/recorder.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "put_var_atomic": {
    "brief": "Operation recording: put_var_atomic",
    "file": "put_var_atomic",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/local/record/put_var_atomic.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "put_var_vecad": {
    "brief": "Operation recording: put_var_vecad",
    "file": "put_var_vecad",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/local/record/put_var_vecad.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "put_dyn_atomic": {
    "brief": "Operation recording: put_dyn_atomic",
    "file": "put_dyn_atomic",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/local/record/put_dyn_atomic.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "dyn_recorder": {
    "brief": "Operation recording: dyn_recorder",
    "file": "dyn_recorder",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/local/record/dyn_recorder.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "csrc_writer": {
    "brief": "Computational graph: csrc_writer",
    "file": "csrc_writer",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/local/graph/csrc_writer.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "cpp_graph_op": {
    "brief": "Computational graph: cpp_graph_op",
    "file": "cpp_graph_op",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/local/graph/cpp_graph_op.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "cpp_graph_itr": {
    "brief": "Computational graph: cpp_graph_itr",
    "file": "cpp_graph_itr",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/local/graph/cpp_graph_itr.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "json_writer": {
    "brief": "Computational graph: json_writer",
    "file": "json_writer",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/local/graph/json_writer.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "json_parser": {
    "brief": "Computational graph: json_parser",
    "file": "json_parser",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/local/graph/json_parser.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "json_lexer": {
    "brief": "Computational graph: json_lexer",
    "file": "json_lexer",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/local/graph/json_lexer.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "forward_any": {
    "brief": "Internal sweep implementation: forward_any",
    "file": "forward_any",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/local/sweep/forward_any.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "forward_0": {
    "brief": "Internal sweep implementation: forward_0",
    "file": "forward_0",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/local/sweep/forward_0.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "for_hes": {
    "brief": "Internal sweep implementation: for_hes",
    "file": "for_hes",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/local/sweep/for_hes.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "forward_dir": {
    "brief": "Internal sweep implementation: forward_dir",
    "file": "forward_dir",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/local/sweep/forward_dir.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "rev_jac": {
    "brief": "Internal sweep implementation: rev_jac",
    "file": "rev_jac",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/local/sweep/rev_jac.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "set_hes_sparse_bool": {
    "brief": "Core AD functionality: set hes sparse bool",
    "file": "set_hes_sparse_bool",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/core/chkpoint_one/set_hes_sparse_bool.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "set_jac_sparse_bool": {
    "brief": "Core AD functionality: set jac sparse bool",
    "file": "set_jac_sparse_bool",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/core/chkpoint_one/set_jac_sparse_bool.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "ctor": {
    "brief": "Core AD functionality: ctor",
    "file": "ctor",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/core/atomic/four/ctor.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "set_hes_sparse_set": {
    "brief": "Core AD functionality: set hes sparse set",
    "file": "set_hes_sparse_set",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/core/chkpoint_one/set_hes_sparse_set.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "set_jac_sparse_set": {
    "brief": "Core AD functionality: set jac sparse set",
    "file": "set_jac_sparse_set",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/core/chkpoint_one/set_jac_sparse_set.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "forward": {
    "brief": "Core AD functionality: forward",
    "file": "forward",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/core/atomic/four/forward.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "discrete": {
    "brief": "Core AD functionality: discrete",
    "file": "discrete",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/core/discrete/discrete.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "vec_ad": {
    "brief": "Core AD functionality: vec ad",
    "file": "vec_ad",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/core/vec_ad/vec_ad.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "graph_op_enum": {
    "brief": "Core AD functionality: graph op enum",
    "file": "graph_op_enum",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/core/graph/graph_op_enum.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "to_json": {
    "brief": "Core AD functionality: to json",
    "file": "to_json",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/core/graph/to_json.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "to_graph": {
    "brief": "Core AD functionality: to graph",
    "file": "to_graph",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/core/graph/to_graph.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "cpp_graph": {
    "brief": "Core AD functionality: cpp graph",
    "file": "cpp_graph",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/core/graph/cpp_graph.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "from_json": {
    "brief": "Core AD functionality: from json",
    "file": "from_json",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/core/graph/from_json.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "from_graph": {
    "brief": "Core AD functionality: from graph",
    "file": "from_graph",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/core/graph/from_graph.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "independent": {
    "brief": "Core AD functionality: independent",
    "file": "independent",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/core/independent/independent.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "atomic": {
    "brief": "Core AD functionality: atomic",
    "file": "atomic",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/core/atomic/four/atomic.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "for_type": {
    "brief": "Core AD functionality: for type",
    "file": "for_type",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/core/atomic/four/for_type.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "hes_sparsity": {
    "brief": "Core AD functionality: hes sparsity",
    "file": "hes_sparsity",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/core/atomic/four/devel/hes_sparsity.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "jac_sparsity": {
    "brief": "Core AD functionality: jac sparsity",
    "file": "jac_sparsity",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/core/atomic/four/devel/jac_sparsity.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "call": {
    "brief": "Core AD functionality: call",
    "file": "call",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "include/cppad/core/atomic/four/call.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "adolc_alloc_mat": {
    "brief": "Speed testing: adolc_alloc_mat",
    "file": "adolc_alloc_mat",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "speed/adolc/adolc_alloc_mat.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "link_sparse_jacobian": {
    "brief": "Speed testing: link_sparse_jacobian",
    "file": "link_sparse_jacobian",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "speed/src/link_sparse_jacobian.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "link_sparse_hessian": {
    "brief": "Speed testing: link_sparse_hessian",
    "file": "link_sparse_hessian",
    "library": "CppAD",
    "layer": "layer-1",
    "header": "speed/src/link_sparse_hessian.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "OsiSpxSolverInterface": {
    "brief": "Osi interface for SoPlex LP solver\nAuthors: Tobias Pfender, Ambros Gleixner, Wei Huang (ZIB Berlin).\nEPL license.\n\nOsiSpxSolverInterface wraps SoPlex >= 1.4.2c via the Osi abstraction.\nImplements initialSolve/resolve/branchAndBound, parameter get/set,\nrow/column access, warm start via CoinWarmStartBasis. Uses soplex::SoPlex\ninternally with DVector/DIdxSet for sparse operations.",
    "file": "OsiSpxSolverInterface",
    "library": "Osi",
    "layer": "layer-1",
    "header": "src/OsiSpx/OsiSpxSolverInterface.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "OsiGrbSolverInterface": {
    "brief": "Osi interface for Gurobi optimizer\nAuthor: Stefan Vigerske (HU Berlin), based on Cplex interface by T. Achterberg.\nEPL license.\n\nOsiGrbSolverInterface wraps Gurobi via the Osi abstraction. Uses GRBmodel\nand GRBenv handles for Gurobi C API. Implements initialSolve/resolve/\nbranchAndBound, row/column manipulation, warm starts, and parameter passing.",
    "file": "OsiGrbSolverInterface",
    "library": "Osi",
    "layer": "layer-1",
    "header": "src/OsiGrb/OsiGrbSolverInterface.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "OsiXprSolverInterface": {
    "brief": "Osi interface for FICO XPRESS-MP solver\nCopyright (C) 2000, International Business Machines Corporation.\nEPL-1.0 license.\n\nOsiXprSolverInterface wraps XPRESS-MP via the Osi abstraction. Uses XPRSprob\nhandle for XPRESS API. Implements initialSolve/resolve/branchAndBound,\nrow/column access, parameter get/set, and problem loading from MPS/LP files.",
    "file": "OsiXprSolverInterface",
    "library": "Osi",
    "layer": "layer-1",
    "header": "src/OsiXpr/OsiXprSolverInterface.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "OsiGlpkSolverInterface": {
    "brief": "Osi interface for GNU Linear Programming Kit (GLPK)\nCopyright (C) 2001, Vivian De Smedt, Braden Hunsaker. EPL license.\n\nOsiGlpkSolverInterface wraps GLPK via the Osi abstraction. Uses glp_prob\nhandle (LPX typedef for compatibility). Implements initialSolve/resolve/\nbranchAndBound, warm starts via CoinWarmStartBasis, and GLPK-specific\nparameter handling. Supports both simplex and MIP solving.",
    "file": "OsiGlpkSolverInterface",
    "library": "Osi",
    "layer": "layer-1",
    "header": "src/OsiGlpk/OsiGlpkSolverInterface.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "OsiCpxSolverInterface": {
    "brief": "Osi interface for IBM ILOG CPLEX optimizer\nAuthor: Tobias Pfender (ZIB Berlin). EPL license.\n\nOsiCpxSolverInterface wraps CPLEX via the Osi abstraction. Uses CPXLPptr\nand CPXENVptr handles for CPLEX Callable Library. Implements initialSolve/\nresolve/branchAndBound, row/column manipulation (OsiRowCut, OsiColCut),\nwarm starts via CoinWarmStartBasis, and CPLEX-specific parameter handling.",
    "file": "OsiCpxSolverInterface",
    "library": "Osi",
    "layer": "layer-1",
    "header": "src/OsiCpx/OsiCpxSolverInterface.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "OsiAuxInfo": {
    "brief": "Auxiliary information for algorithm-specific solver customization",
    "file": "OsiAuxInfo",
    "library": "Osi",
    "layer": "layer-1",
    "header": "src/Osi/OsiAuxInfo.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "OsiRowCut": {
    "brief": "Row-based cutting plane (linear inequality)\n\nRow cuts are the most common form of cutting planes, representing\na linear inequality constraint: lb <= a'x <= ub",
    "file": "OsiRowCut",
    "library": "Osi",
    "layer": "layer-1",
    "header": "src/Osi/OsiRowCut.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "OsiCollections": {
    "brief": "STL container typedefs for Osi cut and data collections\nCopyright (C) 2000, International Business Machines Corporation.\nEPL-1.0 license.\n\nStandard typedefs: OsiVectorInt, OsiVectorDouble, OsiVectorColCutPtr,\nOsiVectorRowCutPtr, OsiVectorCutPtr. Provides cleaner syntax for\nfrequently-used vector types throughout Osi code.",
    "file": "OsiCollections",
    "library": "Osi",
    "layer": "layer-1",
    "header": "src/Osi/OsiCollections.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "OsiBranchingObject": {
    "brief": "Branch-and-bound objects and branching decisions\n\nThis file defines the object-oriented framework for branching in MIP:\n\n- **OsiObject**: Abstract base for anything that can be branched on\n  (integer variables, SOS constraints, etc.)\n- **OsiBranchingObject**: Describes how to perform a specific branch\n- **OsiBranchingInformation**: Solver state passed to branching decisions",
    "file": "OsiBranchingObject",
    "library": "Osi",
    "layer": "layer-1",
    "header": "src/Osi/OsiBranchingObject.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "OsiRowCutDebugger": {
    "brief": "Validate cuts against known optimal solutions",
    "file": "OsiRowCutDebugger",
    "library": "Osi",
    "layer": "layer-1",
    "header": "src/Osi/OsiRowCutDebugger.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "OsiFeatures": {
    "brief": "MIP problem features for algorithm selection and parameter tuning",
    "file": "OsiFeatures",
    "library": "Osi",
    "layer": "layer-1",
    "header": "src/Osi/OsiFeatures.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "OsiSolverParameters": {
    "brief": "Parameter enums for cross-solver configuration in Osi\nCopyright (C) 2000, International Business Machines Corporation.\nEPL-1.0 license.\n\nDefines OsiIntParam (iteration limits, name discipline), OsiDblParam\n(objective limits, tolerances, offset), OsiStrParam (problem/solver names),\nOsiHintParam (crash, presolve, scaling, pivoting hints with OsiHintStrength).\nSolvers implement these via get/setIntParam, get/setDblParam, etc.",
    "file": "OsiSolverParameters",
    "library": "Osi",
    "layer": "layer-1",
    "header": "src/Osi/OsiSolverParameters.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "OsiChooseVariable": {
    "brief": "Variable selection strategies for branch-and-bound\n\nIn MIP solving, choosing which variable to branch on significantly\naffects tree size and solve time. This file provides:\n\n- OsiChooseVariable: Base class for branching variable selection\n- OsiChooseStrong: Strong branching (evaluates candidates by solving LPs)",
    "file": "OsiChooseVariable",
    "library": "Osi",
    "layer": "layer-1",
    "header": "src/Osi/OsiChooseVariable.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "OsiSolverBranch": {
    "brief": "Branch information with tighter bounds for both directions",
    "file": "OsiSolverBranch",
    "library": "Osi",
    "layer": "layer-1",
    "header": "src/Osi/OsiSolverBranch.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "OsiPresolve": {
    "brief": "OSI interface to problem simplification (presolve)\n\nPresolve reduces problem size before solving by applying\ntransformations that preserve optimal solutions:\n- Singleton row/column removal\n- Bound tightening\n- Coefficient reduction\n- Duplicate row/column detection",
    "file": "OsiPresolve",
    "library": "Osi",
    "layer": "layer-1",
    "header": "src/Osi/OsiPresolve.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "OsiCuts": {
    "brief": "Container for collections of row cuts and column cuts",
    "file": "OsiCuts",
    "library": "Osi",
    "layer": "layer-1",
    "header": "src/Osi/OsiCuts.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "OsiColCut": {
    "brief": "Column-based cuts for variable bound tightening\n\nColumn cuts represent bound changes on variables rather than\nadding new constraints. They are used for:\n- Bound tightening from probing\n- Implication-based bound strengthening\n- Reduced cost fixing",
    "file": "OsiColCut",
    "library": "Osi",
    "layer": "layer-1",
    "header": "src/Osi/OsiColCut.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "OsiSolverInterface": {
    "brief": ".NET wrapper for OsiSolverInterface (Open Solver Interface)\n\nC++/CLI wrapper exposing OsiSolverInterface to .NET languages.",
    "file": "OsiSolverInterface",
    "library": "Sonnet",
    "layer": "layer-4",
    "header": "src/SonnetWrapper/OsiSolverInterface.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "OsiCut": {
    "brief": "Abstract base class for cutting planes in branch-and-cut\n\nCutting planes are linear inequalities that can be added to an LP\nrelaxation to tighten the formulation without cutting off any\ninteger-feasible solutions.",
    "file": "OsiCut",
    "library": "Osi",
    "layer": "layer-1",
    "header": "src/Osi/OsiCut.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "OsiMskSolverInterface": {
    "brief": "Osi interface for MOSEK optimizer (version 5.0+)\nAuthor: Bo Jensen (MOSEK ApS). EPL license.\n\nOsiMskSolverInterface wraps MOSEK via the Osi abstraction. Uses MSKtask_t\nand MSKenv_t handles (void* for forward declaration without mosek.h).\nImplements initialSolve/resolve/branchAndBound, parameter handling, and\nsupports LP/MIP/QP/conic solving through MOSEK's unified interface.",
    "file": "OsiMskSolverInterface",
    "library": "Osi",
    "layer": "layer-1",
    "header": "src/OsiMsk/OsiMskSolverInterface.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "qpOASES": {
    "brief": "Main include file for qpOASES quadratic programming solver\n\nqpOASES solves convex quadratic programs (QPs) of the form:",
    "file": "qpOASES",
    "library": "qpOASES",
    "layer": "layer-1",
    "header": "include/qpOASES.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "ConstraintProduct": {
    "brief": "User-defined constraint evaluation interface for structured matrices",
    "file": "ConstraintProduct",
    "library": "qpOASES",
    "layer": "layer-1",
    "header": "include/qpOASES/ConstraintProduct.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "SparseSolver": {
    "brief": "Sparse linear solver interfaces for Schur-complement QP method",
    "file": "SparseSolver",
    "library": "qpOASES",
    "layer": "layer-1",
    "header": "include/qpOASES/SparseSolver.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "SQProblemSchur": {
    "brief": "Sparse QP solver using Schur complement for active-set updates",
    "file": "SQProblemSchur",
    "library": "qpOASES",
    "layer": "layer-1",
    "header": "include/qpOASES/SQProblemSchur.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "Bounds": {
    "brief": "",
    "file": "Bounds",
    "library": "qpOASES",
    "layer": "layer-1",
    "header": "include/qpOASES/Bounds.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "Constraints": {
    "brief": "Constraint hierarchy: linear, quadratic, and nonlinear\n\nConstraint classes forming an inheritance hierarchy.\n\n**Constraint Properties:**\n- classification: Linear, Quadratic, Signomial, Nonlinear\n- convexity: Linear, Convex, Concave, Nonconvex, Unknown\n- type: Equality, LessThan, GreaterThan\n\n**NumericConstraintValue Struct:**\n- functionValue: f(x) at evaluation point\n- normalizedLHSValue: L - f(x), normalizedRHSValue: f(x) - U\n- error: max(0, max(L - f(x), f(x) - U))\n\n**Constraint Class Hierarchy:**\n- Constraint (abstract): Base with index, name, properties\n- NumericConstraint: LHS/RHS bounds, gradient/Hessian computation\n- LinearConstraint: linearTerms, sparse gradient\n- QuadraticConstraint: + quadraticTerms, Hessian\n- NonlinearConstraint: + monomials, signomials, nonlinearExpression\n\n**Derivative Computation:**\n- calculateGradient(): Sparse first derivatives\n- calculateHessian(): Upper triangular second derivatives\n- Sparsity patterns for efficient NLP solver interfaces",
    "file": "Constraints",
    "library": "SHOT",
    "layer": "layer-4",
    "header": "src/Model/Constraints.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "QProblemB": {
    "brief": "Box-constrained QP solver (bounds only, no linear constraints)\n\nSolves QPs with only variable bounds (no constraint matrix A):",
    "file": "QProblemB",
    "library": "qpOASES",
    "layer": "layer-1",
    "header": "include/qpOASES/QProblemB.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "SQProblem": {
    "brief": "Sequential QP solver with varying Hessian and constraint matrices\n\nSQProblem extends QProblem to handle QPs where the Hessian H and\nconstraint matrix A change between solves. This is common in:\n- Nonlinear MPC (linearization changes each step)\n- Sequential Quadratic Programming (SQP) for NLP\n- Moving horizon estimation",
    "file": "SQProblem",
    "library": "qpOASES",
    "layer": "layer-1",
    "header": "include/qpOASES/SQProblem.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "Options": {
    "brief": "Configuration options for qpOASES QP solver\n\nThe Options class controls solver behavior including:\n- Termination criteria (tolerances, iteration limits)\n- Numerical parameters (regularization, pivoting)\n- Output/printing verbosity\n- Initial homotopy and scaling options\n\nPreset configurations:\n- setToDefault(): Balanced defaults\n- setToReliable(): Maximum robustness\n- setToMPC(): Fast for model predictive control\n- setToFast(): Maximum speed, less robust",
    "file": "Options",
    "library": "qpOASES",
    "layer": "layer-1",
    "header": "include/qpOASES/Options.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "Indexlist": {
    "brief": "Sorted index lists for efficient working set operations",
    "file": "Indexlist",
    "library": "qpOASES",
    "layer": "layer-1",
    "header": "include/qpOASES/Indexlist.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "QProblem": {
    "brief": "QP solver with general linear constraints\n\nSolves convex QPs with bounds and linear constraints:",
    "file": "QProblem",
    "library": "qpOASES",
    "layer": "layer-1",
    "header": "include/qpOASES/QProblem.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "Flipper": {
    "brief": "",
    "file": "Flipper",
    "library": "qpOASES",
    "layer": "layer-1",
    "header": "include/qpOASES/Flipper.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "Matrices": {
    "brief": "Matrix classes for QP data with working-set-aware operations",
    "file": "Matrices",
    "library": "qpOASES",
    "layer": "layer-1",
    "header": "include/qpOASES/Matrices.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "SubjectTo": {
    "brief": "Base class for working set management in active-set QP",
    "file": "SubjectTo",
    "library": "qpOASES",
    "layer": "layer-1",
    "header": "include/qpOASES/SubjectTo.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "LapackBlasReplacement": {
    "brief": "LAPACK/BLAS interface declarations for qpOASES linear algebra",
    "file": "LapackBlasReplacement",
    "library": "qpOASES",
    "layer": "layer-1",
    "header": "include/qpOASES/LapackBlasReplacement.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "SolutionAnalysis": {
    "brief": "Post-optimality analysis: KKT verification and sensitivity",
    "file": "SolutionAnalysis",
    "library": "qpOASES",
    "layer": "layer-1",
    "header": "include/qpOASES/extras/SolutionAnalysis.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "OQPinterface": {
    "brief": "Online QP Benchmark Collection interface",
    "file": "OQPinterface",
    "library": "qpOASES",
    "layer": "layer-1",
    "header": "include/qpOASES/extras/OQPinterface.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "pydirectors": {
    "brief": "Python director classes for external differentiated functions",
    "file": "pydirectors",
    "library": "ADOL-C",
    "layer": "layer-2",
    "header": "ADOL-C/swig/pydirectors.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "adolc_all_in": {
    "brief": "Unified ADOL-C header for SWIG bindings",
    "file": "adolc_all_in",
    "library": "ADOL-C",
    "layer": "layer-2",
    "header": "ADOL-C/swig/adolc_all_in.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "pyedfclasses": {
    "brief": "Python wrapper classes for external differentiated functions",
    "file": "pyedfclasses",
    "library": "ADOL-C",
    "layer": "layer-2",
    "header": "ADOL-C/swig/pyedfclasses.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "adubswigfuncs": {
    "brief": "SWIG operator overloads for badouble/adub types",
    "file": "adubswigfuncs",
    "library": "ADOL-C",
    "layer": "layer-2",
    "header": "ADOL-C/swig/adubswigfuncs.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "matrixmemory": {
    "brief": "C-style multi-dimensional array allocation for SWIG",
    "file": "matrixmemory",
    "library": "ADOL-C",
    "layer": "layer-2",
    "header": "ADOL-C/swig/matrixmemory.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "checkpointing": {
    "brief": "Checkpointing support for memory-efficient reverse mode AD\n\nImplements checkpointing (also known as \"time-stepping\" or \"revolve\")\nfor computing adjoints of long time-stepping computations with bounded\nmemory. Instead of storing all intermediate states, only selected\n\"checkpoints\" are stored, and segments are recomputed as needed.",
    "file": "checkpointing",
    "library": "ADOL-C",
    "layer": "layer-2",
    "header": "ADOL-C/include/adolc/checkpointing.h",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "adolc": {
    "brief": "Master include file for ADOL-C automatic differentiation library\n\nADOL-C (Automatic Differentiation by Overloading in C++) computes derivatives\nof mathematical functions via operator overloading and tape-based recording.\nRecords computation as a \"tape\" then replays in forward/reverse mode.",
    "file": "adolc",
    "library": "ADOL-C",
    "layer": "layer-2",
    "header": "ADOL-C/include/adolc/adolc.h",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "adolc_sparse": {
    "brief": "Convenience header for sparse derivative computation\n\nInclude this file to access all sparse derivative functionality:\n- sparse_jac(): Sparse Jacobian computation\n- sparse_hess(): Sparse Hessian computation\n- jac_pat() / hess_pat(): Sparsity pattern detection\n- Bit-pattern forward/reverse modes",
    "file": "adolc_sparse",
    "library": "ADOL-C",
    "layer": "layer-2",
    "header": "ADOL-C/include/adolc/adolc_sparse.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "revolve": {
    "brief": "Optimal binomial checkpointing for memory-efficient reverse mode\n\nImplements the revolve algorithm (Griewank & Walther) for optimal\ncheckpoint placement in reverse mode automatic differentiation.",
    "file": "revolve",
    "library": "ADOL-C",
    "layer": "layer-2",
    "header": "ADOL-C/include/adolc/revolve.h",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "externfcts": {
    "brief": "Support for externally differentiated functions in ADOL-C tapes\n\nProvides mechanisms to incorporate user-supplied derivative code for\nfunctions that cannot or should not be traced (e.g., library calls,\nspecialized solvers, discontinuous functions). The user registers\ncallback functions for forward and reverse mode evaluation.\n\nUse cases:\n- Integrating external solvers (linear algebra, sparse systems)\n- Hand-coded derivatives for performance-critical sections\n- Functions from non-ADOL-C libraries\n- Discontinuous or non-differentiable operations with custom handling\n\nCallback modes:\n- zos_forward: zero-order scalar (function evaluation only)\n- fos_forward/fos_reverse: first-order scalar\n- fov_forward/fov_reverse: first-order vector\n- hos_forward/hos_reverse: higher-order scalar\n- hov_forward/hov_reverse: higher-order vector",
    "file": "externfcts",
    "library": "ADOL-C",
    "layer": "layer-2",
    "header": "ADOL-C/include/adolc/externfcts.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "adolcerror": {
    "brief": "Exception class for ADOL-C errors with source location tracking.\n\nThis exception captures the error message and the source location (file,\nline, column) where it was thrown. Integrates with the C++ standard exception\nhierarchy through std::runtime_error.\n\n@example\nThrow example:\n@code\nthrow ADOLCError(\"wrong number of independents\");  // Auto-captures source\nlocation\n@endcode\n\nHandle example:\n@code\ntry {\n  // ADOL-C operations...\n}\ncatch (ADOLCError& e) {\n  std::cerr << e.what() << std::endl;         // Formatted message\n  std::cerr << \"Error occurred at: \"\n            << e.where().file() << \":\"\n            << e.where().func() << \":\"\n            << e.where().line() << std::endl; // Direct source location\naccess\n}\n@endcode",
    "file": "adolcerror",
    "library": "ADOL-C",
    "layer": "layer-2",
    "header": "ADOL-C/include/adolc/adolcerror.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "adtl": {
    "brief": "Tape-less (traceless) forward-mode automatic differentiation\n\nProvides the adtl::adouble class for direct forward-mode AD without\ntape recording. Each adouble carries both its value and directional\nderivatives, which are propagated immediately through operations.",
    "file": "adtl",
    "library": "ADOL-C",
    "layer": "layer-2",
    "header": "ADOL-C/include/adolc/adtl.h",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "tape_interface": {
    "brief": "Tape management interface for ADOL-C automatic differentiation\n\nProvides functions for managing the \"tape\" - a recorded sequence of\noperations that can be replayed in forward or reverse mode to compute\nderivatives.",
    "file": "tape_interface",
    "library": "ADOL-C",
    "layer": "layer-2",
    "header": "ADOL-C/include/adolc/tape_interface.h",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "adtb_types": {
    "brief": "Core AD types: adouble, pdouble, and tape_location\n\nDefines the fundamental types for tape-based automatic differentiation:\n\n- **adouble**: Active double that records operations on the tape.\n  Use for variables whose derivatives you want to compute.\n\n- **pdouble**: Parameter double for non-differentiable constants that\n  can be changed without re-taping. Use for parameters you want to\n  vary across multiple derivative evaluations.\n\n- **tape_location<T>**: RAII wrapper managing tape location allocation\n  and deallocation for adouble/pdouble.",
    "file": "adtb_types",
    "library": "ADOL-C",
    "layer": "layer-2",
    "header": "ADOL-C/include/adolc/adtb_types.h",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "fixpoint": {
    "brief": "Differentiation through fixed-point iterations\n\nEnables automatic differentiation of implicit functions defined as\nfixed points x* = G(x*, u), where u are parameters.\n\n**Problem:** Many numerical methods involve iterative solvers:\n- Newton's method: x_{k+1} = x_k - f(x_k)/f'(x_k)\n- Nonlinear system solvers\n- Implicit time integrators\n\n**Solution:** fp_iteration() differentiates through the converged result\nwithout differentiating through all iteration steps, using the implicit\nfunction theorem: dx",
    "file": "fixpoint",
    "library": "ADOL-C",
    "layer": "layer-2",
    "header": "ADOL-C/include/adolc/fixpoint.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "advector": {
    "brief": "Traceable vector with differentiable subscript operations\n\nProvides advector, a vector of adoubles that can trace subscripting\nwith adouble indices. This enables automatic differentiation through\narray lookups where the index itself depends on independent variables.\n\n**Key classes:**\n- advector: Vector container with contiguous tape locations\n- adubref: Reference type returned when indexing with adouble (lvalue case)\n\n**Use case example:**\n@code\nadvector table(n);        // Create table of adoubles\nadouble index = ...;      // Index depends on independent variables\nadouble result = table[index];  // Differentiation tracks index dependency\n@endcode\n\n@note This is only for taped (not tapeless) ADOL-C mode",
    "file": "advector",
    "library": "ADOL-C",
    "layer": "layer-2",
    "header": "ADOL-C/include/adolc/advector.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "edfclasses": {
    "brief": "Object-oriented interface for external differentiated functions\n\nProvides C++ class-based wrappers for external functions with user-supplied\nderivatives. Inherit from these base classes to integrate external code\n(e.g., legacy Fortran, optimized BLAS, specialized solvers) into AD.\n\n**Classes:**\n- EDFobject: Basic external function with fixed array sizes\n- EDFobject_iArr: External function with integer array parameters\n- EDFobject_v2: Version 2 interface with variable-size arrays and context\n\n**Required overrides:**\n- function(): Evaluate the external function\n- zos_forward(): Zero-order scalar (function evaluation during taping)\n- fos_forward(): First-order scalar forward mode\n- fov_forward(): First-order vector forward mode\n- fos_reverse(): First-order scalar reverse mode\n- fov_reverse(): First-order vector reverse mode",
    "file": "edfclasses",
    "library": "ADOL-C",
    "layer": "layer-2",
    "header": "ADOL-C/include/adolc/edfclasses.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "interfaces": {
    "brief": "Low-level forward and reverse mode interfaces for tape evaluation\n\nProvides the core differentiation routines that evaluate recorded tapes\nin forward mode (computing directional derivatives) and reverse mode\n(computing adjoints/gradients). These are the building blocks used by\nhigher-level drivers like gradient() and hessian().",
    "file": "interfaces",
    "library": "ADOL-C",
    "layer": "layer-2",
    "header": "ADOL-C/include/adolc/interfaces.h",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "sparsedrivers": {
    "brief": "High-level drivers for sparse Jacobian and Hessian computation\n\nProvides efficient computation of sparse derivatives by exploiting\nsparsity structure using graph coloring and compressed computation.",
    "file": "sparsedrivers",
    "library": "ADOL-C",
    "layer": "layer-2",
    "header": "ADOL-C/include/adolc/sparse/sparsedrivers.h",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "sparse_fo_rev": {
    "brief": "Bit-pattern propagation for sparsity detection\n\nProvides forward and reverse mode interfaces that propagate bit patterns\ninstead of numerical values. Used to efficiently determine the sparsity\nstructure of Jacobian and Hessian matrices.\n\nBit patterns are packed into size_t words for efficiency. For n independent\nvariables, the seed matrix X[n][p] uses p = ceil(n / bits_per_long) words\nper row, where bits_per_long = 8 * sizeof(size_t).\n\nTwo modes:\n- **Tight**: Uses actual values x[] during propagation (more accurate)\n- **Safe**: Uses only bit patterns (faster, may overestimate sparsity)",
    "file": "sparse_fo_rev",
    "library": "ADOL-C",
    "layer": "layer-2",
    "header": "ADOL-C/include/adolc/sparse/sparse_fo_rev.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "taylor": {
    "brief": "Higher-order derivative tensors and implicit function differentiation\n\nProvides drivers for computing higher-order derivative tensors and\ndifferentiating through implicit/inverse functions.",
    "file": "taylor",
    "library": "ADOL-C",
    "layer": "layer-2",
    "header": "ADOL-C/include/adolc/drivers/taylor.h",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "odedrivers": {
    "brief": "Taylor-based ODE integration drivers\n\nProvides drivers for solving and differentiating ODEs of the form\nx' = f(x) using Taylor series expansion. The tape records f(x),\nthen these drivers compute higher-order Taylor coefficients.",
    "file": "odedrivers",
    "library": "ADOL-C",
    "layer": "layer-2",
    "header": "ADOL-C/include/adolc/drivers/odedrivers.h",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "psdrivers": {
    "brief": "Drivers for piecewise smooth (PS) functions with abs-normal form\n\nProvides differentiation tools for functions containing absolute values\nand other piecewise linear operations. These functions are not classically\ndifferentiable at kink points, but have well-defined generalized derivatives.",
    "file": "psdrivers",
    "library": "ADOL-C",
    "layer": "layer-2",
    "header": "ADOL-C/include/adolc/drivers/psdrivers.h",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "CbcConsequence": {
    "brief": "Abstract base for bound implications from branching",
    "file": "CbcConsequence",
    "library": "Cbc",
    "layer": "layer-2",
    "header": "src/CbcConsequence.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "CbcSOS": {
    "brief": "Special Ordered Sets (SOS) Type 1 and Type 2 branching\nCopyright (C) 2002, IBM Corporation and others. All Rights Reserved.\nThis code is licensed under the terms of the Eclipse Public License (EPL).\n\nCbcSOS: Branching for Special Ordered Sets (Beale & Tomlin, 1970):\n\nSOS Type 1: At most ONE variable can be nonzero\n- Common for selection between alternatives (choose one option)\n- SUM x_i <= 1 (or = 1 for exactly one)\n- Binary SOS1 is a special case of clique\n\nSOS Type 2: At most TWO CONSECUTIVE variables can be nonzero\n- Used for piecewise linear approximation (interpolation)\n- Variables ordered by weights; sum to 1\n- Represents point between two breakpoints",
    "file": "CbcSOS",
    "library": "Cbc",
    "layer": "layer-2",
    "header": "src/CbcSOS.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "CbcBranchDecision": {
    "brief": "Abstract base for branching variable selection\nCopyright (C) 2002, IBM Corporation and others. All Rights Reserved.\nThis code is licensed under the terms of the Eclipse Public License (EPL).",
    "file": "CbcBranchDecision",
    "library": "Cbc",
    "layer": "layer-2",
    "header": "src/CbcBranchDecision.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "CbcHeuristicVND": {
    "brief": "VND - Variable Neighborhood Descent\nCopyright (C) 2006, IBM Corporation and others. All Rights Reserved.\nThis code is licensed under the terms of the Eclipse Public License (EPL).\n\nCbcHeuristicVND: Variable Neighborhood Descent metaheuristic.\nSystematically explores neighborhoods of increasing size.",
    "file": "CbcHeuristicVND",
    "library": "Cbc",
    "layer": "layer-2",
    "header": "src/CbcHeuristicVND.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "CbcFathom": {
    "brief": "Fathoming methods to complete subproblems",
    "file": "CbcFathom",
    "library": "Cbc",
    "layer": "layer-2",
    "header": "src/CbcFathom.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "CbcDebug": {
    "brief": "Debugging utilities and test message handlers\n\nCbcDebug: Contains debug memory allocation routines and test message handlers.\n\nFeatures when CLP_DEBUG_MALLOC defined:\n- clp_memory(): Memory debugging\n- clp_malloc()/clp_free(): Custom allocation with tracking\n\nFeatures when TEST_MESSAGE_HANDLER defined:\n- MyMessageHandler2: Example custom message handler\n- Demonstrates trapping and customizing Cbc messages\n- Prefixes messages with \"==\" for identification\n\nThis file is primarily for testing and debugging purposes.\nProduction builds typically have neither macro defined.",
    "file": "CbcDebug",
    "library": "Cbc",
    "layer": "layer-2",
    "header": "src/CbcDebug.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "CbcGenMessages": {
    "brief": "Message IDs for cbc-generic standalone solver\nCopyright (C) 2007, Lou Hafer, IBM Corporation and others.\nThis code is licensed under the terms of the Eclipse Public License (EPL).\n\nCbcGenMsgCode: Enum of message IDs for the cbc-generic application.\nThese are distinct from CbcMessage (library messages) and are used\nonly by the standalone command-line solver.\n\nMessage codes:\n- CBCGEN_TEST_MSG: Test/debug message\n- CBCGEN_NEW_SOLVER: Solver change notification\n- CBCGEN_CONFUSION: Error/confusion state\n\nThe actual message text is defined in CbcGenMessages.cpp.",
    "file": "CbcGenMessages",
    "library": "Cbc",
    "layer": "layer-2",
    "header": "src/CbcGenMessages.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "CbcHeuristic": {
    "brief": "Base class for MIP primal heuristics\nCopyright (C) 2002, IBM Corporation and others. All Rights Reserved.\nThis code is licensed under the terms of the Eclipse Public License (EPL).",
    "file": "CbcHeuristic",
    "library": "Cbc",
    "layer": "layer-2",
    "header": "src/CbcHeuristic.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "CbcGeneralDepth": {
    "brief": "Depth-limited partial evaluation branching",
    "file": "CbcGeneralDepth",
    "library": "Cbc",
    "layer": "layer-2",
    "header": "src/CbcGeneralDepth.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "CbcHeuristicLocal": {
    "brief": "Local search and related improvement heuristics\nCopyright (C) 2002, IBM Corporation and others. All Rights Reserved.\nThis code is licensed under the terms of the Eclipse Public License (EPL).\n\nContains several improvement heuristics for MIP:",
    "file": "CbcHeuristicLocal",
    "library": "Cbc",
    "layer": "layer-2",
    "header": "src/CbcHeuristicLocal.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "CbcObject": {
    "brief": "Abstract base for branching entities (variables, SOS, etc.)",
    "file": "CbcObject",
    "library": "Cbc",
    "layer": "layer-2",
    "header": "src/CbcObject.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "CbcCompare": {
    "brief": "Functor wrapper for node comparison",
    "file": "CbcCompare",
    "library": "Cbc",
    "layer": "layer-2",
    "header": "src/CbcCompare.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "CbcCompareDefault": {
    "brief": "Default adaptive node comparison strategy\nCopyright (C) 2002, IBM Corporation and others. All Rights Reserved.\nThis code is licensed under the terms of the Eclipse Public License (EPL).",
    "file": "CbcCompareDefault",
    "library": "Cbc",
    "layer": "layer-2",
    "header": "src/CbcCompareDefault.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "CbcHeuristicDINS": {
    "brief": "DINS - Distance-Induced Neighborhood Search\nCopyright (C) 2006, IBM Corporation and others. All Rights Reserved.\nThis code is licensed under the terms of the Eclipse Public License (EPL).\n\nCbcHeuristicDINS: Uses multiple solutions to define neighborhoods.\nMaintains a pool of solutions and fixes variables based on\nagreement across the solution pool (Ghosh 2007).",
    "file": "CbcHeuristicDINS",
    "library": "Cbc",
    "layer": "layer-2",
    "header": "src/CbcHeuristicDINS.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "CbcNodeInfo": {
    "brief": "Persistent information for recreating search tree nodes",
    "file": "CbcNodeInfo",
    "library": "Cbc",
    "layer": "layer-2",
    "header": "src/CbcNodeInfo.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "CbcHeuristicDiveFractional": {
    "brief": "Dive heuristic selecting most fractional variable\nCopyright (C) 2008, IBM Corporation and others. All Rights Reserved.\nThis code is licensed under the terms of the Eclipse Public License (EPL).\n\nCbcHeuristicDiveFractional: Simplest diving strategy.\nSelects the variable with value closest to 0.5 (most fractional).",
    "file": "CbcHeuristicDiveFractional",
    "library": "Cbc",
    "layer": "layer-2",
    "header": "src/CbcHeuristicDiveFractional.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "CbcCutModifier": {
    "brief": "Abstract base class for cut modification",
    "file": "CbcCutModifier",
    "library": "Cbc",
    "layer": "layer-2",
    "header": "src/CbcCutModifier.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "CbcCompareActual": {
    "brief": "Aggregator header for concrete comparison classes",
    "file": "CbcCompareActual",
    "library": "Cbc",
    "layer": "layer-2",
    "header": "src/CbcCompareActual.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "CbcSolverHeuristics": {
    "brief": "Heuristic setup and execution routines for cbc-generic",
    "file": "CbcSolverHeuristics",
    "library": "Cbc",
    "layer": "layer-2",
    "header": "src/CbcSolverHeuristics.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "CbcHeuristicGreedy": {
    "brief": "Greedy construction heuristics for set covering/partitioning\nCopyright (C) 2005, IBM Corporation and others. All Rights Reserved.\nThis code is licensed under the terms of the Eclipse Public License (EPL).\n\nContains greedy heuristics suited for set covering/partitioning models:",
    "file": "CbcHeuristicGreedy",
    "library": "Cbc",
    "layer": "layer-2",
    "header": "src/CbcHeuristicGreedy.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "CbcSymmetry": {
    "brief": "Symmetry detection and orbital branching using nauty\nAuthors: Pietro Belotti (Lehigh), Andreas Waechter (IBM)\nAdapted from Couenne (Carnegie-Mellon University, 2006-11)\nThis file is licensed under the Eclipse Public License (EPL)\n\nCbcSymmetry: Detects problem symmetry and exploits it for faster solving.\nUses the nauty library for automorphism group computation.",
    "file": "CbcSymmetry",
    "library": "Cbc",
    "layer": "layer-2",
    "header": "src/CbcSymmetry.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "CbcBranchActual": {
    "brief": "Aggregator for concrete branching classes",
    "file": "CbcBranchActual",
    "library": "Cbc",
    "layer": "layer-2",
    "header": "src/CbcBranchActual.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "CbcHeuristicDiveCoefficient": {
    "brief": "Dive heuristic based on objective coefficients\nCopyright (C) 2008, IBM Corporation and others. All Rights Reserved.\nThis code is licensed under the terms of the Eclipse Public License (EPL).\n\nCbcHeuristicDiveCoefficient: Selects variables based on objective impact.\nPrioritizes fractional variables with large objective coefficients.",
    "file": "CbcHeuristicDiveCoefficient",
    "library": "Cbc",
    "layer": "layer-2",
    "header": "src/CbcHeuristicDiveCoefficient.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "CbcBranchBase": {
    "brief": "Base includes for CBC branching model",
    "file": "CbcBranchBase",
    "library": "Cbc",
    "layer": "layer-2",
    "header": "src/CbcBranchBase.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "CbcGeneral": {
    "brief": "Abstract base for general multi-way branching",
    "file": "CbcGeneral",
    "library": "Cbc",
    "layer": "layer-2",
    "header": "src/CbcGeneral.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "CbcHeuristicDiveGuided": {
    "brief": "Dive heuristic guided by incumbent solution\nCopyright (C) 2008, IBM Corporation and others. All Rights Reserved.\nThis code is licensed under the terms of the Eclipse Public License (EPL).\n\nCbcHeuristicDiveGuided: Uses existing incumbent to guide diving.\nRequires a feasible solution (canHeuristicRun checks this).",
    "file": "CbcHeuristicDiveGuided",
    "library": "Cbc",
    "layer": "layer-2",
    "header": "src/CbcHeuristicDiveGuided.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "CbcLinked": {
    "brief": "Extended solver for nonlinear and bilinear problems",
    "file": "CbcLinked",
    "library": "Cbc",
    "layer": "layer-2",
    "header": "src/CbcLinked.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "CbcCutGenerator": {
    "brief": "Interface between Cbc and Cut Generation Library (CGL)\nCopyright (C) 2003, IBM Corporation and others. All Rights Reserved.\nThis code is licensed under the terms of the Eclipse Public License (EPL).\n\nCbcCutGenerator: Wraps a CglCutGenerator with Cbc-specific controls.\nManages when and how cut generation is called during B&C search.\n\nKey control parameters:\n- whenCutGenerator_: Frequency (every N nodes, -100=disabled, -99=root only)\n- depthCutGenerator_: Depth-based triggering\n- switches_: Bit flags for various options (normal, atSolution, timing, etc.)\n\nStatistics tracked:\n- numberTimes_: Times generator was called\n- numberCuts_: Total cuts generated\n- numberCutsActive_: Cuts still binding at end\n- timeInCutGenerator_: CPU time spent\n\nSupports adaptive behavior:\n- Can be switched off if ineffective\n- Tracks cuts at root vs tree\n- Global cuts and Lagrangean relaxation support",
    "file": "CbcCutGenerator",
    "library": "Cbc",
    "layer": "layer-2",
    "header": "src/CbcCutGenerator.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "CbcEventHandler": {
    "brief": ".NET wrapper for CBC event handling\n\nCbcEvent enum (node, solution, treeStatus, endSearch, etc.) and\nCbcAction enum (noAction, stop, restart, killSolution).\nCbcDelegateEventHandlerProxy bridges .NET delegates to native callbacks.",
    "file": "CbcEventHandler",
    "library": "Sonnet",
    "layer": "layer-4",
    "header": "src/SonnetWrapper/CbcEventHandler.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "CbcSolverAnalyze": {
    "brief": "Problem analysis for integer constraint detection",
    "file": "CbcSolverAnalyze",
    "library": "Cbc",
    "layer": "layer-2",
    "header": "src/CbcSolverAnalyze.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "CbcPartialNodeInfo": {
    "brief": "Incremental subproblem storage as differences from parent",
    "file": "CbcPartialNodeInfo",
    "library": "Cbc",
    "layer": "layer-2",
    "header": "src/CbcPartialNodeInfo.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "CbcCutSubsetModifier": {
    "brief": "Cut modifier that filters cuts based on variable indices",
    "file": "CbcCutSubsetModifier",
    "library": "Cbc",
    "layer": "layer-2",
    "header": "src/CbcCutSubsetModifier.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "ClpConstraintAmpl": {
    "brief": "AMPL-interface constraint for nonlinear Clp extensions",
    "file": "ClpConstraintAmpl",
    "library": "Cbc",
    "layer": "layer-2",
    "header": "src/ClpConstraintAmpl.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "CbcSimpleIntegerDynamicPseudoCost": {
    "brief": "Integer variable with dynamic (learning) pseudocosts\nCopyright (C) 2005, IBM Corporation and others. All Rights Reserved.\nThis code is licensed under the terms of the Eclipse Public License (EPL).\n\nCbcSimpleIntegerDynamicPseudoCost: Implements reliability branching\nbased on Achterberg, Koch & Martin's work. Pseudocosts are learned\nfrom actual branching history rather than being static estimates.\n\nKey statistics tracked per variable:\n- sumUpCost_/sumDownCost_: Cumulative objective changes\n- numberTimesUp_/Down_: Branch count for averaging\n- numberBeforeTrust_: Initialization threshold before trusting estimates",
    "file": "CbcSimpleIntegerDynamicPseudoCost",
    "library": "Cbc",
    "layer": "layer-2",
    "header": "src/CbcSimpleIntegerDynamicPseudoCost.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "CbcSimpleIntegerPseudoCost": {
    "brief": "Integer variable with static pseudocosts\nCopyright (C) 2002, IBM Corporation and others. All Rights Reserved.\nThis code is licensed under the terms of the Eclipse Public License (EPL).\n\nCbcSimpleIntegerPseudoCost: Extends CbcSimpleInteger with static\npseudocost estimates for branch direction preference:\n- upPseudoCost_: Estimated objective increase per unit ceiling\n- downPseudoCost_: Estimated objective increase per unit floor",
    "file": "CbcSimpleIntegerPseudoCost",
    "library": "Cbc",
    "layer": "layer-2",
    "header": "src/CbcSimpleIntegerPseudoCost.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "CbcSubProblem": {
    "brief": "Compact subproblem state for diving heuristics",
    "file": "CbcSubProblem",
    "library": "Cbc",
    "layer": "layer-2",
    "header": "src/CbcSubProblem.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "CbcMipStartIO": {
    "brief": "Read MIP starting solutions from files",
    "file": "CbcMipStartIO",
    "library": "Cbc",
    "layer": "layer-2",
    "header": "src/CbcMipStartIO.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "CbcDummyBranchingObject": {
    "brief": "No-op branching object for special cases",
    "file": "CbcDummyBranchingObject",
    "library": "Cbc",
    "layer": "layer-2",
    "header": "src/CbcDummyBranchingObject.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "CbcHeuristicDiveVectorLength": {
    "brief": "Dive heuristic based on constraint participation\nCopyright (C) 2008, IBM Corporation and others. All Rights Reserved.\nThis code is licensed under the terms of the Eclipse Public License (EPL).\n\nCbcHeuristicDiveVectorLength: Selects variables by column density.\nVariables appearing in many constraints are fixed first.",
    "file": "CbcHeuristicDiveVectorLength",
    "library": "Cbc",
    "layer": "layer-2",
    "header": "src/CbcHeuristicDiveVectorLength.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "CbcCompareDepth": {
    "brief": "Depth-first node selection strategy\nCopyright (C) 2002, IBM Corporation and others. All Rights Reserved.\nThis code is licensed under the terms of the Eclipse Public License (EPL).\n\nCbcCompareDepth: Implements depth-first search (DFS).\nDefault strategy before first solution is found.\n\ntest(x,y) returns true if y is deeper than x in the tree.\nDeepest nodes explored first -> LIFO stack behavior.",
    "file": "CbcCompareDepth",
    "library": "Cbc",
    "layer": "layer-2",
    "header": "src/CbcCompareDepth.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "CbcBranchingObject": {
    "brief": "Abstract base for branching actions",
    "file": "CbcBranchingObject",
    "library": "Cbc",
    "layer": "layer-2",
    "header": "src/CbcBranchingObject.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "CbcNWay": {
    "brief": "N-way branching (exactly one variable at upper bound)\nCopyright (C) 2002, IBM Corporation and others. All Rights Reserved.\nThis code is licensed under the terms of the Eclipse Public License (EPL).\n\nCbcNWay: Multi-way (N-ary) branching for selection constraints.\nExactly one variable at upper bound, all others at lower bound.\nCreates N children, each fixing one variable to its UB.",
    "file": "CbcNWay",
    "library": "Cbc",
    "layer": "layer-2",
    "header": "src/CbcNWay.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "CbcHeuristicPivotAndFix": {
    "brief": "Pivot and Fix heuristic using simplex pivots\nCopyright (C) 2008, IBM Corporation and others. All Rights Reserved.\nThis code is licensed under the terms of the Eclipse Public License (EPL).\n\nCbcHeuristicPivotAndFix: Exploits LP basis structure.\nPerforms simplex pivots to explore nearby basic solutions,\nthen fixes integer variables at their current values.",
    "file": "CbcHeuristicPivotAndFix",
    "library": "Cbc",
    "layer": "layer-2",
    "header": "src/CbcHeuristicPivotAndFix.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "CbcMessage": {
    "brief": "Message IDs and handler for Cbc output\nCopyright (C) 2002, IBM Corporation and others. All Rights Reserved.\nThis code is licensed under the terms of the Eclipse Public License (EPL).\n\nCbcMessage: Defines message IDs (CBC_Message enum) for Cbc logging.\nUses COIN message handling framework (CoinMessageHandler).\n\nKey message categories:\n- CBC_SOLUTION: Integer solution found\n- CBC_STATUS/CBC_STATUS2/CBC_STATUS3: Progress reports\n- CBC_GAP: Optimality gap information\n- CBC_ROOT: Root node summary\n- CBC_GENERATOR: Cut generator statistics\n- CBC_BRANCH: Branching decisions\n- CBC_THREAD_STATS: Parallel statistics\n\nText in CbcMessage.cpp supports multiple languages (default: us_en).",
    "file": "CbcMessage",
    "library": "Cbc",
    "layer": "layer-2",
    "header": "src/CbcMessage.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "CbcHeuristicRandRound": {
    "brief": "Randomized rounding heuristic\nCopyright (C) 2008, IBM Corporation and others. All Rights Reserved.\nThis code is licensed under the terms of the Eclipse Public License (EPL).\n\nCbcHeuristicRandRound: Probabilistic rounding of LP solution.\nRounds fractional variables randomly with probabilities based on\ntheir fractional values (e.g., x=0.7 rounds up with prob 0.7).",
    "file": "CbcHeuristicRandRound",
    "library": "Cbc",
    "layer": "layer-2",
    "header": "src/CbcHeuristicRandRound.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "ClpAmplObjective": {
    "brief": "AMPL-interface nonlinear objective for Clp",
    "file": "ClpAmplObjective",
    "library": "Cbc",
    "layer": "layer-2",
    "header": "src/ClpAmplObjective.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "CbcModel": {
    "brief": ".NET wrapper for CbcModel (COIN-OR Branch and Cut)\n\nC++/CLI wrapper exposing CBC MIP solver to .NET languages.\nWraps branch-and-bound with cut generation capabilities.",
    "file": "CbcModel",
    "library": "Sonnet",
    "layer": "layer-4",
    "header": "src/SonnetWrapper/CbcModel.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "CbcFullNodeInfo": {
    "brief": "Complete subproblem state storage (typically for root node)",
    "file": "CbcFullNodeInfo",
    "library": "Cbc",
    "layer": "layer-2",
    "header": "src/CbcFullNodeInfo.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "CbcParamUtils": {
    "brief": "Utility functions for parameter handling in cbc-generic\nCopyright (C) 2007, Lou Hafer, IBM Corporation and others.\nThis code is licensed under the terms of the Eclipse Public License (EPL).\n\nCbcParamUtils namespace: Callback functions for parameter processing.\nThese are invoked when parameters are set via the command line.\n\nSolution I/O:\n- saveSolution(): Write solution to file\n- readSolution(): Load solution from file\n\nAction handlers (doXxxParam):\n- doBaCParam(): Execute branch-and-cut solve\n- doImportParam(): Load problem from file\n- doSolutionParam(): Write/print solution\n- doHelpParam(): Display help information\n- doExitParam(): Exit the program\n\nPush functions (pushCbcSolverXxxParam):\n- Transfer parameter values to solver/model\n- Separate handlers for Dbl, Int, Kwd, Str, Bool types\n- Special handlers for Cut and Heur parameters\n\nModel parameter handlers:\n- pushCbcModelDblParam/IntParam(): Set CbcModel parameters\n- setCbcModelDefaults(): Initialize model with default values",
    "file": "CbcParamUtils",
    "library": "Cbc",
    "layer": "layer-2",
    "header": "src/CbcParamUtils.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "CbcTreeLocal": {
    "brief": "Local branching search tree (Fischetti-Lodi 2002)\nCopyright (C) 2004, IBM Corporation and others. All Rights Reserved.\nThis code is licensed under the terms of the Eclipse Public License (EPL).",
    "file": "CbcTreeLocal",
    "library": "Cbc",
    "layer": "layer-2",
    "header": "src/CbcTreeLocal.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "CbcBranchLotsize": {
    "brief": "Lot-sizing variable with discrete valid values\nCopyright (C) 2004, IBM Corporation and others. All Rights Reserved.\nThis code is licensed under the terms of the Eclipse Public License (EPL).\n\nCbcLotsize: Variable restricted to specific discrete values (lot sizes).\nUnlike integers (any value in range), lot-sizing variables can only\ntake values from a predefined set: {v1, v2, ..., vn}.",
    "file": "CbcBranchLotsize",
    "library": "Cbc",
    "layer": "layer-2",
    "header": "src/CbcBranchLotsize.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "CbcHeuristicDivePseudoCost": {
    "brief": "Dive heuristic using pseudocost estimates\nCopyright (C) 2008, IBM Corporation and others. All Rights Reserved.\nThis code is licensed under the terms of the Eclipse Public License (EPL).\n\nCbcHeuristicDivePseudoCost: Most informed diving strategy.\nUses pseudocosts to estimate objective change from fixing.",
    "file": "CbcHeuristicDivePseudoCost",
    "library": "Cbc",
    "layer": "layer-2",
    "header": "src/CbcHeuristicDivePseudoCost.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "CbcFollowOn": {
    "brief": "Follow-on branching for crew scheduling problems\nCopyright (C) 2002, IBM Corporation and others. All Rights Reserved.\nThis code is licensed under the terms of the Eclipse Public License (EPL).\n\nCbcFollowOn: Specialized branching for air-crew scheduling and\nsimilar set-partitioning problems. When crew can fly in on flight A\nand out on flight B (or other flights), branch on the connection.",
    "file": "CbcFollowOn",
    "library": "Cbc",
    "layer": "layer-2",
    "header": "src/CbcFollowOn.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "CbcObjectUpdateData": {
    "brief": "Data carrier for updating branching objects after branching",
    "file": "CbcObjectUpdateData",
    "library": "Cbc",
    "layer": "layer-2",
    "header": "src/CbcObjectUpdateData.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "CbcBranchDynamic": {
    "brief": "Dynamic pseudocost-based branching decision\nCopyright (C) 2005, IBM Corporation and others. All Rights Reserved.\nThis code is licensed under the terms of the Eclipse Public License (EPL).\n\nCbcBranchDynamicDecision: Selects branches using dynamic pseudocosts.\n- Before first solution: Uses infeasibility counts\n- After first solution: Uses objective change estimates\n\nPseudocosts are updated during search based on observed\nobjective changes from actual branching decisions.",
    "file": "CbcBranchDynamic",
    "library": "Cbc",
    "layer": "layer-2",
    "header": "src/CbcBranchDynamic.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "CbcCountRowCut": {
    "brief": "Reference-counted row cuts with ownership tracking",
    "file": "CbcCountRowCut",
    "library": "Cbc",
    "layer": "layer-2",
    "header": "src/CbcCountRowCut.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "CbcNode": {
    "brief": "Search tree node for branch-and-cut\nCopyright (C) 2002, IBM Corporation and others. All Rights Reserved.\nThis code is licensed under the terms of the Eclipse Public License (EPL).",
    "file": "CbcNode",
    "library": "Cbc",
    "layer": "layer-2",
    "header": "src/CbcNode.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "CbcHeuristicFPump": {
    "brief": "Feasibility Pump heuristic (Fischetti, Glover & Lodi)\nCopyright (C) 2004, IBM Corporation and others. All Rights Reserved.\nThis code is licensed under the terms of the Eclipse Public License (EPL).",
    "file": "CbcHeuristicFPump",
    "library": "Cbc",
    "layer": "layer-2",
    "header": "src/CbcHeuristicFPump.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "CbcBranchToFixLots": {
    "brief": "Branch to fix many variables simultaneously\nCopyright (C) 2004, IBM Corporation and others. All Rights Reserved.\nThis code is licensed under the terms of the Eclipse Public License (EPL).\n\nCbcBranchToFixLots: Heuristic branching that fixes multiple variables\nin one branch, cutting off the current solution in the other. Useful\nfor reducing problem size when reduced costs indicate fixable variables.",
    "file": "CbcBranchToFixLots",
    "library": "Cbc",
    "layer": "layer-2",
    "header": "src/CbcBranchToFixLots.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "CbcBranchAllDifferent": {
    "brief": "All-different constraint for integer variables\nCopyright (C) 2004, IBM Corporation and others. All Rights Reserved.\nThis code is licensed under the terms of the Eclipse Public License (EPL).\n\nCbcBranchAllDifferent: Enforces that a set of integer variables\nmust all have different values. When two variables i,j have the\nsame value, creates branching disjunction:\n  x_i <= x_j - 1  OR  x_i >= x_j + 1",
    "file": "CbcBranchAllDifferent",
    "library": "Cbc",
    "layer": "layer-2",
    "header": "src/CbcBranchAllDifferent.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "CbcHeuristicRINS": {
    "brief": "RINS - Relaxation Induced Neighborhood Search (Danna et al.)\nCopyright (C) 2006, IBM Corporation and others. All Rights Reserved.\nThis code is licensed under the terms of the Eclipse Public License (EPL).\n\nCbcHeuristicRINS: Implements RINS (Danna, Rothberg & Le Pape, 2005).\nUses LP relaxation to define a neighborhood around the incumbent solution.",
    "file": "CbcHeuristicRINS",
    "library": "Cbc",
    "layer": "layer-2",
    "header": "src/CbcHeuristicRINS.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "CbcCompareEstimate": {
    "brief": "Estimate-based node selection strategy\nCopyright (C) 2002, IBM Corporation and others. All Rights Reserved.\nThis code is licensed under the terms of the Eclipse Public License (EPL).\n\nCbcCompareEstimate: Node selection using solution estimates.\nUsed during rounding phases where estimated objective matters.",
    "file": "CbcCompareEstimate",
    "library": "Cbc",
    "layer": "layer-2",
    "header": "src/CbcCompareEstimate.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "CbcFixVariable": {
    "brief": "Fix variable bounds as branching consequence",
    "file": "CbcFixVariable",
    "library": "Cbc",
    "layer": "layer-2",
    "header": "src/CbcFixVariable.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "CbcHeuristicDW": {
    "brief": "Dantzig-Wolfe decomposition based heuristic\nCopyright (C) 2006, IBM Corporation and others. All Rights Reserved.\nThis code is licensed under the terms of the Eclipse Public License (EPL).\n\nCbcHeuristicDW: Advanced heuristic exploiting block structure.\nVery compute-intensive - detects and exploits Dantzig-Wolfe\ndecomposable structure in the constraint matrix.",
    "file": "CbcHeuristicDW",
    "library": "Cbc",
    "layer": "layer-2",
    "header": "src/CbcHeuristicDW.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "CbcHeuristicDive": {
    "brief": "Abstract base for diving heuristics\nCopyright (C) 2008, IBM Corporation and others. All Rights Reserved.\nThis code is licensed under the terms of the Eclipse Public License (EPL).\n\nCbcHeuristicDive: Abstract base for diving heuristics that explore\nthe tree greedily by fixing variables and re-solving LPs.",
    "file": "CbcHeuristicDive",
    "library": "Cbc",
    "layer": "layer-2",
    "header": "src/CbcHeuristicDive.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "CbcClique": {
    "brief": "Clique branching for binary variable sets\nCopyright (C) 2002, IBM Corporation and others. All Rights Reserved.\nThis code is licensed under the terms of the Eclipse Public License (EPL).\n\nCbcClique: Branching for cliques (sets of binary variables with\nat most one at its \"strong\" value). Generalizes binary SOS1.\n\nStandard form: x1 + x2 + ... + xn <= 1 (all strong at 1)\nGeneral form allows negated variables (y_j = 1 - x_j).\n\nMember types (type_[i]):\n- 1: SOS-style, coefficient +1, strong value is 1\n- 0: Non-SOS, coefficient -1, strong value is 0",
    "file": "CbcClique",
    "library": "Cbc",
    "layer": "layer-2",
    "header": "src/CbcClique.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "CbcHeuristicRENS": {
    "brief": "RENS - Relaxation Enforced Neighborhood Search\nCopyright (C) 2006, IBM Corporation and others. All Rights Reserved.\nThis code is licensed under the terms of the Eclipse Public License (EPL).\n\nCbcHeuristicRENS: Fixes variables based on LP relaxation solution.\nUnlike RINS (which needs an incumbent), RENS works from LP alone.",
    "file": "CbcHeuristicRENS",
    "library": "Cbc",
    "layer": "layer-2",
    "header": "src/CbcHeuristicRENS.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "CbcTree": {
    "brief": "Heap-based storage for live search tree nodes\nCopyright (C) 2004, IBM Corporation and others. All Rights Reserved.\nThis code is licensed under the terms of the Eclipse Public License (EPL).",
    "file": "CbcTree",
    "library": "Cbc",
    "layer": "layer-2",
    "header": "src/CbcTree.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "CbcParameters": {
    "brief": "Central parameter collection for Cbc algorithm control\nCopyright (C) 2007, Lou Hafer, IBM Corporation and others.\nThis code is licensed under the terms of the Eclipse Public License (EPL).\n\nCbcParameters: Master class holding all Cbc solver parameters.\nUsed by cbc-generic to configure and control the MIP solver.\n\nMajor subsystems configured:\n- Cut generators: Gomory, MIR, Probing, Clique, FlowCover, etc.\n- Heuristics: FPump, RINS, RENS, DINS, Diving variants, VND, etc.\n- Search strategy: Node selection, preprocessing, orbital branching\n- Limits: Time, nodes, gap tolerance, solution count\n\nIncludes instances of CGL cut generators and Cbc heuristics.\nLinks to ClpParameters for underlying LP solver control.\n\nKey methods:\n- init(): Initialize with strategy preset\n- setModel(): Associate with CbcModel\n- Various getters/setters for each parameter category\n\nStrategy presets provide common configurations:\n- Default aggressive cutting at root\n- Balanced cut/heuristic emphasis\n- Heuristic-focused for quick solutions",
    "file": "CbcParameters",
    "library": "Cbc",
    "layer": "layer-2",
    "header": "src/CbcParameters.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "CbcThread": {
    "brief": "Multi-threaded parallel B&C support",
    "file": "CbcThread",
    "library": "Cbc",
    "layer": "layer-2",
    "header": "src/CbcThread.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "CbcSolver": {
    "brief": ".NET wrapper for CBC solver entry points (CbcMain0/CbcMain1)\n\nC++/CLI wrapper for CBC solver with callback support.\nCbcSolverCallBack delegate for monitoring solve phases.",
    "file": "CbcSolver",
    "library": "Sonnet",
    "layer": "layer-4",
    "header": "src/SonnetWrapper/CbcSolver.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "CbcSimpleInteger": {
    "brief": "Integer variable branching object",
    "file": "CbcSimpleInteger",
    "library": "Cbc",
    "layer": "layer-2",
    "header": "src/CbcSimpleInteger.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "CbcStrategy": {
    "brief": "Strategy pattern for configuring CbcModel components",
    "file": "CbcStrategy",
    "library": "Cbc",
    "layer": "layer-2",
    "header": "src/CbcStrategy.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "CbcBranchCut": {
    "brief": "Branching by adding cuts (split disjunctions)\nCopyright (C) 2004, IBM Corporation and others. All Rights Reserved.\nThis code is licensed under the terms of the Eclipse Public License (EPL).\n\nCbcBranchCut and CbcCutBranchingObject: Branch by adding cuts\nrather than tightening variable bounds. Implements split disjunctions\nwhere each branch arm adds a different cut to the LP.",
    "file": "CbcBranchCut",
    "library": "Cbc",
    "layer": "layer-2",
    "header": "src/CbcBranchCut.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "CbcParam": {
    "brief": "Individual parameter definitions for cbc-generic\nCopyright (C) 2007, Lou Hafer, IBM Corporation and others.\nThis code is licensed under the terms of the Eclipse Public License (EPL).\n\nCbcParam: Extends CoinParam with Cbc-specific parameter codes.\nUsed by the standalone cbc-generic solver for command-line processing.\n\nParameter categories (CbcParamCode enum):\n- Help: GENERALQUERY, HELP\n- Action: BAB, IMPORT, EXPORT, PRINTSOL, READMIPSTART\n- File: IMPORTFILE, EXPORTFILE, SOLUTIONFILE, MIPSTARTFILE\n- Cut: GOMORYCUTS, MIRCUTS, PROBINGCUTS, KNAPSACKCUTS, etc.\n- Heuristic: FPUMP, RINS, RENS, DIVINGC, GREEDY, etc.\n- Boolean: CPX, DOHEURISTIC, SOS, USESOLUTION\n- Keyword: STRATEGY, PREPROCESS, NODESTRATEGY, ORBITAL\n- Integer: LOGLEVEL, THREADS, CUTDEPTH, MAXNODES, etc.\n- Double: CUTOFF, ALLOWABLEGAP, TIMELIMIT, INCREMENT, etc.\n\nEach parameter links to:\n- parameters_: Parent CbcParameters collection\n- model_: Associated CbcModel (for model parameters)",
    "file": "CbcParam",
    "library": "Cbc",
    "layer": "layer-2",
    "header": "src/CbcParam.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "CbcCompareBase": {
    "brief": "Abstract base class for node comparison/selection",
    "file": "CbcCompareBase",
    "library": "Cbc",
    "layer": "layer-2",
    "header": "src/CbcCompareBase.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "CbcSolverExpandKnapsack": {
    "brief": "Knapsack constraint expansion for tighter formulations",
    "file": "CbcSolverExpandKnapsack",
    "library": "Cbc",
    "layer": "layer-2",
    "header": "src/CbcSolverExpandKnapsack.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "CbcCompareObjective": {
    "brief": "Best-bound (objective-based) node selection\nCopyright (C) 2002, IBM Corporation and others. All Rights Reserved.\nThis code is licensed under the terms of the Eclipse Public License (EPL).\n\nCbcCompareObjective: Implements best-first search.\nAlways explores node with best (lowest for min) LP bound.\n\ntest(x,y) returns true if y has smaller objective than x.\nPrioritizes most promising nodes for optimality proof.",
    "file": "CbcCompareObjective",
    "library": "Cbc",
    "layer": "layer-2",
    "header": "src/CbcCompareObjective.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "CbcFathomDynamicProgramming": {
    "brief": "Dynamic programming fathoming for special problem structures\nCopyright (C) 2004, IBM Corporation and others. All Rights Reserved.\nThis code is licensed under the terms of the Eclipse Public License (EPL).\n\nCbcFathomDynamicProgramming: Exact enumeration via DP for small subproblems.\nAfter branching reduces the problem sufficiently, DP may be faster than B&C.\n\nRequirements for DP applicability:\n- Small integral RHS values\n- All-integer problem with positive integral coefficients\n- Currently: set partitioning (not general covering)",
    "file": "CbcFathomDynamicProgramming",
    "library": "Cbc",
    "layer": "layer-2",
    "header": "src/CbcFathomDynamicProgramming.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "CbcHeuristicDiveLineSearch": {
    "brief": "Dive heuristic along line to LP optimum\nCopyright (C) 2008, IBM Corporation and others. All Rights Reserved.\nThis code is licensed under the terms of the Eclipse Public License (EPL).\n\nCbcHeuristicDiveLineSearch: Geometric diving approach.\nSelects variables along the line from current point to LP optimum.",
    "file": "CbcHeuristicDiveLineSearch",
    "library": "Cbc",
    "layer": "layer-2",
    "header": "src/CbcHeuristicDiveLineSearch.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "CbcBranchDefaultDecision": {
    "brief": "Default branching variable selection\nCopyright (C) 2002, IBM Corporation and others. All Rights Reserved.\nThis code is licensed under the terms of the Eclipse Public License (EPL).\n\nCbcBranchDefaultDecision: Simple selection algorithm without pseudocosts.",
    "file": "CbcBranchDefaultDecision",
    "library": "Cbc",
    "layer": "layer-2",
    "header": "src/CbcBranchDefaultDecision.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "CbcFeasibilityBase": {
    "brief": "User-defined feasibility checking",
    "file": "CbcFeasibilityBase",
    "library": "Cbc",
    "layer": "layer-2",
    "header": "src/CbcFeasibilityBase.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "CbcStatistics": {
    "brief": "Statistics gathering for node processing",
    "file": "CbcStatistics",
    "library": "Cbc",
    "layer": "layer-2",
    "header": "src/CbcStatistics.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "OsiCbcSolverInterface": {
    "brief": ".NET wrapper for OsiCbcSolverInterface (CBC via OSI)\n\nC++/CLI wrapper exposing CBC MIP solver through OSI interface.\nProvides access to CbcModel for node count, strategy, and solution.",
    "file": "OsiCbcSolverInterface",
    "library": "Sonnet",
    "layer": "layer-4",
    "header": "src/SonnetWrapper/OsiCbcSolverInterface.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "Cbc_C_Interface": {
    "brief": "Creates an empty problem",
    "file": "Cbc_C_Interface",
    "library": "Cbc",
    "layer": "layer-2",
    "header": "src/Cbc_C_Interface.h",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "CglResidualCapacity": {
    "brief": "Residual capacity cuts for network design",
    "file": "CglResidualCapacity",
    "library": "Cgl",
    "layer": "layer-2",
    "header": "src/CglResidualCapacity/CglResidualCapacity.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "CglAllDifferent": {
    "brief": "All-different constraint propagation for CSP-style constraints\n\nPropagates all-different constraints: variables in a set must all\ntake different integer values. Common in constraint satisfaction\nproblems (CSP) mapped to MIP.",
    "file": "CglAllDifferent",
    "library": "Cgl",
    "layer": "layer-2",
    "header": "src/CglAllDifferent/CglAllDifferent.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "CglFlowCover": {
    "brief": "Lifted Simple Generalized Flow Cover cuts",
    "file": "CglFlowCover",
    "library": "Cgl",
    "layer": "layer-2",
    "header": "src/CglFlowCover/CglFlowCover.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "CglGomory": {
    "brief": "Gomory mixed-integer cuts from optimal LP basis\n\nGenerates Gomory fractional cuts, the classic MIP cutting planes\nderived by Ralph Gomory in the 1950s-60s. For each fractional basic\nvariable, derives a valid inequality from the simplex tableau row.\n\nAlgorithm:\n1. Requires optimal LP basis (needsOptimalBasis() = true)\n2. For each basic integer variable with fractional value:\n   - Get tableau row: x_i + sum_j a_ij * x_j = b_i\n   - Apply fractional parts: sum_j f(a_ij)*x_j >= f(b_i)\n   - For mixed-integer: separate continuous/integer coefficients\n3. Strengthen using integrality of non-basic integers\n\nKey parameters:\n- limit_/limitAtRoot_: Max nonzeros in cut (dense cuts are expensive)\n- away_/awayAtRoot_: Min distance from integrality to generate cut\n- conditionNumberMultiplier_: Relax cut if basis is ill-conditioned\n- gomoryType_: 0=normal, 1=add original, 2=replace with original matrix\n\nNumerical considerations:\n- Basis condition number affects cut reliability\n- largestFactorMultiplier_ controls cut relaxation for stability\n- alternateFactorization_ uses different factorization for accuracy\n\nGomory cuts are finite and can solve pure integer programs in theory,\nbut numerically fragile. Modern solvers combine with other cuts.",
    "file": "CglGomory",
    "library": "Cgl",
    "layer": "layer-2",
    "header": "src/CglGomory/CglGomory.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "CglTwomir": {
    "brief": "Two-step MIR (TMIR) cut generator\n\nGenerates tMIR and 2-step MIR cuts by applying the MIR inequality\nrecursively with different scaling factors. More general than\nsimple Gomory or MIR cuts.",
    "file": "CglTwomir",
    "library": "Cgl",
    "layer": "layer-2",
    "header": "src/CglTwomir/CglTwomir.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "CglRedSplit": {
    "brief": "Reduce-and-Split cuts for enhanced Gomory generation",
    "file": "CglRedSplit",
    "library": "Cgl",
    "layer": "layer-2",
    "header": "src/CglRedSplit/CglRedSplit.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "CglRedSplitParam": {
    "brief": "Parameters for the Reduce-and-Split cut generator",
    "file": "CglRedSplitParam",
    "library": "Cgl",
    "layer": "layer-2",
    "header": "src/CglRedSplit/CglRedSplitParam.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "CglPreProcess": {
    "brief": "MIP preprocessing with cut generator integration\n\nComprehensive MIP preprocessing that combines OsiPresolve with\ncut generators to strengthen the formulation before branch-and-cut.\nUnlike simple presolve, can add cuts that replace/strengthen constraints.",
    "file": "CglPreProcess",
    "library": "Cgl",
    "layer": "layer-2",
    "header": "src/CglPreProcess/CglPreProcess.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "CglLandP": {
    "brief": "Lift-and-Project cuts via simplex pivoting",
    "file": "CglLandP",
    "library": "Cgl",
    "layer": "layer-2",
    "header": "src/CglLandP/CglLandP.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "CglLandPMessages": {
    "brief": "Message handler for Lift-and-Project simplex",
    "file": "CglLandPMessages",
    "library": "Cgl",
    "layer": "layer-2",
    "header": "src/CglLandP/CglLandPMessages.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "CglLandPSimplex": {
    "brief": "Simplex algorithm for Lift-and-Project cut generation",
    "file": "CglLandPSimplex",
    "library": "Cgl",
    "layer": "layer-2",
    "header": "src/CglLandP/CglLandPSimplex.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "CglLandPValidator": {
    "brief": "Cut validation and cleaning for Lift-and-Project",
    "file": "CglLandPValidator",
    "library": "Cgl",
    "layer": "layer-2",
    "header": "src/CglLandP/CglLandPValidator.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "CglLandPTabRow": {
    "brief": "Tableau row structure for Lift-and-Project simplex",
    "file": "CglLandPTabRow",
    "library": "Cgl",
    "layer": "layer-2",
    "header": "src/CglLandP/CglLandPTabRow.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "CglLandPUtils": {
    "brief": "Utility functions for Lift-and-Project cut generation",
    "file": "CglLandPUtils",
    "library": "Cgl",
    "layer": "layer-2",
    "header": "src/CglLandP/CglLandPUtils.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "CglKnapsackCover": {
    "brief": "Knapsack cover cuts for binary packing constraints\n\nGenerates cover inequalities for knapsack constraints of the form\nsum_j a_j * x_j <= b where x_j are binary. A cover C is a subset\nwhere sum_{j in C} a_j > b, making x_j = 1 for all j in C infeasible.\n\nCover inequality: sum_{j in C} x_j <= |C| - 1\n\nAlgorithm phases:\n1. deriveAKnapsack(): Convert constraint to canonical binary knapsack\n2. Find minimal violated cover using:\n   - findExactMostViolatedMinCover(): Exact via Horowitz-Sahni\n   - findLPMostViolatedMinCover(): LP relaxation heuristic\n   - findGreedyCover(): Simple greedy heuristic\n3. Lifting: Strengthen cover to full-dimensional inequality\n   - liftCoverCut(): Sequence-independent lifting\n   - seqLiftAndUncomplementAndAdd(): Sequence-dependent lifting\n   - liftUpDownAndUncomplementAndAdd(): Up/down lifting for binaries\n\nAdditional features:\n- createCliques(): Build clique structure for probing\n- Horowitz-Sahni algorithm for exact knapsack solving\n- John-Ellis cover finding from OSL (IBM's solver)\n\nKey parameters:\n- maxInKnapsack_: Maximum variables in processed knapsack\n- expensiveCuts_: Enable/disable costly exact methods\n- rowsToCheck_: Restrict which rows to examine",
    "file": "CglKnapsackCover",
    "library": "Cgl",
    "layer": "layer-2",
    "header": "src/CglKnapsackCover/CglKnapsackCover.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "CglOddHole": {
    "brief": "Odd hole cuts from conflict graphs\n\nGenerates odd hole inequalities based on the method from\nGrotschel, Lovasz, and Schrijver (1988). An odd hole is a\nchordless cycle of odd length in the conflict graph.",
    "file": "CglOddHole",
    "library": "Cgl",
    "layer": "layer-2",
    "header": "src/CglOddHole/CglOddHole.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "CglRedSplit2Param": {
    "brief": "Parameters for the enhanced Reduce-and-Split cut generator",
    "file": "CglRedSplit2Param",
    "library": "Cgl",
    "layer": "layer-2",
    "header": "src/CglRedSplit2/CglRedSplit2Param.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "CglRedSplit2": {
    "brief": "Enhanced Reduce-and-Split cuts with multiple strategies",
    "file": "CglRedSplit2",
    "library": "Cgl",
    "layer": "layer-2",
    "header": "src/CglRedSplit2/CglRedSplit2.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "CglBKClique": {
    "brief": "Clique cut separator using Bron-Kerbosch algorithm",
    "file": "CglBKClique",
    "library": "Cgl",
    "layer": "layer-2",
    "header": "src/CglBKClique/CglBKClique.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "CglMessage": {
    "brief": "Message definitions for CGL cut generators\n\nDefines CGL_Message enum codes and CglMessage class for\ninternationalized message output through CoinMessageHandler.\n\nMessage categories:\n- Infeasibility detection: CGL_INFEASIBLE, CGL_UNBOUNDED\n- Preprocessing results: CGL_FIXED, CGL_MADE_INTEGER, CGL_ADDED_INTEGERS\n- Statistics: CGL_PROCESS_STATS, CGL_PROCESS_STATS2\n- Clique processing: CGL_CLIQUES, CGL_PROCESS_CLQSTR, CGL_WARNING_CLQSTR\n- SOS handling: CGL_PROCESS_SOS1, CGL_PROCESS_SOS2\n- Postsolve: CGL_POST_INFEASIBLE, CGL_POST_CHANGED\n- Matrix changes: CGL_ELEMENTS_CHANGED1, CGL_ELEMENTS_CHANGED2",
    "file": "CglMessage",
    "library": "Cgl",
    "layer": "layer-2",
    "header": "src/CglCommon/CglMessage.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "CglParam": {
    "brief": "Base parameter class for cut generator configuration",
    "file": "CglParam",
    "library": "Cgl",
    "layer": "layer-2",
    "header": "src/CglCommon/CglParam.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "CglCutGenerator": {
    "brief": ".NET wrapper for CglCutGenerator (cut generator base class)\n\nC++/CLI wrapper exposing CGL cut generators to .NET languages.\nGeneric template CglCutGeneratorGeneric<T> for derived generators.",
    "file": "CglCutGenerator",
    "library": "Sonnet",
    "layer": "layer-4",
    "header": "src/SonnetWrapper/CglCutGenerator.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "CglTreeInfo": {
    "brief": "Context information for cut generation in branch-and-cut\n\nPasses branch-and-cut tree state to cut generators so they can adapt\ntheir behavior based on tree depth, pass number, and other factors.\n\nCglTreeInfo fields:\n- level: Search tree depth (0 = root)\n- pass: Which cut generation round at this node\n- formulation_rows: Original row count (before generated cuts)\n- inTree: True after first branch\n- options: Bit flags for various modes (see below)\n\nOption flags (can be combined):\n- 1: Treat costed integers as important\n- 4/8: Set global cut flag at root\n- 16: Make cuts globally valid\n- 32: Last round ineffective - be more aggressive\n- 64: In preprocessing stage\n- 128: Looks like we found a solution\n- 8192: Problem is infeasible\n\nCglTreeProbingInfo (derived class):\nExtends CglTreeInfo with variable fixing implications from probing.\n- fixEntries_: What gets fixed when a variable is set\n- toZero_/toOne_: Starts of implication lists\n- Supports analyze() to derive implied bounds",
    "file": "CglTreeInfo",
    "library": "Cgl",
    "layer": "layer-2",
    "header": "src/CglCommon/CglTreeInfo.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "CglStored": {
    "brief": "Cut generator that stores and replays previously found cuts\n\nInstead of computing cuts, CglStored maintains a collection of cuts\nfrom prior solves or other sources, and adds violated ones to the LP.\n\nUse cases:\n- Warm-starting branch-and-cut with cuts from a similar problem\n- Cut pool management across nodes in the search tree\n- Importing cuts computed externally or in a preprocessing phase\n- Debugging by replaying a known cut sequence\n\nCut selection:\n- Only adds cuts violated by more than requiredViolation_ (default 1e-5)\n- Violation = constraint LHS evaluated at current LP solution\n- Avoids adding nearly-satisfied cuts that waste basis updates\n\nCan also store:\n- Best known solution (for primal bounds)\n- Tight variable bounds (from probing/preprocessing)\n- Probing implication information (CglTreeProbingInfo)",
    "file": "CglStored",
    "library": "Cgl",
    "layer": "layer-2",
    "header": "src/CglCommon/CglStored.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "CglMixedIntegerRounding": {
    "brief": "Mixed Integer Rounding (MIR) cuts via Marchand-Wolsey procedure",
    "file": "CglMixedIntegerRounding",
    "library": "Cgl",
    "layer": "layer-2",
    "header": "src/CglMixedIntegerRounding/CglMixedIntegerRounding.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "CglGMI": {
    "brief": "Gomory Mixed-Integer cuts with numerical safety testing",
    "file": "CglGMI",
    "library": "Cgl",
    "layer": "layer-2",
    "header": "src/CglGMI/CglGMI.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "CglGMIParam": {
    "brief": "Parameters for the GMI (Gomory Mixed-Integer) cut generator",
    "file": "CglGMIParam",
    "library": "Cgl",
    "layer": "layer-2",
    "header": "src/CglGMI/CglGMIParam.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "CglClique": {
    "brief": "Clique cuts from set packing structure\n\nGenerates clique inequalities by finding maximal cliques in the\nconflict graph of binary variables. Two binaries conflict if they\ncannot both be 1 in any feasible solution.\n\nClique inequality: sum_{j in C} x_j <= 1 (or = 1 if equality)\n\nGraph construction (frac_graph):\n- Nodes: Binary variables at fractional LP values\n- Edges: Variables that conflict (appear in same set packing row)\n- Edge costs: 1 - x_i - x_j (for odd hole detection)\n\nTwo clique-finding methods:\n1. Star clique (do_star_clique):\n   - Pick a center node, find all neighbors (star)\n   - Enumerate maximal cliques in the star\n   - SCL_MIN_DEGREE/MAX_DEGREE/MAX_XJ_MAX_DEG selection rules\n2. Row clique (do_row_clique):\n   - Start from existing set packing row\n   - Extend to larger clique using adjacent variables\n\nThresholds:\n- scl_candidate_length_threshold: Max size for exact enumeration\n- rcl_candidate_length_threshold: Same for row clique method\n- Beyond threshold: use greedy heuristic\n\nCglFakeClique (derived class):\n- Works on \"fake\" solver with invented rows from probing\n- Integrates with CglProbing for stronger implications",
    "file": "CglClique",
    "library": "Cgl",
    "layer": "layer-2",
    "header": "src/CglClique/CglClique.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "CglProbing": {
    "brief": "Probing cut generator - variable fixing and implications\n\nProbing systematically tests setting integer variables to bounds,\npropagating implications to derive:\n- Variable fixings (column cuts)\n- Bound tightenings\n- Disaggregation cuts (row cuts)\n- Coefficient strengthening\n- Clique structures\n\nProbing outcomes when testing x_j = 0 vs x_j = 1:\n1. One direction infeasible \u2192 fix variable (column cut)\n2. Both infeasible \u2192 problem infeasible\n3. Both feasible, y fixed same way \u2192 y can be fixed\n4. Both feasible, y fixed opposite \u2192 can substitute y = 1-x_j\n5. Constraint went slack by c \u2192 strengthen coefficient\n\nKey structures:\n- disaggregationAction: What gets fixed when probing a variable\n- cutVector_: Stores implications for each integer\n- Clique arrays: oneFixStart_, zeroFixStart_ for clique membership\n\nModes:\n- mode_ 0: Only unsatisfied integers, use snapshot (fast, global)\n- mode_ 1: Unsatisfied integers with current bounds\n- mode_ 2: All integers with current bounds\n\nCglImplication (separate class):\n- Generates cuts directly from stored implication info\n- Uses CglTreeProbingInfo built during probing",
    "file": "CglProbing",
    "library": "Cgl",
    "layer": "layer-2",
    "header": "src/CglProbing/CglProbing.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "CglZeroHalf": {
    "brief": "Zero-half ({0,1/2}) cutting planes\n\nGenerates {0,1/2}-cuts by taking mod-2 combinations of constraint rows.\nBased on Andreello, Caprara, Fischetti (INFORMS J. Computing, 2007).\n\nTheory: If we combine constraints with {0, 1/2} multipliers such that\nall LHS coefficients become even, we get a valid cut by dividing by 2\nand rounding down the RHS.\n\nAlgorithm outline:\n1. Convert constraint matrix to integers (scaling)\n2. Reduce coefficients mod 2 (0-1 matrix)\n3. Find combinations where LHS sums to 0 mod 2 per column\n4. These yield valid {0,1/2}-cuts when RHS is odd\n\nInternal representation:\n- mr_, mc_, mnz_: Matrix dimensions and nonzeros\n- mtbeg_, mtcnt_, mtind_, mtval_: Sparse row storage\n- vlb_, vub_: Variable bounds (integer scaled)\n- Cgl012Cut cutInfo_: Separation algorithm state\n\nUses Dijkstra shortest path (cglShortestPath) for separation.",
    "file": "CglZeroHalf",
    "library": "Cgl",
    "layer": "layer-2",
    "header": "src/CglZeroHalf/CglZeroHalf.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "Cgl012cut": {
    "brief": "Low-level C-style implementation for {0,1/2}-cut separation\nCopyright (C) 2010, IBM Corporation and others. All Rights Reserved.\nThis code is licensed under the terms of the Eclipse Public License (EPL).",
    "file": "Cgl012cut",
    "library": "Cgl",
    "layer": "layer-2",
    "header": "src/CglZeroHalf/Cgl012cut.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "CglDuplicateRow": {
    "brief": "Detect and eliminate duplicate/dominated rows\n\nPreprocessing generator that identifies:\n- Duplicate rows (identical constraints)\n- Dominated rows (one implies another)\n- Variables fixable due to coefficient > effective RHS\n\nDesigned for problems with few rows, many integer variables,\n<= or == constraints, and small integer coefficients/RHS.\n\nduplicate_ array interpretation:\n- -1: Row still active\n- -2: Row removed (all variables fixed)\n- k >= 0: Row is same as row k\n\nModes (mode_):\n- 1: Process rows only\n- 2: Process columns only (dominated columns)\n- 3: Process both rows and columns\n- 4/8: Alternative algorithms\n\nAlgorithm for duplicate detection:\n- If row A is subset of row B with same effective RHS\n- Can fix variables in B not in A\n- Then rows become identical\n\nShould be called before first solve (preprocessing phase).",
    "file": "CglDuplicateRow",
    "library": "Cgl",
    "layer": "layer-2",
    "header": "src/CglDuplicateRow/CglDuplicateRow.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "CglMixedIntegerRounding2": {
    "brief": "Enhanced MIR (Mixed Integer Rounding) cut generator",
    "file": "CglMixedIntegerRounding2",
    "library": "Cgl",
    "layer": "layer-2",
    "header": "src/CglMixedIntegerRounding2/CglMixedIntegerRounding2.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "CglSimpleRounding": {
    "brief": "Simple rounding cuts via GCD (greatest common divisor)\n\nGenerates simple rounding cuts using the GCD method from\nNemhauser and Wolsey (1988, p.211).",
    "file": "CglSimpleRounding",
    "library": "Cgl",
    "layer": "layer-2",
    "header": "src/CglSimpleRounding/CglSimpleRounding.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "CglCliqueStrengthening": {
    "brief": "Preprocessing to extend and merge clique constraints",
    "file": "CglCliqueStrengthening",
    "library": "Cgl",
    "layer": "layer-2",
    "header": "src/CglCliqueStrengthening/CglCliqueStrengthening.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "CglLiftAndProject": {
    "brief": "Lift-and-project cuts for 0-1 programming\n\nImplements lift-and-project cuts based on Balas, Ceria, and Cornuejols.\nCreates cuts by \"lifting\" the problem into higher dimensions where\nthe LP relaxation is tighter, then \"projecting\" back.",
    "file": "CglLiftAndProject",
    "library": "Cgl",
    "layer": "layer-2",
    "header": "src/CglLiftAndProject/CglLiftAndProject.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "CglOddWheel": {
    "brief": "Odd-wheel cut separator (odd cycles with lifting)",
    "file": "CglOddWheel",
    "library": "Cgl",
    "layer": "layer-2",
    "header": "src/CglOddWheel/CglOddWheel.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "TutorialCpp_nlp": {
    "brief": "Ipopt C++ tutorial exercise NLP\n\nTutorialCpp_nlp: tutorial exercise for learning TNLP interface.\nStep-by-step guide to implementing optimization problems.\nThree versions: skeleton (to fill in), mistake (to debug), solution.",
    "file": "TutorialCpp_nlp",
    "library": "Ipopt",
    "layer": "layer-2",
    "header": "tutorial/CodingExercise/Cpp/3-solution/TutorialCpp_nlp.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "IpTNLP": {
    "brief": "User interface for defining NLP problems in standard form\n\nTNLP (Templated NLP) is the primary user-facing class for defining\noptimization problems. Users inherit from TNLP and implement:",
    "file": "IpTNLP",
    "library": "Ipopt",
    "layer": "layer-2",
    "header": "src/Interfaces/IpTNLP.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "IpTNLPAdapter": {
    "brief": "Adapter converting user TNLP interface to internal NLP\n\nTNLPAdapter is a Design Pattern Adapter that converts from the\nuser-facing TNLP format to Ipopt's internal NLP representation:\n\nTNLP (user):           NLP (internal):\n  g_L <= g(x) <= g_U  ->  c(x) = 0           (equalities)\n                          d_L <= d(x) <= d_U (inequalities)\n\nKey responsibilities:\n- Separate mixed constraints into equalities and inequalities\n- Handle fixed variables (as parameters or relaxed bounds)\n- Convert sparse triplet (i,j,val) to internal matrix format\n- Detect linear dependencies in constraints\n- Map between TNLP multipliers and internal dual variables",
    "file": "IpTNLPAdapter",
    "library": "Ipopt",
    "layer": "layer-2",
    "header": "src/Interfaces/IpTNLPAdapter.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "IpSolveStatistics": {
    "brief": "Statistics collected during optimization run\n\nSolveStatistics provides post-solve information accessible via\nIpoptApplication::Statistics(). Captures optimization outcomes\nat the time of construction from internal Ipopt objects.\n\nAvailable statistics:\n- Iteration count\n- Final objective value\n- Final constraint violation (primal infeasibility)\n- Final optimality error (dual infeasibility)\n- Final complementarity\n- Timing information",
    "file": "IpSolveStatistics",
    "library": "Ipopt",
    "layer": "layer-2",
    "header": "src/Interfaces/IpSolveStatistics.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "IpInterfacesRegOp": {
    "brief": "Option registration for Interfaces subsystem\n\nDeclares RegisterOptions_Interfaces() which registers all options\nspecific to the Interfaces module with the RegisteredOptions object.\n\nCalled during IpoptApplication initialization to register options\nlike fixed_variable_treatment, dependency_detection_with_rhs, etc.",
    "file": "IpInterfacesRegOp",
    "library": "Ipopt",
    "layer": "layer-2",
    "header": "src/Interfaces/IpInterfacesRegOp.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "IpAlgTypes": {
    "brief": "Algorithm-level return codes and exception types\n\nDefines SolverReturn enum for internal algorithm status:\n- SUCCESS: Converged to optimality tolerances\n- MAXITER_EXCEEDED, CPUTIME_EXCEEDED, WALLTIME_EXCEEDED\n- STOP_AT_ACCEPTABLE_POINT: Met acceptable (looser) tolerances\n- LOCAL_INFEASIBILITY: Problem appears locally infeasible\n- USER_REQUESTED_STOP: Callback requested termination\n- RESTORATION_FAILURE: Feasibility restoration failed\n- DIVERGING_ITERATES, INVALID_NUMBER_DETECTED\n\nAlso declares standard exceptions thrown during solve:\nLOCALLY_INFEASIBLE, TOO_FEW_DOF, TINY_STEP_DETECTED, etc.",
    "file": "IpAlgTypes",
    "library": "Ipopt",
    "layer": "layer-2",
    "header": "src/Interfaces/IpAlgTypes.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "IpReturnCodes": {
    "brief": "C++ namespace wrapper for Ipopt return codes\n\nWraps IpReturnCodes_inc.h in Ipopt namespace for C++ usage.\nDefines ApplicationReturnStatus enum used by IpoptApplication:\n\n- Solve_Succeeded: Optimal solution found\n- Solved_To_Acceptable_Level: Acceptable tolerance met\n- Infeasible_Problem_Detected: Locally infeasible\n- Maximum_Iterations_Exceeded, Maximum_CpuTime_Exceeded\n- Restoration_Failed, Error_In_Step_Computation\n- Invalid_Option, Invalid_Number_Detected\n- Not_Enough_Degrees_Of_Freedom, Internal_Error",
    "file": "IpReturnCodes",
    "library": "Ipopt",
    "layer": "layer-2",
    "header": "src/Interfaces/IpReturnCodes.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "IpNLP": {
    "brief": "Internal NLP representation using Vector/Matrix abstractions\n\nNLP is Ipopt's internal problem representation with equality constraints\nseparated from inequalities:\n  min  f(x)\n  s.t. c(x) = 0           (equality constraints)\n       d_L <= d(x) <= d_U (inequality constraints)\n       x_L <= x <= x_U    (variable bounds)\n\nUnlike TNLP (user interface with arrays), NLP uses Vector and Matrix\nobjects for all operations. TNLPAdapter converts TNLP to this form.",
    "file": "IpNLP",
    "library": "Ipopt",
    "layer": "layer-2",
    "header": "src/Interfaces/IpNLP.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "IpTNLPReducer": {
    "brief": "Wrapper to solve subproblems with fewer constraints\n\nTNLPReducer wraps an existing TNLP and presents a reduced problem\nwith specified constraints, lower bounds, and upper bounds removed.\nUseful for experimentation with constraint subsets.\n\nCan skip:\n- Constraints (by index)\n- Lower bounds on variables\n- Upper bounds on variables\n- Fix certain variables\n\n@note Not efficient - still evaluates full problem internally.\nPrimarily for debugging and experimentation.",
    "file": "IpTNLPReducer",
    "library": "Ipopt",
    "layer": "layer-2",
    "header": "src/Interfaces/IpTNLPReducer.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "IpStdInterfaceTNLP": {
    "brief": "TNLP implementation wrapping C function pointer interface\n\nStdInterfaceTNLP implements TNLP by delegating to C function pointers\nprovided through IpStdCInterface.h. This enables C programs to use\nIpopt without C++ inheritance.\n\nThe C interface passes:\n- Problem dimensions (n_var, n_con, nele_jac, nele_hess)\n- Bounds arrays (x_L, x_U, g_L, g_U)\n- Starting points (start_x, start_lam, start_z_L, start_z_U)\n- Function pointers for eval_f, eval_g, eval_grad_f, eval_jac_g, eval_h\n\nStdInterfaceTNLP converts C callbacks to TNLP virtual method calls.",
    "file": "IpStdInterfaceTNLP",
    "library": "Ipopt",
    "layer": "layer-2",
    "header": "src/Interfaces/IpStdInterfaceTNLP.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "IpIpoptApplication": {
    "brief": "",
    "file": "IpIpoptApplication",
    "library": "Gravity",
    "layer": "layer-4",
    "header": "thirdparty/Ipopt/include/coin/IpIpoptApplication.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "IpSmartPtr": {
    "brief": "Intrusive reference-counting smart pointer for Ipopt\n\nProvides SmartPtr<T> template class implementing automatic memory\nmanagement via reference counting. All managed objects must inherit\nfrom ReferencedObject. Used throughout Ipopt for safe object lifetime\nmanagement without manual delete calls.\n\nKey design: intrusive (count stored in object) vs non-intrusive\n(count stored externally). Intrusive chosen to avoid double-counting\nwhen raw pointers are passed between SmartPtr instances.\n\n@note Does NOT handle circular references - use weak pointers or\nexplicit release methods for bidirectional object graphs.",
    "file": "IpSmartPtr",
    "library": "Ipopt",
    "layer": "layer-2",
    "header": "src/Common/IpSmartPtr.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "IpTaggedObject": {
    "brief": "Base class for objects with change-tracking tags\n\nTaggedObject provides efficient change detection for expensive\ncomputations. Each object maintains a unique tag that changes whenever\nthe object's internal state is modified. Consumers compare stored tags\nto detect changes and avoid redundant recalculation.",
    "file": "IpTaggedObject",
    "library": "Ipopt",
    "layer": "layer-2",
    "header": "src/Common/IpTaggedObject.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "IpReferenced": {
    "brief": "Reference counting base class for SmartPtr management\n\nDefines ReferencedObject - the base class that any object must inherit\nfrom to be managed by SmartPtr<T>. Implements intrusive reference counting\nwhere the count is stored in the object itself rather than externally.\n\nAlso defines Referencer pseudo-class used to track which SmartPtr\ninstances hold references (useful for debugging circular references).",
    "file": "IpReferenced",
    "library": "Ipopt",
    "layer": "layer-2",
    "header": "src/Common/IpReferenced.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "IpException": {
    "brief": "Exception base class and macros for Ipopt error handling\n\nProvides IpoptException base class and convenience macros:\n- DECLARE_STD_EXCEPTION(Type): Define new exception class\n- THROW_EXCEPTION(Type, msg): Throw with file/line info\n- ASSERT_EXCEPTION(cond, Type, msg): Conditional throw\n\nExceptions carry source location (file, line) and message for\ndebugging. Can be reported via Journalist::ReportException().\n\nUses special visibility attributes on macOS to ensure exceptions\ncan be caught across shared library boundaries.",
    "file": "IpException",
    "library": "Ipopt",
    "layer": "layer-2",
    "header": "src/Common/IpException.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "IpUtils": {
    "brief": "General utility functions for Ipopt\n\nProvides platform-independent utility functions:\n- Min/Max template functions for up to 4 arguments\n- IsFiniteNumber() for NaN/Inf detection\n- CpuTime(), SysTime(), WallclockTime() for profiling\n- IpRandom01() for random number generation\n- Snprintf() for safe formatted output\n- Compare_le() for numerical comparison with tolerance\n- Signal handling for graceful interrupt",
    "file": "IpUtils",
    "library": "Ipopt",
    "layer": "layer-2",
    "header": "src/Common/IpUtils.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "IpOptionsList": {
    "brief": "Container for user-specified algorithmic options\n\nOptionsList stores runtime-configurable parameters as string key-value\npairs. Supports integer, numeric, and string option types with automatic\nconversion. Tracks how many times each option has been accessed (useful\nfor detecting unused options).\n\nOptions are case-insensitive. Values can be set via:\n- SetNumericValue(), SetIntegerValue(), SetStringValue()\n- ReadFromStream() for ipopt.opt format files\n\nIntegrates with RegisteredOptions for validation and default values.",
    "file": "IpOptionsList",
    "library": "Ipopt",
    "layer": "layer-2",
    "header": "src/Common/IpOptionsList.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "IpTypes": {
    "brief": "Fundamental type definitions for Ipopt (C++ namespace wrapper)\n\nWraps the C type definitions from IpTypes.h in the Ipopt namespace:\n- Number (ipnumber): floating-point type for all numerical values\n- Index (ipindex): integer type for array indices and dimensions\n\nActual types depend on compile-time configuration (IPOPT_SINGLE,\nIPOPT_INT64). Default is double for Number and int for Index.",
    "file": "IpTypes",
    "library": "Ipopt",
    "layer": "layer-2",
    "header": "src/Common/IpTypes.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "IpTimedTask": {
    "brief": "Timer class for profiling algorithm components\n\nTimedTask provides RAII-style timing measurement for code blocks.\nTracks CPU time, system time, and wall clock time. Multiple\nStart()/End() pairs accumulate total time across invocations.\n\nUsage:\n  TimedTask timer;\n  timer.Start();\n  // ... expensive operation ...\n  timer.End();\n  double elapsed = timer.TotalCpuTime();\n\nUsed throughout Ipopt to report timing breakdown by category\n(function evaluation, linear solve, line search, etc.).",
    "file": "IpTimedTask",
    "library": "Ipopt",
    "layer": "layer-2",
    "header": "src/Common/IpTimedTask.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "IpJournalist": {
    "brief": "Logging and output management system for Ipopt\n\nImplements a flexible logging framework with multiple output destinations\n(Journals) and fine-grained control over verbosity by category.\n\nPrint levels (EJournalLevel): J_NONE < J_ERROR < J_WARNING < J_SUMMARY\n  < J_ITERSUMMARY < J_DETAILED < J_VECTOR < J_MATRIX < J_ALL\n\nCategories (EJournalCategory): J_MAIN, J_LINE_SEARCH, J_LINEAR_ALGEBRA,\n  J_BARRIER_UPDATE, J_SOLVE_PD_SYSTEM, etc. plus J_USER1-J_USER17 for apps.\n\nEach Journal (console, file, stream) can have independent level settings\nper category. Printf-style and stream-style output both supported.",
    "file": "IpJournalist",
    "library": "Ipopt",
    "layer": "layer-2",
    "header": "src/Common/IpJournalist.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "IpLibraryLoader": {
    "brief": "Dynamic library loading for runtime solver selection\n\nLibraryLoader provides platform-independent dynamic library loading:\n- dlopen()/dlsym() on POSIX systems\n- LoadLibrary()/GetProcAddress() on Windows\n\nUsed to load linear solver libraries (HSL, Pardiso, etc.) at runtime\nwithout compile-time linkage. Allows users to provide proprietary\nsolvers without recompiling Ipopt.\n\nIPOPT_SHAREDLIBEXT defined to \"so\", \"dylib\", or \"dll\" per platform.\n\n@since 3.14.0",
    "file": "IpLibraryLoader",
    "library": "Ipopt",
    "layer": "layer-2",
    "header": "src/Common/IpLibraryLoader.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "IpCachedResults": {
    "brief": "Template class for caching computed results with dependency tracking\n\nCachedResults<T> stores computed values along with their dependencies\n(TaggedObjects and scalar parameters). Results are automatically\ninvalidated when any dependency changes via the Observer pattern.",
    "file": "IpCachedResults",
    "library": "Ipopt",
    "layer": "layer-2",
    "header": "src/Common/IpCachedResults.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "IpRegOptions": {
    "brief": "Option registration, validation, and documentation system\n\nProvides infrastructure for declaring algorithm options with:\n- Type information (OT_Number, OT_Integer, OT_String)\n- Valid ranges (bounds for numerics, allowed values for strings)\n- Default values\n- Documentation strings for help generation\n- Categories for organizing options in documentation\n\nRegisteredOptions aggregates all RegisteredOption instances and\nprovides lookup, validation, and documentation generation.\n\nEach Ipopt component registers its options in RegisterAllOptions()\nduring initialization.",
    "file": "IpRegOptions",
    "library": "Ipopt",
    "layer": "layer-2",
    "header": "src/Common/IpRegOptions.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "IpObserver": {
    "brief": "Observer design pattern implementation for change notification\n\nImplements Subject/Observer pattern for automatic cache invalidation.\nTaggedObjects (vectors, matrices) act as Subjects; dependent computed\nquantities (CachedResults) act as Observers. When a Subject changes,\nall attached Observers are notified to invalidate their cached values.\n\nNotification types:\n- NT_Changed: Subject data has been modified\n- NT_BeingDestroyed: Subject is being deleted\n- NT_All: Receive all notification types",
    "file": "IpObserver",
    "library": "Ipopt",
    "layer": "layer-2",
    "header": "src/Common/IpObserver.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "IpDebug": {
    "brief": "Debug assertion and verbose tracing macros\n\nProvides compile-time controlled debugging facilities:\n\nIPOPT_CHECKLEVEL > 0 enables:\n- DBG_ASSERT(cond): Runtime assertions\n- DBG_ASSERT_EXCEPTION(cond, type, msg): Conditional exceptions\n- DBG_DO(cmd): Execute only in debug mode\n\nIPOPT_VERBOSITY >= 1 enables tracing:\n- DBG_START_FUN/DBG_START_METH: Trace function entry/exit\n- DBG_PRINT: Printf-style debug output with indentation\n- DBG_EXEC: Conditional execution based on verbosity\n\nAll macros compile to nothing when disabled (zero overhead).",
    "file": "IpDebug",
    "library": "Ipopt",
    "layer": "layer-2",
    "header": "src/Common/IpDebug.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "IpLeastSquareMults": {
    "brief": "Least-squares estimation of equality constraint multipliers\n\nLeastSquareMultipliers computes initial estimates for the equality\nconstraint multipliers y_c and y_d by solving a least-squares problem.\n\nFormulation: Find y minimizing ||\u2207_x L(x,y)||^2 where\n  \u2207_x L = \u2207f(x) + J_c^T y_c + J_d^T y_d - z_L + z_U\n\nThis is equivalent to solving the normal equations:\n  [J_c J_c^T    0    ] [y_c]   [-J_c (\u2207f - z_L + z_U)]\n  [   0     J_d J_d^T] [y_d] = [-J_d (\u2207f - z_L + z_U)]\n\nActually solved via augmented system:\n  [0  J_c^T  J_d^T] [r  ]   [\u2207f - z_L + z_U]\n  [J_c  0     0   ] [y_c] = [     0        ]\n  [J_d  0     0   ] [y_d]   [     0        ]\n\nUses AugSystemSolver to solve the linear system with W=0.\n\nUsage:\n- DefaultIterateInitializer: Initial multiplier estimates\n- MinC_1NrmRestorationPhase: Post-restoration multiplier reset",
    "file": "IpLeastSquareMults",
    "library": "Ipopt",
    "layer": "layer-2",
    "header": "src/Algorithm/IpLeastSquareMults.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "IpGenAugSystemSolver": {
    "brief": "Augmented system solver using GenKKTSolverInterface\n\nGenAugSystemSolver adapts the AugSystemSolver interface to use\nGenKKTSolverInterface, which provides a more generic linear solver\ninterface supporting iterative methods.\n\nThis class:\n- Extracts raw Number* arrays from Vector objects\n- Passes Matrix objects directly from the NLP\n- Manages caching to avoid redundant matrix updates\n\nMultiSolve() implementation:\n1. Check if augmented system matrices have changed (via tags)\n2. If changed, update solver_interface_ with new matrices\n3. Extract RHS vectors to raw arrays\n4. Call solver_interface_->Solve()\n5. Copy solutions back to Vector objects\n\nTag-based caching tracks:\n- W matrix and W_factor\n- Diagonal matrices D_x, D_s, D_c, D_d\n- Jacobians J_c, J_d\n- Regularization deltas\n\nInertia and quality:\n- NumberOfNegEVals(): Query solver for eigenvalue count\n- ProvidesInertia(): Check if solver supports this\n- IncreaseQuality(): Request better pivoting/tolerance",
    "file": "IpGenAugSystemSolver",
    "library": "Ipopt",
    "layer": "layer-2",
    "header": "src/Algorithm/IpGenAugSystemSolver.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "IpLineSearch": {
    "brief": "Strategy interface for globalization via line search\n\nLineSearch is the abstract base for all line search strategies\nin Ipopt's globalization framework. Given a search direction\n(from IpData.delta()), finds an acceptable trial point.",
    "file": "IpLineSearch",
    "library": "Ipopt",
    "layer": "layer-2",
    "header": "src/Algorithm/IpLineSearch.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "IpLimMemQuasiNewtonUpdater": {
    "brief": "Limited-memory quasi-Newton Hessian approximation (L-BFGS/SR1)\n\nLimMemQuasiNewtonUpdater maintains a low-rank approximation of the\nLagrangian Hessian using limited-memory BFGS or SR1 updates.\n\nCompact representation: W = \u03c3I + V*M^(-1)*V^T where\n- \u03c3: Scalar initialization factor (B0_ if diagonal)\n- V, U: Low-rank update matrices derived from S, Y history\n- S_: Matrix of step vectors s_k = x_{k+1} - x_k\n- Y_: Matrix of gradient differences y_k = \u2207L_{k+1} - \u2207L_k\n\nUpdate types (limited_memory_update_type_):\n- BFGS: Positive definite secant update, may skip if s'y <= 0\n- SR1: Symmetric rank-1, can capture negative curvature\n\nInitialization (limited_memory_initialization_):\n- SCALAR1-4: Various heuristics for \u03c3 based on y'y/s'y\n- CONSTANT: Fixed \u03c3 = limited_memory_init_val_\n\nKey parameters:\n- limited_memory_max_history_: Maximum stored (s,y) pairs\n- limited_memory_max_skipping_: Reset after N consecutive skips\n- sigma_safe_min/max_: Safeguards for initialization factor\n\nRestoration phase (update_for_resto_):\n- Structured update accounting for \u03b7*D_r*x quadratic term\n- Ypart_ stores constraint-only gradient differences",
    "file": "IpLimMemQuasiNewtonUpdater",
    "library": "Ipopt",
    "layer": "layer-2",
    "header": "src/Algorithm/IpLimMemQuasiNewtonUpdater.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "IpExactHessianUpdater": {
    "brief": "Hessian updater using exact second derivatives from NLP\n\nExactHessianUpdater is a trivial HessianUpdater implementation that\nsimply retrieves the exact Hessian of the Lagrangian from the NLP\nat each iteration.",
    "file": "IpExactHessianUpdater",
    "library": "Ipopt",
    "layer": "layer-2",
    "header": "src/Algorithm/IpExactHessianUpdater.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "IpProbingMuOracle": {
    "brief": "Mehrotra's probing heuristic for barrier parameter selection\n\nProbingMuOracle implements Mehrotra's predictor-corrector approach\nto compute the barrier parameter mu. This is the strategy used in\nmany interior point codes like LOQO and PCx.\n\nAlgorithm:\n1. Compute affine scaling direction (predictor step) with sigma=0\n2. Find maximum step to boundary (alpha_aff)\n3. Compute complementarity after affine step: mu_aff\n4. Compute centering parameter: sigma = (mu_aff/mu)^3\n5. Use sigma in corrector step\n\nThe centering parameter sigma controls the balance between:\n- sigma=0: Pure affine scaling (aggressive, may overshoot)\n- sigma=1: Pure centering (conservative, slow progress)\n\nKey parameter:\n- sigma_max_: Upper bound on sigma to prevent excessive centering",
    "file": "IpProbingMuOracle",
    "library": "Ipopt",
    "layer": "layer-2",
    "header": "src/Algorithm/IpProbingMuOracle.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "IpMonotoneMuUpdate": {
    "brief": "Standard monotone barrier parameter update strategy\n\nMonotoneMuUpdate implements the classical IPM approach where the\nbarrier parameter mu is reduced monotonically as the subproblem\nconverges.\n\nUpdate rule:\n1. Solve barrier subproblem to tolerance barrier_tol_factor_ * mu\n2. Reduce mu: new_mu = max(mu_target_, min(kappa_mu * mu, mu^theta_mu))\n   where kappa_mu = mu_linear_decrease_factor_\n   and theta_mu = mu_superlinear_decrease_power_\n3. Update tau (fraction-to-boundary): tau = max(tau_min_, 1 - mu)\n\nKey parameters:\n- mu_init_: Initial barrier parameter\n- mu_linear_decrease_factor_: Linear decrease factor kappa_mu\n- mu_superlinear_decrease_power_: Superlinear power theta_mu\n- tau_min_: Minimum fraction-to-boundary parameter\n- mu_target_: Target mu for termination\n\nFast decrease heuristic:\n- mu_allow_fast_monotone_decrease_: Allow faster decrease when\n  complementarity is already small\n\nInteractions:\n- Calls linesearch_->Reset() when mu changes\n- Filter is cleared on barrier parameter update",
    "file": "IpMonotoneMuUpdate",
    "library": "Ipopt",
    "layer": "layer-2",
    "header": "src/Algorithm/IpMonotoneMuUpdate.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "IpUserScaling": {
    "brief": "NLP scaling using user-provided scaling factors\n\nUserScaling obtains scaling factors directly from the NLP interface\nvia the get_scaling_parameters callback (TNLP) or GetScalingParameters\nmethod (NLP).",
    "file": "IpUserScaling",
    "library": "Ipopt",
    "layer": "layer-2",
    "header": "src/Algorithm/IpUserScaling.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "IpOrigIterationOutput": {
    "brief": "Standard iteration output for original NLP problem\n\nOrigIterationOutput displays the per-iteration summary line\nfor the original (non-restoration) NLP problem.",
    "file": "IpOrigIterationOutput",
    "library": "Ipopt",
    "layer": "layer-2",
    "header": "src/Algorithm/IpOrigIterationOutput.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "IpRestoRestoPhase": {
    "brief": "Recursive restoration for separable n,p variable initialization\n\nRestoRestorationPhase provides a specialized \"restoration within\nrestoration\" procedure for the MinC_1NrmRestorationPhase. It computes\noptimal values for the slack variables (n_c, p_c, n_d, p_d) by\ntreating them as separable from x and s.",
    "file": "IpRestoRestoPhase",
    "library": "Ipopt",
    "layer": "layer-2",
    "header": "src/Algorithm/IpRestoRestoPhase.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "IpIterateInitializer": {
    "brief": "Strategy interface for computing initial iterates\n\nIterateInitializer is the abstract base for strategies that\ncompute the starting point (x, s, y_c, y_d, z_L, z_U, v_L, v_U)\nfor the interior point algorithm.",
    "file": "IpIterateInitializer",
    "library": "Ipopt",
    "layer": "layer-2",
    "header": "src/Algorithm/IpIterateInitializer.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "IpMuOracle": {
    "brief": "Strategy interface for suggesting barrier parameter values\n\nMuOracle is the abstract interface for components that compute\nsuggested values for the barrier parameter mu in adaptive (non-monotone)\nbarrier updates.",
    "file": "IpMuOracle",
    "library": "Ipopt",
    "layer": "layer-2",
    "header": "src/Algorithm/IpMuOracle.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "IpRestoIpoptNLP": {
    "brief": "IpoptNLP adapter for restoration phase feasibility problem\n\nRestoIpoptNLP transforms the original NLP into a feasibility problem\nfor the restoration phase. It introduces slack variables to allow\nconstraint violations and penalizes them in the objective.",
    "file": "IpRestoIpoptNLP",
    "library": "Ipopt",
    "layer": "layer-2",
    "header": "src/Algorithm/IpRestoIpoptNLP.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "IpFilter": {
    "brief": "Multi-dimensional filter for globalization (W\u00e4chter-Biegler)\n\nThe Filter implements the filter globalization mechanism where a\npoint is acceptable if it improves in at least one of multiple\nobjectives (typically constraint violation \u03b8 and objective \u03c6).\n\nFilter acceptance rule: A point (\u03b8, \u03c6) is acceptable to the filter\nif for every entry (\u03b8_i, \u03c6_i) in the filter, either \u03b8 < \u03b8_i or \u03c6 < \u03c6_i.\n\nKey concepts:\n- FilterEntry: Single entry storing coordinates and iteration number\n- Dominated entries are removed when new entries are added\n- Margin parameters (gamma_theta, gamma_phi) provide sufficient decrease\n\nClasses:\n- FilterEntry: Single point in the filter with coordinates\n- Filter: Container managing list of entries with add/query operations\n\nUsed by FilterLSAcceptor for filter line search acceptance tests.",
    "file": "IpFilter",
    "library": "Ipopt",
    "layer": "layer-2",
    "header": "src/Algorithm/IpFilter.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "IpIpoptNLP": {
    "brief": "Internal NLP interface with caching and scaling\n\nIpoptNLP abstracts the optimization problem for internal use:\n  min f(x)  s.t.  c(x) = 0, d_L <= d(x) <= d_U, x_L <= x <= x_U",
    "file": "IpIpoptNLP",
    "library": "Ipopt",
    "layer": "layer-2",
    "header": "src/Algorithm/IpIpoptNLP.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "IpConvCheck": {
    "brief": "Strategy interface for checking algorithm termination\n\nConvergenceCheck is the abstract base for convergence testing\nstrategies. Called each iteration to determine if optimization\nshould continue, has converged, or has failed.",
    "file": "IpConvCheck",
    "library": "Ipopt",
    "layer": "layer-2",
    "header": "src/Algorithm/IpConvCheck.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "IpWarmStartIterateInitializer": {
    "brief": "Warm start initialization from previous solution\n\nWarmStartIterateInitializer initializes IPM iterates from a\npreviously computed solution, enabling faster convergence for\nrelated problems (e.g., MPC, parametric optimization).\n\nWarm start sources:\n- warm_start_entire_iterate_: Use GetWarmStartIterate() from NLP\n- Otherwise: Use initialization vectors from NLP\n\nProcessing steps:\n1. Push primals away from bounds (warm_start_bound_push/frac_)\n2. Push slacks (warm_start_slack_bound_push/frac_)\n3. Clip multipliers (warm_start_mult_init_max_)\n4. Ensure bound multipliers positive (warm_start_mult_bound_push_)\n\nTarget mu adjustment (warm_start_target_mu_):\n- Adjusts slack/multiplier pairs toward target complementarity\n- process_target_mu(): Scales to achieve s*z \u2248 target_mu\n- adapt_to_target_mu(): Fine-tunes pairing\n\nKey parameters:\n- warm_start_bound_push_: Absolute bound push\n- warm_start_bound_frac_: Relative bound push\n- warm_start_mult_init_max_: Maximum multiplier magnitude\n- warm_start_target_mu_: Target barrier parameter",
    "file": "IpWarmStartIterateInitializer",
    "library": "Ipopt",
    "layer": "layer-2",
    "header": "src/Algorithm/IpWarmStartIterateInitializer.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "IpEqMultCalculator": {
    "brief": "Strategy interface for computing equality constraint multipliers\n\nEqMultiplierCalculator is the abstract base for computing estimates\nof the equality constraint multipliers y_c and y_d. These estimates\nare used for:",
    "file": "IpEqMultCalculator",
    "library": "Ipopt",
    "layer": "layer-2",
    "header": "src/Algorithm/IpEqMultCalculator.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "IpLowRankSSAugSystemSolver": {
    "brief": "Low-rank Hessian handling via single backsolve (iterative solver friendly)\n\nLowRankSSAugSystemSolver handles LowRankUpdateSymMatrix Hessians\n(from L-BFGS) by augmenting the system rather than using\nSherman-Morrison. This requires only ONE factorization/backsolve.",
    "file": "IpLowRankSSAugSystemSolver",
    "library": "Ipopt",
    "layer": "layer-2",
    "header": "src/Algorithm/IpLowRankSSAugSystemSolver.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "IpLoqoMuOracle": {
    "brief": "LOQO formula for barrier parameter selection\n\nLoqoMuOracle computes the barrier parameter using the heuristic\nfrom the LOQO solver (Vanderbei). This provides a simple formula\nbased on current complementarity.\n\nThe LOQO formula typically uses:\n  sigma = min(0.1, 100*mu)\n  mu_new = sigma * (current_complementarity / n)\n\nThis is a simple, stateless oracle that doesn't require solving\nan additional linear system (unlike probing or quality function).\n\nCompared to other strategies:\n- ProbingMuOracle: Requires affine step computation\n- QualityFunctionMuOracle: Requires 1D optimization\n- LoqoMuOracle: Direct formula, no extra computation",
    "file": "IpLoqoMuOracle",
    "library": "Ipopt",
    "layer": "layer-2",
    "header": "src/Algorithm/IpLoqoMuOracle.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "IpPDSearchDirCalc": {
    "brief": "Newton search direction computation via primal-dual system\n\nPDSearchDirCalculator is the standard SearchDirectionCalculator\nimplementation that computes the Newton step by solving the\nprimal-dual KKT system.",
    "file": "IpPDSearchDirCalc",
    "library": "Ipopt",
    "layer": "layer-2",
    "header": "src/Algorithm/IpPDSearchDirCalc.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "IpGradientScaling": {
    "brief": "NLP scaling based on gradient magnitudes at initial point\n\nGradientScaling computes scaling factors for the NLP based on the\nmaximum gradient norms at the user-provided starting point. This\nimproves problem conditioning by normalizing objective and constraint\nmagnitudes.",
    "file": "IpGradientScaling",
    "library": "Ipopt",
    "layer": "layer-2",
    "header": "src/Algorithm/IpGradientScaling.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "IpIpoptCalculatedQuantities": {
    "brief": "Cached computation of all derived quantities from iterates\n\nIpoptCalculatedQuantities is the central caching layer for computed\nvalues derived from the current/trial iterates in IpoptData:\n\nCached quantities include:\n- Slacks: slack_x_L, slack_x_U, slack_s_L, slack_s_U\n- Objective: f, grad_f, barrier_obj, grad_barrier_obj\n- Constraints: c, d, d-s, jac_c, jac_d, J^T*y products\n- Primal-dual: grad_lag_x/s, complementarity, relaxed_compl\n- Errors: primal/dual infeasibility, complementarity, nlp_error\n- Line search: frac_to_bound, sigma matrices",
    "file": "IpIpoptCalculatedQuantities",
    "library": "Ipopt",
    "layer": "layer-2",
    "header": "src/Algorithm/IpIpoptCalculatedQuantities.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "IpHessianUpdater": {
    "brief": "Strategy interface for Hessian computation/approximation\n\nHessianUpdater is the abstract base for strategies that provide\nthe Hessian of the Lagrangian (or an approximation) to the algorithm.\nThe result is stored in IpData.W().",
    "file": "IpHessianUpdater",
    "library": "Ipopt",
    "layer": "layer-2",
    "header": "src/Algorithm/IpHessianUpdater.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "IpRestoMinC_1Nrm": {
    "brief": "Restoration phase minimizing 1-norm of constraint violation\n\nMinC_1NrmRestorationPhase is the main restoration phase implementation.\nWhen the line search cannot make progress, it minimizes constraint\nviolation to find a feasible point from which optimization can continue.\n\nRestoration NLP formulation:\n  min  \u03c1 * ||[p_c; n_c; p_d; n_d]||_1 + (\u03b7/2) * ||D_r(x - x_ref)||_2^2\n  s.t. c(x) - p_c + n_c = 0\n       d_L <= d(x) - p_d + n_d <= d_U\n       x_L <= x <= x_U\n       p_c, n_c, p_d, n_d >= 0\n\nWhere:\n- \u03c1: Penalty on infeasibility (resto_penalty_parameter)\n- \u03b7: Proximity weight (resto_proximity_weight * sqrt(mu))\n- D_r: Diagonal scaling based on reference point\n- x_ref: Starting point for restoration\n\nKey behaviors:\n- Uses nested IpoptAlgorithm to solve restoration NLP\n- eq_mult_calculator_ reinitializes multipliers after restoration\n- bound_mult_reset_threshold_: Limits post-restoration bound multipliers\n- count_restorations_: Tracks restoration phase calls",
    "file": "IpRestoMinC_1Nrm",
    "library": "Ipopt",
    "layer": "layer-2",
    "header": "src/Algorithm/IpRestoMinC_1Nrm.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "IpBacktrackingLSAcceptor": {
    "brief": "Strategy interface for step acceptance in backtracking line search\n\nBacktrackingLSAcceptor defines the interface for step acceptance\ntests used by BacktrackingLineSearch. Implementations decide whether\na trial point should be accepted based on various criteria.",
    "file": "IpBacktrackingLSAcceptor",
    "library": "Ipopt",
    "layer": "layer-2",
    "header": "src/Algorithm/IpBacktrackingLSAcceptor.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "IpPenaltyLSAcceptor": {
    "brief": "Penalty function line search using Waltz-Morales-Nocedal-Orban method\n\nPenaltyLSAcceptor implements exact penalty function globalization\nas an alternative to filter line search. Based on the paper by\nWaltz, Morales, Nocedal, and Orban.\n\nMerit function: phi_nu(x) = f(x) + nu * ||c(x)||_1\n\nAcceptance criterion:\n  phi_nu(x + alpha*d) <= phi_nu(x) + eta * alpha * pred\nwhere pred is the predicted reduction.\n\nPenalty parameter nu:\n- Automatically updated to ensure descent direction\n- Increased by nu_inc_ when direction is not descent\n- nu_init_ provides starting value\n\nKey parameters:\n- nu_init_, nu_inc_: Penalty parameter initialization/increment\n- eta_: Sufficient decrease parameter (Armijo)\n- rho_: Parameter for predicted reduction calculation\n- max_soc_: Maximum second order correction steps",
    "file": "IpPenaltyLSAcceptor",
    "library": "Ipopt",
    "layer": "layer-2",
    "header": "src/Algorithm/IpPenaltyLSAcceptor.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "IpRestoFilterConvCheck": {
    "brief": "Restoration phase convergence check for filter line search\n\nRestoFilterConvergenceCheck specializes restoration phase termination\nfor use with the filter globalization mechanism. It checks whether\nthe current restoration point would be acceptable to the original\nproblem's filter.",
    "file": "IpRestoFilterConvCheck",
    "library": "Ipopt",
    "layer": "layer-2",
    "header": "src/Algorithm/IpRestoFilterConvCheck.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "IpBacktrackingLineSearch": {
    "brief": "General backtracking line search with filter/restoration support\n\nBacktrackingLineSearch is the main LineSearch implementation,\nproviding a flexible framework for globalization strategies:\n\nCore algorithm:\n1. Start with full step alpha = alpha_max (fraction-to-boundary)\n2. Test acceptability via BacktrackingLSAcceptor\n3. If rejected, reduce alpha *= alpha_red_factor and retry\n4. If alpha becomes too small, trigger restoration phase\n\nAdvanced features:\n- Watchdog mechanism: Accept poor steps temporarily to escape local minima\n- Second-order correction (SOC): Improve constraint satisfaction\n- Soft restoration phase: Accept steps that reduce primal-dual error\n- Magic steps: Improve slack/bound multiplier pairing\n- Corrector steps: Improve local convergence rate\n\nKey parameters:\n- alpha_for_y: How to step in equality multipliers\n- watchdog_trial_iter_max: Watchdog iteration limit\n- max_soc: Maximum second-order corrections",
    "file": "IpBacktrackingLineSearch",
    "library": "Ipopt",
    "layer": "layer-2",
    "header": "src/Algorithm/IpBacktrackingLineSearch.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "IpEquilibrationScaling": {
    "brief": "NLP scaling using MC19 matrix equilibration\n\nEquilibrationScaling computes scaling factors using the HSL MC19\nsymmetric indefinite matrix equilibration routine. This produces\nwell-conditioned scaling by analyzing the Jacobian structure.",
    "file": "IpEquilibrationScaling",
    "library": "Ipopt",
    "layer": "layer-2",
    "header": "src/Algorithm/IpEquilibrationScaling.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "IpRestoPenaltyConvCheck": {
    "brief": "Restoration phase convergence for penalty line search\n\nRestoPenaltyConvergenceCheck extends RestoConvergenceCheck for use\nwhen the original algorithm uses penalty function globalization\n(as opposed to filter method).",
    "file": "IpRestoPenaltyConvCheck",
    "library": "Ipopt",
    "layer": "layer-2",
    "header": "src/Algorithm/IpRestoPenaltyConvCheck.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "IpRestoPhase": {
    "brief": "Strategy interface for restoration phase fallback\n\nRestorationPhase is the abstract base for the fallback mechanism\nwhen the line search cannot make progress. The restoration phase\nminimizes constraint violation to find a feasible point.\n\nTriggered when:\n- Line search step size becomes too small\n- No search direction can be computed (singular KKT system)\n- Algorithm explicitly requests fallback (ActivateFallbackMechanism)\n\nExceptions thrown on restoration failure:\n- RESTORATION_CONVERGED_TO_FEASIBLE_POINT: Success, found feasible point\n- RESTORATION_FAILED: Could not reduce infeasibility\n- RESTORATION_MAXITER_EXCEEDED: Hit iteration limit\n- RESTORATION_USER_STOP: User callback requested stop\n\nMain implementation: RestoIterationOutput minimizes ||c(x)||^2 + ||d(x)-s||^2\nusing the interior point method on a modified feasibility problem.",
    "file": "IpRestoPhase",
    "library": "Ipopt",
    "layer": "layer-2",
    "header": "src/Algorithm/IpRestoPhase.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "IpNLPScaling": {
    "brief": "NLP scaling framework for problem conditioning\n\nNLPScalingObject is the abstract base for applying diagonal scaling\nto the NLP to improve numerical conditioning. Transforms:\n  min s_f*f(S_x^{-1}*x\u0303)  s.t.  s_c*c(S_x^{-1}*x\u0303)=0, ...",
    "file": "IpNLPScaling",
    "library": "Ipopt",
    "layer": "layer-2",
    "header": "src/Algorithm/IpNLPScaling.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "IpFilterLSAcceptor": {
    "brief": "Filter line search acceptor using W\u00e4chter-Biegler method\n\nFilterLSAcceptor implements the filter globalization strategy where\nstep acceptance is based on improvement in either constraint violation\n(theta) or barrier objective (phi).\n\nAcceptance criteria:\n- Armijo sufficient decrease in barrier function, OR\n- Sufficient reduction in constraint violation (switching condition)\n- Point must be acceptable to current filter\n\nKey parameters:\n- theta_max_fact_: Upper bound factor on infeasibility\n- gamma_phi_, gamma_theta_: Margin parameters for filter\n- eta_phi_: Armijo parameter\n- s_phi_, s_theta_: Exponents in switching condition\n\nSecond-order correction (SOC):\n- When step is rejected, solves for constraint linearization error\n- Up to max_soc_ corrections tried\n- kappa_soc_ controls required constraint reduction between SOCs\n\nCorrector steps:\n- Affine or primal-dual corrector for fast local convergence\n- Applied even when step is acceptable\n\nFilter management:\n- Dominated entries removed on filter augmentation\n- Filter reset heuristic when repeatedly rejected by filter",
    "file": "IpFilterLSAcceptor",
    "library": "Ipopt",
    "layer": "layer-2",
    "header": "src/Algorithm/IpFilterLSAcceptor.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "IpRestoConvCheck": {
    "brief": "Base class for restoration phase convergence checking\n\nRestoConvergenceCheck extends OptimalityErrorConvergenceCheck for\nthe restoration phase, adding termination criteria based on\nacceptability to the original problem's globalization mechanism.",
    "file": "IpRestoConvCheck",
    "library": "Ipopt",
    "layer": "layer-2",
    "header": "src/Algorithm/IpRestoConvCheck.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "IpDefaultIterateInitializer": {
    "brief": "Standard initialization procedure for IPM iterates\n\nDefaultIterateInitializer computes starting points for all primal\nand dual variables based on user options and problem bounds.\n\nPrimal initialization (x, s):\n- Start from user-provided x0 or NLP default\n- Push away from bounds: x_new = max(x_L + \u03b5, min(x, x_U - \u03b5))\n- bound_push_, bound_frac_: Absolute/relative push parameters\n- least_square_init_primal_: Fit linearized constraints\n\nDual initialization:\n- Equality multipliers (y_c, y_d): Least-squares or zero\n- eq_mult_calculator_: Computes min ||y|| s.t. KKT gradient\n- constr_mult_init_max_: Reject large multiplier estimates\n- Bound multipliers (z_L, z_U, v_L, v_U):\n  - B_CONSTANT: bound_mult_init_val_\n  - B_MU_BASED: mu_init_ / slack\n\nWarm start:\n- warm_start_init_point_: Use warm_start_initializer_ instead\n- Delegates to WarmStartIterateInitializer\n\nStatic utilities:\n- push_variables(): Move point away from bounds\n- least_square_mults(): Compute y from gradient conditions",
    "file": "IpDefaultIterateInitializer",
    "library": "Ipopt",
    "layer": "layer-2",
    "header": "src/Algorithm/IpDefaultIterateInitializer.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "IpPDSystemSolver": {
    "brief": "Abstract interface for solving the full primal-dual KKT system\n\nPDSystemSolver defines the interface for solving the 8x8 block\nprimal-dual linear system that arises at each Newton iteration:\n\n  [W    0   Jc^T  Jd^T  -Px_L  Px_U   0     0   ] [dx  ]   [rx  ]\n  [0    0    0    -I     0     0    -Pd_L  Pd_U ] [ds  ]   [rs  ]\n  [Jc   0    0     0     0     0     0     0   ] [dyc ] = [rc  ]\n  [Jd  -I    0     0     0     0     0     0   ] [dyd ]   [rd  ]\n  [Zl  Px_L^T ...                              ] [dzL ]   [rzL ]\n  [...]                                          [dzU ]   [rzU ]\n  [...]                                          [dvL ]   [rvL ]\n  [...]                                          [dvU ]   [rvU ]\n\nImplementations typically reduce this to the 4x4 augmented system\nby eliminating the bound multiplier equations, then solve via\nAugSystemSolver. The key implementation is PDFullSpaceSolver.",
    "file": "IpPDSystemSolver",
    "library": "Ipopt",
    "layer": "layer-2",
    "header": "src/Algorithm/IpPDSystemSolver.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "IpMuUpdate": {
    "brief": "Strategy interface for updating barrier parameter mu\n\nMuUpdate is the abstract base for strategies that determine the\nbarrier parameter mu and fraction-to-boundary parameter tau for\neach iteration of the interior point method.",
    "file": "IpMuUpdate",
    "library": "Ipopt",
    "layer": "layer-2",
    "header": "src/Algorithm/IpMuUpdate.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "IpNLPBoundsRemover": {
    "brief": "NLP adapter that converts variable bounds to inequality constraints\n\nNLPBoundsRemover is an NLP adapter primarily used for inexact/iterative\nlinear solvers that require the KKT system to have a specific structure\nwithout bound constraints.",
    "file": "IpNLPBoundsRemover",
    "library": "Ipopt",
    "layer": "layer-2",
    "header": "src/Algorithm/IpNLPBoundsRemover.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "IpAlgorithmRegOp": {
    "brief": "Registration function for all Algorithm module options\n\nDeclares RegisterOptions_Algorithm() which registers all options\nfor the Ipopt algorithm components with the RegisteredOptions system.\n\nThis function is called during IpoptApplication initialization to\nmake all algorithm options available. It aggregates option registration\nfrom numerous strategy classes.\n\nRegistered option categories include:\n- Main algorithm options (IpoptAlgorithm)\n- Line search options (BacktrackingLineSearch, FilterLSAcceptor)\n- Barrier parameter options (MonotoneMuUpdate, AdaptiveMuUpdate)\n- Linear solver options (PDFullSpaceSolver, AugSystemSolver)\n- Initialization options (DefaultIterateInitializer)\n- Scaling options (NLPScaling, GradientScaling)\n- Convergence options (OptimalityErrorConvergenceCheck)\n- Output options (OrigIterationOutput)",
    "file": "IpAlgorithmRegOp",
    "library": "Ipopt",
    "layer": "layer-2",
    "header": "src/Algorithm/IpAlgorithmRegOp.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "IpRestoIterationOutput": {
    "brief": "Iteration output during restoration phase\n\nRestoIterationOutput provides per-iteration summary output while\nthe algorithm is in restoration phase. It displays metrics for the\nORIGINAL NLP (not the restoration feasibility problem).\n\nOutput format:\n- Iteration number marked with 'r' prefix to indicate restoration\n- Objective value from original NLP\n- Constraint violation (theta) for original constraints\n- Dual infeasibility for original problem\n\nDual output mode:\nIf resto_orig_iteration_output is provided, produces two lines:\n1. Restoration phase problem metrics\n2. Original NLP metrics (using original scaling)\n\nConfiguration:\n- print_info_string_: Whether to print info at end of line\n- inf_pr_output_: What to show in inf_pr column\n- print_frequency_iter_: Iteration print frequency\n- print_frequency_time_: Time-based print frequency",
    "file": "IpRestoIterationOutput",
    "library": "Ipopt",
    "layer": "layer-2",
    "header": "src/Algorithm/IpRestoIterationOutput.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "IpAdaptiveMuUpdate": {
    "brief": "Adaptive (non-monotone) barrier parameter update strategy\n\nAdaptiveMuUpdate implements the free-mode/fixed-mode approach for\nbarrier parameter updates. In free mode, mu is computed adaptively\neach iteration. In fixed mode, monotone decrease is enforced.\n\nTwo operating modes:\n- Free mode: MuOracle suggests mu (e.g., Mehrotra predictor-corrector\n  or quality function minimization). Allows temporary mu increases.\n- Fixed mode: Monotone decrease enforced. Triggered when free mode\n  fails to make sufficient progress.\n\nGlobalization strategies (adaptive_mu_globalization_):\n- KKT_ERROR: Track reduction in primal-dual KKT error\n- FILTER_OBJ_CONSTR: Use filter on (theta, phi)\n- NEVER_MONOTONE_MODE: Always stay in free mode\n\nFree mode oracles (via MuOracle):\n- QualityFunctionMuOracle: Minimize quality function\n- ProbingMuOracle: Try candidate mu values\n- LoqoMuOracle: LOQO-style adaptive rule\n\nFixed mode behavior:\n- Uses fix_mu_oracle_ or average complementarity\n- restore_accepted_iterate_: Can restore last good free-mode point\n\nReference value tracking:\n- refs_vals_: List of recent KKT error values\n- refs_red_fact_: Required reduction factor\n- num_refs_max_: Maximum stored references",
    "file": "IpAdaptiveMuUpdate",
    "library": "Ipopt",
    "layer": "layer-2",
    "header": "src/Algorithm/IpAdaptiveMuUpdate.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "IpQualityFunctionMuOracle": {
    "brief": "Barrier parameter selection via quality function minimization\n\nQualityFunctionMuOracle computes the barrier parameter by minimizing\na quality function that measures how close the predictor-corrector\nstep brings the iterate to optimality.\n\nAlgorithm:\n1. Compute affine scaling direction (mu = 0)\n2. Compute centering direction (pure mu term)\n3. For combined step (sigma * centering + affine), find optimal sigma\n4. Convert optimal sigma to mu = sigma * average_complementarity\n\nQuality function Q(sigma) measures (configurable):\n- Primal-dual error norm after step\n- Centrality deviation from mu-centered path\n- Balancing term for primal/dual progress\n\nConfiguration options:\n- quality_function_norm_: NM_NORM_1, NM_NORM_2, NM_NORM_MAX\n- quality_function_centrality_: CEN_NONE, CEN_LOG, CEN_RECIPROCAL\n- quality_function_balancing_term_: BT_NONE, BT_CUBIC\n\nGolden section search:\n- Finds optimal sigma in [sigma_min_, sigma_max_]\n- Tolerances: quality_function_section_sigma_tol_, _qf_tol_\n- Maximum iterations: quality_function_max_section_steps_",
    "file": "IpQualityFunctionMuOracle",
    "library": "Ipopt",
    "layer": "layer-2",
    "header": "src/Algorithm/IpQualityFunctionMuOracle.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "IpAugRestoSystemSolver": {
    "brief": "Augmented system solver exploiting restoration phase structure\n\nAugRestoSystemSolver is a decorator that exploits the known structure\nof the restoration phase problem to reduce the augmented system to\nthe original problem size.",
    "file": "IpAugRestoSystemSolver",
    "library": "Ipopt",
    "layer": "layer-2",
    "header": "src/Algorithm/IpAugRestoSystemSolver.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "IpAugSystemSolver": {
    "brief": "Abstract interface for solving the 4x4 augmented KKT system\n\nAugSystemSolver defines the interface for solving the reduced\naugmented system obtained by eliminating bound multiplier equations:\n\n  [W + Dx + \u03b4x*I      0        Jc^T      Jd^T  ] [sol_x]   [rhs_x]\n  [    0         Ds + \u03b4s*I     0         -I   ] [sol_s] = [rhs_s]\n  [   Jc             0      Dc - \u03b4c*I    0    ] [sol_c]   [rhs_c]\n  [   Jd            -I         0      Dd - \u03b4d*I] [sol_d]   [rhs_d]",
    "file": "IpAugSystemSolver",
    "library": "Ipopt",
    "layer": "layer-2",
    "header": "src/Algorithm/IpAugSystemSolver.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "IpPDPerturbationHandler": {
    "brief": "Inertia correction via primal-dual perturbation (regularization)\n\nPDPerturbationHandler manages the regularization parameters\n(delta_x, delta_s, delta_c, delta_d) added to the KKT system to\nensure correct inertia (n positive, m+p negative eigenvalues).\n\nThe perturbed augmented system is:\n  [W + D_x + \u03b4_x I   ...  ]\n  [  ...   D_s + \u03b4_s I  ...]\n  [  ...   ... D_c - \u03b4_c I]\n  [  ...   ...   D_d - \u03b4_d I]\n\nPerturbation strategies:\n- ConsiderNewSystem(): Called for each new matrix, may add \u03b4_c, \u03b4_d\n  if structurally singular Jacobian is detected\n- PerturbForSingularity(): Handle numerically singular system\n- PerturbForWrongInertia(): Correct incorrect eigenvalue count\n\nHeuristics:\n- Track structural degeneracy (hess_degenerate_, jac_degenerate_)\n- Increase perturbation exponentially until acceptable\n- Decrease perturbation when not needed",
    "file": "IpPDPerturbationHandler",
    "library": "Ipopt",
    "layer": "layer-2",
    "header": "src/Algorithm/IpPDPerturbationHandler.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "IpStdAugSystemSolver": {
    "brief": "Standard augmented system solver forming explicit matrix\n\nStdAugSystemSolver is the main implementation of AugSystemSolver\nfor sparse triple-format matrices (SymTMatrix). It explicitly\nassembles the 4x4 augmented system as a CompoundSymMatrix:\n\n  [W + D_x + \u03b4_x I      0         J_c^T      J_d^T  ]\n  [     0          D_s + \u03b4_s I    0          -I    ]\n  [    J_c             0       D_c - \u03b4_c I    0     ]\n  [    J_d            -I          0       D_d - \u03b4_d I]\n\nImplementation details:\n- Uses CompoundSymMatrixSpace with SumSymMatrix for (1,1) block\n- DiagMatrix for D_x, D_s, D_c, D_d contributions\n- IdentityMatrix for scalar delta regularization\n- Tracks matrix tags to avoid unnecessary reassembly\n- Delegates factorization/solve to SymLinearSolver",
    "file": "IpStdAugSystemSolver",
    "library": "Ipopt",
    "layer": "layer-2",
    "header": "src/Algorithm/IpStdAugSystemSolver.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "IpIpoptAlg": {
    "brief": "Main Ipopt algorithm orchestrating the interior point method\n\nIpoptAlgorithm is the central class implementing the primal-dual\ninterior point method. Each iteration:\n1. UpdateHessian() - Evaluate or update Hessian approximation\n2. UpdateBarrierParameter() - Adjust mu using chosen strategy\n3. ComputeSearchDirection() - Solve KKT system for Newton step\n4. ComputeAcceptableTrialPoint() - Line search with filter/merit\n5. AcceptTrialPoint() - Update current iterate\n\nUses Strategy pattern: line search, mu update, convergence check\nare all pluggable components configured via AlgorithmBuilder.",
    "file": "IpIpoptAlg",
    "library": "Ipopt",
    "layer": "layer-2",
    "header": "src/Algorithm/IpIpoptAlg.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "IpRestoIterateInitializer": {
    "brief": "Iterate initialization for restoration phase\n\nRestoIterateInitializer computes starting values for all variables\nin the restoration phase feasibility problem. This includes the\noriginal variables (x, s) and the slack variables (n_c, p_c, n_d, p_d).",
    "file": "IpRestoIterateInitializer",
    "library": "Ipopt",
    "layer": "layer-2",
    "header": "src/Algorithm/IpRestoIterateInitializer.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "IpIteratesVector": {
    "brief": "Combined primal-dual iterate vector for IPM algorithm\n\nIteratesVector is a specialized CompoundVector with fixed 8 components\nrepresenting the complete primal-dual iterate of the interior point method:",
    "file": "IpIteratesVector",
    "library": "Ipopt",
    "layer": "layer-2",
    "header": "src/Algorithm/IpIteratesVector.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "IpPDFullSpaceSolver": {
    "brief": "Full-space primal-dual system solver with inertia correction\n\nPDFullSpaceSolver is the main implementation of PDSystemSolver.\nIt reduces the 8x8 primal-dual system to the 4x4 augmented system\nby eliminating bound multiplier equations:\n  d_z = S^{-1}(rhs_z - Z*P^T*d_x)\n\nKey features:\n- Iterative refinement with quality monitoring (residual_ratio)\n- Inertia correction via PDPerturbationHandler (adds delta_x, delta_c)\n- Automatic retries with increased pivot tolerance\n- Handles singular systems by adding regularization\n\nParameters:\n- min/max_refinement_steps: Iterative refinement bounds\n- residual_ratio_max: Acceptable solution quality threshold\n- neg_curv_test_tol: Tolerance for inertia heuristics",
    "file": "IpPDFullSpaceSolver",
    "library": "Ipopt",
    "layer": "layer-2",
    "header": "src/Algorithm/IpPDFullSpaceSolver.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "IpTimingStatistics": {
    "brief": "Collection of timing statistics for algorithm profiling\n\nTimingStatistics aggregates TimedTask objects for all major\nalgorithm components, enabling performance profiling and\nbottleneck identification.\n\nTiming categories:\n- Algorithm phases: InitializeIterates, UpdateHessian, OutputIteration,\n  UpdateBarrierParameter, ComputeSearchDirection, etc.\n- Linear system: PDSystemSolverTotal, LinearSystemFactorization,\n  LinearSystemBackSolve, LinearSystemScaling\n- NLP evaluations: f_eval_time, grad_f_eval_time, c_eval_time,\n  jac_c_eval_time, d_eval_time, jac_d_eval_time, h_eval_time\n- Auxiliary: Task1-Task6 for ad-hoc profiling\n\nKey methods:\n- ResetTimes(): Clear all accumulated times\n- EnableTimes()/DisableTimes(): Control timing overhead\n- PrintAllTimingStatistics(): Output formatted timing report\n- TotalFunctionEvaluationCpuTime(): Sum of NLP evaluation times\n\nEach TimedTask tracks CPU time, system time, and wall-clock time.",
    "file": "IpTimingStatistics",
    "library": "Ipopt",
    "layer": "layer-2",
    "header": "src/Algorithm/IpTimingStatistics.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "IpSearchDirCalculator": {
    "brief": "Strategy interface for computing the Newton search direction\n\nSearchDirectionCalculator is the strategy interface for computing\nthe search direction at each IPM iteration. The computed direction\nis stored in IpData().delta() (an IteratesVector).",
    "file": "IpSearchDirCalculator",
    "library": "Ipopt",
    "layer": "layer-2",
    "header": "src/Algorithm/IpSearchDirCalculator.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "IpAlgBuilder": {
    "brief": "Builder pattern for constructing configured IpoptAlgorithm\n\nAlgorithmBuilder assembles a complete IpoptAlgorithm from components\nbased on user options. This implements the Builder design pattern,\ncentralizing the complex construction logic.\n\nBuild order (with dependency chain):\n1. SymLinearSolver (MA27/57/77/86/97, MUMPS, Pardiso, WSMP, etc.)\n2. AugSystemSolver (wraps SymLinearSolver for augmented system)\n3. PDSystemSolver (solves full primal-dual system)\n4. SearchDirectionCalculator, EqMultiplierCalculator\n5. IterateInitializer, LineSearch, MuUpdate, ConvergenceCheck\n\nCustomization: Subclass and override virtual Build* methods,\nor provide custom_solver in constructor.",
    "file": "IpAlgBuilder",
    "library": "Ipopt",
    "layer": "layer-2",
    "header": "src/Algorithm/IpAlgBuilder.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "IpIterationOutput": {
    "brief": "Strategy interface for per-iteration output display\n\nIterationOutput is the abstract base for strategies that produce\nthe iteration summary line and optional detailed output.\n\nStandard output line (from OrigIterationOutput):\n  iter  objective   inf_pr   inf_du   lg(mu)  ||d||  lg(rg) alpha_du alpha_pr ls\n\nInfPrOutput enum controls whether inf_pr shows internal (with slacks)\nor original NLP constraint violation.\n\nImplementations:\n- OrigIterationOutput: Standard one-line summary for original problem\n- RestoIterationOutput: Output during restoration phase\n\nOutput controlled by print_level option (0-12).",
    "file": "IpIterationOutput",
    "library": "Ipopt",
    "layer": "layer-2",
    "header": "src/Algorithm/IpIterationOutput.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "IpIpoptData": {
    "brief": "Central storage for all iteration data in Ipopt\n\nIpoptData holds the algorithmic state across iterations:\n- curr_: Current iterate (x, s, y_c, y_d, z_L, z_U, v_L, v_U)\n- trial_: Trial point from line search\n- delta_: Search direction from KKT solve\n- delta_aff_: Affine-scaling step (for Mehrotra predictor-corrector)\n- W_: Hessian or Hessian approximation",
    "file": "IpIpoptData",
    "library": "Ipopt",
    "layer": "layer-2",
    "header": "src/Algorithm/IpIpoptData.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "IpLowRankAugSystemSolver": {
    "brief": "Low-rank Hessian handling via Sherman-Morrison (multiple backsolves)\n\nLowRankAugSystemSolver handles LowRankUpdateSymMatrix Hessians\n(from L-BFGS quasi-Newton) using the Sherman-Morrison formula.\n\nL-BFGS Hessian: W = sigma*I + V*M*V^T (compact representation)\n- V: n x 2k matrix of gradient/step differences\n- M: 2k x 2k small dense matrix\n- k: number of stored corrections (limited memory)\n\nSherman-Morrison approach:\n(A + UV^T)^{-1} = A^{-1} - A^{-1}U(I + V^TA^{-1}U)^{-1}V^TA^{-1}\n\nImplementation:\n1. Solve diagonal system: Vtilde = A^{-1}*V (2k backsolves)\n2. Form small dense matrix: J = I + V^T*Vtilde\n3. Solve J*y = V^T*A^{-1}*rhs (small dense solve)\n4. Correct: x = A^{-1}*rhs - Vtilde*y\n\nStorage:\n- J1_, J2_: Dense matrices for correction\n- Vtilde1_, Utilde2_: MultiVectorMatrix backsolve results\n- Wdiag_: Diagonal part passed to base solver",
    "file": "IpLowRankAugSystemSolver",
    "library": "Ipopt",
    "layer": "layer-2",
    "header": "src/Algorithm/IpLowRankAugSystemSolver.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "IpOrigIpoptNLP": {
    "brief": "Standard IpoptNLP implementation wrapping user's NLP\n\nOrigIpoptNLP is the concrete implementation of IpoptNLP for standard\noptimization problems. It wraps the user's NLP (via TNLP/TNLPAdapter)\nand applies scaling transformations:\n\n  min s_f\u00b7f(S_x^{-1}\u00b7x\u0303)  s.t.  s_c\u00b7c(S_x^{-1}\u00b7x\u0303)=0, ...",
    "file": "IpOrigIpoptNLP",
    "library": "Ipopt",
    "layer": "layer-2",
    "header": "src/Algorithm/IpOrigIpoptNLP.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "IpAlgStrategy": {
    "brief": "Base class for all pluggable algorithm components\n\nAlgorithmStrategyObject is the abstract base for Ipopt's Strategy pattern\nimplementation. All pluggable algorithm components inherit from this:\n- LineSearch, MuUpdate, ConvergenceCheck\n- SearchDirectionCalculator, HessianUpdater\n- PDSystemSolver, AugSystemSolver",
    "file": "IpAlgStrategy",
    "library": "Ipopt",
    "layer": "layer-2",
    "header": "src/Algorithm/IpAlgStrategy.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "IpOptErrorConvCheck": {
    "brief": "Standard convergence check based on optimality error tolerances\n\nOptimalityErrorConvergenceCheck implements the standard termination\ncriteria for Ipopt based on KKT optimality conditions.\n\nOptimal convergence (tol):\n- Dual infeasibility <= dual_inf_tol_\n- Constraint violation <= constr_viol_tol_\n- Complementarity <= compl_inf_tol_\n- Overall scaled error <= tol\n\nAcceptable convergence (acceptable_tol):\n- Less stringent tolerances applied for acceptable_iter_ iterations\n- Terminates early if stuck near acceptable solution\n- acceptable_obj_change_tol_: Detects stagnation in objective\n\nFailure conditions:\n- max_iterations_: Iteration limit exceeded\n- max_wall_time_, max_cpu_time_: Time limits\n- diverging_iterates_tol_: Primal variables diverging\n- mu_target_: Target barrier parameter reached\n\nCurrentIsAcceptable():\n- Returns true if acceptable-level tolerances are met\n- Used by line search to decide on restoration phase",
    "file": "IpOptErrorConvCheck",
    "library": "Ipopt",
    "layer": "layer-2",
    "header": "src/Algorithm/IpOptErrorConvCheck.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "IpExpansionMatrix": {
    "brief": "Expansion/projection matrices for dimension mapping\n\nExpansionMatrix maps between vectors of different sizes:\n- MultVector: Embeds small vector into larger space (zero-fills)\n- TransMultVector: Projects large vector to smaller space (extracts)",
    "file": "IpExpansionMatrix",
    "library": "Ipopt",
    "layer": "layer-2",
    "header": "src/LinAlg/IpExpansionMatrix.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "IpMultiVectorMatrix": {
    "brief": "Tall-skinny matrix stored as collection of column Vectors\n\nMultiVectorMatrix represents an m x k matrix (k << m) where each\ncolumn is stored as a separate Vector. Efficient for:\n- Limited-memory quasi-Newton: store recent gradient differences\n- Low-rank updates: V*V^T matvec via two sequential operations",
    "file": "IpMultiVectorMatrix",
    "library": "Ipopt",
    "layer": "layer-2",
    "header": "src/LinAlg/IpMultiVectorMatrix.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "IpVector": {
    "brief": "Abstract base class for all vector types in Ipopt\n\nVector is the foundation of Ipopt's linear algebra abstraction.\nProvides BLAS-1 style operations (Copy, Scal, Axpy, Dot, Nrm2, etc.)\nplus IPM-specific operations (AddOneVector, FracToBound, etc.).",
    "file": "IpVector",
    "library": "Ipopt",
    "layer": "layer-2",
    "header": "src/LinAlg/IpVector.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "IpBlas": {
    "brief": "C++ wrappers for BLAS (Basic Linear Algebra Subprograms)\n\nProvides platform-independent access to BLAS Level 1, 2, and 3 routines.",
    "file": "IpBlas",
    "library": "Ipopt",
    "layer": "layer-2",
    "header": "src/LinAlg/IpBlas.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": true
  },
  "IpCompoundMatrix": {
    "brief": "Block-structured matrix composed of sub-matrices\n\nCompoundMatrix implements the Composite pattern for matrices,\nrepresenting a block matrix: M = [M_00, M_01, ...; M_10, ...]",
    "file": "IpCompoundMatrix",
    "library": "Ipopt",
    "layer": "layer-2",
    "header": "src/LinAlg/IpCompoundMatrix.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "IpIdentityMatrix": {
    "brief": "Scalar multiple of the identity matrix (factor * I)\n\nIdentityMatrix represents matrices of the form factor*I where\nI is the identity. Stores only the scalar factor - O(1) storage.\nMatrix-vector multiply is just a scale operation: y = factor*x.",
    "file": "IpIdentityMatrix",
    "library": "Ipopt",
    "layer": "layer-2",
    "header": "src/LinAlg/IpIdentityMatrix.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "IpSumSymMatrix": {
    "brief": "Symmetric matrix as weighted sum: M = sum(alpha_i * M_i)\n\nSumSymMatrix represents a symmetric matrix as a sum of symmetric terms,\neach with its own scalar factor. Preserves symmetry of components.",
    "file": "IpSumSymMatrix",
    "library": "Ipopt",
    "layer": "layer-2",
    "header": "src/LinAlg/IpSumSymMatrix.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "IpLowRankUpdateSymMatrix": {
    "brief": "Symmetric matrix as low-rank update: M = D + V*V^T - U*U^T\n\nLowRankUpdateSymMatrix represents matrices in factored form:\n  M = P_LR * (D + V*V^T - U*U^T) * P_LR^T  (if reduced_diag)\n  M = D + P_LR * (V*V^T - U*U^T) * P_LR^T  (otherwise)",
    "file": "IpLowRankUpdateSymMatrix",
    "library": "Ipopt",
    "layer": "layer-2",
    "header": "src/LinAlg/IpLowRankUpdateSymMatrix.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "IpScaledMatrix": {
    "brief": "Matrix decorator applying row and column scaling\n\nScaledMatrix wraps an unscaled matrix M to represent D_r * M * D_c\nwhere D_r and D_c are diagonal scaling matrices (stored as vectors).",
    "file": "IpScaledMatrix",
    "library": "Ipopt",
    "layer": "layer-2",
    "header": "src/LinAlg/IpScaledMatrix.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "IpZeroMatrix": {
    "brief": "Matrix with all zero entries (null matrix)\n\nZeroMatrix represents a matrix of zeros with given dimensions.\nNo storage required. Matrix-vector multiply just scales y by beta.",
    "file": "IpZeroMatrix",
    "library": "Ipopt",
    "layer": "layer-2",
    "header": "src/LinAlg/IpZeroMatrix.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "IpDenseVector": {
    "brief": "Dense vector implementation storing contiguous Number arrays\n\nDenseVector is the primary Vector implementation in Ipopt.\nTwo storage modes:\n- Heterogeneous: Full array of values (Values() method)\n- Homogeneous: Single scalar repeated for all elements (Scalar() method)",
    "file": "IpDenseVector",
    "library": "Ipopt",
    "layer": "layer-2",
    "header": "src/LinAlg/IpDenseVector.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "IpTransposeMatrix": {
    "brief": "Matrix wrapper representing transpose of another matrix\n\nTransposeMatrix wraps an existing matrix M to represent M^T without\nexplicitly forming the transpose. MultVector becomes TransMultVector\non the original, and vice versa.",
    "file": "IpTransposeMatrix",
    "library": "Ipopt",
    "layer": "layer-2",
    "header": "src/LinAlg/IpTransposeMatrix.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "IpSymScaledMatrix": {
    "brief": "Symmetric matrix with symmetric (congruent) scaling\n\nSymScaledMatrix wraps a symmetric matrix M to represent D * M * D\nwhere D is a diagonal scaling matrix. Unlike ScaledMatrix which has\nseparate row/column scaling, symmetric scaling uses the same vector.",
    "file": "IpSymScaledMatrix",
    "library": "Ipopt",
    "layer": "layer-2",
    "header": "src/LinAlg/IpSymScaledMatrix.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "IpSumMatrix": {
    "brief": "Matrix representing weighted sum of matrices: M = sum(alpha_i * M_i)\n\nSumMatrix represents a matrix as a sum of terms, each with its own\nscalar factor: M = alpha_0*M_0 + alpha_1*M_1 + ... + alpha_n*M_n",
    "file": "IpSumMatrix",
    "library": "Ipopt",
    "layer": "layer-2",
    "header": "src/LinAlg/IpSumMatrix.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "IpZeroSymMatrix": {
    "brief": "Symmetric matrix with all zero entries\n\nZeroSymMatrix represents a symmetric zero matrix (n x n).\nNo storage required. Inherits from SymMatrix for type safety.",
    "file": "IpZeroSymMatrix",
    "library": "Ipopt",
    "layer": "layer-2",
    "header": "src/LinAlg/IpZeroSymMatrix.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "IpMatrix": {
    "brief": "Abstract base class for all (unsymmetric) matrix types\n\nMatrix provides the abstraction for general (non-symmetric) matrices.\nPrimary operations: MultVector (y = \u03b1*A*x + \u03b2*y) and TransMultVector.",
    "file": "IpMatrix",
    "library": "Ipopt",
    "layer": "layer-2",
    "header": "src/LinAlg/IpMatrix.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "IpCompoundSymMatrix": {
    "brief": "Block-structured symmetric matrix (lower triangle storage)\n\nCompoundSymMatrix implements a symmetric block matrix where only\nthe lower triangular blocks are stored: M[i][j] with j <= i.\nDiagonal blocks must themselves be SymMatrix types.",
    "file": "IpCompoundSymMatrix",
    "library": "Ipopt",
    "layer": "layer-2",
    "header": "src/LinAlg/IpCompoundSymMatrix.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "IpExpandedMultiVectorMatrix": {
    "brief": "Short-fat matrix V^T*P^T with expansion for KKT construction\n\nExpandedMultiVectorMatrix represents a k x n matrix (k << n) as\nV^T * P^T where V is a MultiVectorMatrix-like collection of row\nvectors and P is an optional ExpansionMatrix.",
    "file": "IpExpandedMultiVectorMatrix",
    "library": "Ipopt",
    "layer": "layer-2",
    "header": "src/LinAlg/IpExpandedMultiVectorMatrix.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "IpCompoundVector": {
    "brief": "Composite vector stacking multiple sub-vectors\n\nCompoundVector implements the Composite pattern for vectors,\nrepresenting: x_compound = [x_0; x_1; ...; x_{n-1}]",
    "file": "IpCompoundVector",
    "library": "Ipopt",
    "layer": "layer-2",
    "header": "src/LinAlg/IpCompoundVector.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "IpDiagMatrix": {
    "brief": "Diagonal matrix stored as a vector\n\nDiagMatrix efficiently represents diagonal matrices by storing only\nthe diagonal elements as a Vector. Matrix-vector multiply is O(n).",
    "file": "IpDiagMatrix",
    "library": "Ipopt",
    "layer": "layer-2",
    "header": "src/LinAlg/IpDiagMatrix.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "IpSymMatrix": {
    "brief": "Abstract base class for symmetric matrices\n\nSymMatrix extends Matrix for symmetric matrices (A = A^T).\nTransMultVector automatically delegates to MultVector since\ntranspose is a no-op for symmetric matrices.",
    "file": "IpSymMatrix",
    "library": "Ipopt",
    "layer": "layer-2",
    "header": "src/LinAlg/IpSymMatrix.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "IpDenseSymMatrix": {
    "brief": "Dense symmetric matrix in BLAS lower-triangular storage\n\nDenseSymMatrix stores only the lower triangle in column-major format,\nfollowing BLAS/LAPACK conventions for symmetric matrices.",
    "file": "IpDenseSymMatrix",
    "library": "Ipopt",
    "layer": "layer-2",
    "header": "src/LinAlg/IpDenseSymMatrix.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "IpDenseGenMatrix": {
    "brief": "Dense general (non-symmetric) matrix with linear algebra operations\n\nDenseGenMatrix stores elements in column-major (Fortran) format\nand provides direct factorization capabilities:\n- Cholesky factorization (for positive definite matrices)\n- LU factorization with pivoting (for general matrices)\n- Forward/back substitution solves",
    "file": "IpDenseGenMatrix",
    "library": "Ipopt",
    "layer": "layer-2",
    "header": "src/LinAlg/IpDenseGenMatrix.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "IpLapack": {
    "brief": "C++ wrappers for LAPACK (Linear Algebra PACKage) routines\n\nProvides platform-independent access to LAPACK for dense matrices.",
    "file": "IpLapack",
    "library": "Ipopt",
    "layer": "layer-2",
    "header": "src/LinAlg/IpLapack.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "AmplTNLP": {
    "brief": "",
    "file": "AmplTNLP",
    "library": "Gravity",
    "layer": "layer-4",
    "header": "thirdparty/Ipopt/include/coin/AmplTNLP.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "IpCGPenaltyLSAcceptor": {
    "brief": "Chen-Goldfarb penalty function line search acceptor",
    "file": "IpCGPenaltyLSAcceptor",
    "library": "Ipopt",
    "layer": "layer-2",
    "header": "src/contrib/CGPenalty/IpCGPenaltyLSAcceptor.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "IpPiecewisePenalty": {
    "brief": "Piecewise linear penalty function (PLPF) data structure",
    "file": "IpPiecewisePenalty",
    "library": "Ipopt",
    "layer": "layer-2",
    "header": "src/contrib/CGPenalty/IpPiecewisePenalty.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "IpCGPerturbationHandler": {
    "brief": "Perturbation handler for Chen-Goldfarb penalty method",
    "file": "IpCGPerturbationHandler",
    "library": "Ipopt",
    "layer": "layer-2",
    "header": "src/contrib/CGPenalty/IpCGPerturbationHandler.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "IpCGPenaltyCq": {
    "brief": "Calculated quantities for Chen-Goldfarb penalty method\n\nCGPenaltyCq provides cached computation of quantities specific to\nthe Chen-Goldfarb penalty function algorithm, extending the base\nIpoptCalculatedQuantities.\n\nKey computed quantities:\n- curr/trial_penalty_function(): phi_rho(x) = f(x) + rho*||c(x)||\n- curr_direct_deriv_penalty_function(): Directional derivative\n- curr_fast_direct_deriv_penalty_function(): For fast CG direction\n- curr_cg_pert_fact(): Perturbation factor for KKT regularization\n- compute_curr_cg_penalty(): Line search penalty parameter\n- compute_curr_cg_penalty_scale(): KKT scaling penalty\n\nAlso computes Jacobian norms and multiplier scaling factors\nneeded for the penalty parameter update rules.\n\nAll quantities use CachedResults for efficiency.",
    "file": "IpCGPenaltyCq",
    "library": "Ipopt",
    "layer": "layer-2",
    "header": "src/contrib/CGPenalty/IpCGPenaltyCq.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "IpCGSearchDirCalc": {
    "brief": "Search direction calculator for Chen-Goldfarb penalty method",
    "file": "IpCGSearchDirCalc",
    "library": "Ipopt",
    "layer": "layer-2",
    "header": "src/contrib/CGPenalty/IpCGSearchDirCalc.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "IpCGPenaltyData": {
    "brief": "Algorithm state data for Chen-Goldfarb penalty method\n\nCGPenaltyData extends IpoptAdditionalData to store all state\nspecific to the Chen-Goldfarb penalty function algorithm.\n\nStored directions:\n- delta_cgpen_: Standard Chen-Goldfarb search direction\n- delta_cgfast_: Fast (pure Newton) direction when near solution\n\nPenalty parameters:\n- curr_penalty_: Current line search penalty parameter (rho)\n- curr_kkt_penalty_: Penalty for KKT system scaling\n- curr_penalty_pert_: Current perturbation factor\n\nAlgorithm control:\n- never_try_pure_Newton_: Flag to disable fast direction\n- restor_iter_: Iteration count for restoration tracking\n- max_alpha_x_: Recorded primal step size\n\nThe data is accessed via IpData().AdditionalData() and cast\nto CGPenaltyData using the CGPenData() accessor pattern.",
    "file": "IpCGPenaltyData",
    "library": "Ipopt",
    "layer": "layer-2",
    "header": "src/contrib/CGPenalty/IpCGPenaltyData.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "IpCGPenaltyRegOp": {
    "brief": "Registration of Chen-Goldfarb penalty method options\n\nDeclares RegisterOptions_CGPenalty(), which registers all options\nspecific to the Chen-Goldfarb penalty function globalization\nstrategy.\n\nOptions include:\n- Penalty parameter initialization and bounds\n- PLPF (piecewise linear penalty function) parameters\n- Fast direction control parameters\n- Armijo and sufficient decrease factors\n- Perturbation handling parameters\n\nCalled when Ipopt is configured to use the CG penalty method\ninstead of the default filter line search.",
    "file": "IpCGPenaltyRegOp",
    "library": "Ipopt",
    "layer": "layer-2",
    "header": "src/contrib/CGPenalty/IpCGPenaltyRegOp.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "IpInexactNewtonNormal": {
    "brief": "Newton normal step from slack-scaled augmented system\n\nInexactNewtonNormalStep computes the normal step component by\nsolving a reduced system derived from the slack-scaled KKT system.",
    "file": "IpInexactNewtonNormal",
    "library": "Ipopt",
    "layer": "layer-2",
    "header": "src/Algorithm/Inexact/IpInexactNewtonNormal.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "IpInexactSearchDirCalc": {
    "brief": "Search direction via normal-tangential decomposition\n\nInexactSearchDirCalculator computes the search direction using\niterative linear solvers by decomposing into normal and tangential\ncomponents, enabling inexact Newton methods.",
    "file": "IpInexactSearchDirCalc",
    "library": "Ipopt",
    "layer": "layer-2",
    "header": "src/Algorithm/Inexact/IpInexactSearchDirCalc.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "IpInexactRegOp": {
    "brief": "Registration function for all inexact algorithm options\n\nRegisterOptions_Inexact() registers all configurable parameters\nfor the inexact Newton algorithm variant with the options system.",
    "file": "IpInexactRegOp",
    "library": "Ipopt",
    "layer": "layer-2",
    "header": "src/Algorithm/Inexact/IpInexactRegOp.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "IpInexactAlgBuilder": {
    "brief": "Builder for inexact step computation algorithm variant\n\nInexactAlgorithmBuilder constructs the complete IpoptAlgorithm\nconfigured for inexact Newton methods using iterative linear solvers.",
    "file": "IpInexactAlgBuilder",
    "library": "Ipopt",
    "layer": "layer-2",
    "header": "src/Algorithm/Inexact/IpInexactAlgBuilder.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "IpInexactPDSolver": {
    "brief": "Primal-dual system solver for inexact Newton methods\n\nInexactPDSolver solves the primal-dual system using iterative linear\nsolvers, allowing for inexact solutions that don't fully satisfy\nthe linearized KKT conditions.",
    "file": "IpInexactPDSolver",
    "library": "Ipopt",
    "layer": "layer-2",
    "header": "src/Algorithm/Inexact/IpInexactPDSolver.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "IpInexactLSAcceptor": {
    "brief": "Penalty function line search for inexact step algorithm\n\nInexactLSAcceptor implements backtracking line search using an\nexact penalty function, adapted for inexact Newton steps that\ndon't fully satisfy the linearized KKT conditions.",
    "file": "IpInexactLSAcceptor",
    "library": "Ipopt",
    "layer": "layer-2",
    "header": "src/Algorithm/Inexact/IpInexactLSAcceptor.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "IpIterativePardisoSolverInterface": {
    "brief": "Pardiso iterative solver interface for inexact Newton method\n\nIterativePardisoSolverInterface wraps the Pardiso sparse solver in\niterative (preconditioned Krylov) mode for use with inexact Newton.",
    "file": "IpIterativePardisoSolverInterface",
    "library": "Ipopt",
    "layer": "layer-2",
    "header": "src/Algorithm/Inexact/IpIterativePardisoSolverInterface.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "IpInexactCq": {
    "brief": "Cached quantities for inexact Newton / Chen-Goldfarb penalty method\n\nInexactCq provides precomputed and cached quantities specific to the\ninexact Newton algorithm, extending IpoptCalculatedQuantities.",
    "file": "IpInexactCq",
    "library": "Ipopt",
    "layer": "layer-2",
    "header": "src/Algorithm/Inexact/IpInexactCq.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "IpInexactData": {
    "brief": "Algorithm-specific data storage for inexact Newton method\n\nInexactData stores the decomposed step components and algorithm state\nrequired by the inexact Newton / Chen-Goldfarb penalty method.",
    "file": "IpInexactData",
    "library": "Ipopt",
    "layer": "layer-2",
    "header": "src/Algorithm/Inexact/IpInexactData.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "IpInexactTSymScalingMethod": {
    "brief": "Slack-based matrix scaling for inexact algorithm\n\nInexactTSymScalingMethod computes symmetric scaling factors for the\naugmented system, using current slack values for the inexact algorithm.",
    "file": "IpInexactTSymScalingMethod",
    "library": "Ipopt",
    "layer": "layer-2",
    "header": "src/Algorithm/Inexact/IpInexactTSymScalingMethod.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "IpInexactDoglegNormal": {
    "brief": "Dogleg trust region method for normal step computation\n\nInexactDoglegNormalStep computes the normal step using a dogleg\napproach that combines steepest descent and Newton directions\nwithin a trust region.",
    "file": "IpInexactDoglegNormal",
    "library": "Ipopt",
    "layer": "layer-2",
    "header": "src/Algorithm/Inexact/IpInexactDoglegNormal.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "IpInexactNormalStepCalc": {
    "brief": "Abstract base class for normal step computation\n\nInexactNormalStepCalculator defines the interface for computing\nthe normal step component in the inexact Newton decomposition.",
    "file": "IpInexactNormalStepCalc",
    "library": "Ipopt",
    "layer": "layer-2",
    "header": "src/Algorithm/Inexact/IpInexactNormalStepCalc.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "IpPardisoMKLSolverInterface": {
    "brief": "Interface to Intel MKL PARDISO sparse solver\n\nPardisoMKLSolverInterface wraps Intel's MKL implementation of PARDISO.\nWhile sharing the same API as pardiso-project.org's version, Intel MKL\nPARDISO has some differences in features and behavior.",
    "file": "IpPardisoMKLSolverInterface",
    "library": "Ipopt",
    "layer": "layer-2",
    "header": "src/Algorithm/LinearSolvers/IpPardisoMKLSolverInterface.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "IpTSymLinearSolver": {
    "brief": "Driver connecting SymMatrix to sparse linear solver interfaces\n\nTSymLinearSolver is the main driver that connects Ipopt's SymMatrix\nobjects to concrete sparse linear solvers. It handles:\n- Matrix format conversion (SymMatrix to triplet/CSR)\n- Optional matrix scaling\n- Delegation to SparseSymLinearSolverInterface implementations",
    "file": "IpTSymLinearSolver",
    "library": "Ipopt",
    "layer": "layer-2",
    "header": "src/Algorithm/LinearSolvers/IpTSymLinearSolver.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "IpTripletToCSRConverter": {
    "brief": "Convert sparse matrix from triplet to CSR format\n\nTripletToCSRConverter converts symmetric matrices from triplet\n(COO) format to Compressed Sparse Row (CSR) format. Handles both\nupper-triangular-only and full-matrix storage.",
    "file": "IpTripletToCSRConverter",
    "library": "Ipopt",
    "layer": "layer-2",
    "header": "src/Algorithm/LinearSolvers/IpTripletToCSRConverter.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "IpMc19TSymScalingMethod": {
    "brief": "Matrix scaling using HSL MC19 equilibration\n\nMc19TSymScalingMethod uses the HSL subroutine MC19 to compute\nequilibration scaling factors for symmetric matrices.",
    "file": "IpMc19TSymScalingMethod",
    "library": "Ipopt",
    "layer": "layer-2",
    "header": "src/Algorithm/LinearSolvers/IpMc19TSymScalingMethod.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "IpWsmpSolverInterface": {
    "brief": "Interface to IBM WSMP sparse symmetric direct solver\n\nWsmpSolverInterface wraps the Watson Sparse Matrix Package (WSMP),\na high-performance parallel direct solver developed at IBM for\nsparse symmetric indefinite linear systems.",
    "file": "IpWsmpSolverInterface",
    "library": "Ipopt",
    "layer": "layer-2",
    "header": "src/Algorithm/LinearSolvers/IpWsmpSolverInterface.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "IpMumpsSolverInterface": {
    "brief": "Interface to MUMPS parallel sparse direct solver\n\nMumpsSolverInterface wraps MUMPS (MUltifrontal Massively Parallel\nsparse direct Solver), a freely available solver supporting MPI\nparallelism for distributed memory systems.",
    "file": "IpMumpsSolverInterface",
    "library": "Ipopt",
    "layer": "layer-2",
    "header": "src/Algorithm/LinearSolvers/IpMumpsSolverInterface.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "IpTSymScalingMethod": {
    "brief": "Base class for matrix scaling in triplet format\n\nTSymScalingMethod is the abstract base class for computing diagonal\nscaling factors for symmetric matrices. Scaling improves numerical\nconditioning of the linear system.\n\nScaling transformation:\n  Original: A * x = b\n  Scaled:   (D*A*D) * (D^{-1}*x) = D*b\nwhere D = diag(scaling_factors).\n\nThe ComputeSymTScalingFactors method takes:\n- n: matrix dimension\n- nnz: number of nonzeros\n- airn, ajcn: row/column indices (triplet format)\n- a: matrix values\n- scaling_factors: output array of length n\n\nImplementations:\n- Mc19TSymScalingMethod: HSL MC19 equilibration\n- SlackBasedTSymScalingMethod: Simple slack-based scaling",
    "file": "IpTSymScalingMethod",
    "library": "Ipopt",
    "layer": "layer-2",
    "header": "src/Algorithm/LinearSolvers/IpTSymScalingMethod.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "IpSlackBasedTSymScalingMethod": {
    "brief": "Simple scaling based on current slack values\n\nSlackBasedTSymScalingMethod computes scaling factors using only\nthe current slack values, without requiring external HSL routines.\nDesigned for use with inexact/iterative linear solvers.\n\nUnlike MC19 which performs full equilibration, this method uses\na simpler heuristic based on:\n- Current slack variable values s\n- Diagonal elements of the KKT system\n\nBenefits:\n- No external library dependencies\n- Lightweight computation\n- Suitable when full equilibration is unnecessary\n\nLimitations:\n- May not achieve as good conditioning as MC19\n- Best for problems where slacks dominate scaling needs",
    "file": "IpSlackBasedTSymScalingMethod",
    "library": "Ipopt",
    "layer": "layer-2",
    "header": "src/Algorithm/LinearSolvers/IpSlackBasedTSymScalingMethod.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "IpGenKKTSolverInterface": {
    "brief": "Generic interface for iterative/matrix-free KKT solvers\n\nGenKKTSolverInterface provides an alternative to\nSparseSymLinearSolverInterface for solvers that work with the\nfull KKT structure rather than requiring explicit sparse matrices.\n\nThe 4x4 block KKT system:\n  [W + D_x + delta_x*I,  0,         J_c^T,  J_d^T ] [sol_x]   [rhs_x]\n  [0,          D_s + delta_s*I,   0,     -I     ] [sol_s] = [rhs_s]\n  [J_c,        0,         D_c - delta_c*I,  0  ] [sol_c]   [rhs_c]\n  [J_d,       -I,         0,    D_d - delta_d*I] [sol_d]   [rhs_d]\n\nInterface differences from SparseSymLinearSolverInterface:\n- Receives Matrix/SymMatrix objects directly (not sparse arrays)\n- Diagonal arrays (D_x, D_s, D_c, D_d) as Number* pointers\n- Better suited for iterative solvers (Krylov, GMRES)\n- Can use matrix-vector products without explicit assembly\n\nUsed by GenAugSystemSolver to adapt this interface to AugSystemSolver.",
    "file": "IpGenKKTSolverInterface",
    "library": "Ipopt",
    "layer": "layer-2",
    "header": "src/Algorithm/LinearSolvers/IpGenKKTSolverInterface.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "IpSpralSolverInterface": {
    "brief": "Interface to SPRAL SSIDS sparse symmetric solver\n\nSpralSolverInterface wraps SPRAL (Sparse Parallel Robust Algorithms\nLibrary), an open-source alternative to HSL solvers developed by\nSTFC RAL. SSIDS is SPRAL's symmetric indefinite direct solver.",
    "file": "IpSpralSolverInterface",
    "library": "Ipopt",
    "layer": "layer-2",
    "header": "src/Algorithm/LinearSolvers/IpSpralSolverInterface.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "IpMa86SolverInterface": {
    "brief": "Interface to HSL MA86 parallel sparse symmetric solver\n\nMa86SolverInterface wraps the HSL MA86 solver, a DAG-based\nparallel direct solver for symmetric indefinite systems.",
    "file": "IpMa86SolverInterface",
    "library": "Ipopt",
    "layer": "layer-2",
    "header": "src/Algorithm/LinearSolvers/IpMa86SolverInterface.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "IpMa28TDependencyDetector": {
    "brief": "Dependency detector using HSL MA28 unsymmetric solver\n\nMa28TDependencyDetector uses the unsymmetric sparse solver MA28\nto detect linearly dependent rows in the constraint Jacobian.\nUnlike the symmetric solvers, MA28 handles general rectangular\nmatrices, making it suitable for analyzing the constraint Jacobian\ndirectly.\n\nThe detection works by attempting LU factorization with threshold\npivoting. When a pivot falls below tolerance (ma28_pivtol_), the\ncorresponding row is flagged as linearly dependent.\n\nInput format: Triplet (row, col, val) for general matrices\n\nUsed by Ipopt's constraint degeneracy detection mechanism.",
    "file": "IpMa28TDependencyDetector",
    "library": "Ipopt",
    "layer": "layer-2",
    "header": "src/Algorithm/LinearSolvers/IpMa28TDependencyDetector.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "IpTSymDependencyDetector": {
    "brief": "Dependency detection using symmetric linear solver\n\nTSymDependencyDetector detects linearly dependent constraint rows\nby using a TSymLinearSolver that provides degeneracy detection.\n\nMethod:\nSome symmetric linear solvers (e.g., MA57 via ProvidesDegeneracyDetection)\ncan identify dependent rows during factorization. This class\nleverages that capability.\n\nAlgorithm:\n1. Form symmetric matrix J*J^T (or equivalent structure)\n2. Attempt factorization with the TSymLinearSolver\n3. If solver detects singularity, query dependent row indices\n4. Return list of dependent rows in c_deps\n\nRequirements:\n- The underlying linear solver must implement\n  ProvidesDegeneracyDetection() returning true\n- Must implement DetermineDependentRows() for the sparse format\n\nThis is preferred over MA28-based detection when using a solver\nthat already provides this capability.",
    "file": "IpTSymDependencyDetector",
    "library": "Ipopt",
    "layer": "layer-2",
    "header": "src/Algorithm/LinearSolvers/IpTSymDependencyDetector.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "IpTDependencyDetector": {
    "brief": "Base class for detecting linearly dependent constraint rows\n\nTDependencyDetector is the abstract base class for algorithms that\ndetect linearly dependent rows in the constraint Jacobian. This is\nneeded to handle degenerate problems where some constraints are\nredundant.\n\nPurpose:\nIf rank(J_c) < m_c, the KKT system is singular. Detecting and\nremoving dependent rows allows the solver to proceed.\n\nInterface:\n- DetermineDependentRows(): Takes Jacobian in triplet format,\n  returns list of dependent row indices in c_deps\n\nInput format (MA28 style triplet):\n- n_rows, n_cols: Jacobian dimensions\n- n_jac_nz: Number of nonzeros\n- jac_c_vals, jac_c_iRow, jac_c_jCol: Values and indices\n\nThe input arrays may be modified internally (working space).",
    "file": "IpTDependencyDetector",
    "library": "Ipopt",
    "layer": "layer-2",
    "header": "src/Algorithm/LinearSolvers/IpTDependencyDetector.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "IpSymLinearSolver": {
    "brief": "Base class for symmetric indefinite linear solvers\n\nSymLinearSolver is the abstract base class for all symmetric linear\nsolvers used in Ipopt's augmented system. The solver must handle\nsymmetric indefinite matrices and optionally provide inertia.",
    "file": "IpSymLinearSolver",
    "library": "Ipopt",
    "layer": "layer-2",
    "header": "src/Algorithm/LinearSolvers/IpSymLinearSolver.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "IpMa57TSolverInterface": {
    "brief": "Interface to HSL MA57 sparse symmetric indefinite solver\n\nMa57TSolverInterface wraps the Harwell MA57 subroutine, an improved\nmultifrontal solver over MA27 with better memory management and\nnumerical stability.",
    "file": "IpMa57TSolverInterface",
    "library": "Ipopt",
    "layer": "layer-2",
    "header": "src/Algorithm/LinearSolvers/IpMa57TSolverInterface.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "IpIterativeWsmpSolverInterface": {
    "brief": "Interface to IBM WSMP iterative (WISMP) solver\n\nIterativeWsmpSolverInterface wraps the iterative variant of WSMP\n(called WISMP), which uses incomplete LU factorization as a\npreconditioner for iterative refinement.",
    "file": "IpIterativeWsmpSolverInterface",
    "library": "Ipopt",
    "layer": "layer-2",
    "header": "src/Algorithm/LinearSolvers/IpIterativeWsmpSolverInterface.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "IpPardisoSolverInterface": {
    "brief": "Interface to PARDISO sparse solver from pardiso-project.org\n\nPardisoSolverInterface wraps the PARDISO solver distributed by\npardiso-project.org (not to be confused with Intel MKL's PARDISO).\nPARDISO is a high-performance parallel direct solver for sparse\nsymmetric indefinite systems.",
    "file": "IpPardisoSolverInterface",
    "library": "Ipopt",
    "layer": "layer-2",
    "header": "src/Algorithm/LinearSolvers/IpPardisoSolverInterface.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "IpMa77SolverInterface": {
    "brief": "Interface to HSL MA77 out-of-core sparse symmetric solver\n\nMa77SolverInterface wraps the HSL MA77 solver, designed for\nlarge-scale problems that may not fit entirely in memory.",
    "file": "IpMa77SolverInterface",
    "library": "Ipopt",
    "layer": "layer-2",
    "header": "src/Algorithm/LinearSolvers/IpMa77SolverInterface.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "IpSparseSymLinearSolverInterface": {
    "brief": "Interface for sparse symmetric indefinite linear solvers\n\nSparseSymLinearSolverInterface defines the interface that concrete\nlinear solvers (MA27, MA57, MUMPS, Pardiso, etc.) must implement.",
    "file": "IpSparseSymLinearSolverInterface",
    "library": "Ipopt",
    "layer": "layer-2",
    "header": "src/Algorithm/LinearSolvers/IpSparseSymLinearSolverInterface.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "IpMa27TSolverInterface": {
    "brief": "Interface to HSL MA27 sparse symmetric indefinite solver\n\nMa27TSolverInterface wraps the Harwell MA27 subroutine for solving\nsparse symmetric indefinite linear systems using multifrontal\nfactorization with threshold pivoting.",
    "file": "IpMa27TSolverInterface",
    "library": "Ipopt",
    "layer": "layer-2",
    "header": "src/Algorithm/LinearSolvers/IpMa27TSolverInterface.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "IpMa97SolverInterface": {
    "brief": "Interface to HSL MA97 modern parallel sparse symmetric solver\n\nMa97SolverInterface wraps the HSL MA97 solver, the most modern\nHSL solver for symmetric indefinite systems with advanced\nparallelism and scaling strategies.",
    "file": "IpMa97SolverInterface",
    "library": "Ipopt",
    "layer": "layer-2",
    "header": "src/Algorithm/LinearSolvers/IpMa97SolverInterface.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "IpLinearSolversRegOp": {
    "brief": "Registration of all linear solver options\n\nDeclares RegisterOptions_LinearSolvers(), which registers options\nfor all available linear solvers (MA27, MA57, MA77, MA86, MA97,\nMUMPS, Pardiso, WSMP, SPRAL, etc.).\n\nCalled during Ipopt initialization to make solver-specific options\navailable through the OptionsList mechanism. Each solver interface\nhas its own RegisterOptions() method that is invoked here.\n\nOptions typically include:\n- Pivot tolerance bounds\n- Ordering method selection\n- Scaling options\n- Memory allocation factors\n- Parallelism settings (thread counts)",
    "file": "IpLinearSolversRegOp",
    "library": "Ipopt",
    "layer": "layer-2",
    "header": "src/Algorithm/LinearSolvers/IpLinearSolversRegOp.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "IpTripletHelper": {
    "brief": "Recursive conversion of abstract matrices to triplet format\n\nTripletHelper provides static methods for extracting COO (Coordinate)\nsparse format from Ipopt's abstract Matrix hierarchy. Used to interface\nwith external linear solvers expecting triplet format.",
    "file": "IpTripletHelper",
    "library": "Ipopt",
    "layer": "layer-2",
    "header": "src/LinAlg/TMatrices/IpTripletHelper.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "IpSymTMatrix": {
    "brief": "Symmetric sparse matrix in triplet (COO) format\n\nSymTMatrix stores symmetric sparse matrices using coordinate format:\nthree arrays (Irn, Jcn, Values) of length nnz representing nonzeros.",
    "file": "IpSymTMatrix",
    "library": "Ipopt",
    "layer": "layer-2",
    "header": "src/LinAlg/TMatrices/IpSymTMatrix.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "IpGenTMatrix": {
    "brief": "General sparse matrix in triplet (COO) format\n\nGenTMatrix stores a general (non-symmetric) sparse matrix using\ntriplet/coordinate format: three arrays for row indices, column\nindices, and values.",
    "file": "IpGenTMatrix",
    "library": "Ipopt",
    "layer": "layer-2",
    "header": "src/LinAlg/TMatrices/IpGenTMatrix.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "SensAmplTNLP": {
    "brief": "sIPOPT AMPL interface with sensitivity support\n\nSensAmplTNLP extends AmplTNLP with sensitivity parameter handling.\nReads sens_init_constr suffix for constraint parameter indices.\nEnables parametric sensitivity analysis for AMPL models.",
    "file": "SensAmplTNLP",
    "library": "Ipopt",
    "layer": "layer-2",
    "header": "contrib/sIPOPT/AmplSolver/SensAmplTNLP.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "SensSuffixHandler": {
    "brief": "sIPOPT AMPL suffix handler\n\nSensSuffixHandler: processes AMPL suffixes for sensitivity analysis.\nReads parameter indices and perturbation values from .row/.col suffixes.\nEnables AMPL-based sensitivity specification.",
    "file": "SensSuffixHandler",
    "library": "Ipopt",
    "layer": "layer-2",
    "header": "contrib/sIPOPT/src/SensSuffixHandler.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "SensAlgorithm": {
    "brief": "sIPOPT sensitivity analysis main algorithm\n\nSensAlgorithm: controller for parametric sensitivity analysis in Ipopt.\nComputes directional derivatives and sensitivity matrices for solution\nw.r.t. parameter perturbations. Uses Schur complement decomposition\nto efficiently compute sensitivities after optimal solution found.",
    "file": "SensAlgorithm",
    "library": "Ipopt",
    "layer": "layer-2",
    "header": "contrib/sIPOPT/src/SensAlgorithm.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "SensBuilder": {
    "brief": "sIPOPT builder for sensitivity analysis components\n\nSensBuilder: factory for creating sIPOPT algorithm components.\nAssembles SchurDriver, StepCalculator, and Measurement objects\nbased on options. Configures sensitivity computation pipeline.",
    "file": "SensBuilder",
    "library": "Ipopt",
    "layer": "layer-2",
    "header": "contrib/sIPOPT/src/SensBuilder.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "SensReducedHessianCalculator": {
    "brief": "sIPOPT reduced Hessian computation\n\nSensReducedHessianCalculator: computes reduced Hessian of Lagrangian.\nProjects full Hessian onto null space of active constraints.\nUsed for computing second-order sensitivity information.",
    "file": "SensReducedHessianCalculator",
    "library": "Ipopt",
    "layer": "layer-2",
    "header": "contrib/sIPOPT/src/SensReducedHessianCalculator.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "SensDenseGenSchurDriver": {
    "brief": "sIPOPT dense Schur complement driver\n\nSensDenseGenSchurDriver: dense matrix implementation of SchurDriver.\nComputes Schur complement S = C - B*K^{-1}*A for sensitivity analysis.\nSuitable for problems with moderate numbers of sensitivity parameters.",
    "file": "SensDenseGenSchurDriver",
    "library": "Ipopt",
    "layer": "layer-2",
    "header": "contrib/sIPOPT/src/SensDenseGenSchurDriver.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "SensApplication": {
    "brief": "sIPOPT application wrapper for sensitivity analysis\n\nSensApplication wraps IpoptApplication with sensitivity extensions.\nEntry point for sIPOPT: runs optimization then sensitivity analysis.\nManages parameter perturbations and extracts sensitivity information.",
    "file": "SensApplication",
    "library": "Ipopt",
    "layer": "layer-2",
    "header": "contrib/sIPOPT/src/SensApplication.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "SensMeasurement": {
    "brief": "sIPOPT measurement interface for parameter values\n\nSensMeasurement: abstract interface for providing parameter values.\nMeasurement objects supply perturbed parameter values to sensitivity\nanalysis. Enables real-time or batch parameter updates.",
    "file": "SensMeasurement",
    "library": "Ipopt",
    "layer": "layer-2",
    "header": "contrib/sIPOPT/src/SensMeasurement.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "SensPCalculator": {
    "brief": "sIPOPT perturbation calculator interface\n\nSensPCalculator: abstract interface for computing perturbations.\nCalculates right-hand sides for sensitivity linear systems based\non how parameters affect KKT conditions.",
    "file": "SensPCalculator",
    "library": "Ipopt",
    "layer": "layer-2",
    "header": "contrib/sIPOPT/src/SensPCalculator.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "SensUtils": {
    "brief": "sIPOPT utility functions and enums\n\nSensUtils: utility types for sIPOPT sensitivity analysis.\nDefines SensAlgorithmExitStatus enum for return codes.\nCommon helper functions used across sIPOPT components.",
    "file": "SensUtils",
    "library": "Ipopt",
    "layer": "layer-2",
    "header": "contrib/sIPOPT/src/SensUtils.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "SensRegOp": {
    "brief": "sIPOPT registration operations for options\n\nSensRegOp: registers sIPOPT-specific options with Ipopt.\nAdds sensitivity analysis parameters like n_sens_steps, sens_prefix,\nand computation modes to Ipopt option system.",
    "file": "SensRegOp",
    "library": "Ipopt",
    "layer": "layer-2",
    "header": "contrib/sIPOPT/src/SensRegOp.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "SensSchurDriver": {
    "brief": "sIPOPT Schur complement driver interface\n\nSensSchurDriver: abstract interface for Schur complement operations.\nManages factorization and solve phases for sensitivity analysis.\nImplementations handle dense, sparse, or iterative approaches.",
    "file": "SensSchurDriver",
    "library": "Ipopt",
    "layer": "layer-2",
    "header": "contrib/sIPOPT/src/SensSchurDriver.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "SensIndexSchurData": {
    "brief": "sIPOPT index-based Schur data storage\n\nSensIndexSchurData: stores index-based data for Schur complement.\nTracks which rows/columns of KKT system correspond to parameters.\nManages sparse structure for efficient Schur complement computation.",
    "file": "SensIndexSchurData",
    "library": "Ipopt",
    "layer": "layer-2",
    "header": "contrib/sIPOPT/src/SensIndexSchurData.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "SensStdStepCalc": {
    "brief": "sIPOPT standard sensitivity step calculator\n\nSensStdStepCalc: standard implementation of SensitivityStepCalculator.\nComputes sensitivity steps using Schur complement and back-solves.\nHandles bound corrections for perturbed solutions.",
    "file": "SensStdStepCalc",
    "library": "Ipopt",
    "layer": "layer-2",
    "header": "contrib/sIPOPT/src/SensStdStepCalc.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "SensBacksolver": {
    "brief": "sIPOPT backsolver interface for linear systems\n\nSensBacksolver: abstract interface for solving linear systems in sIPOPT.\nUsed for Schur complement right-hand side solutions. Implementations\nleverage existing Ipopt linear solvers for efficient back-substitution.",
    "file": "SensBacksolver",
    "library": "Ipopt",
    "layer": "layer-2",
    "header": "contrib/sIPOPT/src/SensBacksolver.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "SensSimpleBacksolver": {
    "brief": "sIPOPT simple backsolver implementation\n\nSensSimpleBacksolver: basic implementation using Ipopt linear solver.\nWraps existing factorized KKT system for back-substitution.\nReuses factorization from optimization for sensitivity solves.",
    "file": "SensSimpleBacksolver",
    "library": "Ipopt",
    "layer": "layer-2",
    "header": "contrib/sIPOPT/src/SensSimpleBacksolver.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "SensSchurData": {
    "brief": "sIPOPT Schur complement data structures\n\nSensSchurData: abstract base for Schur complement data storage.\nDefines interface for storing and accessing matrix blocks needed\nfor Schur complement S = C - B*K^{-1}*A computation.",
    "file": "SensSchurData",
    "library": "Ipopt",
    "layer": "layer-2",
    "header": "contrib/sIPOPT/src/SensSchurData.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "SensStepCalc": {
    "brief": "sIPOPT sensitivity step calculator interface\n\nSensStepCalc: abstract interface for computing sensitivity steps.\nGiven parameter perturbation, computes resulting change in solution.\nCore component of sIPOPT sensitivity analysis pipeline.",
    "file": "SensStepCalc",
    "library": "Ipopt",
    "layer": "layer-2",
    "header": "contrib/sIPOPT/src/SensStepCalc.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "SensIndexPCalculator": {
    "brief": "sIPOPT index-based perturbation calculator\n\nSensIndexPCalculator: calculates perturbations for indexed parameters.\nIdentifies which variables/constraints are perturbed and computes\ncorresponding right-hand sides for sensitivity linear systems.",
    "file": "SensIndexPCalculator",
    "library": "Ipopt",
    "layer": "layer-2",
    "header": "contrib/sIPOPT/src/SensIndexPCalculator.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "SensMetadataMeasurement": {
    "brief": "sIPOPT metadata-based measurement\n\nSensMetadataMeasurement: reads parameter perturbations from NLP metadata.\nExtracts sensitivity parameters from AMPL suffixes or TNLP metadata.\nEnables automatic parameter identification from problem definition.",
    "file": "SensMetadataMeasurement",
    "library": "Ipopt",
    "layer": "layer-2",
    "header": "contrib/sIPOPT/src/SensMetadataMeasurement.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "IpoptRNLP": {
    "brief": "R language interface for Ipopt TNLP\n\nIpoptRNLP derives from TNLP to bridge Ipopt with R. Handles callback\nto R functions for objective (eval_f), gradient (eval_grad_f),\nconstraints (eval_g), Jacobian (eval_jac_g), and Hessian (eval_h).\nManages R SEXP objects for environment, bounds, and sparse structures.\nSupports Hessian approximation mode. Part of ipoptr R package.",
    "file": "IpoptRNLP",
    "library": "Ipopt",
    "layer": "layer-2",
    "header": "contrib/RInterface/src/IpoptRNLP.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "IpoptRJournal": {
    "brief": "R output journal for Ipopt progress messages\n\nIpoptRJournal derives from Journal to redirect Ipopt output to R.\nSends iteration progress and solver messages to R console via Rprintf.\nAllows R users to monitor optimization progress interactively.",
    "file": "IpoptRJournal",
    "library": "Ipopt",
    "layer": "layer-2",
    "header": "contrib/RInterface/src/IpoptRJournal.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "IpStdCInterface": {
    "brief": "",
    "file": "IpStdCInterface",
    "library": "Ipopt",
    "layer": "layer-2",
    "header": "src/Interfaces/IpStdCInterface.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "MC": {
    "brief": "Max-cut problem data structures",
    "file": "MC",
    "library": "Bcp",
    "layer": "layer-3",
    "header": "Applications/MaxCut/include/MC.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "MC_solution": {
    "brief": "Max-cut solution representation",
    "file": "MC_solution",
    "library": "Bcp",
    "layer": "layer-3",
    "header": "Applications/MaxCut/include/MC_solution.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "MC_tm_param": {
    "brief": "Max-cut TM parameters",
    "file": "MC_tm_param",
    "library": "Bcp",
    "layer": "layer-3",
    "header": "Applications/MaxCut/include/MC_tm_param.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "MC_tm": {
    "brief": "Max-cut tree manager for BCP",
    "file": "MC_tm",
    "library": "Bcp",
    "layer": "layer-3",
    "header": "Applications/MaxCut/include/MC_tm.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "MC_lp_param": {
    "brief": "Max-cut LP parameters",
    "file": "MC_lp_param",
    "library": "Bcp",
    "layer": "layer-3",
    "header": "Applications/MaxCut/include/MC_lp_param.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "MC_init": {
    "brief": "Max-cut BCP initialization",
    "file": "MC_init",
    "library": "Bcp",
    "layer": "layer-3",
    "header": "Applications/MaxCut/include/MC_init.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "MC_cut": {
    "brief": "Max-cut cutting planes",
    "file": "MC_cut",
    "library": "Bcp",
    "layer": "layer-3",
    "header": "Applications/MaxCut/include/MC_cut.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "MC_lp": {
    "brief": "Max-cut LP relaxation for BCP",
    "file": "MC_lp",
    "library": "Bcp",
    "layer": "layer-3",
    "header": "Applications/MaxCut/include/MC_lp.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "MKC_knapsack": {
    "brief": "MKC knapsack subproblem for column generation",
    "file": "MKC_knapsack",
    "library": "Bcp",
    "layer": "layer-3",
    "header": "Applications/Mkc/include/MKC_knapsack.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "MKC_var": {
    "brief": "MKC variable/column definitions",
    "file": "MKC_var",
    "library": "Bcp",
    "layer": "layer-3",
    "header": "Applications/Mkc/include/MKC_var.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "MKC_vargen": {
    "brief": "MKC variable generation (pricing)",
    "file": "MKC_vargen",
    "library": "Bcp",
    "layer": "layer-3",
    "header": "Applications/Mkc/include/MKC_vargen.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "MKC_solution": {
    "brief": "MKC solution representation",
    "file": "MKC_solution",
    "library": "Bcp",
    "layer": "layer-3",
    "header": "Applications/Mkc/include/MKC_solution.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "MKC_optim": {
    "brief": "MKC optimization routines",
    "file": "MKC_optim",
    "library": "Bcp",
    "layer": "layer-3",
    "header": "Applications/Mkc/include/MKC_optim.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "MKC_lp_param": {
    "brief": "MKC LP parameters",
    "file": "MKC_lp_param",
    "library": "Bcp",
    "layer": "layer-3",
    "header": "Applications/Mkc/include/MKC_lp_param.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "MKC_lp": {
    "brief": "MKC LP relaxation for BCP",
    "file": "MKC_lp",
    "library": "Bcp",
    "layer": "layer-3",
    "header": "Applications/Mkc/include/MKC_lp.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "MKC_tm_param": {
    "brief": "MKC TM parameters",
    "file": "MKC_tm_param",
    "library": "Bcp",
    "layer": "layer-3",
    "header": "Applications/Mkc/include/MKC_tm_param.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "MKC_tm": {
    "brief": "MKC tree manager for BCP",
    "file": "MKC_tm",
    "library": "Bcp",
    "layer": "layer-3",
    "header": "Applications/Mkc/include/MKC_tm.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "MKC_init": {
    "brief": "MKC BCP initialization",
    "file": "MKC_init",
    "library": "Bcp",
    "layer": "layer-3",
    "header": "Applications/Mkc/include/MKC_init.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "KS": {
    "brief": "Knapsack solver for CSP column generation",
    "file": "KS",
    "library": "Bcp",
    "layer": "layer-3",
    "header": "Applications/Csp/include/KS.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "CSP_tm_param": {
    "brief": "CSP tree manager parameters",
    "file": "CSP_tm_param",
    "library": "Bcp",
    "layer": "layer-3",
    "header": "Applications/Csp/include/CSP_tm_param.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "CSP_var": {
    "brief": "CSP variable/pattern definitions",
    "file": "CSP_var",
    "library": "Bcp",
    "layer": "layer-3",
    "header": "Applications/Csp/include/CSP_var.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "CSP_userexits": {
    "brief": "CSP user exit callbacks",
    "file": "CSP_userexits",
    "library": "Bcp",
    "layer": "layer-3",
    "header": "Applications/Csp/include/CSP_userexits.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "CSP_init": {
    "brief": "CSP BCP initialization",
    "file": "CSP_init",
    "library": "Bcp",
    "layer": "layer-3",
    "header": "Applications/Csp/include/CSP_init.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "CSP_tm": {
    "brief": "CSP tree manager for BCP",
    "file": "CSP_tm",
    "library": "Bcp",
    "layer": "layer-3",
    "header": "Applications/Csp/include/CSP_tm.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "CSP": {
    "brief": "Cutting stock problem definitions",
    "file": "CSP",
    "library": "Bcp",
    "layer": "layer-3",
    "header": "Applications/Csp/include/CSP.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "CSP_lp": {
    "brief": "CSP LP relaxation for BCP",
    "file": "CSP_lp",
    "library": "Bcp",
    "layer": "layer-3",
    "header": "Applications/Csp/include/CSP_lp.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "CSP_colgen": {
    "brief": "CSP column generation",
    "file": "CSP_colgen",
    "library": "Bcp",
    "layer": "layer-3",
    "header": "Applications/Csp/include/CSP_colgen.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "CSP_lp_param": {
    "brief": "CSP LP parameters",
    "file": "CSP_lp_param",
    "library": "Bcp",
    "layer": "layer-3",
    "header": "Applications/Csp/include/CSP_lp_param.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "BCP_matrix": {
    "brief": "Matrix and vector representations for BCP LP relaxation",
    "file": "BCP_matrix",
    "library": "Bcp",
    "layer": "layer-3",
    "header": "Bcp/src/include/BCP_matrix.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "BCP_indexed_pricing": {
    "brief": "Indexed pricing list for column generation",
    "file": "BCP_indexed_pricing",
    "library": "Bcp",
    "layer": "layer-3",
    "header": "Bcp/src/include/BCP_indexed_pricing.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "BCP_enum_process_t": {
    "brief": "Process type enumeration for BCP",
    "file": "BCP_enum_process_t",
    "library": "Bcp",
    "layer": "layer-3",
    "header": "Bcp/src/include/BCP_enum_process_t.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "BCP_lp_user": {
    "brief": "User customization interface for LP process",
    "file": "BCP_lp_user",
    "library": "Bcp",
    "layer": "layer-3",
    "header": "Bcp/src/include/BCP_lp_user.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "BCP_lp_functions": {
    "brief": "LP process internal function declarations",
    "file": "BCP_lp_functions",
    "library": "Bcp",
    "layer": "layer-3",
    "header": "Bcp/src/include/BCP_lp_functions.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "BCP_vector_short": {
    "brief": "BCP_vec<short> specialization",
    "file": "BCP_vector_short",
    "library": "Bcp",
    "layer": "layer-3",
    "header": "Bcp/src/include/BCP_vector_short.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "BCP_vector_change": {
    "brief": "Delta-encoded vector storage for BCP",
    "file": "BCP_vector_change",
    "library": "Bcp",
    "layer": "layer-3",
    "header": "Bcp/src/include/BCP_vector_change.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "BCP_lp_pool": {
    "brief": "Cut and variable pools for LP process",
    "file": "BCP_lp_pool",
    "library": "Bcp",
    "layer": "layer-3",
    "header": "Bcp/src/include/BCP_lp_pool.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "BCP_lp_param": {
    "brief": "LP process parameters for BCP Branch-Cut-Price",
    "file": "BCP_lp_param",
    "library": "Bcp",
    "layer": "layer-3",
    "header": "Bcp/src/include/BCP_lp_param.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "BCP_message_pvm": {
    "brief": "PVM message passing for BCP",
    "file": "BCP_message_pvm",
    "library": "Bcp",
    "layer": "layer-3",
    "header": "Bcp/src/include/BCP_message_pvm.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "BCP_branch": {
    "brief": "Internal branching object for BCP Branch-Cut-Price",
    "file": "BCP_branch",
    "library": "Bcp",
    "layer": "layer-3",
    "header": "Bcp/src/include/BCP_branch.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "BCP_cut": {
    "brief": "Cut (constraint) representation for BCP Branch-Cut-Price",
    "file": "BCP_cut",
    "library": "Bcp",
    "layer": "layer-3",
    "header": "Bcp/src/include/BCP_cut.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "BCP_vg": {
    "brief": "Variable Generator process for BCP Branch-Cut-Price (pricing)",
    "file": "BCP_vg",
    "library": "Bcp",
    "layer": "layer-3",
    "header": "Bcp/src/include/BCP_vg.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "BCP_message": {
    "brief": "Abstract message passing interface for BCP parallelism",
    "file": "BCP_message",
    "library": "Bcp",
    "layer": "layer-3",
    "header": "Bcp/src/include/BCP_message.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "BCP_tm": {
    "brief": "Tree Manager process for BCP Branch-Cut-Price framework",
    "file": "BCP_tm",
    "library": "Bcp",
    "layer": "layer-3",
    "header": "Bcp/src/include/BCP_tm.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "BCP_vg_param": {
    "brief": "Variable Generator parameters for BCP",
    "file": "BCP_vg_param",
    "library": "Bcp",
    "layer": "layer-3",
    "header": "Bcp/src/include/BCP_vg_param.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "BCP_cg": {
    "brief": "Cut Generator process for BCP Branch-Cut-Price framework",
    "file": "BCP_cg",
    "library": "Bcp",
    "layer": "layer-3",
    "header": "Bcp/src/include/BCP_cg.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "BCP_vector_char": {
    "brief": "BCP_vec<char> specialization",
    "file": "BCP_vector_char",
    "library": "Bcp",
    "layer": "layer-3",
    "header": "Bcp/src/include/BCP_vector_char.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "BCP_warmstart_primaldual": {
    "brief": "Primal-dual warm start for BCP",
    "file": "BCP_warmstart_primaldual",
    "library": "Bcp",
    "layer": "layer-3",
    "header": "Bcp/src/include/BCP_warmstart_primaldual.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "BCP_os": {
    "brief": "OS abstraction layer for BCP",
    "file": "BCP_os",
    "library": "Bcp",
    "layer": "layer-3",
    "header": "Bcp/src/include/BCP_os.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "BCP_lp_main_loop": {
    "brief": "LP process main loop entry point",
    "file": "BCP_lp_main_loop",
    "library": "Bcp",
    "layer": "layer-3",
    "header": "Bcp/src/include/BCP_lp_main_loop.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "BCP_tm_functions": {
    "brief": "Tree Manager internal function declarations",
    "file": "BCP_tm_functions",
    "library": "Bcp",
    "layer": "layer-3",
    "header": "Bcp/src/include/BCP_tm_functions.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "BCP_warmstart_basis": {
    "brief": "BCP warm start basis implementation",
    "file": "BCP_warmstart_basis",
    "library": "Bcp",
    "layer": "layer-3",
    "header": "Bcp/src/include/BCP_warmstart_basis.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "BCP_enum": {
    "brief": "Core enumerations for BCP Branch-Cut-Price framework",
    "file": "BCP_enum",
    "library": "Bcp",
    "layer": "layer-3",
    "header": "Bcp/src/include/BCP_enum.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "BCP_process": {
    "brief": "BCP process base class and scheduler",
    "file": "BCP_process",
    "library": "Bcp",
    "layer": "layer-3",
    "header": "Bcp/src/include/BCP_process.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "BCP_cg_param": {
    "brief": "Cut Generator parameters for BCP",
    "file": "BCP_cg_param",
    "library": "Bcp",
    "layer": "layer-3",
    "header": "Bcp/src/include/BCP_cg_param.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "BCP_cg_user": {
    "brief": "User customization interface for Cut Generator process",
    "file": "BCP_cg_user",
    "library": "Bcp",
    "layer": "layer-3",
    "header": "Bcp/src/include/BCP_cg_user.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "BCP_obj_change": {
    "brief": "Delta encoding for variable/cut bound changes",
    "file": "BCP_obj_change",
    "library": "Bcp",
    "layer": "layer-3",
    "header": "Bcp/src/include/BCP_obj_change.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "BCP_node_change": {
    "brief": "Complete node delta encoding for tree storage",
    "file": "BCP_node_change",
    "library": "Bcp",
    "layer": "layer-3",
    "header": "Bcp/src/include/BCP_node_change.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "BCP_lp": {
    "brief": "LP process for BCP Branch-Cut-Price framework",
    "file": "BCP_lp",
    "library": "Bcp",
    "layer": "layer-3",
    "header": "Bcp/src/include/BCP_lp.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "BCP_message_single": {
    "brief": "Single-process message passing for BCP",
    "file": "BCP_message_single",
    "library": "Bcp",
    "layer": "layer-3",
    "header": "Bcp/src/include/BCP_message_single.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "BCP_main_fun": {
    "brief": "Process entry point functions for BCP",
    "file": "BCP_main_fun",
    "library": "Bcp",
    "layer": "layer-3",
    "header": "Bcp/src/include/BCP_main_fun.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "BCP_vg_user": {
    "brief": "User customization interface for Variable Generator process",
    "file": "BCP_vg_user",
    "library": "Bcp",
    "layer": "layer-3",
    "header": "Bcp/src/include/BCP_vg_user.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "BCP_solution": {
    "brief": "Solution representation for BCP Branch-Cut-Price",
    "file": "BCP_solution",
    "library": "Bcp",
    "layer": "layer-3",
    "header": "Bcp/src/include/BCP_solution.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "BCP_error": {
    "brief": "Fatal error handling for BCP",
    "file": "BCP_error",
    "library": "Bcp",
    "layer": "layer-3",
    "header": "Bcp/src/include/BCP_error.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "BCP_functions": {
    "brief": "Warmstart serialization utilities",
    "file": "BCP_functions",
    "library": "Bcp",
    "layer": "layer-3",
    "header": "Bcp/src/include/BCP_functions.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "BCP_vector_double": {
    "brief": "BCP_vec<double> specialization",
    "file": "BCP_vector_double",
    "library": "Bcp",
    "layer": "layer-3",
    "header": "Bcp/src/include/BCP_vector_double.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "BCP_warmstart": {
    "brief": "LP warm start information for BCP Branch-Cut-Price",
    "file": "BCP_warmstart",
    "library": "Bcp",
    "layer": "layer-3",
    "header": "Bcp/src/include/BCP_warmstart.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "BCP_tm_user": {
    "brief": "User customization interface for Tree Manager process",
    "file": "BCP_tm_user",
    "library": "Bcp",
    "layer": "layer-3",
    "header": "Bcp/src/include/BCP_tm_user.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "BCP_math": {
    "brief": "Mathematical constants for BCP",
    "file": "BCP_math",
    "library": "Bcp",
    "layer": "layer-3",
    "header": "Bcp/src/include/BCP_math.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "BCP_var": {
    "brief": "Variable representation for BCP Branch-Cut-Price",
    "file": "BCP_var",
    "library": "Bcp",
    "layer": "layer-3",
    "header": "Bcp/src/include/BCP_var.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "BCP_mempool": {
    "brief": "Memory pool allocator for BCP",
    "file": "BCP_mempool",
    "library": "Bcp",
    "layer": "layer-3",
    "header": "Bcp/src/include/BCP_mempool.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "BCP_enum_branch": {
    "brief": "Branching-related enumerations for BCP",
    "file": "BCP_enum_branch",
    "library": "Bcp",
    "layer": "layer-3",
    "header": "Bcp/src/include/BCP_enum_branch.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "BCP_vector_general": {
    "brief": "Generic BCP_vec<T> method implementations",
    "file": "BCP_vector_general",
    "library": "Bcp",
    "layer": "layer-3",
    "header": "Bcp/src/include/BCP_vector_general.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "BCP_lp_branch": {
    "brief": "LP-side branching objects for BCP Branch-Cut-Price",
    "file": "BCP_lp_branch",
    "library": "Bcp",
    "layer": "layer-3",
    "header": "Bcp/src/include/BCP_lp_branch.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "BCP_parameters": {
    "brief": "BCP parameters",
    "file": "BCP_parameters",
    "library": "Bcp",
    "layer": "layer-3",
    "header": "Bcp/src/include/BCP_parameters.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "BCP_set_intersects": {
    "brief": "Set intersection test utility",
    "file": "BCP_set_intersects",
    "library": "Bcp",
    "layer": "layer-3",
    "header": "Bcp/src/include/BCP_set_intersects.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "BCP_warmstart_dual": {
    "brief": "Dual-only warm start for BCP",
    "file": "BCP_warmstart_dual",
    "library": "Bcp",
    "layer": "layer-3",
    "header": "Bcp/src/include/BCP_warmstart_dual.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "BCP_tmstorage": {
    "brief": "BCP tree storage process",
    "file": "BCP_tmstorage",
    "library": "Bcp",
    "layer": "layer-3",
    "header": "Bcp/src/include/BCP_tmstorage.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "BCP_vector_int": {
    "brief": "BCP_vec<int> specialization",
    "file": "BCP_vector_int",
    "library": "Bcp",
    "layer": "layer-3",
    "header": "Bcp/src/include/BCP_vector_int.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "BCP_message_tag": {
    "brief": "Message tag enumeration for BCP inter-process communication",
    "file": "BCP_message_tag",
    "library": "Bcp",
    "layer": "layer-3",
    "header": "Bcp/src/include/BCP_message_tag.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "BCP_vector_bool": {
    "brief": "BCP_vec<bool> specialization",
    "file": "BCP_vector_bool",
    "library": "Bcp",
    "layer": "layer-3",
    "header": "Bcp/src/include/BCP_vector_bool.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "BCP_problem_core": {
    "brief": "Core problem formulation for BCP Branch-Cut-Price",
    "file": "BCP_problem_core",
    "library": "Bcp",
    "layer": "layer-3",
    "header": "Bcp/src/include/BCP_problem_core.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "BCP_tm_node": {
    "brief": "Search tree node representation in Tree Manager",
    "file": "BCP_tm_node",
    "library": "Bcp",
    "layer": "layer-3",
    "header": "Bcp/src/include/BCP_tm_node.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "BCP_enum_tm": {
    "brief": "Tree Manager enumerations for BCP",
    "file": "BCP_enum_tm",
    "library": "Bcp",
    "layer": "layer-3",
    "header": "Bcp/src/include/BCP_enum_tm.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "BCP_buffer": {
    "brief": "Message buffer for BCP inter-process communication",
    "file": "BCP_buffer",
    "library": "Bcp",
    "layer": "layer-3",
    "header": "Bcp/src/include/BCP_buffer.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "BCP_vector_sanity": {
    "brief": "Position vector validation utility",
    "file": "BCP_vector_sanity",
    "library": "Bcp",
    "layer": "layer-3",
    "header": "Bcp/src/include/BCP_vector_sanity.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "BCP_USER": {
    "brief": "User initialization and packing interface for BCP",
    "file": "BCP_USER",
    "library": "Bcp",
    "layer": "layer-3",
    "header": "Bcp/src/include/BCP_USER.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "BCP_lp_result": {
    "brief": "LP solve results for BCP Branch-Cut-Price",
    "file": "BCP_lp_result",
    "library": "Bcp",
    "layer": "layer-3",
    "header": "Bcp/src/include/BCP_lp_result.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "BCP_message_mpi": {
    "brief": "MPI message passing for BCP",
    "file": "BCP_message_mpi",
    "library": "Bcp",
    "layer": "layer-3",
    "header": "Bcp/src/include/BCP_message_mpi.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "BCP_lp_node": {
    "brief": "LP process node representation",
    "file": "BCP_lp_node",
    "library": "Bcp",
    "layer": "layer-3",
    "header": "Bcp/src/include/BCP_lp_node.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "BCP_tm_param": {
    "brief": "Tree Manager parameters for BCP Branch-Cut-Price",
    "file": "BCP_tm_param",
    "library": "Bcp",
    "layer": "layer-3",
    "header": "Bcp/src/include/BCP_tm_param.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "BCP_string": {
    "brief": "Simple string class for BCP",
    "file": "BCP_string",
    "library": "Bcp",
    "layer": "layer-3",
    "header": "Bcp/src/include/BCP_string.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "BCP_vector": {
    "brief": "Custom vector class for BCP with performance optimizations",
    "file": "BCP_vector",
    "library": "Bcp",
    "layer": "layer-3",
    "header": "Bcp/src/include/BCP_vector.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "BONMIN_ReferenceManual": {
    "brief": "Bonmin Doxygen documentation main page\n\nMain page for Bonmin reference manual. Provides overview of Mixed\nInteger Nonlinear Programming solver combining B&B with Ipopt NLP.",
    "file": "BONMIN_ReferenceManual",
    "library": "Bonmin",
    "layer": "layer-3",
    "header": "doc/BONMIN_ReferenceManual.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "BonBranchingTQP": {
    "brief": "QP adapter for strong branching in MINLP\nCopyright (C) International Business Machines Corporation and\nCarnegie Mellon University 2006, 2008. All Rights Reserved.\nThis code is published under the Eclipse Public License.",
    "file": "BonBranchingTQP",
    "library": "Bonmin",
    "layer": "layer-3",
    "header": "src/Interfaces/BonBranchingTQP.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "BonMsgUtils": {
    "brief": "Message utilities and macros for Bonmin\nThis code is published under the Eclipse Public License.\n\nProvides ADD_MSG macro and message ID functions for standard,\nwarning, and error messages in the COIN message system.",
    "file": "BonMsgUtils",
    "library": "Bonmin",
    "layer": "layer-3",
    "header": "src/Interfaces/BonMsgUtils.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "BonTypes": {
    "brief": "Type utilities for Bonmin (vector wrapper, reference counting)\nThis code is published under the Eclipse Public License.\n\nProvides:\n- Bonmin::vector: std::vector wrapper with pointer access for Fortran\n- SimpleReferenced: Wrapper to store objects in Coin::ReferencedObject\n- SimpleReferencedPtr: Wrapper to store pointers in ReferencedObject\n- make_referenced: Factory functions for creating referenced wrappers",
    "file": "BonTypes",
    "library": "Bonmin",
    "layer": "layer-3",
    "header": "src/Interfaces/BonTypes.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "BonTMINLP2TNLP": {
    "brief": "Adapter converting TMINLP (MINLP) to TNLP (NLP) for Ipopt",
    "file": "BonTMINLP2TNLP",
    "library": "Bonmin",
    "layer": "layer-3",
    "header": "src/Interfaces/BonTMINLP2TNLP.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "BonTMINLP2OsiLP": {
    "brief": "Abstract transformer from MINLP to LP outer approximation\n\nBase class for building linear outer approximations of nonlinear problems.\nUsed to create MILP relaxations for OA-based algorithms.\n\n**Key methods:**\n- extract(): Build initial OA in an OsiSolverInterface\n- get_oas(): Generate OA cuts at a given point\n- get_refined_oa(): Get refined OA cuts\n\n**Coefficient cleaning (cleanNnz):**\nSmall coefficients are handled specially to avoid numerical issues:\n- Values < very_tiny_: Ignored completely\n- Values < tiny_: Try to absorb into RHS if bounds allow",
    "file": "BonTMINLP2OsiLP",
    "library": "Bonmin",
    "layer": "layer-3",
    "header": "src/Interfaces/BonTMINLP2OsiLP.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "BonColReader": {
    "brief": "Reader for AMPL .col and .row name files\nCopyright (C) Carnegie Mellon University 2005. All Rights Reserved.\nThis code is published under the Eclipse Public License.\n\nNamesReader: Reads variable and constraint names from AMPL-generated\n.col (column names) and .row (row names) files. Provides bidirectional\nlookup between indices and names via hash map.\n\nAuthors: Pierre Bonami, Carnegie Mellon University\nDate: May 26, 2005",
    "file": "BonColReader",
    "library": "Bonmin",
    "layer": "layer-3",
    "header": "src/Interfaces/BonColReader.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "BonExitCodes": {
    "brief": "Error codes for uncatchable errors in Bonmin\n\nDefines error codes for fatal errors that cannot be handled via exceptions.\n\n**Error codes:**\n- ERROR_IN_AMPL_SUFFIXES (111): Invalid AMPL suffix specification\n- UNSUPPORTED_CBC_OBJECT: CbcObject type not supported by Bonmin",
    "file": "BonExitCodes",
    "library": "Bonmin",
    "layer": "layer-3",
    "header": "src/Interfaces/BonExitCodes.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "BonBoundsReader": {
    "brief": "Reader for variable bound modification files\nCopyright (C) Carnegie Mellon University 2005. All Rights Reserved.\nThis code is published under the Eclipse Public License.\n\nBoundsReader: Reads files containing variable bound changes in\nMPS-like format. Applies bound modifications to OsiTMINLPInterface\nfor scenario analysis or user-specified bound tightening.\n\nAuthors: Pierre Bonami, Carnegie Mellon University\nDate: May 26, 2005",
    "file": "BonBoundsReader",
    "library": "Bonmin",
    "layer": "layer-3",
    "header": "src/Interfaces/BonBoundsReader.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "BonCutStrengthener": {
    "brief": "Strengthening OA cuts via NLP optimization\n\nImproves outer approximation cuts by solving auxiliary NLPs to find\ntighter bounds on linearizations. Also supports disjunctive cuts.",
    "file": "BonCutStrengthener",
    "library": "Bonmin",
    "layer": "layer-3",
    "header": "src/Interfaces/BonCutStrengthener.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "BonStrongBranchingSolver": {
    "brief": "Abstract base class for strong branching NLP solves",
    "file": "BonStrongBranchingSolver",
    "library": "Bonmin",
    "layer": "layer-3",
    "header": "src/Interfaces/BonStrongBranchingSolver.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "BonStartPointReader": {
    "brief": "Reader for Ipopt initialization point files\nCopyright (C) Carnegie Mellon University 2005. All Rights Reserved.\nThis code is published under the Eclipse Public License.\n\nStartPointReader: Reads .initP files containing starting point\ninformation for Ipopt initialization. File format is: number of\nprimals, number of duals, then values. Variables ordered as:\nprimals, dual lower bounds, dual upper bounds, constraint duals.\n\nAuthors: Pierre Bonami, Carnegie Mellon University\nDate: May 26, 2005",
    "file": "BonStartPointReader",
    "library": "Bonmin",
    "layer": "layer-3",
    "header": "src/Interfaces/BonStartPointReader.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "BonTNLPSolver": {
    "brief": "Abstract interface for NLP solvers used in branch-and-bound",
    "file": "BonTNLPSolver",
    "library": "Bonmin",
    "layer": "layer-3",
    "header": "src/Interfaces/BonTNLPSolver.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "BonRegisteredOptions": {
    "brief": "Extended option registration with algorithm validity tracking\n\nExtends Ipopt's RegisteredOptions to track which options are valid for\nwhich Bonmin algorithms, enabling algorithm-specific option filtering.\n\n**Algorithm validity bits (ExtraOptInfosBits):**\n- validInHybrid (1): B-Hyb algorithm\n- validInQG (2): Quesada-Grossmann B-QG\n- validInOA (4): Pure outer approximation B-OA\n- validInBBB (8): Pure NLP-based branch-and-bound B-BB\n- validInEcp (16): Extended cutting plane B-Ecp\n- validIniFP (32): Iterated feasibility pump B-iFP\n- validInCbc (64): Cbc parallel mode\n\n**Category types (ExtraCategoriesInfo):**\n- BonminCategory, IpoptCategory, FilterCategory, BqpdCategory, CouenneCategory",
    "file": "BonRegisteredOptions",
    "library": "Bonmin",
    "layer": "layer-3",
    "header": "src/Interfaces/BonRegisteredOptions.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "BonCurvatureEstimator": {
    "brief": "Curvature estimation for branching decisions (NOT SUPPORTED)",
    "file": "BonCurvatureEstimator",
    "library": "Bonmin",
    "layer": "layer-3",
    "header": "src/Interfaces/BonCurvatureEstimator.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "BonOsiTMINLPInterface": {
    "brief": "OsiSolverInterface wrapper for TMINLP problems",
    "file": "BonOsiTMINLPInterface",
    "library": "Bonmin",
    "layer": "layer-3",
    "header": "src/Interfaces/BonOsiTMINLPInterface.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "BonStdInterfaceTMINLP": {
    "brief": "C-callback based TMINLP implementation for standard interface\nCopyright (C) Shaurya Sharma. All Rights Reserved.\nThis code is published under the Eclipse Public License.\n\nStdInterfaceTMINLP: TMINLP implementation using C function pointers\nfor callbacks (eval_f, eval_g, eval_grad_f, etc.). Enables use of\nBonmin from C or languages with C FFI. Mirrors Ipopt's StdCInterface.\n\nAuthors: Shaurya Sharma\nDate: June 7, 2015",
    "file": "BonStdInterfaceTMINLP",
    "library": "Bonmin",
    "layer": "layer-3",
    "header": "src/Interfaces/BonStdInterfaceTMINLP.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "BonTMINLP": {
    "brief": "Base class for Mixed-Integer Nonlinear Programs (MINLP)",
    "file": "BonTMINLP",
    "library": "Bonmin",
    "layer": "layer-3",
    "header": "src/Interfaces/BonTMINLP.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "BonTNLP2FPNLP": {
    "brief": "Adapter for Feasibility Pump NLP formulation\n\nWraps a TNLP to create Feasibility Pump subproblems by modifying the\nobjective to minimize distance to a target integer point.\n\n**Modified objective:**\nf_FP(x) = lambda * ||x_I - x\u0303_I||_p + (1-lambda) * sigma * f(x)\nwhere x\u0303_I is the target integer point, p is norm (1 or 2).\n\n**Optional constraints:**\n- Cutoff constraint: f(x) <= cutoff (improve on incumbent)\n- Local branching: sum |x_i - x\u0303_i| <= rhs (neighborhood search)\n\n**Key parameters:**\n- lambda_: Weight on distance (vs original objective)\n- sigma_: Scaling for original objective\n- norm_: L1 or L2 distance metric",
    "file": "BonTNLP2FPNLP",
    "library": "Bonmin",
    "layer": "layer-3",
    "header": "src/Interfaces/BonTNLP2FPNLP.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "BonAuxInfos": {
    "brief": "Auxiliary information passing between Bonmin B&B components\n\nExtends OsiBabSolver to pass solver-specific information during\nbranch-and-cut, including NLP solutions found by heuristics.\n\n**Key functionality:**\n- nlpSolution_: Store solutions from NLP solves/heuristics\n- infeasibleNode_: Flag for cut generator detected infeasibility\n- bestSolution2_: Alternate objective tracking (for bi-objective)\n\n**Usage pattern:**\nCut generators and heuristics store found solutions here;\nthe B&B framework queries for incumbents.",
    "file": "BonAuxInfos",
    "library": "Bonmin",
    "layer": "layer-3",
    "header": "src/Interfaces/BonAuxInfos.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "BonGuessHeuristic": {
    "brief": "Pseudocost-based initial guess heuristic for MINLP\nCopyright (C) International Business Machines 2007. All Rights Reserved.\nThis code is published under the Eclipse Public License.",
    "file": "BonGuessHeuristic",
    "library": "Bonmin",
    "layer": "layer-3",
    "header": "src/CbcBonmin/BonGuessHeuristic.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "BonBabInfos": {
    "brief": "Information passing between Bonmin B&B components\n\nExtends OsiAuxInfo to pass Bonmin-specific information between components\nduring branch-and-cut. Provides access to the Bab solver and solution info.\n\n**Key functionality:**\n- babPtr_: Access to the Bab object (and via it, CbcModel)\n- hasSolution(): Check if incumbent exists\n- bestSolution_: Current best known solution (from AuxInfo)\n\nUsed by cut generators and heuristics to query current B&B state.",
    "file": "BonBabInfos",
    "library": "Bonmin",
    "layer": "layer-3",
    "header": "src/CbcBonmin/BonBabInfos.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "BonCbcNode": {
    "brief": "Extended node information classes for MINLP branch-and-bound\n\nExtends Cbc's node information to track MINLP-specific data like sequences\nof infeasible or unsolved subproblems along a branch.\n\n**Classes:**\n- BonCbcFullNodeInfo: Complete node recreation from scratch\n- BonCbcPartialNodeInfo: Incremental node changes from parent\n\n**MINLP-specific tracking:**\n- sequenceOfInfeasiblesSize_: Consecutive infeasible NLP subproblems\n- sequenceOfUnsolvedSize_: Consecutive NLP solver failures\n\nThese counts help detect problematic branches where NLP solves consistently\nfail, enabling early pruning heuristics to avoid wasted computation.",
    "file": "BonCbcNode",
    "library": "Bonmin",
    "layer": "layer-3",
    "header": "src/CbcBonmin/BonCbcNode.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "BonCbc": {
    "brief": "Main branch-and-bound driver for Bonmin using Cbc\n\nThe Bab class is the entry point for solving MINLPs with Bonmin. It wraps\nCbcModel to provide branch-and-bound with NLP solvers for subproblems.\n\n**Key method:**\n- branchAndBound(BabSetupBase&): Main solve routine\n\n**Return statuses (MipStatuses):**\n- FeasibleOptimal: Optimal solution found and proven\n- ProvenInfeasible: Problem proven infeasible\n- Feasible: Integer solution found (not proven optimal)\n- UnboundedOrInfeasible: Continuous relaxation unbounded\n- NoSolutionKnown: No feasible solution found\n\n**Solution access:**\n- bestSolution(): Primal solution vector\n- bestObj(): Objective value of best solution\n- bestBound(): Best known lower bound",
    "file": "BonCbc",
    "library": "Bonmin",
    "layer": "layer-3",
    "header": "src/CbcBonmin/BonCbc.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "BonDiver": {
    "brief": "Diving-based tree traversal strategies for MINLP branch-and-bound\n\nImplements tree traversal strategies that \"dive\" down branches before\nbacktracking, often finding feasible solutions faster than pure best-bound.",
    "file": "BonDiver",
    "library": "Bonmin",
    "layer": "layer-3",
    "header": "src/CbcBonmin/BonDiver.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "BonCbcNlpStrategy": {
    "brief": "NLP failure handling strategy for Cbc in MINLP context\nCopyright (C) International Business Machines Corporation and\nCarnegie Mellon University 2006. All Rights Reserved.\nThis code is published under the Eclipse Public License.\n\nCbcNlpStrategy: Strategy class for handling NLP solve failures during\nbranch-and-bound. Tracks consecutive failures and infeasibilities,\noptionally treating failures as infeasible to continue search.\n\nAuthors: John J. Forrest, IBM; Pierre Bonami, CMU\nDate: March 15, 2006",
    "file": "BonCbcNlpStrategy",
    "library": "Bonmin",
    "layer": "layer-3",
    "header": "src/CbcBonmin/BonCbcNlpStrategy.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "BonBonminSetup": {
    "brief": "Main Bonmin algorithm configuration and initialization\n\nExtends BabSetupBase with Bonmin-specific algorithm selection and\ninitialization for all MINLP algorithms.\n\n**Algorithm enum:**\n- B_BB (0): NLP-based branch-and-bound\n- B_OA (1): Pure Outer Approximation decomposition\n- B_QG (2): Quesada-Grossmann branch-and-cut\n- B_Hyb (3): Hybrid OA with NLP at nodes (default)\n- B_Ecp (4): Extended Cutting Plane (FilMINT-style)\n- B_IFP (5): Iterated Feasibility Pump\n\n**Initialization:**\n- initializeBBB(): Pure B&B with NLP at every node\n- initializeBHyb(): Hybrid with OA cuts + occasional NLP",
    "file": "BonBonminSetup",
    "library": "Bonmin",
    "layer": "layer-3",
    "header": "src/Algorithms/BonBonminSetup.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "BonSubMipSolver": {
    "brief": "Unified interface for solving MILP subproblems in OA decomposition\n\nProvides a common interface for solving MILP subproblems using either\nCbc (via OsiClpSolverInterface) or CPLEX (via OsiCpxSolverInterface).\nUsed by OA decomposition algorithms to solve the linearized master problem.",
    "file": "BonSubMipSolver",
    "library": "Bonmin",
    "layer": "layer-3",
    "header": "src/Algorithms/BonSubMipSolver.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "BonSolverHelp": {
    "brief": "Utility functions for OA and Feasibility Pump algorithms\nCopyright (C) International Business Machines (IBM) 2006.\nAll Rights Reserved.\nThis code is published under the Eclipse Public License.\n\nHelper functions for manipulating solver state during OA decomposition\nand Feasibility Pump: checking integer feasibility, fixing/relaxing\ninteger variables, comparing solutions, and installing cuts.\n\nAuthors: Pierre Bonami, IBM\nDate: December 7, 2006",
    "file": "BonSolverHelp",
    "library": "Bonmin",
    "layer": "layer-3",
    "header": "src/Algorithms/BonSolverHelp.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "BonBabSetupBase": {
    "brief": "Base configuration class for branch-and-bound MINLP solvers\n\nAggregates all components needed to run branch-and-bound: NLP solver,\ncut generators, heuristics, branching rules, and tree traversal strategy.\nServes as the central configuration point for Bonmin algorithms.\n\n**Key components:**\n- nonlinearSolver_: OsiTMINLPInterface for NLP subproblems\n- cutGenerators_: List of CglCutGenerator (OA, ECP, Gomory, etc.)\n- heuristics_: List of CbcHeuristic (feasibility pump, rounding, etc.)\n- branchingMethod_: OsiChooseVariable for variable selection\n\n**Tree search strategies:**\n- NodeComparison: bestBound, DFS, BFS, dynamic, bestGuess\n- TreeTraversal: HeapOnly, DiveFromBest, ProbedDive, DfsDiveFromBest\n\n**Branching strategies (VarSelectStra_Enum):**\n- MOST_FRACTIONAL: Simple, fast, often poor\n- STRONG_BRANCHING: Evaluate candidates via LP/NLP solves\n- RELIABILITY_BRANCHING: Use pseudo-costs when trusted",
    "file": "BonBabSetupBase",
    "library": "Bonmin",
    "layer": "layer-3",
    "header": "src/Algorithms/BonBabSetupBase.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "BonCbcLpStrategy": {
    "brief": "Cbc strategy for configuring cut generators in OA\nCopyright (C) Carnegie Mellon University 2006. All Rights Reserved.\nThis code is published under the Eclipse Public License.\n\nCbcStrategyChooseCuts: Strategy class extending CbcStrategyDefault\nto configure cut generators (Gomory, MIR, etc.) for use in Outer\nApproximation LP subproblems. Sets generator frequencies based on\nBabSetupBase configuration.\n\nAuthors: Pierre Bonami, Carnegie Mellon University\nDate: March 15, 2006",
    "file": "BonCbcLpStrategy",
    "library": "Bonmin",
    "layer": "layer-3",
    "header": "src/Algorithms/BonCbcLpStrategy.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "BonIpoptSolver": {
    "brief": "Ipopt implementation of TNLPSolver for NLP subproblems",
    "file": "BonIpoptSolver",
    "library": "Bonmin",
    "layer": "layer-3",
    "header": "src/Interfaces/Ipopt/BonIpoptSolver.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "BonIpoptWarmStart": {
    "brief": "Warm start storage for Ipopt within branch-and-bound\n\nStores primal and dual solution values for warm starting subsequent NLP\nsolves. Inherits from both CoinWarmStartPrimalDual (for actual data) and\nCoinWarmStartBasis (for Cbc integration compatibility).\n\n**Data layout (dual part has 2*n + m values):**\n- [0, n): Dual multipliers for lower bounds (z_L for x >= l)\n- [n, 2n): Dual multipliers for upper bounds (z_U for x <= u)\n- [2n, 2n+m): Dual multipliers for constraints (lambda for g(x))\n\n**Classes:**\n- IpoptWarmStart: Main warm start container\n- IpoptWarmStartDiff: Differential update for tree traversal",
    "file": "BonIpoptWarmStart",
    "library": "Bonmin",
    "layer": "layer-3",
    "header": "src/Interfaces/Ipopt/BonIpoptWarmStart.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "BonIpoptInteriorWarmStarter": {
    "brief": "Interior point warm start for Ipopt in branch-and-bound\n\nStores interior point iterates from a solved NLP for warm starting child\nnodes. Unlike simple optimal-point warm start, this preserves barrier\nparameter (mu) and interior structure, enabling faster convergence.\n\n**Key methods:**\n- UpdateStoredIterates(): Called during optimization to save promising iterates\n- WarmStartIterate(): Computes initial point for new problem from stored data\n- Finalize(): Post-processing after parent NLP solve completes\n\n**Stored data per iterate:**\n- Primal/dual iterate vectors\n- Barrier parameter mu\n- NLP error, primal/dual infeasibility, complementarity",
    "file": "BonIpoptInteriorWarmStarter",
    "library": "Bonmin",
    "layer": "layer-3",
    "header": "src/Interfaces/Ipopt/BonIpoptInteriorWarmStarter.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "BonBqpdSolver": {
    "brief": "Interface to BQPD quadratic programming solver\nCopyright (C) International Business Machines Corporation, 2007.\nAll Rights Reserved.\nThis code is published under the Eclipse Public License.\n\nBqpdSolver: TNLPSolver implementation wrapping the BQPD Fortran solver\nfor solving quadratic programs during strong branching. Provides hot\nstart capability for efficient re-optimization with changed bounds.\n\nUses BranchingTQP to create QP approximations of the MINLP.\n\nAuthors: Andreas Waechter, IBM (based on BonFilterSolver.cpp)\nDate: July 9, 2007",
    "file": "BonBqpdSolver",
    "library": "Bonmin",
    "layer": "layer-3",
    "header": "src/Interfaces/Filter/BonBqpdSolver.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "BonFilterWarmStart": {
    "brief": "Warm start storage for FilterSQP solver\n\nStores warm start information for FilterSQP, including primal/dual values\nand FilterSQP's internal lws (integer working set) array. Inherits from both\nCoinWarmStartPrimalDual and CoinWarmStartBasis for Cbc compatibility.\n\n**Data stored:**\n- x: Primal variables (from CoinWarmStartPrimalDual)\n- lam: Dual multipliers (from CoinWarmStartPrimalDual)\n- lws: FilterSQP's integer working set array (active set info)\n- istat[14]: FilterSQP status array\n\n**Classes:**\n- FilterWarmStart: Main warm start container\n- FilterWarmStartDiff: Differential update for tree traversal",
    "file": "BonFilterWarmStart",
    "library": "Bonmin",
    "layer": "layer-3",
    "header": "src/Interfaces/Filter/BonFilterWarmStart.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "BonFilterSolver": {
    "brief": "FilterSQP implementation of TNLPSolver for NLP subproblems",
    "file": "BonFilterSolver",
    "library": "Bonmin",
    "layer": "layer-3",
    "header": "src/Interfaces/Filter/BonFilterSolver.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "BonFilterTypes": {
    "brief": "Fortran type definitions for FilterSQP interface\n\nDefines type aliases for interfacing with the Fortran FilterSQP library.\nUses FORTRAN_INTEGER_TYPE from Ipopt's configuration for portability\nacross different Fortran compilers (32-bit vs 64-bit integers).",
    "file": "BonFilterTypes",
    "library": "Bonmin",
    "layer": "layer-3",
    "header": "src/Interfaces/Filter/BonFilterTypes.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "BonBqpdWarmStart": {
    "brief": "Warm start information for BQPD solver\nCopyright (C) International Business Machines Corporation 2007.\nAll Rights Reserved.\nThis code is published under the Eclipse Public License.\n\nBqpdWarmStart: Stores warm start information for BQPD QP solver.\nInherits from both CoinWarmStartPrimalDual (actual warm start data)\nand CoinWarmStartBasis (for Cbc integration compatibility).\n\nAuthors: Andreas Waechter, IBM (based on BonFilterWarmStart.hpp)\nDate: August 3, 2007",
    "file": "BonBqpdWarmStart",
    "library": "Bonmin",
    "layer": "layer-3",
    "header": "src/Interfaces/Filter/BonBqpdWarmStart.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "BonSolReader": {
    "brief": "Reader for AMPL .sol solution files\nCopyright (C) CNRS 2011. All Rights Reserved.\nThis code is published under the Eclipse Public License.\n\nSolReader: Reads solution files in AMPL .sol format containing\nvariable values. Used to load known solutions for warm starting\nor comparison with computed solutions.\n\nAuthors: Pierre Bonami, LIF, CNRS\nDate: March 1, 2011",
    "file": "BonSolReader",
    "library": "Bonmin",
    "layer": "layer-3",
    "header": "src/Interfaces/Ampl/BonSolReader.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "BonAmplInterface": {
    "brief": "OsiSolverInterface for AMPL .nl file input\n\nExtends OsiTMINLPInterface to read problems from AMPL .nl files.\nProvides convenient entry point for AMPL-based modeling.\n\n**Usage:**\n@code\nAmplInterface solver;\nsolver.readAmplNlFile(argv, roptions, options, journalist);\n@endcode\n\n**Additional features:**\n- readNames(): Read variable/row names from .col/.row files\n- amplModel(): Access underlying AmplTMINLP",
    "file": "BonAmplInterface",
    "library": "Bonmin",
    "layer": "layer-3",
    "header": "src/Interfaces/Ampl/BonAmplInterface.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "BonAmplTMINLP": {
    "brief": "AMPL interface for MINLP problems via .nl files\n\nImplements TMINLP by reading AMPL .nl files, extracting integer variable\ninformation, SOS constraints, branching priorities, and convexity markers.\n\n**AMPL suffix reading:**\n- read_priorities(): Variable branching priorities\n- read_sos(): SOS1/SOS2 constraint definitions\n- read_convexities(): Constraint convexity markers (for OA)\n- read_onoff(): Perspective reformulation indicators\n- read_obj_suffixes(): Upper bounding objective (UBObj prefix)\n\n**AMPL solve_result_num codes:**\n- 3: Integer optimal\n- 220: Proven infeasible\n- 421: Limit reached with feasible solution\n- 410: Limit reached, no feasible solution\n- 500: Error",
    "file": "BonAmplTMINLP",
    "library": "Bonmin",
    "layer": "layer-3",
    "header": "src/Interfaces/Ampl/BonAmplTMINLP.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "BonHeuristicFPump": {
    "brief": "Feasibility Pump heuristic for MINLP\n\nImplements the Feasibility Pump algorithm adapted for nonlinear problems.\nAlternates between:\n1. Rounding to nearest integer solution\n2. Projecting back to feasible continuous space via NLP\n\n**Classes:**\n- HeuristicFPump: Main feasibility pump heuristic (CbcHeuristic)\n- RoundingFPump: Helper for intelligent rounding considering constraints",
    "file": "BonHeuristicFPump",
    "library": "Bonmin",
    "layer": "layer-3",
    "header": "src/CbcBonmin/Heuristics/BonHeuristicFPump.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "BonHeuristicDiveMIPFractional": {
    "brief": "MIP-based diving heuristic selecting most fractional variable\nCopyright (C) 2007, International Business Machines Corporation and others.\nAll Rights Reserved.\nThis code is published under the Eclipse Public License.",
    "file": "BonHeuristicDiveMIPFractional",
    "library": "Bonmin",
    "layer": "layer-3",
    "header": "src/CbcBonmin/Heuristics/BonHeuristicDiveMIPFractional.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "BonLocalSolverBasedHeuristic": {
    "brief": "Base class for heuristics using local NLP/MINLP solves",
    "file": "BonLocalSolverBasedHeuristic",
    "library": "Bonmin",
    "layer": "layer-3",
    "header": "src/CbcBonmin/Heuristics/BonLocalSolverBasedHeuristic.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "BonFixAndSolveHeuristic": {
    "brief": "Fix-and-Solve heuristic for MINLP",
    "file": "BonFixAndSolveHeuristic",
    "library": "Bonmin",
    "layer": "layer-3",
    "header": "src/CbcBonmin/Heuristics/BonFixAndSolveHeuristic.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "BonHeuristicDiveMIPVectorLength": {
    "brief": "MIP-based diving heuristic selecting by constraint participation\nCopyright (C) 2007, International Business Machines Corporation and others.\nAll Rights Reserved.\nThis code is published under the Eclipse Public License.",
    "file": "BonHeuristicDiveMIPVectorLength",
    "library": "Bonmin",
    "layer": "layer-3",
    "header": "src/CbcBonmin/Heuristics/BonHeuristicDiveMIPVectorLength.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "BonDummyPump": {
    "brief": "Placeholder/testing heuristic for feasibility pump\nCopyright (C) CNRS\nThis code is published under the Eclipse Public License.\n\nDummyPump: Simple placeholder heuristic extending LocalSolverBasedHeuristic.\nUsed for testing or as template for new heuristics.\n\nProvides minimal implementation of solution() method.\n\nAuthors: Pierre Bonami, LIF Universit\u00e9 de la M\u00e9diterran\u00e9e-CNRS\nDate: 06/18/2008",
    "file": "BonDummyPump",
    "library": "Bonmin",
    "layer": "layer-3",
    "header": "src/CbcBonmin/Heuristics/BonDummyPump.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "BonHeuristicLocalBranching": {
    "brief": "Local Branching heuristic for MINLP improvement",
    "file": "BonHeuristicLocalBranching",
    "library": "Bonmin",
    "layer": "layer-3",
    "header": "src/CbcBonmin/Heuristics/BonHeuristicLocalBranching.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "BonPumpForMinlp": {
    "brief": "Feasibility Pump heuristic adapted for MINLP\nCopyright (C) CNRS\nThis code is published under the Eclipse Public License.\n\nPumpForMinlp: Feasibility Pump heuristic for nonlinear mixed-integer\nprogramming. Extends the MIP Feasibility Pump to handle nonlinear\nconstraints by using NLP subproblem solves.\n\nAlternates between:\n- Rounding current NLP solution to integer\n- Solving NLP with objective minimizing distance to rounded point\n\nAuthors: Pierre Bonami, LIF Universit\u00e9 de la M\u00e9diterran\u00e9e-CNRS\nDate: 02/18/2009",
    "file": "BonPumpForMinlp",
    "library": "Bonmin",
    "layer": "layer-3",
    "header": "src/CbcBonmin/Heuristics/BonPumpForMinlp.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "BonHeuristicDive": {
    "brief": "Base class for diving heuristics in MINLP",
    "file": "BonHeuristicDive",
    "library": "Bonmin",
    "layer": "layer-3",
    "header": "src/CbcBonmin/Heuristics/BonHeuristicDive.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "BonHeuristicDiveFractional": {
    "brief": "NLP-based diving heuristic selecting most fractional variable\nCopyright (C) 2007, International Business Machines Corporation and others.\nAll Rights Reserved.\nThis code is published under the Eclipse Public License.",
    "file": "BonHeuristicDiveFractional",
    "library": "Bonmin",
    "layer": "layer-3",
    "header": "src/CbcBonmin/Heuristics/BonHeuristicDiveFractional.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "BonHeuristicDiveMIP": {
    "brief": "Base class for MIP-based diving heuristics in MINLP\nCopyright (C) 2007, International Business Machines Corporation and others.\nAll Rights Reserved.\nThis code is published under the Eclipse Public License.",
    "file": "BonHeuristicDiveMIP",
    "library": "Bonmin",
    "layer": "layer-3",
    "header": "src/CbcBonmin/Heuristics/BonHeuristicDiveMIP.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "BonHeuristicDiveVectorLength": {
    "brief": "NLP-based diving heuristic selecting by constraint participation\nCopyright (C) 2007, International Business Machines Corporation and others.\nAll Rights Reserved.\nThis code is published under the Eclipse Public License.",
    "file": "BonHeuristicDiveVectorLength",
    "library": "Bonmin",
    "layer": "layer-3",
    "header": "src/CbcBonmin/Heuristics/BonHeuristicDiveVectorLength.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "BonHeuristicRINS": {
    "brief": "Relaxation Induced Neighborhood Search (RINS) heuristic for MINLP",
    "file": "BonHeuristicRINS",
    "library": "Bonmin",
    "layer": "layer-3",
    "header": "src/CbcBonmin/Heuristics/BonHeuristicRINS.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "BonMilpRounding": {
    "brief": "MILP-based rounding heuristic for MINLP",
    "file": "BonMilpRounding",
    "library": "Bonmin",
    "layer": "layer-3",
    "header": "src/CbcBonmin/Heuristics/BonMilpRounding.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "BonRandomChoice": {
    "brief": "Random variable selection for branching\nCopyright (C) CNRS 2008. All Rights Reserved.\nThis code is published under the Eclipse Public License.\n\nBonRandomChoice: Variable selection strategy that randomly picks from\nunsatisfied integer variables. Useful for diversification in search\nor as baseline for comparison with sophisticated selection rules.\n\nAuthors: Pierre Bonami, LIF, CNRS-Marseille Universites\nDate: March 17, 2008",
    "file": "BonRandomChoice",
    "library": "Bonmin",
    "layer": "layer-3",
    "header": "src/Algorithms/Branching/BonRandomChoice.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "BonPseudoCosts": {
    "brief": "Pseudo-cost storage and update for MINLP branching\n\nExtends OsiPseudoCosts to track branching history for integer variables.\nPseudo-costs estimate the objective change per unit change in a variable,\nenabling efficient branching decisions without expensive strong branching.",
    "file": "BonPseudoCosts",
    "library": "Bonmin",
    "layer": "layer-3",
    "header": "src/Algorithms/Branching/BonPseudoCosts.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "BonQpBranchingSolver": {
    "brief": "QP-based strong branching solver\n\nImplements strong branching by solving QP approximations of the NLP\nsubproblems. Faster than full NLP but more accurate than LP.",
    "file": "BonQpBranchingSolver",
    "library": "Bonmin",
    "layer": "layer-3",
    "header": "src/Algorithms/Branching/BonQpBranchingSolver.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "BonLpBranchingSolver": {
    "brief": "LP-based strong branching solver using ECP cuts\n\nImplements strong branching by solving LP relaxations enhanced with\nExtended Cutting Plane (ECP) cuts, avoiding full NLP solves.",
    "file": "BonLpBranchingSolver",
    "library": "Bonmin",
    "layer": "layer-3",
    "header": "src/Algorithms/Branching/BonLpBranchingSolver.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "BonCurvBranchingSolver": {
    "brief": "Curvature-based branching solver (DEPRECATED)\nCopyright (C) 2006, 2007 International Business Machines Corporation.\nAll Rights Reserved.\n\nCurvBranchingSolver: Strong branching solver that uses curvature\nestimation to predict bound changes. Uses second-order information\nfrom the Hessian to guide variable selection.\n\nNOTE: This code is no longer supported.",
    "file": "BonCurvBranchingSolver",
    "library": "Bonmin",
    "layer": "layer-3",
    "header": "src/Algorithms/Branching/BonCurvBranchingSolver.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "BonChooseVariable": {
    "brief": "Strong branching and pseudo-cost based variable selection for MINLP\n\nImplements branching variable selection for nonlinear branch-and-bound.\nCombines strong branching (solving LP/NLP relaxations) with pseudo-costs\n(estimates from historical branching information).\n\n**Key classes:**\n- BonChooseVariable: Main branching decision maker (extends OsiChooseVariable)\n- HotInfo: Stores strong branching results for a candidate\n\n**Branching decision process:**\n1. setupList(): Identify fractional variables, rank by pseudo-costs\n2. doStrongBranching(): Evaluate top candidates via LP/NLP solves\n3. chooseVariable(): Select best candidate based on objective change\n\n**Pseudo-cost computation:**\n- Estimates objective change per unit change in variable value\n- Updated after each branching decision using actual results\n- Used to avoid expensive strong branching after trust is established",
    "file": "BonChooseVariable",
    "library": "Bonmin",
    "layer": "layer-3",
    "header": "src/Algorithms/Branching/BonChooseVariable.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "BonOAMessages": {
    "brief": "Message definitions for Outer Approximation algorithms\nCopyright (C) Carnegie Mellon University 2006. All Rights Reserved.\nThis code is published under the Eclipse Public License.\n\nDefines message IDs and OaMessages class for output during\nOuter Approximation cutting plane algorithms. Messages include\nNLP solve status, bound updates, and iteration statistics.\n\nAuthors: Pierre Bonami, Carnegie Mellon University\nDate: July 15, 2005",
    "file": "BonOAMessages",
    "library": "Bonmin",
    "layer": "layer-3",
    "header": "src/Algorithms/OaGenerators/BonOAMessages.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "BonFpForMinlp": {
    "brief": "Feasibility Pump for MINLP via Outer Approximation\nCopyright (C) CNRS 2008. All Rights Reserved.\nThis code is published under the Eclipse Public License.\n\nMinlpFeasPump: Feasibility Pump implementation for MINLP using OA\ndecomposition. Alternates between solving MIP with distance-to-integer\nobjective and NLP with fixed integers to find feasible solutions.",
    "file": "BonFpForMinlp",
    "library": "Bonmin",
    "layer": "layer-3",
    "header": "src/Algorithms/OaGenerators/BonFpForMinlp.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "BonEcpCuts": {
    "brief": "Extended Cutting Plane (ECP) cut generator for MINLP\n\nGenerates OA cuts iteratively at LP solution points, refining the\nlinear approximation without requiring NLP solves at every iteration.",
    "file": "BonEcpCuts",
    "library": "Bonmin",
    "layer": "layer-3",
    "header": "src/Algorithms/OaGenerators/BonEcpCuts.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "BonDummyHeuristic": {
    "brief": "Simple placeholder heuristic wrapping NLP solver\nCopyright (C) Carnegie Mellon University 2005. All Rights Reserved.\nThis code is published under the Eclipse Public License.\n\nDummyHeuristic: Minimal heuristic that calls NLP solver to provide\nsolutions. Used for testing or as template for new heuristics.\nAlways reports ready to run (shouldHeurRun returns true).\n\nAuthors: Pierre Bonami, Carnegie Mellon University\nDate: May 26, 2005",
    "file": "BonDummyHeuristic",
    "library": "Bonmin",
    "layer": "layer-3",
    "header": "src/Algorithms/OaGenerators/BonDummyHeuristic.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "BonOaNlpOptim": {
    "brief": "NLP-based outer approximation cut generator\n\nGenerates OA cuts by solving NLP relaxations at B&B nodes, rather than\nat integer feasible points (as in classical OA). More expensive per cut,\nbut can improve bounds at fractional nodes.",
    "file": "BonOaNlpOptim",
    "library": "Bonmin",
    "layer": "layer-3",
    "header": "src/Algorithms/OaGenerators/BonOaNlpOptim.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "BonOaFeasChecker": {
    "brief": "OA-based feasibility checker for MILP solutions\n\nChecks if MILP solution is feasible for original MINLP by evaluating\nnonlinear constraints and generating OA/Benders cuts if infeasible.",
    "file": "BonOaFeasChecker",
    "library": "Bonmin",
    "layer": "layer-3",
    "header": "src/Algorithms/OaGenerators/BonOaFeasChecker.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "BonOaDecBase": {
    "brief": "Base class for Outer Approximation (OA) decomposition algorithms\n\nImplements the foundation for OA-based MINLP algorithms. OA iterates between\nsolving MILP subproblems and NLP subproblems, generating linear outer\napproximations of the nonlinear constraints.\n\n**OA algorithm outline:**\n1. Solve MILP relaxation \u2192 get integer solution x*\n2. Fix integers to x*, solve NLP \u2192 get nonlinear solution y*\n3. Generate linearization cuts at y* (gradient-based)\n4. Add cuts to MILP, repeat until convergence\n\n**Key components:**\n- solverManip: RAII helper to save/restore solver state\n- performOa(): Virtual method implementing specific OA variant\n- post_nlp_solve(): Handle NLP solution and update bounds\n\n**Parameters:**\n- global_: Add cuts globally (valid at all nodes)\n- addOnlyViolated_: Only add cuts violated by current solution\n- maxLocalSearch_: Limit on local search iterations",
    "file": "BonOaDecBase",
    "library": "Bonmin",
    "layer": "layer-3",
    "header": "src/Algorithms/OaGenerators/BonOaDecBase.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "BonOACutGenerator2": {
    "brief": "Classical Outer Approximation cut generator for MINLP\n\nImplements the standard OA algorithm of Duran & Grossmann (1986) for convex\nMINLP. Generates linearization cuts by Taylor expansion of nonlinear\nconstraints at NLP solutions.",
    "file": "BonOACutGenerator2",
    "library": "Bonmin",
    "layer": "layer-3",
    "header": "src/Algorithms/OaGenerators/BonOACutGenerator2.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "BonAmplSetup": {
    "brief": "AMPL-specific Bonmin setup and initialization\n\nExtends BonminSetup to initialize from AMPL command-line arguments\nand .nl files. Handles reading options and model from AMPL.\n\n**Initialization methods:**\n- initialize(argv): Read from command line and files\n- initialize(argv, opt_content, nl_content): Read from strings (for Bcp)\n- fillOsiInterface(): Initialize existing interface from strings",
    "file": "BonAmplSetup",
    "library": "Bonmin",
    "layer": "layer-3",
    "header": "src/Algorithms/Ampl/BonAmplSetup.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "BonOuterApprox": {
    "brief": "Concrete outer approximation extractor for MINLP\n\nBuilds linear outer approximations of nonlinear constraints by\nlinearizing at a given point (typically NLP solution).",
    "file": "BonOuterApprox",
    "library": "Bonmin",
    "layer": "layer-3",
    "header": "src/Algorithms/QuadCuts/BonOuterApprox.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "BonLinearCutsGenerator": {
    "brief": "Composite cut generator managing multiple linear cut generators\nCopyright (C) International Business Machines Corporation 2007.\nAll Rights Reserved.\nThis code is published under the Eclipse Public License.",
    "file": "BonLinearCutsGenerator",
    "library": "Bonmin",
    "layer": "layer-3",
    "header": "src/Algorithms/QuadCuts/BonLinearCutsGenerator.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "BonQuadRow": {
    "brief": "Quadratic row storage for NLP solver interface\nCopyright (C) International Business Machines Corporation 2007.\nAll Rights Reserved.\nThis code is published under the Eclipse Public License.\n\nQuadRow: Stores quadratic constraint l < c + ax + x'Qx < u with\nefficient gradient and Hessian evaluation. Provides methods for\nNLP solver interface: eval_f, eval_grad, eval_hessian.\n\nCan be initialized from QuadCut or linear OsiRowCut.\n\nAuthors: Pierre Bonami, IBM\nDate: October 6, 2007",
    "file": "BonQuadRow",
    "library": "Bonmin",
    "layer": "layer-3",
    "header": "src/Algorithms/QuadCuts/BonQuadRow.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "BonQuadCut": {
    "brief": "Quadratic cutting plane for MINLP\nCopyright (C) International Business Machines Corporation 2007.\nAll Rights Reserved.\nThis code is published under the Eclipse Public License.\n\nQuadCut: Extends OsiRowCut to include quadratic term x'Qx.\nStores c + ax + x'Qx with upper/lower storage modes for Q.\n\nCuts: Collection class extending OsiCuts to manage QuadCut objects\nalongside standard linear cuts.\n\nAuthors: Pierre Bonami, IBM\nDate: October 6, 2007",
    "file": "BonQuadCut",
    "library": "Bonmin",
    "layer": "layer-3",
    "header": "src/Algorithms/QuadCuts/BonQuadCut.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "BonTMINLPLinObj": {
    "brief": "TMINLP adapter that linearizes the objective function\nCopyright (C) International Business Machines Corporation 2007.\nAll Rights Reserved.\nThis code is published under the Eclipse Public License.\n\nTMINLPLinObj: Transforms a TMINLP by moving the objective into a\nconstraint, adding epigraph variable \u03b7. Converts min f(x) to\nmin \u03b7 s.t. f(x) - \u03b7 \u2264 0. Useful for algorithms requiring linear\nobjectives (e.g., some OA variants).\n\nAuthors: Pierre Bonami, IBM\nDate: August 16, 2007",
    "file": "BonTMINLPLinObj",
    "library": "Bonmin",
    "layer": "layer-3",
    "header": "src/Algorithms/QuadCuts/BonTMINLPLinObj.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "BonTMatrix": {
    "brief": "Sparse triangular matrix storage for quadratic forms\nCopyright (C) International Business Machines Corporation 2007.\nAll Rights Reserved.\nThis code is published under the Eclipse Public License.\n\nTMat: Sparse matrix storage in triplet format (iRow, jCol, value).\nProvides ordering by rows/columns, duplicate removal, and conversion\nto upper triangular form for quadratic forms x'Qx.\n\nUsed for efficient gradient and Hessian computation in QuadRow.\n\nAuthors: Pierre Bonami, IBM\nDate: October 6, 2007",
    "file": "BonTMatrix",
    "library": "Bonmin",
    "layer": "layer-3",
    "header": "src/Algorithms/QuadCuts/BonTMatrix.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "BonArraysHelpers": {
    "brief": "Array resize and copy utilities for Bonmin\nCopyright (C) International Business Machines Corporation 2007.\nAll Rights Reserved.\nThis code is published under the Eclipse Public License.\n\nTemplate functions for resizing arrays while preserving content:\n- resizeAndCopyArray: Resize and copy up to min(old,new) elements\n- resizeAndCopyArray with capacity: Only reallocate if needed\n\nAuthors: Pierre Bonami, IBM\nDate: October 6, 2007",
    "file": "BonArraysHelpers",
    "library": "Bonmin",
    "layer": "layer-3",
    "header": "src/Algorithms/QuadCuts/BonArraysHelpers.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "BonTMINLP2Quad": {
    "brief": "TMINLP2TNLP extension supporting quadratic cuts\nCopyright (C) International Business Machines Corporation 2007.\nAll Rights Reserved.\nThis code is published under the Eclipse Public License.\n\nTMINLP2TNLPQuadCuts: Extends TMINLP2TNLP to handle quadratic cuts\nin the NLP subproblem. Manages adding/removing cuts, updating\nJacobian and Hessian structures, and evaluating cut contributions.\n\nSupports both linear (OsiRowCut) and quadratic (QuadCut) cuts.\n\nAuthors: Pierre Bonami, IBM\nDate: October 6, 2007",
    "file": "BonTMINLP2Quad",
    "library": "Bonmin",
    "layer": "layer-3",
    "header": "src/Algorithms/QuadCuts/BonTMINLP2Quad.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "BonNWayObject": {
    "brief": "Bonmin N-way branching object\n\nN-way branching object for robot planning applications.\nCreates multi-way branches instead of binary left/right.",
    "file": "BonNWayObject",
    "library": "Bonmin",
    "layer": "layer-3",
    "header": "experimental/RobotBonmin/BonNWayObject.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "RobotSetup": {
    "brief": "Bonmin robot planning setup\n\nConfiguration for robot path planning MINLP application.\nSets up Bonmin solver for robotics optimization problems.",
    "file": "RobotSetup",
    "library": "Bonmin",
    "layer": "layer-3",
    "header": "experimental/RobotBonmin/RobotSetup.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "BonNWayChoose": {
    "brief": "Bonmin N-way branching choice\n\nN-way branching variable selection for robot path planning.\nExperimental: selects among multiple branching candidates.",
    "file": "BonNWayChoose",
    "library": "Bonmin",
    "layer": "layer-3",
    "header": "experimental/RobotBonmin/BonNWayChoose.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "BB_cut": {
    "brief": "Bonmin BCP cutting plane interface\n\nCutting plane interface for Bonmin integrated with BCP framework.\nExperimental: combines branch-cut-price with MINLP solving.",
    "file": "BB_cut",
    "library": "Bonmin",
    "layer": "layer-3",
    "header": "experimental/Bcp/BB_cut.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "BM": {
    "brief": "Bonmin BCP main interface\n\nMain interface for experimental Bonmin-BCP integration.\nCombines branch-cut-price parallel framework with MINLP.",
    "file": "BM",
    "library": "Bonmin",
    "layer": "layer-3",
    "header": "experimental/Bcp/BM.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "SepaHeuristicInnerApproximation": {
    "brief": "Separable MINLP inner approximation\n\nInner approximation heuristic for separable MINLP problems.\nExploits problem structure for better approximations.",
    "file": "SepaHeuristicInnerApproximation",
    "library": "Bonmin",
    "layer": "layer-3",
    "header": "experimental/Separable/SepaHeuristicInnerApproximation.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "BonHeuristicInnerApproximation": {
    "brief": "Bonmin inner approximation heuristic for MINLP\n\nPrimal heuristic using inner approximation of feasible region.\nGenerates feasible MINLP solutions from LP relaxations.",
    "file": "BonHeuristicInnerApproximation",
    "library": "Bonmin",
    "layer": "layer-3",
    "header": "experimental/Separable/BonHeuristicInnerApproximation.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "SepaTMINLP2OsiLP": {
    "brief": "Separable MINLP to LP conversion\n\nConverts separable TMINLP to Osi LP relaxation.\nCreates piecewise linear approximations for separable functions.",
    "file": "SepaTMINLP2OsiLP",
    "library": "Bonmin",
    "layer": "layer-3",
    "header": "experimental/Separable/SepaTMINLP2OsiLP.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "SepaSetup": {
    "brief": "Separable MINLP setup\n\nConfiguration for separable MINLP solver variant.\nSpecialized setup exploiting separability in objective/constraints.",
    "file": "SepaSetup",
    "library": "Bonmin",
    "layer": "layer-3",
    "header": "experimental/Separable/SepaSetup.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "BonOuterDescription": {
    "brief": "Bonmin outer approximation description for convex MINLP\n\nOuter approximation (OA) cut management for MINLP.\nLinearization-based approach for convex MINLP.",
    "file": "BonOuterDescription",
    "library": "Bonmin",
    "layer": "layer-3",
    "header": "experimental/Separable/BonOuterDescription.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "AlpsKnowledgeBrokerMPI": {
    "brief": "MPI-based parallel implementation of ALPS knowledge broker\n\nAlpsKnowledgeBrokerMPI provides scalable parallel tree search using MPI.\nImplements hierarchical Master-Hub-Worker architecture.\n\n**Process hierarchy:**\n- Master (rank 0): Inter-cluster load balancing, termination detection\n- Hubs: Manage worker clusters, intra-cluster load balancing\n- Workers: Process subtrees, report status to hub\n\n**Core methods per process type:**\n- masterMain(): Balance hubs, check termination\n- hubMain(): Balance workers, report to master\n- workerMain(): Explore subtrees, request work\n\n**Load balancing:**\n- Inter-cluster: Master moves work between hubs\n- Intra-cluster: Hub moves work between workers\n- Work donation: Split subtrees when requested\n\n**Static initialization schemes:**\n- Root initialization: Master generates nodes, distributes\n- Spiral: Distribute initial work in spiral pattern\n\n**MPI communicators:**\n- MPI_COMM_WORLD: All processes\n- clusterComm_: Hub and its workers\n- hubComm_: Master and all hubs",
    "file": "AlpsKnowledgeBrokerMPI",
    "library": "CHiPPS-ALPS",
    "layer": "layer-3",
    "header": "src/AlpsKnowledgeBrokerMPI.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "AlpsParameterBase": {
    "brief": "Generic parameter management infrastructure for ALPS\n\nBase classes for defining and parsing typed parameter sets.\nDerived from BCP_parameters.hpp design.\n\n**AlpsParameterT enum:**\n- AlpsBoolPar, AlpsIntPar, AlpsDoublePar, AlpsStringPar\n- AlpsStringArrayPar: Multiple values per key\n\n**AlpsParameter class:**\nIdentifies a single parameter by type and index within type.\n\n**AlpsParameterSet class:**\nContainer for typed parameter arrays with file parsing.\nSubclasses must implement:\n- createKeywordList(): Define keyword\u2192parameter mappings\n- setDefaultEntries(): Set default values\n\n**Reading parameters:**\n- readFromFile(): Parse parameter file\n- readFromStream(): Parse from istream\n- readFromArglist(): Parse command-line args",
    "file": "AlpsParameterBase",
    "library": "CHiPPS-ALPS",
    "layer": "layer-3",
    "header": "src/AlpsParameterBase.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "Alps": {
    "brief": "Core definitions for ALPS parallel tree search framework\n\nCentral header defining enumerations, constants, and types for the\nAbstract Library for Parallel Search (ALPS).\n\n**Core enumerations:**\n- AlpsNodeStatus: Node states (Candidate, Evaluated, Pregnant, Branched, Fathomed)\n- AlpsSearchType: Search strategies (BestFirst, BreadthFirst, DepthFirst, Hybrid)\n- AlpsKnowledgeType: Knowledge categories (Model, Node, Solution, SubTree)\n- AlpsExitStatus: Termination status (Optimal, TimeLimit, NodeLimit, etc.)\n- AlpsPhase: Execution phase (Rampup, Search, Rampdown)\n\n**Key constants:**\n- ALPS_OBJ_MAX, ALPS_BND_MAX: Numerical bounds\n- ALPS_ZERO, ALPS_GEN_TOL: Numerical tolerances\n\n**Design philosophy:**\n- Subtree is the basic unit of work in parallel execution\n- Workers process subtrees autonomously\n- Hub brokers coordinate work distribution",
    "file": "Alps",
    "library": "CHiPPS-ALPS",
    "layer": "layer-3",
    "header": "src/Alps.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "AlpsKnowledgePool": {
    "brief": "Abstract base class for knowledge storage pools\n\nAlpsKnowledgePool defines the API for all pool types in ALPS.\nKnowledge is stored with associated priority values for ordering.\n\n**Pool types (AlpsKnowledgePoolType):**\n- NodePool: Stores tree nodes awaiting processing\n- SolutionPool: Stores feasible solutions found\n- SubTreePool: Stores subtrees for parallel distribution\n\n**Core API:**\n- addKnowledge(kl, priority): Add with ordering priority\n- getKnowledge(): Peek at highest-priority item\n- popKnowledge(): Remove highest-priority item\n- getBestKnowledge(): Get best quality item\n- hasKnowledge(): Check if pool is non-empty",
    "file": "AlpsKnowledgePool",
    "library": "CHiPPS-ALPS",
    "layer": "layer-3",
    "header": "src/AlpsKnowledgePool.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "AlpsModel": {
    "brief": "Abstract base class for user problem data in ALPS tree search\n\nAlpsModel holds problem-specific data (constraints, objectives, variables).\nUsers inherit this class and implement virtual methods for their application.\n\n**Key virtual methods to implement:**\n- readInstance(): Read problem from file (master process only)\n- setupSelf(): Initialize model after data loaded/received\n- preprocess(): Preprocessing before search\n- createRoot(): Create the root tree node\n- encode()/decodeToSelf(): Serialize for parallel distribution\n\n**Parallel execution flow:**\n1. Master: readInstance() \u2192 setupSelf() \u2192 preprocess() \u2192 createRoot()\n2. Master: encode() model and send to workers\n3. Workers: decodeToSelf() \u2192 setupSelf() \u2192 begin processing nodes\n4. All: postprocess() after search completes",
    "file": "AlpsModel",
    "library": "CHiPPS-ALPS",
    "layer": "layer-3",
    "header": "src/AlpsModel.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "AlpsEncoded": {
    "brief": "Serialization buffer for ALPS knowledge objects\n\nAlpsEncoded is the binary buffer for packing/unpacking AlpsKnowledge\nobjects for network transmission in parallel search.\n\n**Buffer structure:**\n- type_: Integer identifying the knowledge type\n- size_: Current data size in bytes\n- representation_: Raw byte buffer\n- pos_: Current read position\n\n**Template methods for serialization:**\n- writeRep(T): Write single value\n- readRep(T): Read single value\n- writeRep(T*, len): Write array with length prefix\n- readRep(T*, len): Read array\n- writeRep/readRep for std::string, std::vector\n\n**Memory management:**\n- Default: 16KB initial allocation\n- make_fit(): Grows buffer as needed (4x growth)\n- clear(): Reset buffer to empty state\n\nBased on BCP_buffer and CoinEncoded designs.",
    "file": "AlpsEncoded",
    "library": "CHiPPS-ALPS",
    "layer": "layer-3",
    "header": "src/AlpsEncoded.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "AlpsKnowledgeBrokerSerial": {
    "brief": "Serial (single-process) implementation of ALPS knowledge broker\n\nAlpsKnowledgeBrokerSerial provides single-threaded tree search.\nUse this for debugging or when parallel execution is not needed.\n\n**Usage:**\n@code\nMyModel model;\nAlpsKnowledgeBrokerSerial broker(argc, argv, model);\nbroker.search(&model);\nbroker.printBestSolution();\n@endcode\n\n**Key methods:**\n- initializeSearch(): Read parameters and problem data\n- rootSearch(): Execute tree search from root\n- searchLog(): Print search statistics\n- printBestSolution(): Output best solution found\n\n**Differences from MPI version:**\n- Single subtree pool (no distribution)\n- No message passing or load balancing\n- All phases (rampup/search/rampdown) in one process",
    "file": "AlpsKnowledgeBrokerSerial",
    "library": "CHiPPS-ALPS",
    "layer": "layer-3",
    "header": "src/AlpsKnowledgeBrokerSerial.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "AlpsTreeNode": {
    "brief": "Search tree node abstraction for ALPS parallel tree search\n\nAlpsTreeNode represents a single node in the search tree. Users inherit\nthis class to implement application-specific node processing.\n\n**Node status lifecycle (AlpsNodeStatus):**\n- Candidate: Waiting in pool for processing\n- Evaluated: Processed, waiting for branching decision\n- Pregnant: Ready to branch, has child descriptions\n- Branched: Children created and added to pool\n- Fathomed: Pruned (by bound, infeasibility, or solution)\n\n**Key virtual methods:**\n- process(): Perform bounding operation (e.g., LP solve)\n- branch(): Create child nodes from pregnant node\n- createNewTreeNode(): Factory for child node creation\n\n**Node data:**\n- quality_: Node quality for selection (lower = better)\n- solEstimate_: Estimated solution quality\n- desc_: AlpsNodeDesc holding problem-specific data\n- explicit_: 1=full description, 0=relative/diff",
    "file": "AlpsTreeNode",
    "library": "CHiPPS-ALPS",
    "layer": "layer-3",
    "header": "src/AlpsTreeNode.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "AlpsSubTree": {
    "brief": "Subtree management for ALPS parallel tree search\n\nAlpsSubTree is the basic unit of work in parallel ALPS. Workers process\nentire subtrees autonomously, enabling scalable parallelism.\n\n**Key components:**\n- root_: Root node of this subtree\n- nodePool_: Leaf nodes awaiting processing\n- diveNodePool_: Nodes for diving exploration\n- activeNode_: Currently being processed\n\n**Core operations:**\n- exploreSubTree(): Process nodes up to limits\n- exploreUnitWork(): Process bounded amount of work\n- createChildren(): Branch and add children to pool\n- splitSubTree(): Split off portion for redistribution\n- rampUp(): Generate initial nodes for parallel start\n\n**Diving strategy:**\n- diveNodePool_ holds nodes for deep exploration\n- diveDepth_ tracks current dive depth\n- Helps find feasible solutions quickly\n\n**Dead node removal:**\n- removeDeadNodes(): Recursively remove fathomed branches\n- fathomAllNodes(): Clear entire subtree",
    "file": "AlpsSubTree",
    "library": "CHiPPS-ALPS",
    "layer": "layer-3",
    "header": "src/AlpsSubTree.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "AlpsNodePool": {
    "brief": "Priority queue for tree nodes awaiting processing\n\nAlpsNodePool stores candidate nodes ordered by search strategy.\nUses AlpsPriorityQueue with AlpsSearchStrategy comparison.\n\n**Storage:**\n- candidateList_: Priority queue of AlpsTreeNode pointers\n- searchStrategy_: Comparison function for ordering\n\n**Key operations:**\n- addKnowledge(): Add node with quality as priority\n- getKnowledge()/popKnowledge(): Access/remove best node\n- setNodeSelection(): Change search strategy (re-heaps)\n- getBestNode(): Get node with best quality\n\n**Search strategies supported:**\n- BestFirst: Lowest quality value first\n- DepthFirst: Deepest node first\n- BreadthFirst: Shallowest node first\n- BestEstimate: Best estimated solution first",
    "file": "AlpsNodePool",
    "library": "CHiPPS-ALPS",
    "layer": "layer-3",
    "header": "src/AlpsNodePool.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "AlpsMessage": {
    "brief": "Log messages for ALPS search status and events\n\nDefines ALPS_Message enum for CoinMessageHandler logging.\nNOT the MPI message tags (see AlpsMessageTag.h).\n\n**Message categories:**\n- ALPS_DONATE_*: Work donation events\n- ALPS_LOADBAL_*: Load balancing status\n- ALPS_RAMPUP_*: Initial distribution phase\n- ALPS_TERM_*: Termination detection\n- ALPS_S_*: Serial-only messages\n- ALPS_T_*: Termination reasons\n\n**AlpsMessage class:**\nExtends CoinMessages with ALPS-specific message definitions.\nUsed with CoinMessageHandler for consistent logging.",
    "file": "AlpsMessage",
    "library": "CHiPPS-ALPS",
    "layer": "layer-3",
    "header": "src/AlpsMessage.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "AlpsKnowledge": {
    "brief": "Base class for all ALPS knowledge types (Model, Node, Solution, SubTree)\n\nAlpsKnowledge is the abstract base for all sharable data in parallel search.\nDerived classes must implement encode()/decode() for serialization.\n\n**Knowledge types (AlpsKnowledgeType):**\n- Model: Problem data shared at initialization\n- Node: Search tree nodes processed by workers\n- Solution: Feasible solutions found during search\n- SubTree: Collections of nodes for work distribution\n\n**Serialization for parallel execution:**\n- encode(): Pack object into AlpsEncoded buffer\n- decode(): Create new object from AlpsEncoded\n- decodeToSelf(): Unpack into existing object\n\nSimple contiguous classes can use default encode/decode.\nClasses with pointers or STL containers must override.",
    "file": "AlpsKnowledge",
    "library": "CHiPPS-ALPS",
    "layer": "layer-3",
    "header": "src/AlpsKnowledge.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "AlpsSolution": {
    "brief": "Base class for solutions found during ALPS tree search\n\nAlpsSolution is the abstract base class for feasible solutions.\nUsers inherit this class to store application-specific solution data.\n\n**Base class data:**\n- index_: Node index where solution was found\n- depth_: Tree depth where solution was found\n\n**Key virtual methods:**\n- print(): Output solution to stream\n- encode()/decodeToSelf(): Serialize for parallel sharing\n\nSolutions are stored in AlpsSolutionPool with their quality values.\nThe incumbent (best solution) is tracked and used for pruning.",
    "file": "AlpsSolution",
    "library": "CHiPPS-ALPS",
    "layer": "layer-3",
    "header": "src/AlpsSolution.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "AlpsSolutionPool": {
    "brief": "Storage for feasible solutions found during search\n\nAlpsSolutionPool stores solutions ordered by quality (priority).\nLower priority value = better solution (for minimization).\n\n**Storage:**\n- solutions_: multimap<double, AlpsSolution*> ordered by quality\n- maxNumSolutions_: Maximum solutions to retain\n\n**Key operations:**\n- addKnowledge(): Add solution, possibly discard worst if at limit\n- getBestKnowledge(): Get solution with lowest priority (best)\n- getAllKnowledges(): Get all solutions for output\n- clean(): Delete all solutions\n\n**AlpsSolutionInterface macro:**\nConvenience macro defining getNumSolutions, getBestSolution, etc.\nfor use in classes that contain a solution pool.",
    "file": "AlpsSolutionPool",
    "library": "CHiPPS-ALPS",
    "layer": "layer-3",
    "header": "src/AlpsSolutionPool.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "AlpsSubTreePool": {
    "brief": "Pool of subtrees for work distribution in parallel search\n\nAlpsSubTreePool stores subtrees for load balancing between processes.\nKey component for parallel scalability in ALPS.\n\n**Storage:**\n- subTreeList_: Priority queue of AlpsSubTree pointers\n- Ordering by subtree quality for work distribution\n\n**Key operations:**\n- addKnowledge(): Add subtree from work donation\n- getKnowledge()/popKnowledge(): Get subtree for processing\n- setComparison(): Set subtree selection strategy\n- getBestQuality(): Get quality of best subtree\n\n**Parallel use:**\n- Serial: Single subtree in pool\n- Parallel: Multiple subtrees for load balancing\n- Subtrees split/merged for work sharing",
    "file": "AlpsSubTreePool",
    "library": "CHiPPS-ALPS",
    "layer": "layer-3",
    "header": "src/AlpsSubTreePool.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "AlpsKnowledgeBroker": {
    "brief": "Central manager for parallel tree search knowledge and coordination\n\nAlpsKnowledgeBroker is the abstract base class for search coordination.\nIt manages knowledge pools, search strategy, and execution statistics.\n\n**Key responsibilities:**\n- Manage SubTreePool and SolutionPool\n- Register knowledge types for serialization\n- Track search statistics (nodes processed, branched, etc.)\n- Apply search strategy (node/tree selection)\n\n**Knowledge pool management:**\n- addKnowledge()/getKnowledge(): Store/retrieve knowledge\n- registerClass(): Register decode functions for parallel\n- decoderObject(): Get decoder for knowledge type\n\n**Search phases (AlpsPhase):**\n- Rampup: Initial node generation and distribution\n- Search: Main parallel exploration\n- Rampdown: Collect results and terminate\n\n**Implementations:**\n- AlpsKnowledgeBrokerSerial: Single-process execution\n- AlpsKnowledgeBrokerMPI: MPI-based parallel execution",
    "file": "AlpsKnowledgeBroker",
    "library": "CHiPPS-ALPS",
    "layer": "layer-3",
    "header": "src/AlpsKnowledgeBroker.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "AlpsNodeDesc": {
    "brief": "Node description holding subproblem-specific data\n\nAlpsNodeDesc holds problem data for a tree node separate from tree\nstructure data. Users inherit this class for application-specific data.\n\n**Design rationale:**\n- AlpsTreeNode: Tree structure (parent, children, status)\n- AlpsNodeDesc: Subproblem data (bounds, constraints, etc.)\n\nThis separation simplifies parallel communication: only the\ndescription needs to be encoded for node transfer.\n\n**Representation modes:**\n- Explicit: Full problem data stored\n- Relative: Differences from parent node",
    "file": "AlpsNodeDesc",
    "library": "CHiPPS-ALPS",
    "layer": "layer-3",
    "header": "src/AlpsNodeDesc.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "AlpsTime": {
    "brief": "Timer utilities for ALPS search (CPU and wall clock)\n\nProvides timing functions and AlpsTimer class for measuring execution time.\n\n**Free functions:**\n- AlpsCpuTime(): Alias for CoinCpuTime()\n- AlpsGetTimeOfDay(): Wall clock (MPI_Wtime if MPI, else CoinGetTimeOfDay)\n\n**AlpsTimer class:**\n- start()/stop(): Control timing interval\n- getCpuTime()/getWallClockTime(): Get elapsed time\n- getTime(): Returns CPU or wall based on clockType_\n- reachCpuLimit()/reachWallLimit(): Check time limits\n- setLimit(): Set time limit for checks\n\n**Clock types (AlpsClockType):**\n- AlpsClockTypeCpu: Process CPU time\n- AlpsClockTypeWallClock: Real elapsed time (default)",
    "file": "AlpsTime",
    "library": "CHiPPS-ALPS",
    "layer": "layer-3",
    "header": "src/AlpsTime.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "AlpsParams": {
    "brief": "Parameter set for ALPS tree search configuration\n\nAlpsParams extends AlpsParameterSet with ALPS-specific parameters.\nParameters control search strategy, limits, load balancing, and logging.\n\n**Boolean parameters (boolParams):**\n- deleteDeadNode: Remove fathomed nodes (default: true)\n- interClusterBalance: Master balances hubs (default: true)\n- intraClusterBalance: Hub balances workers (default: true)\n\n**Integer parameters (intParams):**\n- nodeLimit: Max nodes to process (default: INT_MAX)\n- solLimit: Max solutions to store (default: INT_MAX)\n- searchStrategy: 0=best, 1=estimate, 2=BFS, 3=DFS, 4=hybrid\n- msgLevel: Output verbosity (0=none, 1=summary, 2=moderate, 3=verbose)\n- hubNum: Number of hub processes\n- unitWorkNodes: Nodes per work unit\n\n**Double parameters (dblParams):**\n- timeLimit: Max search time in seconds\n- tolerance: Numerical tolerance (default: 1e-6)\n- donorThreshold/receiverThreshold: Load balancing thresholds",
    "file": "AlpsParams",
    "library": "CHiPPS-ALPS",
    "layer": "layer-3",
    "header": "src/AlpsParams.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "AlpsSearchStrategyBase": {
    "brief": "Template base class for search strategy comparison functions\n\nDefines the template interface for node and subtree comparison.\nUsed in priority queues to order items for selection.\n\n**AlpsSearchStrategy<T> template:**\n- compare(x, y): Return true if y preferred over x\n- operator(): Calls compare() for STL compatibility\n- weight_: Optional parameter for tuning\n- type_: Strategy identifier (BestFirst, DFS, etc.)\n\n**Virtual methods for advanced strategies:**\n- selectNextNode(): Custom node selection logic\n- createNewNodes(): Custom branching logic\n\n**AlpsCompare<T> wrapper:**\nAdapter holding strategy pointer for use with std::priority_queue.\nUsed in AlpsPriorityQueue.",
    "file": "AlpsSearchStrategyBase",
    "library": "CHiPPS-ALPS",
    "layer": "layer-3",
    "header": "src/AlpsSearchStrategyBase.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "AlpsSearchStrategy": {
    "brief": "Node and subtree selection strategies for ALPS tree search\n\nDefines comparison classes for selecting which node or subtree to explore next.\ncompare(x,y) returns true if y should be processed before x.\n\n**Subtree selection (AlpsTreeSelection):**\n- AlpsTreeSelectionBest: Best quality subtree first\n- AlpsTreeSelectionBreadth: Shallowest root first\n- AlpsTreeSelectionDepth: Deepest root first\n- AlpsTreeSelectionEstimate: Best estimated solution first\n\n**Node selection (AlpsNodeSelection):**\n- AlpsNodeSelectionBest: Best bound first (minimize dual gap)\n- AlpsNodeSelectionBreadth: BFS (shallowest first)\n- AlpsNodeSelectionDepth: DFS (deepest first, finds solutions fast)\n- AlpsNodeSelectionEstimate: Best estimated solution first\n- AlpsNodeSelectionHybrid: Combination strategy\n\n**Hybrid strategy:**\nCombines best-first selection with diving for solution finding.\nselectNextNode() and createNewNodes() can be overridden.",
    "file": "AlpsSearchStrategy",
    "library": "CHiPPS-ALPS",
    "layer": "layer-3",
    "header": "src/AlpsSearchStrategy.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "BlisHeurRound": {
    "brief": "Simple rounding heuristic for MILP\n\nAttempts to find an integer-feasible solution by rounding\nfractional variables from the LP solution.\n\n**Algorithm:**\n1. Start with LP relaxation solution\n2. Round each integer variable to nearest integer\n3. Check if resulting solution is feasible\n4. If not, try to fix infeasibilities\n\n**Matrix storage:**\nMaintains both column-major (matrix_) and row-major (matrixByRow_)\nrepresentations for efficient access during rounding.\n\n**seed_:** Random seed for tie-breaking decisions.",
    "file": "BlisHeurRound",
    "library": "CHiPPS-BLIS",
    "layer": "layer-3",
    "header": "src/BlisHeurRound.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "BlisBranchStrategyPseudo": {
    "brief": "Pseudo-cost branching strategy based on historical LP degradation\n\nPseudo-cost branching uses learned estimates of objective degradation\nto select branching variables without solving child LPs.\n\n**Pseudo-cost definition:**\nFor variable x\u2c7c with fractional value f\u2c7c = x\u2c7c* - floor(x\u2c7c*):\n- \u03c8\u2c7c\u207b = average (\u0394Obj / f\u2c7c) over down branches\n- \u03c8\u2c7c\u207a = average (\u0394Obj / (1-f\u2c7c)) over up branches\n\n**Algorithm:**\n1. For each fractional integer variable x\u2c7c with value x\u2c7c*:\n   - Estimate down degradation: \u0394\u207b = \u03c8\u2c7c\u207b \u00b7 f\u2c7c\n   - Estimate up degradation: \u0394\u207a = \u03c8\u2c7c\u207a \u00b7 (1-f\u2c7c)\n   - Score = \u03bc\u00b7min(\u0394\u207b, \u0394\u207a) + (1-\u03bc)\u00b7max(\u0394\u207b, \u0394\u207a)\n2. Select variable with highest score\n\n**Initialization:**\nBefore enough observations, uses default pseudo-costs or\nfalls back to other criteria (objective coefficient, etc.)\n\n**Complexity:** O(n) where n = number of integer variables\nMuch faster than strong branching but less accurate.",
    "file": "BlisBranchStrategyPseudo",
    "library": "CHiPPS-BLIS",
    "layer": "layer-3",
    "header": "src/BlisBranchStrategyPseudo.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "BlisBranchStrategyRel": {
    "brief": "Reliability branching strategy (strong + pseudo-cost hybrid)\n\nReliability branching combines the accuracy of strong branching with\nthe efficiency of pseudo-costs. It uses strong branching until\npseudo-cost estimates become \"reliable\" (observed enough times).\n\n**Algorithm:**\n1. For each fractional integer variable x\u2c7c:\n   - If pseudo-costs for x\u2c7c are reliable (count \u2265 relibility_):\n     Use pseudo-cost estimate for score\n   - Else:\n     Perform strong branching (solve child LPs)\n     Update pseudo-costs with observed degradation\n2. Select variable with highest score\n\n**relibility_ parameter:**\nNumber of observations required before trusting pseudo-costs.\nHigher values \u2192 more strong branching (accurate but slow)\nLower values \u2192 more pseudo-cost usage (fast but less accurate)\n\n**Advantages:**\n- Best of both worlds: accurate early, fast later\n- Pseudo-costs improve as search progresses\n- Default strategy in many modern MILP solvers",
    "file": "BlisBranchStrategyRel",
    "library": "CHiPPS-BLIS",
    "layer": "layer-3",
    "header": "src/BlisBranchStrategyRel.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "BlisConstraint": {
    "brief": "Constraint (cut) representation for BLIS branch-and-cut\n\nRepresents a linear constraint (row) that can be added to the LP.\nUsed for both original constraints and generated cutting planes.\n\n**Data members:**\n- size_, indices_, values_: Sparse row representation\n- Bounds inherited from BcpsConstraint (lbHard, ubHard, lbSoft, ubSoft)\n\n**Key methods:**\n- createOsiRowCut(): Convert to OsiRowCut for LP solver\n- violation(): Compute constraint violation for given LP solution\n- hashing(): Compute hash key for duplicate detection\n\n**Usage in branch-and-cut:**\n1. CglCutGenerator produces OsiRowCut objects\n2. Converted to BlisConstraint for storage in pool\n3. Applied to LP via createOsiRowCut() when needed",
    "file": "BlisConstraint",
    "library": "CHiPPS-BLIS",
    "layer": "layer-3",
    "header": "src/BlisConstraint.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "BlisMessage": {
    "brief": "Log messages for BLIS MILP solver events\n\nDefines BLIS_Message enum for CoinMessageHandler logging.\nSimilar to CoinMessages but specialized for BLIS output.\n\n**Message types:**\n- BLIS_CUTOFF_INC: Cutoff improvement\n- BLIS_CUT_STAT_*: Cut generation statistics\n- BLIS_GAP_*: Optimality gap status\n- BLIS_HEUR_*: Heuristic events and statistics\n- BLIS_ROOT_*: Root node processing info",
    "file": "BlisMessage",
    "library": "CHiPPS-BLIS",
    "layer": "layer-3",
    "header": "src/BlisMessage.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "BlisConGenerator": {
    "brief": "Interface between BLIS and CGL cut generators\n\nWraps a CglCutGenerator with configuration controlling when and how\ncutting planes are generated during branch-and-cut.\n\n**Strategy options (BlisCutStrategy):**\n- None: Cut generator disabled\n- Root: Generate cuts only at root node\n- Auto: BLIS decides based on effectiveness\n- Periodic: Generate every cutGenerationFrequency_ nodes\n\n**Trigger conditions:**\n- normal_: Call in standard cut generation loop\n- atSolution_: Call when integer solution found\n- whenInfeasible_: Call when LP becomes infeasible\n\n**Statistics tracked:**\n- numConsGenerated_/numConsUsed_: Cut effectiveness\n- time_: CPU time spent in generator\n- calls_/noConsCalls_: Call frequency tracking\n\n**Usage:**\n1. Create: BlisConGenerator(model, new CglGomory(), \"Gomory\")\n2. Register: model->addCutGenerator(generator)\n3. BLIS calls generateConstraints() based on strategy",
    "file": "BlisConGenerator",
    "library": "CHiPPS-BLIS",
    "layer": "layer-3",
    "header": "src/BlisConGenerator.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "BlisHelp": {
    "brief": "Utility functions for BLIS solver operations\n\nHelper functions for common BLIS operations including cut conversion,\nstrong branching, warm start serialization, and parallel cut detection.\n\n**Cut conversion:**\n- BlisOsiCutToConstraint(): Convert OsiRowCut to BlisConstraint\n\n**Strong branching:**\n- BlisStrongBranch(): Evaluate branching on a single variable\n  Returns degradation estimates for up/down branches\n\n**Warm start serialization:**\n- BlisEncodeWarmStart(): Pack CoinWarmStartBasis to AlpsEncoded\n- BlisDecodeWarmStart(): Unpack CoinWarmStartBasis from AlpsEncoded\n\n**Cut management:**\n- BlisHashingOsiRowCut(): Compute hash for duplicate detection\n- BlisParallelCutCut(): Check if two cuts are parallel\n- BlisParallelCutCon(): Check cut vs. constraint parallelism\n- BlisParallelConCon(): Check constraint vs. constraint parallelism",
    "file": "BlisHelp",
    "library": "CHiPPS-BLIS",
    "layer": "layer-3",
    "header": "src/BlisHelp.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "BlisBranchStrategyMaxInf": {
    "brief": "Maximum infeasibility branching strategy\n\nThe simplest branching variable selection: branch on the integer\nvariable that is furthest from being integer.\n\n**Algorithm:**\n1. For each fractional integer variable x\u2c7c with value x\u2c7c*:\n   - Compute infeasibility: inf = min(x\u2c7c* - floor(x\u2c7c*), ceil(x\u2c7c*) - x\u2c7c*)\n   - This is the distance to nearest integer\n2. Select variable with maximum infeasibility\n\n**Rationale:**\nVariables far from integrality are \"more fractional\" and branching\non them may force larger changes to the LP solution.\n\n**Trade-offs:**\n- Very fast: O(n) scan of integer variables\n- No learning or LP solves required\n- Generally produces larger search trees than pseudo-cost or strong\n- Good for initial exploration or when speed matters more than tree size",
    "file": "BlisBranchStrategyMaxInf",
    "library": "CHiPPS-BLIS",
    "layer": "layer-3",
    "header": "src/BlisBranchStrategyMaxInf.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "BlisHeuristic": {
    "brief": "Base class for primal heuristics in BLIS\n\nPrimal heuristics search for integer-feasible solutions during\nbranch-and-cut. Good solutions improve the cutoff for pruning.\n\n**Strategy options (BlisHeurStrategy):**\n- None: Heuristic disabled\n- Root: Run only at root node\n- Auto: BLIS decides based on effectiveness\n- Periodic: Run every heurCallFrequency_ nodes\n- BeforeRoot: Run before solving first LP (e.g., feasibility pump)\n\n**Key virtual method:**\n- searchSolution(): Try to find a solution improving objectiveValue\n  Returns true if solution found, fills newSolution array\n\n**Statistics tracked:**\n- numSolutions_: Solutions found by this heuristic\n- time_: CPU time spent\n- calls_/noSolsCalls_: Success rate tracking",
    "file": "BlisHeuristic",
    "library": "CHiPPS-BLIS",
    "layer": "layer-3",
    "header": "src/BlisHeuristic.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "BlisBranchObjectInt": {
    "brief": "Branching object for integer variable dichotomy\n\nRepresents a two-way branch on an integer variable.\nCreated when branching decisions are made at a tree node.\n\n**Branch structure:**\nFor variable x\u2c7c with fractional value v*:\n- Down branch: down_[0] \u2264 x\u2c7c \u2264 down_[1] = floor(v*)\n- Up branch: up_[0] = ceil(v*) \u2264 x\u2c7c \u2264 up_[1]\n\n**Direction semantics:**\n- direction_ = -1: Down branch executed first\n- direction_ = +1: Up branch executed first\n\n**Key methods:**\n- branch(): Apply bounds for current arm, advance to next\n- getDown()/getUp(): Access bound arrays\n\n**Serialization:**\nencode()/decode() for MPI transmission of branch decisions.",
    "file": "BlisBranchObjectInt",
    "library": "CHiPPS-BLIS",
    "layer": "layer-3",
    "header": "src/BlisBranchObjectInt.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "BlisBranchStrategyBilevel": {
    "brief": "Branching strategy for bilevel programming problems\n\nSpecialized branching for bilevel optimization problems where there\nis a leader (upper-level) and follower (lower-level) decision maker.\n\n**Bilevel programming:**\n- Leader optimizes over (x, y) where y solves follower's problem\n- min_x { F(x, y) : G(x, y) \u2265 0, y \u2208 argmin_y { f(x, y) : g(x, y) \u2265 0 } }\n- MILP reformulation uses complementarity or indicator constraints\n\n**Branching approach:**\nTypically branches on complementarity-related variables or\nuses specialized selection for leader vs. follower variables.",
    "file": "BlisBranchStrategyBilevel",
    "library": "CHiPPS-BLIS",
    "layer": "layer-3",
    "header": "src/BlisBranchStrategyBilevel.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "BlisModel": {
    "brief": "MILP model class extending BiCePS for branch-and-cut\n\nBlisModel is the main model class for the BLIS MILP solver.\nExtends BcpsModel with LP solver, cut generators, heuristics, and branching.\n\n**Initialization workflow:**\n1. readInstance() or importModel(): Load problem data\n2. readParameters(): Configure solver behavior\n3. setupSelf(): Initialize LP solver, objects, strategies\n4. preprocess(): Apply presolve transformations\n5. createRoot(): Create initial search tree node\n\n**LP Solver integration:**\n- origLpSolver_: User-provided OsiSolverInterface\n- presolvedLpSolver_: After presolve transformations\n- lpSolver_: Active solver (presolved or original)\n\n**Cut generation:**\n- addCutGenerator(): Register CglCutGenerator or BlisConGenerator\n- cutStrategy_: When to generate (Root, Auto, Periodic)\n- constraintPool_: Store generated cuts\n\n**Branching:**\n- branchStrategy_: BcpsBranchStrategy for variable selection\n- objects_: BcpsObject array (integer variables, SOS, etc.)\n- priority_: Branching priorities per object\n\n**Heuristics:**\n- addHeuristic(): Register BlisHeuristic instances\n- heurStrategy_: When to call (Root, Auto, Periodic, BeforeRoot)\n\n**Solution management:**\n- incumbent_: Best integer solution found\n- cutoff_: Objective bound for pruning\n- storeSolution(): Record new solutions\n\n**Parallel support:**\n- encode()/decodeToSelf(): Serialize model for MPI\n- packSharedKnowledge(): Share pseudo-costs, cuts, variables",
    "file": "BlisModel",
    "library": "CHiPPS-BLIS",
    "layer": "layer-3",
    "header": "src/BlisModel.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "BlisVariable": {
    "brief": "Variable representation for column generation in BLIS\n\nExtends BcpsVariable with sparse column representation for LP.\nUsed when variables are generated dynamically (column generation).\n\n**Data members:**\n- objCoef_: Objective coefficient for this variable\n- size_, indices_, values_: Sparse column in constraint matrix\n\n**Usage:**\nIn standard MILP solving, variables are implicit in the LP solver.\nBlisVariable is used when variables need to be:\n- Communicated between processes (parallel B&C)\n- Generated dynamically (column generation/branch-and-price)\n- Stored in variable pools for sharing",
    "file": "BlisVariable",
    "library": "CHiPPS-BLIS",
    "layer": "layer-3",
    "header": "src/BlisVariable.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "Blis": {
    "brief": "Core enumerations and constants for BLIS (BiCePS Linear Integer Solver)\n\nBLIS is a concrete implementation of the CHiPPS framework for MILP.\nHierarchy: ALPS (parallel search) \u2192 BiCePS (branch-cut-price) \u2192 BLIS (MILP).\n\n**BlisLpStatus enum:**\nLP relaxation solve outcomes (Optimal, Infeasible, IterLim, etc.)\n\n**BlisReturnStatus enum:**\nNode processing outcomes (Ok, ErrLp, Feasible, Branch, etc.)\n\n**BlisCutStrategy enum:**\n- NotSet, None: No cut generation\n- Root: Generate cuts only at root node\n- Auto: Automatic frequency selection\n- Periodic: Generate every cutGenerationFrequency_ nodes\n\n**BlisHeurStrategy enum:**\nSame as cut strategy plus BeforeRoot (e.g., feasibility pump)\n\n**BlisBranchingStrategy enum:**\n- MaxInfeasibility: Branch on most fractional variable\n- PseudoCost: Use pseudo-costs from LP degradation\n- Reliability: Pseudo-costs with strong branching fallback\n- Strong: Full strong branching (solve child LPs)\n- Bilevel: For bilevel programming problems\n\n**BlisBranchingObjectType enum:**\nInteger variables, SOS constraints, bilevel variables",
    "file": "Blis",
    "library": "CHiPPS-BLIS",
    "layer": "layer-3",
    "header": "src/Blis.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "BlisPseudo": {
    "brief": "Pseudo-cost data structure for branching variable selection\n\nTracks historical LP objective degradation when branching on a variable.\nUsed to estimate branching quality without solving child LPs.\n\n**Pseudo-cost formula:**\nFor variable x\u2c7c branched with fractional part f:\n- Up cost: \u03c8\u207a = \u0394obj\u207a / (1 - f), averaged over up branches\n- Down cost: \u03c8\u207b = \u0394obj\u207b / f, averaged over down branches\n\n**Score calculation:**\nscore_ = weight_ * min(downCost_, upCost_) + (1 - weight_) * max(...)\nDefault weight_ = 1.0 emphasizes minimum degradation.\n\n**Key members:**\n- upCost_/downCost_: Average per-unit objective change\n- upCount_/downCount_: Number of observations (for reliability)\n- weight_: Weighting in score formula [0, 1]\n\n**Usage:**\n- update(): Called after branching to incorporate new observation\n- getScore(): Returns estimated branching quality\n- Serializable via AlpsKnowledge for parallel sharing",
    "file": "BlisPseudo",
    "library": "CHiPPS-BLIS",
    "layer": "layer-3",
    "header": "src/BlisPseudo.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "BlisObjectInt": {
    "brief": "Integer variable object for branching decisions\n\nRepresents an integer-constrained variable in the MILP model.\nStores original bounds, breakeven point, and pseudo-costs.\n\n**Key attributes:**\n- columnIndex_: LP column index for this integer variable\n- originalLower_/Upper_: Bounds before any branching\n- breakEven_: Threshold for up vs. down preference (default 0.5)\n- pseudocost_: BlisPseudocost for branching decisions\n\n**Key methods:**\n- infeasibility(): Returns fractionality in [0.0, 0.5]\n- createBranchObject(): Creates BlisBranchObjectInt for branching\n- feasibleRegion(): Fixes variable to nearest integer\n- preferredNewFeasible(): Direction based on reduced cost\n\n**Pseudo-costs:**\nEach integer object maintains its own pseudo-cost history,\nenabling per-variable learning for branching decisions.",
    "file": "BlisObjectInt",
    "library": "CHiPPS-BLIS",
    "layer": "layer-3",
    "header": "src/BlisObjectInt.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "BlisBranchStrategyStrong": {
    "brief": "Strong branching strategy for MILP variable selection\n\nStrong branching is the most accurate (but expensive) branching strategy.\nFor each candidate variable, it actually solves child LP relaxations\nto measure the objective degradation.\n\n**Algorithm:**\n1. For each fractional integer variable x\u2c7c:\n   - Create down branch (x\u2c7c \u2264 floor(x\u2c7c*))\n   - Create up branch (x\u2c7c \u2265 ceil(x\u2c7c*))\n   - Solve both LPs (limited iterations)\n   - Record objective change \u0394Down, \u0394Up\n2. Score = \u03bc\u00b7min(\u0394Down, \u0394Up) + (1-\u03bc)\u00b7max(\u0394Down, \u0394Up)\n3. Select variable with highest score\n\n**BlisStrong struct:**\nStores results for one candidate: objective changes, infeasibility counts,\nsolver completion status for up/down branches.\n\n**Trade-offs:**\n- Produces smallest search trees (best variable selection)\n- Very expensive at each node (many LP solves)\n- Typically used with iteration limits per candidate LP",
    "file": "BlisBranchStrategyStrong",
    "library": "CHiPPS-BLIS",
    "layer": "layer-3",
    "header": "src/BlisBranchStrategyStrong.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "BlisParams": {
    "brief": "BLIS-specific parameter set for MILP solver configuration\n\nExtends AlpsParameterSet with parameters controlling branching,\ncut generation, heuristics, and optimality tolerances.\n\n**Parameter categories:**\n\n**chrParams (bool):**\n- cutRampUp: Generate cuts during parallel ramp-up\n- presolve: Apply presolve transformations\n- shareConstraints/Variables: Parallel knowledge sharing\n- sharePseudocostRampUp/Search: Share branching data\n\n**intParams:**\n- branchStrategy: 0=MaxInf, 1=Pseudo, 2=Reliability, 3=Strong, 4=Bilevel\n- cutStrategy, cut*Strategy: Cut generator control (-2=root, -1=auto, 0=off)\n- heurStrategy, heur*Strategy: Heuristic control\n- strongCandSize: Candidates for strong branching\n- pseudoRelibility: Observations before trusting pseudo-costs\n\n**dblParams:**\n- cutoff: Upper bound for pruning\n- cutoffInc: Cutoff increment for fathoming\n- integerTol: Tolerance for integrality\n- optimalRelGap/AbsGap: Termination gaps\n- pseudoWeight: Score formula weighting",
    "file": "BlisParams",
    "library": "CHiPPS-BLIS",
    "layer": "layer-3",
    "header": "src/BlisParams.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "BlisSolution": {
    "brief": "Integer solution representation for BLIS\n\nExtends BcpsSolution with BLIS-specific solution handling.\nStores variable values and objective for integer-feasible solutions.\n\n**Key methods:**\n- print(): Output solution, showing near-integer values as integers\n- encode()/decode(): Serialization for parallel solution sharing\n\n**Usage:**\nCreated by heuristics or when LP solution is integer-feasible.\nStored in AlpsSolutionPool, shared across processes in parallel.",
    "file": "BlisSolution",
    "library": "CHiPPS-BLIS",
    "layer": "layer-3",
    "header": "src/BlisSolution.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "BlisBranchObjectBilevel": {
    "brief": "Branching object for bilevel programming problems\n\nSpecialized branching object for bilevel optimization where\nbranching may involve multiple variables (a \"branching set\").\n\n**branchingSet_:**\nA deque of variable indices that are affected by this branch.\nUnlike standard integer branching (single variable), bilevel\nproblems may require coordinated changes to multiple variables.",
    "file": "BlisBranchObjectBilevel",
    "library": "CHiPPS-BLIS",
    "layer": "layer-3",
    "header": "src/BlisBranchObjectBilevel.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "BlisNodeDesc": {
    "brief": "Node description storing LP basis and branching info\n\nExtends BcpsNodeDesc with simplex warm start and pseudo-cost data.\nContains the state needed to reconstruct a search tree node.\n\n**Warm start data:**\n- basis_: CoinWarmStartBasis for LP hot-starting\n- Stores structural and artificial variable status (basic/nonbasic)\n\n**Branching history (for pseudo-cost updates):**\n- branchedDir_: Direction of branch that created this node (-1/+1)\n- branchedInd_: Object index that was branched on\n- branchedVal_: Value at branching point (used in pseudo-cost update)\n\n**Serialization:**\nencode()/decode() serialize basis and branching info for MPI.\nUses BlisEncodeWarmStart/BlisDecodeWarmStart helpers.",
    "file": "BlisNodeDesc",
    "library": "CHiPPS-BLIS",
    "layer": "layer-3",
    "header": "src/BlisNodeDesc.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "BlisTreeNode": {
    "brief": "Concrete branch-and-bound tree node for MILP solving\n\nBlisTreeNode extends BcpsTreeNode with LP-based bounding and cut generation.\nImplements the main node processing loop for branch-and-cut.\n\n**Node processing (process()):**\n1. installSubProblem(): Set up LP with current bounds\n2. bound(): Solve LP relaxation\n3. callHeuristics(): Search for integer solutions\n4. generateConstraints(): Add cutting planes\n5. selectBranchObject(): Choose branching variable\n6. branch(): Create child nodes\n\n**Cut generation workflow:**\n- generateConstraints(): Call registered CglCutGenerators\n- getViolatedConstraints(): Check for violated cuts\n- applyConstraints(): Add cuts to LP and re-solve\n- parallel(): Remove duplicate/parallel cuts\n\n**Bound tightening:**\n- reducedCostFix(): Fix variables using reduced costs\n\n**Node descriptions:**\n- convertToExplicit(): Full bound/cut information\n- convertToRelative(): Delta from parent (space-efficient)\n\n**Branching:**\n- selectBranchObject(): Use model's BcpsBranchStrategy\n- branch(): Create children with modified bounds",
    "file": "BlisTreeNode",
    "library": "CHiPPS-BLIS",
    "layer": "layer-3",
    "header": "src/BlisTreeNode.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "BonCouenneInterface": {
    "brief": "Couenne's interface to Bonmin/AMPL\n\nExtends Bonmin's AmplInterface to read AMPL models and build\nCouenne's symbolic problem representation with convex relaxations.\n\n**Key methods:**\n- readAmplNlFile(): Read AMPL .nl file into Couenne structures\n- extractLinearRelaxation(): Build initial LP relaxation with OA cuts\n\n**Linear relaxation extraction:**\n1. Solve continuous NLP relaxation\n2. Generate linearization cuts at NLP optimum\n3. Load cuts into OsiSolverInterface for B&B",
    "file": "BonCouenneInterface",
    "library": "Couenne",
    "layer": "layer-3",
    "header": "src/interfaces/BonCouenneInterface.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "CouenneUserInterface": {
    "brief": "Abstract base class for Couenne user interfaces\n\nDefines the interface contract for problem input sources.\nConcrete implementations read from AMPL, OSInstance, or custom formats.\n\n**Required methods (pure virtual):**\n- getCouenneProblem(): Return symbolic problem representation\n- getTMINLP(): Return Bonmin TMINLP interface for NLP solves\n\n**Optional hooks:**\n- setupJournals(): Configure output streams (default: stdout)\n- addBabPlugins(): Add cut generators, heuristics, bound tighteners\n- writeSolution(): Output final solution\n\n**Usage pattern:**\n```cpp\nCouenneAmplInterface interface(options, journalist);\nCouenneProblem* prob = interface.getCouenneProblem();\n// ... solve ...\ninterface.writeSolution(bab);\n```",
    "file": "CouenneUserInterface",
    "library": "Couenne",
    "layer": "layer-3",
    "header": "src/interfaces/CouenneUserInterface.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "CouenneTNLP": {
    "brief": "Ipopt TNLP interface for Couenne problems\n\nWraps CouenneProblem as an Ipopt::TNLP for NLP solving.\nComputes derivatives using Couenne's symbolic expression DAG.\n\n**Purpose:**\nAllows Ipopt to solve the continuous relaxation or NLP\nsubproblems arising during Couenne's spatial B&B.\n\n**Derivative computation:**\n- Gradient: Via expression differentiation (gradient_ vector)\n- Jacobian: Via ExprJac symbolic Jacobian structure\n- Hessian: Via ExprHess symbolic Hessian of Lagrangian\n\n**Key methods (Ipopt callbacks):**\n- get_nlp_info(): Returns dimensions and sparsity info\n- get_bounds_info(): Variable/constraint bounds\n- eval_f(), eval_grad_f(): Objective and gradient\n- eval_g(), eval_jac_g(): Constraints and Jacobian\n- eval_h(): Hessian of Lagrangian\n- finalize_solution(): Store optimal solution\n\n**Hessian storage:**\noptHessian_ can store the optimal Hessian for later use\n(e.g., in distance computations for Feasibility Pump).",
    "file": "CouenneTNLP",
    "library": "Couenne",
    "layer": "layer-3",
    "header": "src/interfaces/CouenneTNLP.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "CouenneMINLPInterface": {
    "brief": "OsiSolverInterface for MINLP via Couenne expressions\n\nProvides an Osi-compatible interface for solving MINLP continuous\nrelaxations using NLP solvers (Ipopt or FilterSQP). Gradients and\nJacobians are computed from the expression DAG.\n\n**Solver enum:**\n- EIpopt: Interior-point via Ipopt\n- EFilterSQP: Sequential quadratic programming\n- EAll: Use multiple solvers for robustness\n\n**Key methods:**\n- initialSolve(): Solve initial continuous relaxation\n- resolve(): Re-solve after bound changes\n- getOuterApproximation(): Generate OA cuts at current point\n- extractLinearRelaxation(): Build LP relaxation from NLP\n\n**Outer approximation support:**\n- getOuterApproximation(): Generate linearizations at solution\n- getConstraintOuterApproximation(): Single constraint OA\n- getBendersCut(): Benders decomposition cut\n- getFeasibilityOuterApproximation(): Cuts for feasibility pump\n\n**Strong branching:**\nUses StrongBranchingSolver for approximate LP-based evaluation\nduring variable selection.",
    "file": "CouenneMINLPInterface",
    "library": "Couenne",
    "layer": "layer-3",
    "header": "src/interfaces/CouenneMINLPInterface.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "CouenneDisjCuts": {
    "brief": "Disjunctive cut generator for nonconvex MINLP\n\nGenerates lift-and-project style disjunctive cuts by solving a\nCut-Generating Linear Program (CGLP) for each disjunction.",
    "file": "CouenneDisjCuts",
    "library": "Couenne",
    "layer": "layer-3",
    "header": "src/disjunctive/CouenneDisjCuts.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "CouenneAmplInterface": {
    "brief": "AMPL .nl file reader for Couenne\n\nReads optimization problems from AMPL Solver Library (ASL)\nformat and converts to Couenne's expression DAG representation.\n\n**Key methods:**\n- getCouenneProblem(): Parse .nl file \u2192 CouenneProblem\n- getTMINLP(): Wrap as Bonmin TMINLP for NLP solves\n- writeSolution(): Write .sol file back to AMPL\n\n**Internal conversion:**\n- readASLfg(): Read using ASL fg (function/gradient) reader\n- readnl(): Alternative .nl parsing\n- nl2e(): Convert ASL expr* to Couenne expression*\n\n**ASL integration:**\nUses the AMPL Solver Library (ASL) C structures to parse\nthe binary .nl format. The nl2e() method recursively converts\nASL expression trees to Couenne expression nodes.",
    "file": "CouenneAmplInterface",
    "library": "Couenne",
    "layer": "layer-3",
    "header": "src/readnl/CouenneAmplInterface.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "CouExpr": {
    "brief": "Expression container with operator overloading for algebraic construction\n\nProvides a user-friendly wrapper around the expression DAG with\noverloaded operators for building mathematical expressions in\nnatural algebraic notation.\n\n**CouExpr container:**\n- Wraps an expression* with value semantics (cloning on copy)\n- Allows algebraic expression construction: e1 + e2, sin(e), etc.\n\n**Supported operations:**\n- Arithmetic: +, -, *, /, %, ^ (power)\n- Trigonometric: sin, cos\n- Other: log, exp\n\n**Operand types:**\n- CouExpr & CouExpr \u2192 CouExpr\n- CouNumber & CouExpr \u2192 CouExpr\n- CouExpr & CouNumber \u2192 CouExpr\n\n**Example:**\n```cpp\nCouExpr x(exprVar), y(exprVar);\nCouExpr f = sin(x) + x*y + exp(y);\nexpression* e = f.Expression();\n```",
    "file": "CouExpr",
    "library": "Couenne",
    "layer": "layer-3",
    "header": "src/expression/CouExpr.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "CouenneDomain": {
    "brief": "Point and bounding box with save/restore stack\n\nManages the current solution point and variable bounds during\nexpression evaluation and bound tightening. Provides LIFO\nsave/restore functionality for backtracking.\n\n**DomainPoint:**\n- x_[]: Current variable values\n- lb_[]: Lower bounds\n- ub_[]: Upper bounds\n- copied_: True if data is owned (must free on destruction)\n- isNlp_: True if point came from NLP solver (feasible)\n\n**Domain:**\n- point_: Current active point\n- domStack_: Stack of saved points for restore\n\n**push()/pop() pattern:**\n```cpp\ndomain.push(newPoint);  // Save current, use new\n// ... work with new bounds ...\ndomain.pop();           // Restore previous\n```\n\n**Usage:**\nDuring B&B, each node has different bounds. push() saves the\nparent's bounds before processing a child; pop() restores them\nwhen backtracking.",
    "file": "CouenneDomain",
    "library": "Couenne",
    "layer": "layer-3",
    "header": "src/expression/CouenneDomain.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "CouenneExpression": {
    "brief": "Base class for expression DAG nodes in Couenne\n\nDefines the abstract interface for all expression types (constants,\nvariables, operators). Each expression can evaluate itself, generate\nconvex relaxation cuts, and participate in bound propagation.\n\n**Expression hierarchy:**\n- exprConst: Constant values\n- exprVar/exprAux: Original and auxiliary variables\n- exprOp: Operators (unary, binary, n-ary)\n- exprCopy/exprClone: References to other expressions\n\n**Key virtual methods:**\n- operator()(): Evaluate expression at current point\n- generateCuts(): Generate OA-style convexification cuts for w = f(x)\n- impliedBound(): Backward bound propagation (w bounds \u2192 x bounds)\n- getBounds(): Forward bound propagation (x bounds \u2192 w bounds)\n- standardize(): Convert to auxiliary variable form\n\n**auxSign enum:**\nDefines how auxiliary w relates to its expression f(x):\n- AUX_LEQ: w <= f(x) (under-estimator)\n- AUX_EQ: w = f(x) (equality definition)\n- AUX_GEQ: w >= f(x) (over-estimator)",
    "file": "CouenneExpression",
    "library": "Couenne",
    "layer": "layer-3",
    "header": "src/expression/CouenneExpression.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "CouenneExprBound": {
    "brief": "Expressions representing variable bounds (l_i, u_i)\n\nExpression nodes that evaluate to the current lower/upper bound\nof a variable. Used in parametric convexification to express\nbound-dependent cuts.\n\n**exprLowerBound:**\n- Evaluates to domain_->lb(varIndex_)\n- Prints as \"l_i\" where i is variable index\n- Derivative is 0 (bounds are parameters, not variables)\n\n**exprUpperBound:**\n- Evaluates to domain_->ub(varIndex_)\n- Prints as \"u_i\" where i is variable index\n- Derivative is 0\n\n**Usage example:**\nFor convexification cut on f(x) with x \u2208 [l, u]:\nThe secant line passes through (l, f(l)) and (u, f(u)).\nThe cut coefficients depend on l and u, represented\nas exprLowerBound and exprUpperBound.\n\n**Note:**\nThese behave like constants for differentiation purposes\nbut their values change during B&B as bounds tighten.",
    "file": "CouenneExprBound",
    "library": "Couenne",
    "layer": "layer-3",
    "header": "src/expression/CouenneExprBound.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "CouenneExprVar": {
    "brief": "Variable expression class for original decision variables\n\nRepresents decision variables in the expression DAG. All problem\nvariables (original and auxiliary) derive from this class.\n\n**Key attributes:**\n- varIndex_: Index in the problem's variable vector\n- domain_: Pointer to current point and bounds\n\n**Methods:**\n- operator()(): Return current variable value from domain\n- lb()/ub(): Access current lower/upper bounds\n- differentiate(): Returns 1 if differentiating w.r.t. this variable\n- impliedBound(): Propagate bounds from auxiliary to original variables\n\n**Linearity:**\nOriginal variables have Linearity() = LINEAR (affine in themselves).",
    "file": "CouenneExprVar",
    "library": "Couenne",
    "layer": "layer-3",
    "header": "src/expression/CouenneExprVar.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "CouennePrecisions": {
    "brief": "Numerical tolerances and constants for Couenne\n\nCentral definition of numerical tolerances used throughout\nCouenne for comparisons, cut generation, and bound handling.\n\n**General tolerances:**\n- COUENNE_EPS (1e-7): General numerical tolerance\n- COUENNE_BOUND_PREC (1e-5): Looser tolerance for bounds\n- COUENNE_EPS_INT (1e-9): Integrality check tolerance\n- COUENNE_EPS_SIMPL (1e-20): Simplification zero threshold\n\n**Infinity and bounds:**\n- COUENNE_INFINITY (1e50): Represents \u00b1\u221e in bounds\n- MAX_BOUND (1e45): Practical bound maximum\n- Couenne_large_bound (9.999e12): LP unbounded threshold\n\n**Cut coefficients:**\n- COU_MAX_COEFF (1e9): Maximum cut coefficient\n- COU_MIN_COEFF (1e-9): Minimum cut coefficient\n(Ensures numerical stability in LP solver)\n\n**Utility macros:**\n- COUENNE_round(x): Round to nearest integer\n- COUENNE_sign(x): Return +1 or -1",
    "file": "CouennePrecisions",
    "library": "Couenne",
    "layer": "layer-3",
    "header": "src/expression/CouennePrecisions.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "CouenneExprConst": {
    "brief": "Constant expression node\n\nRepresents a constant value in the expression DAG.\nLeaf node with fixed value that never changes.\n\n**Properties:**\n- Type: CONST (leaf node)\n- Linearity: ZERO if |value| < \u03b5, else CONSTANT\n- Bounds: [value, value] (trivial)\n- Differentiation: Always returns 0\n- Rank: 0 (lowest priority for branching)\n\n**isInteger():**\nChecks if the constant value is an integer (within tolerance).\nUsed for determining integrality of expressions.\n\n**Usage:**\n- Constant terms in objective/constraints\n- Right-hand sides of constraints\n- Exponents in power expressions",
    "file": "CouenneExprConst",
    "library": "Couenne",
    "layer": "layer-3",
    "header": "src/expression/CouenneExprConst.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "CouenneExprIVar": {
    "brief": "Integer variable expression node\n\nRepresents an integer-restricted decision variable in the\nexpression DAG. Inherits from exprVar with additional\nintegrality information.\n\n**Integer markers:**\n- isInteger(): Always returns true (variable is integer-valued)\n- isDefinedInteger(): Always returns true (defined as integer)\n\n**Printed notation:**\nPrints as \"y_i\" where i is the variable index, distinguishing\nfrom continuous variables which print as \"x_i\".\n\n**Usage:**\nInteger variables require special handling in:\n- Branch-and-bound (must branch to enforce integrality)\n- Feasibility checking (must satisfy x \u2208 \u2124)\n- Solution rounding in heuristics",
    "file": "CouenneExprIVar",
    "library": "Couenne",
    "layer": "layer-3",
    "header": "src/expression/CouenneExprIVar.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "CouenneExprStore": {
    "brief": "Expression that returns previously stored value\n\nReturns the Value() of the pointed-to expression rather than\nre-evaluating it. Used for efficiency when an expression has\nalready been evaluated and the value cached.\n\n**Key difference from exprCopy/exprClone:**\n- exprCopy: Calls (*copy_)() to evaluate\n- exprClone: Calls (*copy_)() to evaluate\n- exprStore: Calls copy_->Value() to get cached value\n\n**Usage pattern:**\nWhen an expression tree is evaluated top-down, intermediate\nresults can be stored in value_ fields. exprStore allows\nretrieval of these stored values without re-computation.\n\n**Destructor:**\nLike exprClone, sets copy_ = NULL to prevent deletion.\nDoes NOT own the pointed-to expression.",
    "file": "CouenneExprStore",
    "library": "Couenne",
    "layer": "layer-3",
    "header": "src/expression/CouenneExprStore.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "CouenneTypes": {
    "brief": "Core type definitions and enumerations for Couenne\n\nCentral header defining enums, types, and small classes used\nthroughout the Couenne codebase.\n\n**Key enumerations:**\n- nodeType: CONST, VAR, UNARY, N_ARY, COPY, AUX, EMPTY\n- linearity_type: ZERO, CONSTANT, LINEAR, QUADRATIC, NONLINEAR\n- convexity: CONVEX, CONCAVE, AFFINE, NONCONVEX\n- expr_type: Codes for each expression class (COU_EXPRSUM, etc.)\n- monotonicity: INCREAS, DECREAS, NONMONOTONE\n\n**t_chg_bounds class:**\nTracks whether lower/upper bounds have been:\n- UNCHANGED: No modification\n- CHANGED: Modified during bound tightening\n- EXACT: Bound is tight (equality holds)\n\n**CouNumber:**\ntypedef double CouNumber - the main floating-point type.\n\n**unary_function:**\nFunction pointer type for unary operators: CouNumber \u2192 CouNumber",
    "file": "CouenneTypes",
    "library": "Couenne",
    "layer": "layer-3",
    "header": "src/expression/CouenneTypes.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "CouenneExprOp": {
    "brief": "Base class for n-ary operators in expression DAG\n\nBase for all non-leaf operators (sum, mul, pow, div, etc.).\nProvides argument list management and common functionality.\n\n**Key attributes:**\n- arglist_: Array of pointers to child expressions\n- nargs_: Number of arguments\n\n**Derived operator classes:**\n- exprSum, exprSub: Addition and subtraction\n- exprMul, exprDiv: Multiplication and division\n- exprPow: Power function x^k\n- exprLog, exprExp: Logarithm and exponential\n- exprSin, exprCos: Trigonometric functions\n- exprMin, exprMax: Min/max functions\n- exprAbs: Absolute value\n\n**Methods:**\n- standardize(): Replace with auxiliary variable w = f(x)\n- clonearglist(): Deep copy argument list for cloning\n- rank(): Maximum rank of arguments + 1",
    "file": "CouenneExprOp",
    "library": "Couenne",
    "layer": "layer-3",
    "header": "src/expression/CouenneExprOp.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "CouenneExprAux": {
    "brief": "Auxiliary variable class for reformulated nonlinear expressions\n\nAuxiliary variables replace nonlinear terms during standardization,\nenabling generation of convex relaxations. If w = f(x), then cuts\nare generated for the relation between w and f(x).",
    "file": "CouenneExprAux",
    "library": "Couenne",
    "layer": "layer-3",
    "header": "src/expression/CouenneExprAux.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "CouenneExprCopy": {
    "brief": "Reference copy of an expression\n\nPoints to another expression and delegates all operations to it.\nUsed to share expressions without duplicating the entire subtree.\n\n**Key concept:**\nexprCopy owns its copy_ pointer and destroys it in destructor.\nThis is the \"owning\" copy - use exprClone for non-owning.\n\n**Delegation pattern:**\nAll methods (evaluate, differentiate, bounds, etc.) forward\nto the underlying copy_ expression.\n\n**Original():**\nReturns the ultimate underlying expression, chasing through\nany chain of copies to find the actual expr.\n\n**value_:**\nCaches the last computed value for use by exprStore expressions.\n\n**Important warning:**\nThis destructor deletes copy_, unlike exprClone and exprStore.\nBe careful about ownership when using expression copies.",
    "file": "CouenneExprCopy",
    "library": "Couenne",
    "layer": "layer-3",
    "header": "src/expression/CouenneExprCopy.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "CouenneExprClone": {
    "brief": "Non-owning reference to another expression\n\nPoints to another expression but does NOT own it - the destructor\nsets copy_ = NULL to prevent exprCopy's destructor from deleting it.\n\n**Key difference from exprCopy:**\n- exprCopy: Owns copy_, deletes it in destructor\n- exprClone: Does NOT own copy_, just references it\n\n**Usage:**\nUse exprClone when you need multiple references to the same\nexpression without duplicating memory or ownership.\n\n**getOriginal():**\nUsed in constructor to skip through chains of clones/copies\nto find the actual underlying expression.\n\n**Evaluation:**\noperator() calls (*copy_)() which evaluates the pointed-to\nexpression and returns its result.",
    "file": "CouenneExprClone",
    "library": "Couenne",
    "layer": "layer-3",
    "header": "src/expression/CouenneExprClone.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "CouenneExprUnary": {
    "brief": "Base class for univariate function expressions\n\nProvides common framework for all single-argument functions like\nsin, cos, log, exp, sqrt, etc. Derived classes override F() to\ndefine the actual function.\n\n**Key virtual methods for derived classes:**\n- F(): Return the unary_function pointer for evaluation\n- generateCuts(): Create convexification cuts for w = f(x)\n- impliedBound(): Backward propagation (w bounds \u2192 x bounds)\n\n**Convexification approach:**\nUnivariate functions use tangent cuts (supporting hyperplanes) on\nconvex regions and secant cuts on concave regions.",
    "file": "CouenneExprUnary",
    "library": "Couenne",
    "layer": "layer-3",
    "header": "src/expression/CouenneExprUnary.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "CouenneChooseVariable": {
    "brief": "Variable selection for branching in global optimization",
    "file": "CouenneChooseVariable",
    "library": "Couenne",
    "layer": "layer-3",
    "header": "src/branch/CouenneChooseVariable.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "CouenneThreeWayBranchObj": {
    "brief": "Three-way spatial branching for continuous variables",
    "file": "CouenneThreeWayBranchObj",
    "library": "Couenne",
    "layer": "layer-3",
    "header": "src/branch/CouenneThreeWayBranchObj.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "CouenneVarObject": {
    "brief": "Variable-based branching object for MINLP",
    "file": "CouenneVarObject",
    "library": "Couenne",
    "layer": "layer-3",
    "header": "src/branch/CouenneVarObject.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "CouenneComplBranchingObject": {
    "brief": "Branching object for complementarity constraints",
    "file": "CouenneComplBranchingObject",
    "library": "Couenne",
    "layer": "layer-3",
    "header": "src/branch/CouenneComplBranchingObject.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "CouenneBranchingObject": {
    "brief": "Spatial branching object for continuous and integer variables\n\nExecutes branching on a variable (which may be continuous) to\npartition the domain and tighten the convex relaxation.",
    "file": "CouenneBranchingObject",
    "library": "Couenne",
    "layer": "layer-3",
    "header": "src/branch/CouenneBranchingObject.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "CouenneOrbitObj": {
    "brief": "Orbital branching using symmetry detection (DISABLED)",
    "file": "CouenneOrbitObj",
    "library": "Couenne",
    "layer": "layer-3",
    "header": "src/branch/CouenneOrbitObj.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "CouenneVTObject": {
    "brief": "Violation transfer branching for MINLP variables",
    "file": "CouenneVTObject",
    "library": "Couenne",
    "layer": "layer-3",
    "header": "src/branch/CouenneVTObject.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "CouenneProjections": {
    "brief": "Point-to-segment projection utilities\n\nGeometric utilities for projecting points onto line segments,\nused in convexification cut generation and branching point selection.",
    "file": "CouenneProjections",
    "library": "Couenne",
    "layer": "layer-3",
    "header": "src/branch/CouenneProjections.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "CouenneComplObject": {
    "brief": "Branching object for complementarity constraints",
    "file": "CouenneComplObject",
    "library": "Couenne",
    "layer": "layer-3",
    "header": "src/branch/CouenneComplObject.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "CouenneNauty": {
    "brief": "Interface to nauty library for symmetry detection\n\nWraps the nauty graph automorphism library to detect symmetries\nin MINLP problems. Symmetry information enables orbital branching\nand isomorphism pruning to reduce the search space.",
    "file": "CouenneNauty",
    "library": "Couenne",
    "layer": "layer-3",
    "header": "src/branch/CouenneNauty.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "CouenneObject": {
    "brief": "Branching object for auxiliary variables w = f(x)\n\nDefines branching for auxiliary variables based on their infeasibility\n|w - f(x)|. Creates branches to restore feasibility of the relation.",
    "file": "CouenneObject",
    "library": "Couenne",
    "layer": "layer-3",
    "header": "src/branch/CouenneObject.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "CouenneOrbitBranchingObj": {
    "brief": "Orbital branching object using symmetry",
    "file": "CouenneOrbitBranchingObj",
    "library": "Couenne",
    "layer": "layer-3",
    "header": "src/branch/CouenneOrbitBranchingObj.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "CouenneSOSObject": {
    "brief": "Special Ordered Set (SOS) branching for Couenne",
    "file": "CouenneSOSObject",
    "library": "Couenne",
    "layer": "layer-3",
    "header": "src/branch/CouenneSOSObject.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "CouenneChooseStrong": {
    "brief": "Strong branching for global MINLP optimization\n\nExtends Bonmin's strong branching to handle nonconvex constraints\nby evaluating actual LP bound improvement from branching.",
    "file": "CouenneChooseStrong",
    "library": "Couenne",
    "layer": "layer-3",
    "header": "src/branch/CouenneChooseStrong.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "CouenneCutGenerator": {
    "brief": "Main convexification cut generator for global MINLP optimization\n\nGenerates linear outer approximation cuts to build convex relaxations\nof nonconvex MINLPs. Works with the symbolic CouenneProblem representation.\n\n**Cut generation (generateCuts):**\n1. For each auxiliary variable w = f(x), generate linearization cuts\n2. Cuts are based on expression type (convex envelope, secants, tangents)\n3. Uses current LP solution as linearization point\n\n**Convexification types (conv_type):**\n- Current-point linearization (most common)\n- Multi-point sampling for tighter relaxations\n\n**Cut types generated:**\n- Tangent cuts for convex functions\n- Secant cuts for concave functions\n- McCormick envelope cuts for bilinear terms\n- Specialized cuts for sin, cos, exp, log, etc.\n\n**Helper methods:**\n- addEnvelope(): Generate convex/concave envelope for univariate function\n- addSegment(): Add secant line between two points\n- addTangent(): Add tangent at given point\n- createCut(): Build and validate OsiRowCut",
    "file": "CouenneCutGenerator",
    "library": "Couenne",
    "layer": "layer-3",
    "header": "src/convex/CouenneCutGenerator.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "CouenneFixPoint": {
    "brief": "Fixpoint-based bound tightening via constraint propagation\n\nImplements Feasibility-Based Bound Tightening (FBBT) using fixpoint\niteration. Propagates bounds through expression DAG until no further\ntightening is possible.",
    "file": "CouenneFixPoint",
    "library": "Couenne",
    "layer": "layer-3",
    "header": "src/bound_tightening/CouenneFixPoint.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "CouenneBTPerfIndicator": {
    "brief": "Performance metrics for bound tightening\n\nTracks effectiveness of bound tightening methods (FBBT, OBBT, etc.)\nby measuring how much bounds are reduced and how many variables are fixed.\n\n**Metrics tracked:**\n- nFixed_: Number of variables fixed (lb == ub)\n- boundRatio_: Average bound width shrinkage ratio\n- shrunkInf_: Bounds that became finite from infinite\n- shrunkDoubleInf_: [-inf,inf] that became [a,inf] or [-inf,b]\n- nProvedInfeas_: Number of infeasibility proofs\n\n**Usage:**\n1. Call setOldBounds() before bound tightening\n2. Run bound tightening\n3. Call update() with new bounds\n4. Metrics accumulated for end-of-run summary\n\n**Timing:**\n- totalTime_: CPU time spent in this bound tightener\n- nRuns_: Number of invocations",
    "file": "CouenneBTPerfIndicator",
    "library": "Couenne",
    "layer": "layer-3",
    "header": "src/bound_tightening/CouenneBTPerfIndicator.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "CouenneMultiVarProbe": {
    "brief": "Multi-variable probing for bound tightening",
    "file": "CouenneMultiVarProbe",
    "library": "Couenne",
    "layer": "layer-3",
    "header": "src/bound_tightening/CouenneMultiVarProbe.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "CouenneSparseBndVec": {
    "brief": "Sparse vector with O(1) initialization for bound tracking\n\nEfficient sparse+dense hybrid data structure for tracking which\nvariables had bounds tightened. Avoids O(n) initialization cost.\n\n**Data structure (Briggs-Torczon):**\n- dInd_[0..n_-1]: Dense list of assigned indices\n- sInd_[i]: Position of index i in dense list (garbage if unset)\n- data_[i]: Value at index i (garbage if unset)\n\n**Key operations:**\n- operator[](i): O(1) access, auto-initializes new entries\n- reset(): O(1) clear (just set n_ = 0)\n- nElements(): Number of assigned entries\n- indices()/data(): Access for iteration\n\n**Why useful in FBBT:**\nIn bound tightening, typically k << n variables have bounds\ntightened. This structure allows O(k) iteration over tightened\nbounds without O(n) initialization/cleanup overhead.\n\n**Note:**\nValgrind will complain about uninitialized reads - this is expected\ndue to the lazy initialization design.",
    "file": "CouenneSparseBndVec",
    "library": "Couenne",
    "layer": "layer-3",
    "header": "src/bound_tightening/CouenneSparseBndVec.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "CouenneInfeasCut": {
    "brief": "Signal infeasibility via fictitious cut\n\nMechanism for bound tighteners to signal detected infeasibility\nto the node solver without early termination.\n\n**WipeMakeInfeas():**\nAdds a fictitious cut 1 \u2264 x\u2080 \u2264 -1 to the cut set. This\nimpossible constraint signals to subsequent components that\nthe node is infeasible.\n\n**isWiped():**\nChecks whether the cut set contains the infeasibility signal.\nCut generators should check this before expensive operations.\n\n**Why needed:**\nIn Cgl's cut generator framework, generators cannot directly\nprune nodes. This sentinel cut mechanism allows bound tighteners\nto signal infeasibility discovered during FBBT/OBBT.",
    "file": "CouenneInfeasCut",
    "library": "Couenne",
    "layer": "layer-3",
    "header": "src/bound_tightening/CouenneInfeasCut.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "CouenneAggrProbing": {
    "brief": "Aggressive probing for bound tightening\n\nImplements Optimality-Based Bound Tightening (OBBT) through aggressive\nprobing. Temporarily fixes a variable bound and solves the resulting\nsubproblem to determine if a tighter bound is achievable.",
    "file": "CouenneAggrProbing",
    "library": "Couenne",
    "layer": "layer-3",
    "header": "src/bound_tightening/CouenneAggrProbing.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "CouenneOSInterface": {
    "brief": "Optimization Services (OS) interface for Couenne\n\nReads optimization problems from OSInstance format (COIN-OR\nOptimization Services) and converts to Couenne representation.\n\n**OSInstance format:**\nXML-based representation for optimization problems defined by\nthe Optimization Services project. Supports linear, quadratic,\nand nonlinear constraints with expression trees.\n\n**Key methods:**\n- getCouenneProblem(): Convert OSInstance \u2192 CouenneProblem\n- getTMINLP(): Wrap as Bonmin TMINLP\n- writeSolution(): Output in OS solution format\n\n**Usage:**\nAlternative to AMPL interface for problems defined via\nOptimization Services XML or programmatic APIs.",
    "file": "CouenneOSInterface",
    "library": "Couenne",
    "layer": "layer-3",
    "header": "src/main/CouenneOSInterface.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "CouenneBab": {
    "brief": "Main Branch-and-Bound driver for Couenne\n\nExtends Bonmin::Bab to add Couenne-specific functionality\nfor spatial branch-and-bound on nonconvex MINLPs.\n\n**Inheritance:**\nCouenneBab \u2192 Bonmin::Bab \u2192 CbcModel\n\n**Key additions over Bonmin::Bab:**\n- Stores CouenneProblem pointer for access to expression DAG\n- Overrides bestSolution() and bestObj() for proper handling\n- bestBound() returns min of parent bound and best objective\n\n**Usage:**\nCalled from BonCouenneSetup after problem setup.\nThe branchAndBound() method runs the full spatial B&B algorithm,\nusing Couenne's convexification, bound tightening, and\nbranching strategies.\n\n**Solution retrieval:**\n- bestSolution(): Optimal variable values (or best known)\n- bestObj(): Objective value at best solution\n- bestBound(): Lower bound on optimal value",
    "file": "CouenneBab",
    "library": "Couenne",
    "layer": "layer-3",
    "header": "src/main/CouenneBab.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "BonCouenneSetup": {
    "brief": "Main setup class for Couenne global optimizer\n\nExtends Bonmin's setup to configure Couenne's global optimization\ncomponents including cut generators, bound tightening, and heuristics.\n\n**Initialization (InitializeCouenne):**\n1. Read AMPL model and options\n2. Create CouenneProblem representation\n3. Standardize problem (create auxiliary variables)\n4. Register cut generators (convexification, bound tightening)\n5. Configure branching and heuristics\n\n**Key components configured:**\n- CouenneCutGenerator: Convexification cuts\n- CouenneFixPoint: FBBT bound tightening\n- CouenneFeasPump: Feasibility pump heuristic\n- CouenneChooseVariable: Branching variable selection\n\n**SmartAsl:**\nReference-counted wrapper for ASL pointer (AMPL Solver Library).",
    "file": "BonCouenneSetup",
    "library": "Couenne",
    "layer": "layer-3",
    "header": "src/main/BonCouenneSetup.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "BonCouenneInfo": {
    "brief": "Information passing between B&B components\n\nExtends Bonmin's BabInfo with Couenne-specific information,\nparticularly storage of NLP solutions found during search.\n\n**NlpSolution class:**\nReference-counted storage for NLP solutions:\n- n_: Number of variables\n- sol_[]: Variable values\n- objVal_: Objective function value\n\n**CouenneInfo:**\n- nlpSols_: List of all NLP solutions found\n- addSolution(): Record a new NLP solution\n- NlpSolutions(): Access stored solutions\n\n**Usage:**\nWhen Couenne finds feasible NLP solutions (from heuristics\nor at B&B nodes), they are stored here for incumbent tracking\nand warm-starting purposes.",
    "file": "BonCouenneInfo",
    "library": "Couenne",
    "layer": "layer-3",
    "header": "src/main/BonCouenneInfo.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "CouenneJournalist": {
    "brief": "Couenne-specific logging categories using Ipopt's Journalist\n\nExtends Ipopt's Journalist logging facility with Couenne-specific\ncategories for selective debug output.\n\n**Log categories defined:**\n- J_BRANCHING: Branch-and-bound variable selection\n- J_BOUNDTIGHTENING: FBBT and OBBT progress\n- J_CONVEXIFYING: Cut generation and convexification\n- J_PROBLEM: Problem construction and reformulation\n- J_NLPHEURISTIC: NLP solve heuristics\n- J_DISJCUTS: Disjunctive cut generation (CGLP)\n- J_REFORMULATE: Expression reformulation\n- J_COUENNE: General Couenne messages\n\n**Usage:**\n```cpp\njnlst->Printf(J_SUMMARY, J_BRANCHING,\n              \"Selected var %d with score %.2f\\n\", idx, score);\n```\n\n**Verbosity levels (from Ipopt):**\n- J_NONE, J_ERROR, J_WARNING, J_SUMMARY, J_DETAILED, ...",
    "file": "CouenneJournalist",
    "library": "Couenne",
    "layer": "layer-3",
    "header": "src/problem/CouenneJournalist.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "CouenneSolverInterface": {
    "brief": "OsiSolverInterface wrapper with bound tightening integration\n\nTemplate class wrapping any OsiSolverInterface (typically OsiClpSolverInterface)\nwith Couenne-specific enhancements for spatial B&B.\n\n**Key features:**\n1. Applies FBBT before resolve() to tighten bounds\n2. Uses expression-based isInteger() for auxiliary variables\n3. Integrates NLP solutions into branching decisions\n\n**Bound tightening integration:**\n- tightenBounds(): Apply FBBT before LP solve\n- tightenBoundsCLP(): Clp-specific variable bound analysis\n- tightenBoundsCLP_Light(): Lightweight version for hot starts\n\n**Infeasibility tracking:**\n- knowInfeasible_: Detected during bound tightening\n- knowDualInfeasible_: Continuous relaxation is unbounded\n- isProvenPrimalInfeasible(): May detect before LP solve\n\n**Template usage:**\nCouenneSolverInterface<OsiClpSolverInterface> wraps Clp\nwith Couenne's bound tightening infrastructure.",
    "file": "CouenneSolverInterface",
    "library": "Couenne",
    "layer": "layer-3",
    "header": "src/problem/CouenneSolverInterface.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "CouenneRecordBestSol": {
    "brief": "Best solution recording with feasibility tracking\n\nMaintains the best feasible solution found during optimization,\nwith detailed violation tracking for debugging and reporting.\n\n**Initial domain info:**\n- cardInitDom: Problem dimension\n- initIsInt[]: Integer variable flags\n- listInt: Indices of integer variables\n- initDomLb[], initDomUb[]: Original bounds (for feasibility check)\n\n**Best solution state:**\n- hasSol: True if any solution has been recorded\n- sol[]: Current best solution vector\n- val: Objective value of best solution\n- maxViol: Maximum violation (bound, integrality, or constraint)\n\n**Modified solution workspace:**\n- modSol[], modSolVal, modSolMaxViol: Temporary storage for\n  checkNLP2 and update operations before committing\n\n**update() methods:**\n- update(sol, card, val, viol): Update if val < current val\n- update(): Commit modSol if modSolVal < current val\n\n**compareAndSave():**\nCompare two solutions, keep better one with finite value (<1e49).\nReturns: -1 if both infinite, 0 if solA saved, 1 if solB saved.",
    "file": "CouenneRecordBestSol",
    "library": "Couenne",
    "layer": "layer-3",
    "header": "src/problem/CouenneRecordBestSol.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "CouenneProblem": {
    "brief": "Central MINLP problem representation with expression DAG\n\nThe heart of Couenne's global optimization approach. Represents MINLPs\nsymbolically as expression trees, enabling automatic convexification,\nbound propagation, and reformulation.\n\n**Key data structures:**\n- variables_: Original, auxiliary, and defined variables\n- objectives_/constraints_: Symbolic expressions\n- graph_: Dependency graph for evaluation ordering\n- auxSet_: Set of auxiliary variables w = f(x) for linearization\n\n**Bound tightening methods:**\n- FBBT (doFBBT_): Feasibility-based bound tightening via constraint propagation\n- OBBT (doOBBT_): Optimality-based bound tightening via LP solves\n- RCBT (doRCBT_): Reduced-cost bound tightening\n- ABT (doABT_): Aggressive bound tightening via domain partitioning\n\n**Reformulation (standardize()):**\nConverts nonlinear expressions into auxiliary variable definitions\nw = f(x), enabling generation of convex relaxations for each operator.\n\n**Symmetry handling:**\nUses nauty library for graph automorphism detection and orbital branching.",
    "file": "CouenneProblem",
    "library": "Couenne",
    "layer": "layer-3",
    "header": "src/problem/CouenneProblem.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "CouenneProblemElem": {
    "brief": "Constraint and objective classes for Couenne problems\n\nDefines the building blocks for optimization problems:\nconstraints with expression bounds and objective functions.\n\n**CouenneConstraint:**\nRepresents lb_ <= body_ <= ub_ where all three are expressions:\n- body_: The constraint expression (e.g., exp(x1+x2))\n- lb_: Lower bound expression (defaults to 0 or -INFINITY)\n- ub_: Upper bound expression (defaults to 0 or +INFINITY)\n\n**Default bound handling:**\n- Both NULL \u2192 equality constraint (lb = ub = 0)\n- lb NULL, ub set \u2192 lb = -INFINITY (one-sided upper)\n- ub NULL, lb set \u2192 ub = +INFINITY (one-sided lower)\n\n**CouenneObjective:**\nMinimization objective wrapper. Maximization problems are\nconverted by negating the objective during problem input.\n\n**standardize():**\nDecomposes complex expressions into auxiliary variable\ndefinitions for reformulation-linearization.",
    "file": "CouenneProblemElem",
    "library": "Couenne",
    "layer": "layer-3",
    "header": "src/problem/CouenneProblemElem.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "CouenneGlobalCutOff": {
    "brief": "Global best solution and cutoff value storage\n\nManages the incumbent (best known feasible solution) and its\nobjective value across the entire B&B search.\n\n**Role in B&B:**\n- Provides cutoff value for pruning nodes\n- Stores best solution found so far\n- Updated when heuristics or B&B find improvements\n\n**Members:**\n- cutoff_: Objective value of best solution (upper bound for min)\n- sol_: Variable values of best solution\n- valid_: Whether stored solution corresponds to cutoff\n\n**Thread safety note:**\nIn parallel environments, this would need synchronization.\nCurrently assumes sequential access.\n\n**setCutOff():**\nUpdates cutoff and optionally stores the solution vector.\nRequires CouenneProblem pointer for size information.",
    "file": "CouenneGlobalCutOff",
    "library": "Couenne",
    "layer": "layer-3",
    "header": "src/problem/CouenneGlobalCutOff.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "CouenneLQelems": {
    "brief": "Linear and quadratic term storage for standardization\n\nData structures for collecting linear and quadratic terms during\nexpression standardization (conversion to auxiliary variable form).\n\n**quadElem:**\nSingle quadratic term c\u00b7x\u1d62\u00b7x\u2c7c:\n- varI_, varJ_: Variable pointers\n- coeff_: Coefficient c\n\n**LinMap:**\nSparse map of linear terms: index \u2192 coefficient\n- insert(index, coe): Add/accumulate coefficient\n- Auto-removes zero entries\n\n**QuadMap:**\nSparse map of quadratic terms: (i,j) \u2192 coefficient\n- insert(indI, indJ, coe): Add/accumulate coefficient\n- Auto-removes zero entries\n\n**Usage:**\nDuring standardization, expressions like x\u00b2 + 2xy + 3x + 4\nare decomposed into LinMap (3x + 4 constant) and QuadMap\n(x\u00b2 + 2xy). These are then converted to auxiliary form.",
    "file": "CouenneLQelems",
    "library": "Couenne",
    "layer": "layer-3",
    "header": "src/standardize/CouenneLQelems.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "CouenneFeasPump": {
    "brief": "Feasibility Pump heuristic for nonconvex MINLP\n\nAlternates between NLP and MILP solves to find feasible solutions:\n- MILP phase: Find integer point closest to NLP solution\n- NLP phase: Find NLP-feasible point closest to integer solution",
    "file": "CouenneFeasPump",
    "library": "Couenne",
    "layer": "layer-3",
    "header": "src/heuristics/CouenneFeasPump.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "CouenneIterativeRounding": {
    "brief": "Iterative rounding heuristic for nonconvex MINLP",
    "file": "CouenneIterativeRounding",
    "library": "Couenne",
    "layer": "layer-3",
    "header": "src/heuristics/CouenneIterativeRounding.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "BonInitHeuristic": {
    "brief": "Heuristic to inject initial NLP solution into Cbc\n\nCommunicates the initial NLP solution (computed before B&B starts)\nto Cbc as a known feasible solution.\n\n**Purpose:**\nWhen Couenne solves the root node NLP and finds a feasible MINLP\nsolution, this heuristic stores it so Cbc can use it as the\ninitial incumbent.\n\n**Usage:**\n```cpp\n// After initial NLP solve\nInitHeuristic heur(objValue, solution, problem);\ncbcModel.addHeuristic(&heur);\n```\n\n**solution() method:**\nReturns the stored initial solution on first call. Subsequent\ncalls return 0 (no new solution) since the initial solution\nhas already been provided.",
    "file": "BonInitHeuristic",
    "library": "Couenne",
    "layer": "layer-3",
    "header": "src/heuristics/BonInitHeuristic.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "CouenneFPpool": {
    "brief": "Solution pool and tabu list for Feasibility Pump\n\nManages collections of solutions found during FP iterations,\nproviding restart points and avoiding revisiting similar solutions.\n\n**CouenneFPsolution:**\nWrapper for a solution with cached infeasibility metrics:\n- nNLinf_: Count of nonlinear infeasibilities\n- nIinf_: Count of integer infeasibilities\n- maxNLinf_/maxIinf_: Maximum violations\n- objVal_: Objective function value\n\n**Comparison modes (what_to_compare):**\n- SUM_NINF: Compare by sum of infeasibility counts\n- SUM_INF: Compare by sum of infeasibility magnitudes\n- OBJVAL: Compare by objective value\n- ALL_VARS: Compare all variable values (for tabu)\n- INTEGER_VARS: Compare only integer variables (for tabu)\n\n**CouenneFPpool:**\nSet of solutions with custom comparator. Used to:\n- Store good MILP solutions for NLP restarts\n- Implement tabu list to avoid cycling\n- Find closest solution in pool (findClosestAndReplace)",
    "file": "CouenneFPpool",
    "library": "Couenne",
    "layer": "layer-3",
    "header": "src/heuristics/CouenneFPpool.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "BonNlpHeuristic": {
    "brief": "NLP heuristic for near-integer B&B nodes",
    "file": "BonNlpHeuristic",
    "library": "Couenne",
    "layer": "layer-3",
    "header": "src/heuristics/BonNlpHeuristic.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "CouenneSparseMatrix": {
    "brief": "Sparse matrix storage for Feasibility Pump distance\n\nSimple COO (coordinate) format sparse matrix used to store\nthe Hessian of the Lagrangian at optimum for later use in\nmodified distance computations.\n\n**Storage format:**\nCOO (Coordinate list):\n- val_[k]: Value of k-th nonzero\n- row_[k]: Row index of k-th nonzero\n- col_[k]: Column index of k-th nonzero\n- num_: Total number of nonzeros\n\n**Usage in Feasibility Pump:**\nThe Hessian from an NLP solve can be saved and used to modify\nthe distance metric in subsequent MILP solves, biasing the\nsearch toward regions where the NLP objective improves.\n\n**Note:** This is a simple storage class, not a full sparse\nmatrix implementation. For operations, use CoinPackedMatrix.",
    "file": "CouenneSparseMatrix",
    "library": "Couenne",
    "layer": "layer-3",
    "header": "src/util/CouenneSparseMatrix.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "CouenneFunTriplets": {
    "brief": "Function triplets: f(x), f'(x), f''(x), and (f')\u207b\u00b9\n\nBundles a univariate function with its first two derivatives and\nthe inverse of the first derivative. Used in convexification to\ncompute tangent points and envelope parameters.\n\n**Abstract base: funtriplet**\n- F(x): Main function value\n- Fp(x): First derivative f'(x)\n- Fpp(x): Second derivative f''(x)\n- FpInv(x): Inverse of first derivative (f')\u207b\u00b9(x)\n\n**simpletriplet:**\nStores function pointers for each operation. Suitable for\nstandard functions like exp, log, sin, cos.\n\n**powertriplet:**\nSpecialized for x\u1d4f with analytical derivatives:\n- F(x) = x\u1d4f\n- Fp(x) = k\u00b7x\u1d4f\u207b\u00b9\n- Fpp(x) = k(k-1)\u00b7x\u1d4f\u207b\u00b2\n- FpInv(y) = (y/k)^(1/(k-1))\n\n**kpowertriplet:**\nExtension for c\u00b7x\u1d4f with scalar multiplier.",
    "file": "CouenneFunTriplets",
    "library": "Couenne",
    "layer": "layer-3",
    "header": "src/util/CouenneFunTriplets.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "CouenneRootQ": {
    "brief": "Root finding for Q^k(x) polynomials in power convexification\n\nFinds roots of the polynomial Q^k(x) = \u03a3\u1d62\u208c\u2081^{2k} i\u00b7x^{i-1} used in\nconvexification of odd powers. Based on Liberti & Pantelides (2003).\n\n**Mathematical background:**\nFor odd power expressions w = x^k, the convex/concave envelope\nrequires finding specific points where tangent lines from the\nboundary touch the curve. The Q^k polynomial characterizes these.\n\n**Usage:**\n- rootQ(k): Computes root for exponent 2k+1\n- Qroot class: Caches computed roots in static map for efficiency\n\n**Implementation:**\n- Odd k: Computed via Newton's method, cached in Qmap\n- Even k (2,4,6,8,10): Hardcoded analytical values\n  - k=2: -(\u221a2 - 1) \u2248 -0.414\n  - k=4: \u2248 -0.560\n  - k=6: \u2248 -0.641\n  - etc.",
    "file": "CouenneRootQ",
    "library": "Couenne",
    "layer": "layer-3",
    "header": "src/util/CouenneRootQ.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "CouenneExprMin": {
    "brief": "N-ary minimum operator w = min(x1, x2, ..., xn)\n\nRepresents the minimum of multiple expressions. The min function is\ncontinuous but nonsmooth (non-differentiable at kinks where arguments\nare equal).\n\n**Convexification challenge:**\nmin is neither convex nor concave. Standard approach:\n- Introduce auxiliary variables: w = min(x1,...,xn)\n- Add constraints: w <= xi for all i (overestimators)\n- Underestimator requires disjunction: w >= x_k for some k\n\n**Bound propagation:**\n- lb(w) = min(lb(x1), ..., lb(xn))\n- ub(w) = min(ub(x1), ..., ub(xn))\n\n**Implementation note:**\nUses copy/store pattern with 2n arguments: copies for evaluation,\nstores for caching evaluated values.",
    "file": "CouenneExprMin",
    "library": "Couenne",
    "layer": "layer-3",
    "header": "src/expression/operators/CouenneExprMin.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "CouenneExprLog": {
    "brief": "Natural logarithm expression w = log(x)\n\nRepresents the natural logarithm function. This is a concave function\non its domain (x > 0), so convexification uses tangent cuts for\noverestimation and secant cuts for underestimation.\n\n**Convexification for w = log(x) on [l,u]:**\n- Overestimator (tangent): w <= log(x0) + (x - x0)/x0 at any x0 in (l,u)\n- Underestimator (secant): w >= log(l) + (log(u) - log(l))/(u - l) * (x - l)\n\n**Implied bounds:**\n- Given w in [wl, wu]: x in [exp(wl), exp(wu)]\n- Given x in [xl, xu] with xl > 0: w in [log(xl), log(xu)]\n\n**Bijective property:**\nLog is bijective with inverse exp(), enabling tighter bound propagation.",
    "file": "CouenneExprLog",
    "library": "Couenne",
    "layer": "layer-3",
    "header": "src/expression/operators/CouenneExprLog.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "CouenneExprSignPow": {
    "brief": "Signed power function w = x * |x|^(k-1) = sign(x) * |x|^k\n\nGeneralizes power to handle negative arguments while preserving\nsign, creating a bijective function for any real k.\n\n**Definition:**\nsignpow(x, k) = x * |x|^(k-1) = sign(x) * |x|^k\n- For x >= 0: same as x^k\n- For x < 0: -|x|^k (preserves sign)\n\n**Key property:**\nUnlike standard power x^k which is undefined for x < 0 when k is\nnon-integer, signpow is defined and continuous for all x.\n\n**Convexification:**\n- For k > 1: convex for x > 0, concave for x < 0\n- For 0 < k < 1: concave for x > 0, convex for x < 0\n- Point x = 0 is an inflection point\n\n**Bijectivity:**\nInverse is sign(y) * |y|^(1/k), enabling exact reverse propagation.",
    "file": "CouenneExprSignPow",
    "library": "Couenne",
    "layer": "layer-3",
    "header": "src/expression/operators/CouenneExprSignPow.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "CouenneExprMultiLin": {
    "brief": "Multilinear product w = x1 * x2 * ... * xn\n\nProduct of n expressions. Generalizes bilinear (n=2) and trilinear (n=3)\nto arbitrary number of factors.\n\n**Standardization approaches:**\n1. Recursive bilinear: w = ((x1*x2)*x3)*... using nested aux variables\n2. Trilinear grouping: group into triplets when n >= 3\n3. Direct multilinear relaxation (more complex cuts)\n\n**Convexification complexity:**\n- Bilinear (n=2): 4 McCormick cuts\n- Trilinear (n=3): 8 Meyer-Floudas cuts\n- n-linear: 2^n cuts (exponential in n)\n\nFor large n, recursive bilinear decomposition is preferred despite\nintroducing auxiliary variables.\n\n**Bound propagation:**\nProduct of intervals requires considering all 2^n corner combinations\nto find the true bounds. Simplified by interval arithmetic.\n\n**Implied bounds (impliedBoundMul):**\nFrom w = x1*x2*...*xn and bounds on w, derive bounds on factors.\nMore complex than bilinear case.\n\n**Branching:**\nbalancedMul() selects branching point to balance the relaxation\nimprovement across all factors.",
    "file": "CouenneExprMultiLin",
    "library": "Couenne",
    "layer": "layer-3",
    "header": "src/expression/operators/CouenneExprMultiLin.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "CouenneExprSum": {
    "brief": "N-ary sum expression w = sum(f_i(x))\n\nRepresents sum of multiple expressions. Sums are linear in their\narguments if all arguments are linear.\n\n**Implied bounds for w = a0 + sum(a_i * x_i):**\nGiven bounds w in [l,u] and coefficients partitioned by sign:\n- I1: indices where a_i > 0\n- I2: indices where a_i < 0\n\nFor i in I1:\n- x_i >= (l - a0 - sum_{j!=i,j in I1}(a_j*u_j) - sum_{j in I2}(a_j*l_j)) / a_i\n- x_i <= (u - a0 - sum_{j!=i,j in I1}(a_j*l_j) - sum_{j in I2}(a_j*u_j)) / a_i\n\n**Quadratic detection:**\ncreateQuadratic() scans sum terms for products and creates exprQuad\nif enough quadratic terms exist for alpha-convexification.\n\n**Linearity:**\nReturns maximum linearity level among all arguments.",
    "file": "CouenneExprSum",
    "library": "Couenne",
    "layer": "layer-3",
    "header": "src/expression/operators/CouenneExprSum.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "CouenneExprOddPow": {
    "brief": "Odd integer power w = x^k where k is odd\n\nHandles x^1, x^3, x^5, etc. These have special structure:\n- Bijective (one-to-one) over all reals\n- Pass through origin with same sign as x\n- No symmetry about y-axis (unlike even powers)\n\n**Convexity structure:**\n- x^3: convex for x > 0, concave for x < 0 (S-shaped)\n- x^5, x^7, ...: similar S-shape, steeper for higher k\n- Inflection point at x = 0\n\n**Bound propagation:**\nSince bijective: lb(w) = lb(x)^k, ub(w) = ub(x)^k (sign preserved)\n\n**Implied bounds (inverse):**\nFrom w = x^k: x = sign(w) * |w|^(1/k)\n- lb(x) = sign(lb(w)) * |lb(w)|^(1/k)\n- ub(x) = sign(ub(w)) * |ub(w)|^(1/k)\n\n**Convexification:**\nFor w = x^k on [a, b]:\n- If both same sign: secant overestimator, tangent underestimators (or vice versa)\n- If spans zero: use separate relaxations for positive and negative parts",
    "file": "CouenneExprOddPow",
    "library": "Couenne",
    "layer": "layer-3",
    "header": "src/expression/operators/CouenneExprOddPow.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "CouenneExprPow": {
    "brief": "Power expression w = x^k with convexification",
    "file": "CouenneExprPow",
    "library": "Couenne",
    "layer": "layer-3",
    "header": "src/expression/operators/CouenneExprPow.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "CouenneExprCeil": {
    "brief": "Ceiling function w = ceil(x)\n\nReturns the smallest integer not less than x. Piecewise constant\nfunction with jump discontinuities at each integer.\n\n**Convexification challenge:**\nceil(x) is neither convex nor concave nor continuous. The function\nis constant on intervals (n-1, n] with value n.\n\n**Bound propagation:**\n- lb(w) = ceil(lb(x))\n- ub(w) = ceil(ub(x))\n\n**Integrality:**\nResult is always integer-valued. Can be used in MINLP constraints\nthat round up quantities.\n\n**Relationship to floor:**\nceil(x) = -floor(-x), so implementations can share code.",
    "file": "CouenneExprCeil",
    "library": "Couenne",
    "layer": "layer-3",
    "header": "src/expression/operators/CouenneExprCeil.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "CouenneExprMax": {
    "brief": "N-ary maximum operator w = max(x1, x2, ..., xn)\n\nRepresents the maximum of multiple expressions. The max function is\nconvex (pointwise supremum of linear functions) but nonsmooth.\n\n**Convexification:**\nmax is convex, so underestimators are straightforward:\n- w >= xi for all i (linear underestimators)\n\nOverestimators require disjunction:\n- w <= x_k for some k (one of the arguments achieves the max)\n\n**Bound propagation:**\n- lb(w) = max(lb(x1), ..., lb(xn))\n- ub(w) = max(ub(x1), ..., ub(xn))\n\n**Subgradient at nondifferentiable points:**\nAt kinks where multiple arguments are equal to max, any convex\ncombination of their gradients is a valid subgradient.",
    "file": "CouenneExprMax",
    "library": "Couenne",
    "layer": "layer-3",
    "header": "src/expression/operators/CouenneExprMax.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "CouenneExprIf": {
    "brief": "Conditional (if-then-else) expression operator\n\nImplements the AMPL ifnl() operator:\n  if (condition) then expr1 else expr2\n\n**Status:** This is a placeholder/stub class. Full implementation\nwould require handling disjunctive convexification.\n\n**Convexification challenge:**\nConditional expressions create disjunctive feasible regions.\nStandard approach would use big-M formulations or disjunctive\nprogramming techniques to handle the branching logic.\n\n**Usage in AMPL:**\nModels with if-then-else create nonsmooth, potentially\ndiscontinuous functions that are difficult to convexify.",
    "file": "CouenneExprIf",
    "library": "Couenne",
    "layer": "layer-3",
    "header": "src/expression/operators/CouenneExprIf.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "CouenneExprBinProd": {
    "brief": "Product of binary variables (specialized multilinear)\n\nRepresents products of binary (0-1) variables: w = x\u2081 * x\u2082 * ... * x\u2099\nwhere each x\u1d62 \u2208 {0, 1}. Inherits from exprMul but exploits the\nbinary domain for tighter cuts.\n\n**Key simplification:**\nFor binary variables, w = 1 iff all x\u1d62 = 1, otherwise w = 0.\nThis is equivalent to logical AND.\n\n**Linearization (standard form):**\nFor n binaries, the product can be linearized exactly with:\n- w \u2264 x\u1d62 for all i (w = 0 if any x\u1d62 = 0)\n- w \u2265 \u03a3x\u1d62 - (n-1) (w = 1 if all x\u1d62 = 1)\n\n**Bounds:**\n- Lower bound: 0 always (product of non-negative)\n- Upper bound: 1 always (product of binaries \u2264 1)\n\n**isCuttable():**\nReturns false - binary products are fully linearizable,\nno convexification cuts beyond the standard form needed.",
    "file": "CouenneExprBinProd",
    "library": "Couenne",
    "layer": "layer-3",
    "header": "src/expression/operators/CouenneExprBinProd.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "CouenneExprExp": {
    "brief": "Exponential expression w = exp(x)\n\nRepresents the exponential function e^x. This is a convex function\nover all of R, so convexification uses secant cuts for overestimation\nand tangent cuts for underestimation.\n\n**Convexification for w = exp(x) on [l,u]:**\n- Underestimator (tangent): w >= exp(x0) + exp(x0)*(x - x0) at any x0 in [l,u]\n- Overestimator (secant): w <= exp(l) + (exp(u) - exp(l))/(u - l) * (x - l)\n\n**Implied bounds:**\n- Given w in [wl, wu] with wl > 0: x in [log(wl), log(wu)]\n- Given x in [xl, xu]: w in [exp(xl), exp(xu)]\n\n**Bijective property:**\nExp is bijective with inverse log(), enabling tighter bound propagation.\n\n**Convexity:** Convex everywhere, simplifying global optimization.",
    "file": "CouenneExprExp",
    "library": "Couenne",
    "layer": "layer-3",
    "header": "src/expression/operators/CouenneExprExp.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "CouenneExprFloor": {
    "brief": "Floor function w = floor(x)\n\nReturns the largest integer not exceeding x. Piecewise constant\nfunction with jump discontinuities at each integer.\n\n**Convexification challenge:**\nfloor(x) is neither convex nor concave nor continuous. The function\nis constant on intervals [n, n+1) with value n.\n\n**Bound propagation:**\n- lb(w) = floor(lb(x))\n- ub(w) = floor(ub(x))\n\n**Integrality:**\nResult is always integer-valued, even when argument is continuous.\nThis can introduce implicit integrality constraints.\n\n**Not cuttable:**\nNo convex relaxation exists for piecewise constant functions.\nMust rely on branching to handle.",
    "file": "CouenneExprFloor",
    "library": "Couenne",
    "layer": "layer-3",
    "header": "src/expression/operators/CouenneExprFloor.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "CouenneExprNorm": {
    "brief": "p-norm expression: ||f(x)||_p\n\nRepresents the \u2113\u209a norm: ||f(x)||_p = (\u03a3\u1d62 |f\u1d62(x)|^p)^(1/p)\n\n**Status:** This is a placeholder/stub class.\n\n**Special cases:**\n- p = 1: Sum of absolute values (piecewise linear)\n- p = 2: Euclidean norm (convex, smooth except at origin)\n- p = \u221e: Maximum absolute value (convex, nonsmooth)\n\n**Convexity:**\nAll \u2113\u209a norms with p \u2265 1 are convex functions.\nThis makes overestimation straightforward (tangent planes),\nbut underestimation requires handling the non-negativity\nand norm structure.\n\n**Common usage:**\n- Distance constraints: ||x - a||\u2082 \u2264 r\n- Regularization: minimize f(x) + \u03bb||x||\u2081",
    "file": "CouenneExprNorm",
    "library": "Couenne",
    "layer": "layer-3",
    "header": "src/expression/operators/CouenneExprNorm.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "CouenneExprDiv": {
    "brief": "Division expression w = x / y\n\nRepresents division of two expressions. Division is reformulated as\nmultiplication: w = x/y becomes w*y = x, using bilinear convexification.\n\n**Standardization:**\nDivision x/y is converted to x * (1/y), where 1/y is handled by exprInv.\nThis allows reuse of McCormick envelope cuts for the product.\n\n**Linearity check:**\nIf denominator is constant, expression inherits linearity of numerator.\nOtherwise, expression is nonlinear.\n\n**Bound safety:**\n- is_boundbox_regular(): Checks if bounds are suitable for convexification\n- SAFE_COEFFICIENT (1e9): Maximum coefficient for OsiRowCut\n- BR_NEXT_ZERO: Safety margin near zero denominator\n\n**Not cuttable:**\nLike products, division is concave on both sides and cannot be\nfurther linearized - only bound tightening helps.",
    "file": "CouenneExprDiv",
    "library": "Couenne",
    "layer": "layer-3",
    "header": "src/expression/operators/CouenneExprDiv.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "CouenneExprSin": {
    "brief": "Sine expression w = sin(x)\n\nRepresents the sine function. Sine is challenging for global optimization\ndue to its oscillatory nature - alternates between convex and concave\nregions every pi interval.\n\n**Convexification challenges:**\n- Convex on [2k*pi - pi, 2k*pi] for integer k\n- Concave on [2k*pi, 2k*pi + pi]\n- Multiple local optima on unbounded domains\n- Special handling needed when domain spans multiple periods\n\n**Implied bounds:**\n- w in [-1, 1] always\n- Given w bounds, x bounds via arcsin with period handling\n- trigImpliedBound(): Generalized procedure for sin/cos\n\n**Branching:**\ntrigSelBranch(): Selects branching points based on convexity regions\nand current LP solution position relative to sin curve.\n\n**Not cuttable:** Due to alternating convexity, cutting planes\nare less effective than branching.",
    "file": "CouenneExprSin",
    "library": "Couenne",
    "layer": "layer-3",
    "header": "src/expression/operators/CouenneExprSin.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "CouenneExprOpp": {
    "brief": "Negation operator w = -x\n\nLinear operator that returns the opposite of an expression.\nPreserves linearity of the argument.\n\n**Convexification:**\n- Affine function: requires no convexification\n- Convex relaxation is exact\n- Linearity() returns same as argument's Linearity()\n\n**Bound propagation:**\n- lb(w) = -ub(x)\n- ub(w) = -lb(x)\nNote: bounds are swapped!\n\n**Implied bounds:**\nFrom w = -x: if w >= a then x <= -a, if w <= b then x >= -b\n\n**Integrality preservation:**\nIf x is integer, -x is also integer.\n\n**Simplification:**\n-(-x) simplifies to x (double negation elimination)",
    "file": "CouenneExprOpp",
    "library": "Couenne",
    "layer": "layer-3",
    "header": "src/expression/operators/CouenneExprOpp.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "CouenneExprEvenPow": {
    "brief": "Even integer power w = x^k where k is even\n\nHandles x^2, x^4, x^6, etc. These have special structure:\n- Always non-negative: w >= 0\n- Symmetric about y-axis: f(x) = f(-x)\n- NOT bijective: x and -x give same w\n\n**Convexity:**\nEven powers are convex everywhere (sum of squares is convex).\nThis greatly simplifies the convex relaxation.\n\n**Bound propagation:**\n- lb(w) = 0 if [lb(x), ub(x)] contains 0\n- lb(w) = min(lb(x)^k, ub(x)^k) otherwise\n- ub(w) = max(lb(x)^k, ub(x)^k)\n\n**Implied bounds (non-bijective!):**\nFrom w = x^k where k even:\n- |x| <= w^(1/k), so -w^(1/k) <= x <= w^(1/k)\n- Cannot determine sign of x from w alone\n\n**Convexification:**\nSince convex: tangent line underestimators everywhere.\nSecant line is the overestimator.\n\n**Special case x^2:**\nMost common even power, often handled separately for efficiency.",
    "file": "CouenneExprEvenPow",
    "library": "Couenne",
    "layer": "layer-3",
    "header": "src/expression/operators/CouenneExprEvenPow.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "CouenneExprAbs": {
    "brief": "Absolute value expression w = |x|\n\nRepresents the absolute value function. This is a convex function\nwith a non-differentiable point at x = 0.\n\n**Convexification for w = |x| on [l,u]:**\n- If l >= 0: w = x (identity)\n- If u <= 0: w = -x (negation)\n- If l < 0 < u: convex envelope is\n  - w >= x (right branch)\n  - w >= -x (left branch)\n  - w <= ((u+l)*x + u*(-l) - l*u) / (u - l) (secant from (l,-l) to (u,u))\n\n**Implied bounds:**\n- w >= 0 always\n- Given w in [0, wu]: x in [-wu, wu] \u2229 [l, u]\n- Given x in [l, u]: w in [min(|l|,|u|)?, max(|l|,|u|)]\n\n**Integer preservation:**\nIf argument is integer, |x| is also integer.",
    "file": "CouenneExprAbs",
    "library": "Couenne",
    "layer": "layer-3",
    "header": "src/expression/operators/CouenneExprAbs.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "CouenneExprMul": {
    "brief": "N-ary multiplication expression with McCormick convexification\n\nRepresents products of the form w = x1 * x2 * ... * xn.\nDuring standardization, n-ary products are decomposed into\nbinary products: w1 = x1*x2, w2 = w1*x3, etc.",
    "file": "CouenneExprMul",
    "library": "Couenne",
    "layer": "layer-3",
    "header": "src/expression/operators/CouenneExprMul.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "CouenneExprCos": {
    "brief": "Cosine function w = cos(x)\n\nBounded periodic function in [-1, 1]. Convexification follows the\nsame approach as exprSin with a phase shift.\n\n**Convexification (depends on bound interval):**\n- If interval < \u03c0: tangent line is overestimator on convex part,\n  underestimator on concave part\n- Secant line connects interval endpoints\n- Newton iteration (trigNewton) finds optimal tangent points\n\n**Implied bounds:**\nSince cos is bounded, w \u2208 [-1, 1] always. Uses trigImpliedBound()\nfor reverse propagation when w bounds are known.\n\n**Derivative:**\nd(cos(x))/dx = -sin(x), used for gradient computations.\n\n**Period handling:**\nIf bound interval spans multiple periods, relaxation becomes\ntrivial: -1 <= w <= 1.",
    "file": "CouenneExprCos",
    "library": "Couenne",
    "layer": "layer-3",
    "header": "src/expression/operators/CouenneExprCos.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "CouenneExprInv": {
    "brief": "Reciprocal function w = 1/x\n\nHyperbolic function that is convex on (0, \u221e) and (-\u221e, 0) separately.\nSingular at x = 0, so domain handling is critical.\n\n**Convexification by domain:**\n- x > 0: 1/x is convex, use secant overestimator and tangent underestimators\n- x < 0: 1/x is convex, same approach\n- If x can cross zero: must handle carefully, possible branching\n\n**Tangent line at x = a:**\nw = 1/a - (x - a)/a\u00b2 = 2/a - x/a\u00b2\n\n**Secant between (a, 1/a) and (b, 1/b):**\nw = 1/a + (1/b - 1/a)/(b - a) * (x - a) = 1/a - (x - a)/(ab)\n\n**Properties:**\n- Bijective: inverse of 1/x is 1/x (self-inverse)\n- Used in division: x/y reformulated as x * (1/y)\n- Derivatives: d(1/x)/dx = -1/x\u00b2, d\u00b2(1/x)/dx\u00b2 = 2/x\u00b3",
    "file": "CouenneExprInv",
    "library": "Couenne",
    "layer": "layer-3",
    "header": "src/expression/operators/CouenneExprInv.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "CouenneExprQuad": {
    "brief": "Quadratic expression with alpha-convexification",
    "file": "CouenneExprQuad",
    "library": "Couenne",
    "layer": "layer-3",
    "header": "src/expression/operators/CouenneExprQuad.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "CouenneExprTrilinear": {
    "brief": "Trilinear product expression w = x*y*z",
    "file": "CouenneExprTrilinear",
    "library": "Couenne",
    "layer": "layer-3",
    "header": "src/expression/operators/CouenneExprTrilinear.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "CouenneExprSub": {
    "brief": "Binary subtraction operator w = x - y\n\nLinear operator for computing the difference of two expressions.\nLinearity is the maximum of the two arguments' linearity.\n\n**Convexification:**\n- Affine in both arguments: no convexification needed\n- Linearity() = max(Linearity(x), Linearity(y))\n\n**Bound propagation:**\n- lb(w) = lb(x) - ub(y)\n- ub(w) = ub(x) - lb(y)\n\n**Implied bounds:**\nFrom w = x - y:\n- x >= lb(w) + lb(y)\n- x <= ub(w) + ub(y)\n- y >= lb(x) - ub(w)\n- y <= ub(x) - lb(w)\n\n**Standardization:**\nMay be rewritten as x + (-1)*y using exprSum and exprOpp\nduring problem transformation.",
    "file": "CouenneExprSub",
    "library": "Couenne",
    "layer": "layer-3",
    "header": "src/expression/operators/CouenneExprSub.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "CouenneExprPWLinear": {
    "brief": "Piecewise linear function expression\n\nRepresents piecewise linear (PWL) functions defined by breakpoints\nand slopes or by point sequences.\n\n**Status:** This is a placeholder/stub class.\n\n**Mathematical form:**\nf(x) = a\u1d62 * x + b\u1d62  for  x\u1d62 \u2264 x < x\u1d62\u208a\u2081\n\n**Convexification:**\n- If convex (slopes increasing): trivial envelope\n- If concave (slopes decreasing): trivial envelope\n- If neither: requires disjunctive handling\n\n**Standard MIP formulation:**\nUses binary variables to select active segment:\n- \u03bb\u1d62 \u2208 [0,1], \u03a3\u03bb\u1d62 = 1, at most 2 adjacent \u03bb\u1d62 positive (SOS2)\n- x = \u03a3\u03bb\u1d62x\u1d62, y = \u03a3\u03bb\u1d62y\u1d62\n\n**Usage:**\nCommon in approximating nonlinear functions or modeling\ncosts with quantity discounts.",
    "file": "CouenneExprPWLinear",
    "library": "Couenne",
    "layer": "layer-3",
    "header": "src/expression/operators/CouenneExprPWLinear.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "CouenneExprGroup": {
    "brief": "Mixed expression: constant + linear + nonlinear terms\n\nRepresents expressions of the form:\n  w = c0 + sum(a_i * x_i) + sum(f_j(x))\nwhere c0 is constant, a_i*x_i are linear terms, and f_j are nonlinear.\n\n**Data structures:**\n- c0_: Constant term\n- lcoeff_: Vector of (variable, coefficient) pairs for linear part\n- Inherits arglist_ from exprSum for nonlinear terms\n\n**Factory pattern:**\ngenExprGroup() checks parameters and returns:\n- exprConst if only constant\n- exprVar if single variable with coefficient 1\n- exprGroup otherwise\n\n**Evaluation:**\noperator() = c0 + sum(coefficient * variable_value) + sum(nonlinear)\n\n**Base for exprQuad:**\nexprQuad extends this to add x'Qx quadratic terms.",
    "file": "CouenneExprGroup",
    "library": "Couenne",
    "layer": "layer-3",
    "header": "src/expression/operators/CouenneExprGroup.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "CouenneExprJac": {
    "brief": "Symbolic Jacobian of constraints via expression DAG\n\nStores the constraint Jacobian as a sparse matrix of expression\npointers. Each nonzero \u2202g_i/\u2202x_j is an expression node that can\nbe evaluated at any point.\n\n**Sparse structure:**\n- nnz_: Number of structural nonzeros\n- iRow_[], jCol_[]: COO format indices\n- expr_[k]: Expression for the k-th nonzero entry\n\n**Construction:**\nBuilt from CouenneProblem by differentiating each constraint\nbody expression with respect to each variable it depends on.\n\n**Usage:**\nCalled by Ipopt's eval_jac_g() callback to provide the\nconstraint Jacobian. Expression-based representation allows\nexact derivatives without finite differences.",
    "file": "CouenneExprJac",
    "library": "Couenne",
    "layer": "layer-3",
    "header": "src/expression/partial/CouenneExprJac.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "CouenneExprHess": {
    "brief": "Symbolic Hessian of Lagrangian via expression DAG\n\nStores the Hessian of the Lagrangian:\n\u2207\u00b2L(x,\u03bb) = \u2207\u00b2f(x) + \u03a3\u1d62 \u03bb\u1d62 \u2207\u00b2g\u1d62(x)\n\n**Sparse structure:**\n- nnz_: Number of structural nonzeros (lower triangle)\n- iRow_[], jCol_[]: COO format indices\n- numL_[k]: How many \u03bb\u1d62 contribute to position k\n- lamI_[k][]: Indices of contributing \u03bb\u1d62\n- expr_[k][j]: Expression for \u2202\u00b2g\u2c7c/\u2202x_iRow[k]\u2202x_jCol[k]\n\n**Evaluation:**\nFor each nonzero position (i,j), sum over all constraints:\nH[i,j] = expr_obj[i,j] + \u03a3\u2096 \u03bb[lamI[k]] * expr[k][...]\n\n**Feasibility pump extension:**\nCan be extended with gg' term for feasibility pump objectives\nby augmenting the objective with ||x - x\u0304||\u00b2 + gradient terms.",
    "file": "CouenneExprHess",
    "library": "Couenne",
    "layer": "layer-3",
    "header": "src/expression/partial/CouenneExprHess.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "CouenneExprBCos": {
    "brief": "Bound operators for cosine expressions\n\nComputes tight bounds for cos(x) given bounds [l, u] on x.\nUsed by FBBT (feasibility-based bound tightening) to propagate\nbounds through trigonometric expressions.\n\n**exprLBCos (lower bound):**\n- Returns -1 if interval spans full period (u - l >= 2\u03c0)\n- Returns -1 if interval contains \u03c0 + 2k\u03c0 (minimum of cos)\n- Otherwise returns min(cos(l), cos(u))\n\n**exprUBCos (upper bound):**\n- Returns +1 if interval spans full period\n- Returns +1 if interval contains 2k\u03c0 (maximum of cos)\n- Otherwise returns max(cos(l), cos(u))\n\n**Period handling:**\nUses floor(l/2\u03c0 - offset) < floor(u/2\u03c0 - offset) to detect\nif critical points lie within [l, u].",
    "file": "CouenneExprBCos",
    "library": "Couenne",
    "layer": "layer-3",
    "header": "src/expression/operators/bounds/CouenneExprBCos.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "CouenneExprBDiv": {
    "brief": "Bound operators for division expressions\n\nComputes tight bounds for n/d given bounds [n, N] on numerator\nand [d, D] on denominator. Handles singularity at d = 0.\n\n**safeDiv():**\nUtility for safe division avoiding NaN:\n- Returns 0 if numerator is ~0\n- Returns \u00b1\u221e if denominator is ~0 (sign-aware)\n- Otherwise returns a/b\n\n**exprLBDiv (lower bound):**\nCase analysis on signs:\n- d > 0: positive denominator \u2192 lb = n/D or n/d\n- d \u2264 0, D > 0: crosses zero \u2192 -\u221e (unbounded)\n- d \u2264 0, D \u2264 0: negative denominator \u2192 lb = N/D or N/d\n\n**exprUBDiv (upper bound):**\nSymmetric case analysis:\n- d > 0: ub = N/D or N/d\n- d \u2264 0, D > 0: crosses zero \u2192 +\u221e\n- d \u2264 0, D \u2264 0: ub = n/D or n/d",
    "file": "CouenneExprBDiv",
    "library": "Couenne",
    "layer": "layer-3",
    "header": "src/expression/operators/bounds/CouenneExprBDiv.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "CouenneExprBQuad": {
    "brief": "Bound expressions for quadratic forms\n\nExpression classes that compute bounds on quadratic forms\n\u2211 q\u1d62\u2c7c\u00b7x\u1d62\u00b7x\u2c7c + \u2211 b\u1d62\u00b7x\u1d62 + c given variable bounds.\n\n**exprLBQuad:**\nReturns lower bound on the quadratic form by calling\ncomputeQBound(-1) on the referenced exprQuad.\n\n**exprUBQuad:**\nReturns upper bound on the quadratic form by calling\ncomputeQBound(+1) on the referenced exprQuad.\n\n**Bound computation (in exprQuad):**\nUses eigenvalue-based approach when Q is indefinite:\n- Decompose Q = \u2211 \u03bb\u1d62\u00b7v\u1d62\u00b7v\u1d62\u1d40\n- Bound each eigenterm using variable bounds\n- Sum contributions accounting for sign of \u03bb\u1d62\n\n**Usage in FBBT:**\nThese expressions enable bound tightening on quadratic\nconstraints without explicitly enumerating all bilinear terms.",
    "file": "CouenneExprBQuad",
    "library": "Couenne",
    "layer": "layer-3",
    "header": "src/expression/operators/bounds/CouenneExprBQuad.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "CouenneExprBMul": {
    "brief": "Bound operators for bilinear product expressions\n\nComputes tight bounds for x * y given bounds [n, N] on x\nand [d, D] on y. Used by FBBT for bound propagation.\n\n**safeProd():**\nUtility for safe multiplication avoiding overflow:\n- Handles \u00b1\u221e * 0 \u2192 0\n- Handles \u00b1\u221e * finite \u2192 \u00b1\u221e (sign-aware)\n- Otherwise returns a * b\n\n**exprLBMul (lower bound):**\nFor bounds [n, N] \u00d7 [d, D]:\n- d \u2265 0, n \u2265 0: lb = n * d\n- d \u2265 0, n < 0: lb = n * D\n- d < 0, N > 0: lb = min(N * d, n * D)\n- d < 0, N \u2264 0, D > 0: lb = n * D\n- d < 0, N \u2264 0, D \u2264 0: lb = N * D\n\n**exprUBMul (upper bound):**\nSymmetric case analysis yielding max of corner products.\n\n**Note:** The four corners {n, N} \u00d7 {d, D} contain the\nextrema for bilinear functions over boxes.",
    "file": "CouenneExprBMul",
    "library": "Couenne",
    "layer": "layer-3",
    "header": "src/expression/operators/bounds/CouenneExprBMul.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "CouenneExprBSin": {
    "brief": "Bound operators for sine expressions\n\nComputes tight bounds for sin(x) given bounds [l, u] on x.\nUsed by FBBT (feasibility-based bound tightening) to propagate\nbounds through trigonometric expressions.\n\n**exprLBSin (lower bound):**\n- Returns -1 if interval spans full period (u - l >= 2\u03c0)\n- Returns -1 if interval contains 3\u03c0/2 + 2k\u03c0 (minimum of sin)\n- Otherwise returns min(sin(l), sin(u))\n\n**exprUBSin (upper bound):**\n- Returns +1 if interval spans full period\n- Returns +1 if interval contains \u03c0/2 + 2k\u03c0 (maximum of sin)\n- Otherwise returns max(sin(l), sin(u))\n\n**Period handling:**\nUses floor(l/2\u03c0 - offset) < floor(u/2\u03c0 - offset) to detect\nif critical points lie within [l, u]:\n- offset = 0.75 for min (3\u03c0/2)\n- offset = 0.25 for max (\u03c0/2)",
    "file": "CouenneExprBSin",
    "library": "Couenne",
    "layer": "layer-3",
    "header": "src/expression/operators/bounds/CouenneExprBSin.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "CouenneTwoImplied": {
    "brief": "Bound tightening from pairs of linear constraints",
    "file": "CouenneTwoImplied",
    "library": "Couenne",
    "layer": "layer-3",
    "header": "src/bound_tightening/twoImpliedBT/CouenneTwoImplied.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "CouenneDepGraph": {
    "brief": "Dependency graph between auxiliary and original variables",
    "file": "CouenneDepGraph",
    "library": "Couenne",
    "layer": "layer-3",
    "header": "src/problem/depGraph/CouenneDepGraph.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "CouenneCrossConv": {
    "brief": "Cuts from redundant relationships between auxiliary variables",
    "file": "CouenneCrossConv",
    "library": "Couenne",
    "layer": "layer-3",
    "header": "src/cut/crossconv/CouenneCrossConv.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "CouennePSDcon": {
    "brief": "Positive semidefinite constraint X \u2ab0 0\n\nRepresents a constraint that a matrix of expressions must be\npositive semidefinite (all eigenvalues non-negative).\n\n**Mathematical meaning:**\nX \u2ab0 0 is equivalent to:\n- All eigenvalues of X are non-negative\n- v'Xv >= 0 for all vectors v\n- X can be written as X = A'A for some matrix A\n\n**Common usage:**\n- Product matrices: X_ij = x_i * x_j must be PSD\n- Covariance matrices in statistics\n- Second-order cone constraints (via PSD embedding)\n\n**Handling in Couenne:**\nPSD constraints are not directly enforceable in MILP/NLP.\nInstead, they are enforced via:\n1. SDP cuts (see CouenneSdpCuts)\n2. Eigenvalue constraints (expensive)\n3. Principal minor constraints",
    "file": "CouennePSDcon",
    "library": "Couenne",
    "layer": "layer-3",
    "header": "src/cut/sdpcuts/CouennePSDcon.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "CouenneSdpCuts": {
    "brief": "SDP-based cutting planes using matrix positive semidefiniteness\n\nGenerates cuts exploiting that product matrices X = (x_ij) where x_ij = x_i*x_j\nmust be positive semidefinite. These cuts strengthen the LP relaxation beyond\nwhat McCormick envelopes provide.",
    "file": "CouenneSdpCuts",
    "library": "Couenne",
    "layer": "layer-3",
    "header": "src/cut/sdpcuts/CouenneSdpCuts.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "dsyevx_wrapper": {
    "brief": "LAPACK dsyevx wrapper for symmetric eigenvalue computation\n\nC++ interface to LAPACK's dsyevx routine for computing selected\neigenvalues and eigenvectors of a real symmetric matrix.\n\n**dsyevx_interface parameters:**\n- n: Matrix dimension\n- A: Input symmetric matrix (upper or lower triangle)\n- m: [out] Number of eigenvalues found\n- w: [out] Eigenvalues in ascending order\n- z: [out] Eigenvectors (column-wise)\n- tolerance: Relative accuracy for eigenvalues\n- lb_ev, ub_ev: Eigenvalue range to compute (RANGE='V')\n- firstidx, lastidx: Index range to compute (RANGE='I')\n\n**Usage in Couenne:**\nUsed by CouenneSdpCuts to compute negative eigenvalues of the\nlifted matrix X - xx\u1d40, where violations indicate cuts.\n\n**Algorithm:**\nDSYEVX uses bisection followed by inverse iteration for\nselected eigenvalues, more efficient than full diagonalization.",
    "file": "dsyevx_wrapper",
    "library": "Couenne",
    "layer": "layer-3",
    "header": "src/cut/sdpcuts/dsyevx_wrapper.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "CouenneMatrix": {
    "brief": "Sparse matrix and vector of expressions\n\nData structures for representing matrices of Couenne expressions,\nused primarily for SDP cuts and PSD constraints.\n\n**Classes:**\n- CouenneScalar: Single indexed expression element\n- CouenneSparseVector: Sparse vector of expressions (ordered set)\n- CouenneExprMatrix: Sparse matrix with row and column major storage\n\n**Storage:**\nUses std::set with custom comparators for O(log n) lookup.\nBoth row-major and column-major views maintained for efficient\nmatrix-vector and matrix-matrix operations.\n\n**Usage in SDP cuts:**\nX = (x_ij) where x_ij is the auxiliary for product x_i * x_j.\nvarIndices_ stores the original variables x_i used in products.\n\n**Operations:**\n- Vector dot product: v1 * v2\n- Matrix-vector product: M * v\n- Matrix-matrix product: M1 * M2\n- Threshold multiplication (early termination)",
    "file": "CouenneMatrix",
    "library": "Couenne",
    "layer": "layer-3",
    "header": "src/cut/sdpcuts/CouenneMatrix.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "CouenneEllipCuts": {
    "brief": "Ellipsoidal cuts for nonconvex quadratic constraints\n\nPlaceholder for ellipsoidal cutting planes derived from\nthe geometry of quadratic constraints.\n\n**Concept (not yet implemented):**\nFor a quadratic constraint x\u1d40Qx + b\u1d40x \u2264 c, the feasible\nregion forms an ellipsoid (if Q \u227b 0). Ellipsoidal cuts\nexploit this structure for tighter relaxations.\n\n@note Currently empty - functionality may be in development\n      or handled elsewhere (e.g., CouenneSdpCuts).",
    "file": "CouenneEllipCuts",
    "library": "Couenne",
    "layer": "layer-3",
    "header": "src/cut/ellipcuts/CouenneEllipCuts.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "cons_rowcuts": {
    "brief": "constraint handler for rowcuts constraints\n        enables separation of convexification cuts during SCIP solution procedure",
    "file": "cons_rowcuts",
    "library": "Couenne",
    "layer": "layer-3",
    "header": "src/heuristics/cons_rowcuts.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "DecompApp": {
    "brief": "User application interface - derive to define your decomposition\n\nDecompApp is the main user-facing class. Derive from it to define:\n- Model decomposition (core vs relaxed constraints)\n- Subproblem solvers\n- Problem-specific heuristics",
    "file": "DecompApp",
    "library": "Dip",
    "layer": "layer-3",
    "header": "Dip/src/DecompApp.h",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "DecompCutPool": {
    "brief": "Pool of generated cuts (DecompCut) for cut management\n\nDecompCutPool manages cuts waiting to enter the master problem.\nInherits from std::vector<DecompWaitingRow> for storage.\n\n**Key Functions:**\n- reExpand(): Regenerate row coefficients when columns change\n- createRowReform(): Transform x-space cut to lambda-space\n- setViolations(): Calculate cut violations vs current solution\n\n**Cut Selection:**\n- is_greater_thanD comparator sorts by violation\n- Most violated cuts enter master first\n- Duplicate cuts filtered via hash\n\n**Reformulation:**\nCuts in x-space must be reformulated to lambda-space for\nDantzig-Wolfe master: a'x >= b becomes a'(sum_s s*lambda_s) >= b\ncreateRowReform() handles this transformation.\n\n**Validity Flag:**\n- m_rowsAreValid: Track if cuts need re-expansion\n- Set false when column set changes\n- reExpand() regenerates coefficients",
    "file": "DecompCutPool",
    "library": "Dip",
    "layer": "layer-3",
    "header": "Dip/src/DecompCutPool.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "DecompAlgoCGL": {
    "brief": "Interface to CGL (COIN-OR Cut Generation Library)\n\nDecompAlgoCGL wraps CGL cut generators for use in DIP algorithms.\nProvides automatic generation of standard MIP cuts.\n\n**Available CGL Generators:**\n- CglClique: Clique cuts from conflict graph\n- CglOddHole: Odd hole inequalities\n- CglFlowCover: Flow cover cuts\n- CglKnapsackCover: Knapsack cover cuts\n- CglMixedIntegerRounding2: MIR cuts\n- CglGomory: Gomory mixed-integer cuts\n\n**Usage:**\n- Created by DecompAlgo during initialization\n- Called during PHASE_CUT to generate cuts\n- Returns cuts via DecompCutOsi wrapper\n\n**Configuration:**\n- Generators enabled/disabled via DecompParam\n- Per-generator parameters can be set\n- Different strategies for PC vs C algorithms\n\n**Integration:**\nCGL generates cuts in x-space. For Price-and-Cut, these are\nreformulated to lambda-space before adding to master.",
    "file": "DecompAlgoCGL",
    "library": "Dip",
    "layer": "layer-3",
    "header": "Dip/src/DecompAlgoCGL.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "DecompCut": {
    "brief": "Cut representation in original x-space\n\nDecompCut represents a cutting plane (valid inequality) that can be\nadded to strengthen the formulation. Cuts are defined in original\nx-space and expanded to the master problem.",
    "file": "DecompCut",
    "library": "Dip",
    "layer": "layer-3",
    "header": "Dip/src/DecompCut.h",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "DecompConstraintSet": {
    "brief": "Storage for constraint matrix and bounds (A, b, l, u)\n\nDecompConstraintSet stores the full specification of a constraint set\nused in decomposition: matrix, row/column bounds, integrality markers.\n\n**Matrix Storage:**\n- M: CoinPackedMatrix (row-major or column-major)\n- rowLB, rowUB: Row bounds (rowLB <= Ax <= rowUB)\n- colLB, colUB: Variable bounds\n- rowSense, rowRhs: Alternative row format ('L', 'G', 'E', 'R')\n\n**Variable Information:**\n- integerVars: Indices of integer variables\n- integerMark: 'I' for integer, 'C' for continuous\n- colNames, rowNames: Human-readable names\n\n**Block Structure:**\n- activeColumns: Which columns appear in this block\n- activeColumnsS: Set version for O(1) lookup\n- masterOnlyCols: Columns that only appear in master\n\n**Sparse Representation:**\nFor blocks with few active columns:\n- m_isSparse: Enable sparse mode\n- m_origToSparse, m_sparseToOrig: Column mappings\nReduces memory for blocks with disjoint variable sets.",
    "file": "DecompConstraintSet",
    "library": "Dip",
    "layer": "layer-3",
    "header": "Dip/src/DecompConstraintSet.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "AlpsDecompTreeNode": {
    "brief": "ALPS tree node for DIP branch-and-bound\n\nAlpsDecompTreeNode represents a node in the B&B tree, deriving from\nAlpsTreeNode to integrate with ALPS's tree management.\n\n**Key Responsibilities:**\n- Store branching decisions (bound changes from parent)\n- Implement process() to solve node via DecompAlgo\n- Implement branch() to create child nodes\n- Check for new incumbents\n\n**Branching Storage:**\n- downBranchLB_, downBranchUB_: Bounds for down branch\n- upBranchLB_, upBranchUB_: Bounds for up branch\nStored as (var_index, bound_value) pairs.\n\n**Key Methods:**\n- process(): Main bounding - calls DecompAlgo::processNode()\n- branch(): Create children with new bounds\n- checkIncumbent(): Test if solution improves best known\n- createNewTreeNode(): Factory for child nodes\n\n**Node Processing Flow:**\n1. ALPS selects node from tree\n2. Calls process() which invokes DecompAlgo\n3. DecompAlgo returns bound and status\n4. If fractional, branch() creates children",
    "file": "AlpsDecompTreeNode",
    "library": "Dip",
    "layer": "layer-3",
    "header": "Dip/src/AlpsDecompTreeNode.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "AlpsDecompModel": {
    "brief": "ALPS integration - model class bridging DIP and ALPS B&B\n\nAlpsDecompModel derives from AlpsModel to integrate DIP's decomposition\nalgorithms with ALPS's branch-and-bound framework.\n\n**Key Responsibilities:**\n- Hold pointer to active DecompAlgo\n- Create root node (AlpsDecompTreeNode)\n- Manage solution pool and incumbent\n- Handle ALPS callbacks and parameters\n\n**ALPS Hierarchy:**\nAlpsKnowledge -> AlpsModel -> AlpsDecompModel\n\n**Key Methods:**\n- createRoot(): Create initial tree node\n- setupSelf(): Initialize from parameters\n- registerKnowledge(): Register solution types\n\n**Data Flow:**\n1. User creates DecompApp and DecompAlgo\n2. AlpsDecompModel wraps the algorithm\n3. ALPS drives B&B, calling process() on nodes\n4. Nodes delegate to DecompAlgo for bounding",
    "file": "AlpsDecompModel",
    "library": "Dip",
    "layer": "layer-3",
    "header": "Dip/src/AlpsDecompModel.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "DecompVar": {
    "brief": "Column generation variable (lambda) representation\n\nDecompVar represents a column in the Dantzig-Wolfe reformulation.\nEach lambda_s corresponds to an extreme point s of a subproblem\npolyhedron: conv{x : A'x >= b', x integer}.",
    "file": "DecompVar",
    "library": "Dip",
    "layer": "layer-3",
    "header": "Dip/src/DecompVar.h",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "DecompWaitingCol": {
    "brief": "Wrapper pairing DecompVar with its master column coefficients\n\nDecompWaitingCol bundles a DecompVar (the x-space representation)\nwith its expanded column (A''s) for the master problem.\n\n**Data Members:**\n- m_var: The variable in x-space (extreme point s)\n- m_col: CoinPackedVector of (A''s) master coefficients\n\n**Purpose:**\nWhen pricing generates a new column s, we need both:\n1. The x-space representation for solution reconstruction\n2. The master coefficients for LP updates\nThis class keeps them paired.\n\n**Lifecycle:**\n- Created during pricing when subproblem returns solution\n- Stored in DecompVarPool\n- m_col regenerated via reExpand() when master changes\n- Eventually transferred to master LP",
    "file": "DecompWaitingCol",
    "library": "Dip",
    "layer": "layer-3",
    "header": "Dip/src/DecompWaitingCol.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "DecompStats": {
    "brief": "Statistics tracking for DIP algorithm performance\n\nProvides classes for recording and reporting algorithm statistics.\n\n**DecompObjBound:**\nRecords bound history at checkpoints:\n- phase, cutPass, pricePass: Algorithm state\n- timeStamp: Wall clock from start\n- thisBound/thisBoundUB: Current node bounds\n- bestBound: Global lower bound\n- thisBoundIP: Best integer solution\n\n**DecompStats:**\nAggregate statistics for the algorithm:\n- objHistoryBound: Vector of DecompObjBound snapshots\n- Various timers for profiling subsystems\n- Counts of cuts/columns generated\n\n**Usage:**\n- DecompAlgo creates and updates stats during execution\n- Bound history enables convergence analysis\n- Timers help identify bottlenecks",
    "file": "DecompStats",
    "library": "Dip",
    "layer": "layer-3",
    "header": "Dip/src/DecompStats.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "DecompWaitingRow": {
    "brief": "Wrapper pairing DecompCut with its row coefficients\n\nDecompWaitingRow bundles a DecompCut with both its x-space row\nand reformulated lambda-space row for the master problem.\n\n**Data Members:**\n- m_cut: The cut object with bounds and metadata\n- m_row: CoinPackedVector in original x-space\n- m_rowReform: CoinPackedVector in lambda-space for master\n\n**Reformulation:**\nOriginal cut: a'x >= b\nIn master: sum_s (a's)lambda_s >= b\nm_rowReform stores coefficients (a's) for each lambda variable.\n\n**Lifecycle:**\n- Created during cut generation\n- Stored in DecompCutPool\n- m_rowReform computed via createRowReform()\n- Eventually added to master LP",
    "file": "DecompWaitingRow",
    "library": "Dip",
    "layer": "layer-3",
    "header": "Dip/src/DecompWaitingRow.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "DecompParam": {
    "brief": "Comprehensive parameter class for DIP algorithm configuration\n\nDecompParam contains 100+ parameters controlling all aspects of DIP\ndecomposition algorithms. Parameters read from file via UtilParameters.\n\n**Logging Parameters:**\n- LogLevel: Verbosity (0=silent to 5=debug)\n- LogDumpModel: When to dump LP models (0=never, 2=always)\n- LogObjHistory: Print objective progress\n\n**Algorithm Limits:**\n- TotalCutItersLimit, TotalPriceItersLimit: Iteration caps\n- RoundCutItersLimit, RoundPriceItersLimit: Per-round limits\n- TimeLimit: Wall clock limit\n- NodeLimit: Max B&B nodes\n\n**Subproblem Control:**\n- SubProbTimeLimitExact: Time for exact subproblem solves\n- SubProbTimeLimitHeur: Time for heuristic solves\n- SubProbNumSolLimit: Max solutions per subproblem\n- SubProbParallelType: OpenMP scheduling strategy\n\n**Dual Stabilization:**\n- DualStab: Enable Wentges stabilization\n- DualStabAlpha: Smoothing parameter [0,1]\n\n**Branching:**\n- BranchEnforceInSubProb: Branch on x in subproblems\n- BranchEnforceInMaster: Branch on lambda in master\n\n**Strategy:**\n- PCStrategy: Balance pricing vs cutting\n- CutCglStrategy: Which CGL cuts to use",
    "file": "DecompParam",
    "library": "Dip",
    "layer": "layer-3",
    "header": "Dip/src/DecompParam.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "DecompAlgo": {
    "brief": "Base class for all DIP decomposition algorithms\n\nDecompAlgo is the algorithmic engine that orchestrates:\n- Master problem management (LP relaxation)\n- Subproblem solving (pricing/column generation)\n- Cut generation and management\n- Phase transitions and convergence\n\n**Key Data Members:**\n- m_masterSI: Master LP solver interface\n- m_app: Pointer to user's DecompApp\n- m_modelCore/m_modelRelax: Problem decomposition\n- m_vars/m_cuts: Generated columns and cuts\n- m_xhat: Current LP solution in original x-space\n\n**Algorithm Phases:**\n- PHASE_PRICE1: Feasibility with artificial variables\n- PHASE_PRICE2: Optimizing with generated columns\n- PHASE_CUT: Adding violated inequalities\n\n**Virtual Methods for Subclasses:**\n- createMasterProblem(): Build initial restricted master\n- processNode(): Main node processing loop\n- generateVars(): Column generation (pricing)\n- generateCuts(): Cut separation\n- getMasterDualSolution(): Dual values for pricing\n\n**Derived Classes:**\n- DecompAlgoPC: Price-and-Cut (Dantzig-Wolfe)\n- DecompAlgoC: Cutting plane only\n- DecompAlgoRC: Relax-and-Cut (Lagrangian)",
    "file": "DecompAlgo",
    "library": "Dip",
    "layer": "layer-3",
    "header": "Dip/src/DecompAlgo.h",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "DecompModel": {
    "brief": "Wrapper classes for constraint sets used in decomposition\n\nProvides model containers that wrap DecompConstraintSet with\nmetadata and optional solver interfaces.\n\n**DecompModel:**\nBasic wrapper for a constraint set (A'x >= b' or A''x >= b'')\n- m_model: Pointer to the constraint set\n- m_modelName: Human-readable name for debugging\n- m_blockId: Which block this belongs to (-1 for core)\n\n**DecompSubModel:**\nExtended model with OsiSolverInterface for subproblem solving\n- m_osi: Solver interface (Clp, Cpx, Grb, etc.)\n- solveAsMIP(): Solve subproblem as MIP\n- Used when user doesn't provide custom solveRelaxed()\n\n**Usage in Decomposition:**\n- Core model (A''): Linking constraints kept in master\n- Relax models (A'): Block constraints for subproblems\n- Each block b has m_modelRelax[b] in DecompApp",
    "file": "DecompModel",
    "library": "Dip",
    "layer": "layer-3",
    "header": "Dip/src/DecompModel.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "AlpsDecompSolution": {
    "brief": "ALPS solution wrapper for DIP incumbent solutions\n\nAlpsDecompSolution derives from AlpsSolution to integrate DIP\nsolutions with ALPS's solution management and reporting.\n\n**Data Members:**\n- m_size: Number of variables\n- m_values: Solution vector\n- m_quality: Objective value\n- m_app: Pointer to DecompApp for printing\n\n**ALPS Integration:**\n- Stored in ALPS solution pool\n- Used for incumbent tracking\n- Supports encode/decode for parallelism\n\n**Lifecycle:**\n- Created when DIP finds integer-feasible solution\n- Passed to ALPS via registerKnowledge()\n- Best solution reported at termination",
    "file": "AlpsDecompSolution",
    "library": "Dip",
    "layer": "layer-3",
    "header": "Dip/src/AlpsDecompSolution.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "AlpsDecompNodeDesc": {
    "brief": "ALPS node descriptor storing branching bounds\n\nAlpsDecompNodeDesc derives from AlpsNodeDesc to store the\ndescription of a tree node for serialization and reconstruction.\n\n**Storage:**\nDIP doesn't use full differencing (delta encoding), so node\ndescriptions primarily store bound changes from branching:\n- Variable lower/upper bound modifications\n- Warm start basis (optional)\n\n**Key Methods:**\n- encode(): Serialize to AlpsEncoded for transmission\n- decode(): Reconstruct from encoded form\n\n**ALPS Integration:**\n- Each AlpsDecompTreeNode has an AlpsDecompNodeDesc\n- Used for checkpointing and parallel distribution\n- Compact representation for tree storage",
    "file": "AlpsDecompNodeDesc",
    "library": "Dip",
    "layer": "layer-3",
    "header": "Dip/src/AlpsDecompNodeDesc.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "DecompAlgoRC": {
    "brief": "Relax-and-Cut algorithm (Lagrangian relaxation with cuts)\n\nDecompAlgoRC implements Lagrangian relaxation:\n- Dualize complicating constraints with multipliers u\n- Solve Lagrangian subproblem: min (c - u'A'')x s.t. A'x >= b'\n- Update multipliers via subgradient optimization\n- Add cuts to improve bounds",
    "file": "DecompAlgoRC",
    "library": "Dip",
    "layer": "layer-3",
    "header": "Dip/src/DecompAlgoRC.h",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "Decomp": {
    "brief": "Central header with enums, constants, and solver interfaces for DIP\n\nThis is the foundational include for DIP (Decomposition for Integer\nProgramming). It provides all enums, constants, and conditional solver\ninterface includes.",
    "file": "Decomp",
    "library": "Dip",
    "layer": "layer-3",
    "header": "Dip/src/Decomp.h",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "DecompMemPool": {
    "brief": "Pre-allocated memory arrays for performance\n\nDecompMemPool provides reusable scratch arrays to avoid repeated\nallocations during the inner loops of the algorithm.\n\n**Pre-allocated Arrays:**\n- dblArrNCoreCols: Double array sized for core columns\n- dblArrNCoreRows: Double array sized for core rows\n\n**Usage:**\nRather than allocating temporary arrays in hot paths like\nreduced cost calculation or constraint evaluation, use these\npre-allocated buffers for better cache performance.\n\n**Memory Management:**\n- allocateMemory(): Size arrays based on problem dimensions\n- Destructor frees all allocated memory\n- Single allocation at algorithm start",
    "file": "DecompMemPool",
    "library": "Dip",
    "layer": "layer-3",
    "header": "Dip/src/DecompMemPool.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "DecompAlgoPC": {
    "brief": "Price-and-Cut algorithm (Dantzig-Wolfe decomposition with cuts)\n\nDecompAlgoPC implements the most powerful DIP algorithm combining:\n- Column generation (pricing subproblems)\n- Cut generation (violated inequalities)\n- Branch-and-bound integration via ALPS",
    "file": "DecompAlgoPC",
    "library": "Dip",
    "layer": "layer-3",
    "header": "Dip/src/DecompAlgoPC.h",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "DecompSolution": {
    "brief": "Solution storage for feasible/incumbent solutions\n\nDecompSolution stores primal solutions found during decomposition\n(from heuristics, subproblems, or node processing).\n\n**Key Data Members:**\n- m_size: Number of variables (columns)\n- m_values: Solution vector x*\n- m_quality: Objective value c'x* (for incumbent tracking)\n\n**Solution Sources:**\n- Subproblem solutions (during pricing)\n- User heuristics (DecompApp::APPheuristics)\n- Rounding/diving heuristics\n- Integer LP solutions\n\n**Output Methods:**\n- print(): Display solution with specified precision\n- printMIPLIB(): Output in MIPLIB solution format\n\n**Integration:**\nSolutions are passed to ALPS via AlpsDecompModel for\nincumbent tracking and solution reporting.",
    "file": "DecompSolution",
    "library": "Dip",
    "layer": "layer-3",
    "header": "Dip/src/DecompSolution.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "DecompSolverResult": {
    "brief": "Container for subproblem/LP solver results\n\nDecompSolverResult captures all outputs from solving a subproblem\nor LP relaxation, including status, bounds, and solutions.\n\n**Status Information:**\n- m_solStatus: Solver-specific status code\n- m_isOptimal: True if proven optimal\n- m_isUnbounded: True if unbounded detected\n- m_isCutoff: True if cutoff by bound\n\n**Bounds:**\n- m_objLB: Lower bound on optimal value\n- m_objUB: Upper bound / incumbent value\n\n**Solutions:**\n- m_nSolutions: Number of solutions found\n- m_solution: Vector of solution vectors (for solution pools)\n\n**Usage:**\nReturned by subproblem solvers to DecompAlgo. Used for:\n- Generating new columns (m_solution contains extreme points)\n- Checking feasibility (m_isOptimal, m_solStatus)\n- Updating bounds (m_objLB, m_objUB)",
    "file": "DecompSolverResult",
    "library": "Dip",
    "layer": "layer-3",
    "header": "Dip/src/DecompSolverResult.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "DecompVarPool": {
    "brief": "Pool of generated columns (DecompVar) for column generation\n\nDecompVarPool manages columns waiting to enter the master problem.\nInherits from std::vector<DecompWaitingCol> for storage.",
    "file": "DecompVarPool",
    "library": "Dip",
    "layer": "layer-3",
    "header": "Dip/src/DecompVarPool.h",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "DecompAlgoC": {
    "brief": "Cutting Plane Method algorithm (no column generation)\n\nDecompAlgoC implements classic cutting plane method:\n- Solve LP relaxation\n- Find violated cuts\n- Add cuts and resolve\n- Repeat until integer or no cuts found",
    "file": "DecompAlgoC",
    "library": "Dip",
    "layer": "layer-3",
    "header": "Dip/src/DecompAlgoC.h",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "DippyDecompAlgo": {
    "brief": "",
    "file": "DippyDecompAlgo",
    "library": "Dip",
    "layer": "layer-3",
    "header": "Dip/src/dippy/DippyDecompAlgo.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "DcoHeuristic": {
    "brief": "Abstract base class for primal heuristics",
    "file": "DcoHeuristic",
    "library": "DisCO",
    "layer": "layer-3",
    "header": "src/DcoHeuristic.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "DcoModel": {
    "brief": "Main model class for Mixed-Integer Conic Optimization\n\nDcoModel derives from BcpsModel and represents the master MISOCP problem.\nIt manages problem data, solver interfaces, and algorithm configuration.\n\n**Two Solving Modes:**\n- Direct conic: Uses OsiConicSolverInterface (CPLEX, Mosek)\n- OA (Outer Approximation): Uses OsiSolverInterface with linear cuts\n\n**Problem Structure:**\n- matrix_: Linear constraint matrix (CoinPackedMatrix)\n- coneStart_, coneMembers_, coneType_: Conic constraints\n- integerCols_: Indices of integer variables\n- relaxedCols_, relaxedRows_: Objects with relaxed integrality/cone\n\n**Algorithm Components:**\n- branchStrategy_: Variable selection (MaxInf, Pseudo, Strong, Reliability)\n- conGenerators_: Map of constraint generators (MILP + conic cuts)\n- heuristics_: Primal heuristics (rounding)\n\n**Key Virtual Methods:**\n- readInstance(): Load MPS or CBF files\n- setupSelf(): Initialize solver, cuts, heuristics\n- createRoot(): Create root DcoTreeNode\n- feasibleSolution(): Check integer and cone feasibility",
    "file": "DcoModel",
    "library": "DisCO",
    "layer": "layer-3",
    "header": "src/DcoModel.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "DcoNodeDesc": {
    "brief": "Tree node description storing branching and warm-start data\n\nDcoNodeDesc stores the information that distinguishes a tree node\nfrom its parent, enabling node reconstruction and pseudocost updates.\n\n**Inheritance:** DcoNodeDesc -> BcpsNodeDesc -> AlpsNodeDesc\n\n**Branching Data (for pseudocost updates):**\n- branchedDir_: Up or down branch direction\n- branchedInd_: Index of variable branched on\n- branchedVal_: Value at which branching occurred\n\n**Warm Start:**\n- basis_: CoinWarmStartBasis for LP warm-starting\n\n**From BcpsNodeDesc (inherited):**\n- vars_: Variable bound modifications (BcpsObjectListMod)\n- cons_: Constraint modifications (BcpsObjectListMod)\n\n**Serialization:**\nencode()/decode() for parallel tree distribution.",
    "file": "DcoNodeDesc",
    "library": "DisCO",
    "layer": "layer-3",
    "header": "src/DcoNodeDesc.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "DcoConstraint": {
    "brief": "Abstract base class for DisCO constraints\n\nDcoConstraint is the base class for all constraints in DisCO,\nsupporting both linear and conic constraint types.\n\n**Inheritance:** DcoConstraint -> BcpsConstraint -> BcpsObject -> AlpsKnowledge\n\n**Constraint Hierarchy:**\n- DcoConstraint (ABC)\n  - DcoLinearConstraint: Linear row with coefficients\n  - DcoConicConstraint: Lorentz or rotated Lorentz cone\n\n**Type Field (DcoConstraintType):**\n- Core: Original problem constraints\n- MILP cuts: Clique, Gomory, MIR, etc.\n- Conic cuts: IPM, OA approximations\n\n**Key Methods:**\n- createOsiRowCut(): Convert to OsiRowCut (returns NULL for conic)\n- constraintType(): Get/set the constraint source type",
    "file": "DcoConstraint",
    "library": "DisCO",
    "layer": "layer-3",
    "header": "src/DcoConstraint.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "DcoConicConstraint": {
    "brief": "Second-order cone (Lorentz cone) constraint representation\n\nDcoConicConstraint represents conic constraints of two types:\n- Lorentz cone: ||x_1...x_{n-1}|| <= x_n\n- Rotated Lorentz cone: 2*x_1*x_2 >= ||x_3...x_n||^2\n\n**Data Members:**\n- coneType_: DcoLorentzCone or DcoRotatedLorentzCone\n- coneSize_: Number of variables in cone\n- members_: Variable indices forming the cone\n- supports_: Linear constraints approximating the cone (OA)\n- activeSupports_: Which supports are binding\n\n**OA (Outer Approximation):**\nWhen using linear solvers, conic constraints are approximated by\nlinear supporting hyperplanes. The supports_ array stores these\ncuts, and activeSupports_ tracks which are currently tight.\n\n**Feasibility:**\ninfeasibility() returns the cone violation at the current solution,\nused to decide if more OA cuts are needed.",
    "file": "DcoConicConstraint",
    "library": "DisCO",
    "layer": "layer-3",
    "header": "src/DcoConicConstraint.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "DcoVariable": {
    "brief": "Variable representation for MISOCP\n\nDcoVariable represents a decision variable in the optimization problem,\nstoring bounds, integrality type, and branching information.\n\n**Inheritance:** DcoVariable -> BcpsVariable -> BcpsObject -> AlpsKnowledge\n\n**BcpsObject Fields (inherited):**\n- lbHard_/ubHard_: Original bounds\n- lbSoft_/ubSoft_: Current bounds (may be tighter from branching)\n- intType_: Integer ('I'), binary ('B'), or continuous ('C')\n- objectIndex_: Position in model's variable array\n\n**Key Methods:**\n- infeasibility(): Returns integrality violation (for integer variables)\n- createBranchObject(): Create DcoBranchObject for branching on this\n- clone(): Deep copy for node differencing\n\n**Storage:**\nVariables are stored in BcpsModel::variables_ (inherited by DcoModel).\nInteger variable indices are tracked in DcoModel::integerCols_.",
    "file": "DcoVariable",
    "library": "DisCO",
    "layer": "layer-3",
    "header": "src/DcoVariable.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "DcoBranchStrategyRel": {
    "brief": "DisCO reliability branching",
    "file": "DcoBranchStrategyRel",
    "library": "DisCO",
    "layer": "layer-3",
    "header": "src/DcoBranchStrategyRel.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "DcoSolution": {
    "brief": "Incumbent solution for MISOCP\n\nDcoSolution stores a feasible solution found during branch-and-bound,\nincluding the variable values and objective quality.\n\n**Inheritance:** DcoSolution -> BcpsSolution -> AlpsSolution -> AlpsKnowledge\n\n**From BcpsSolution (inherited):**\n- size_: Number of variables\n- values_: Solution vector\n- quality_: Objective value\n\n**Selection Methods:**\n- selectNonzeros(): Return solution with only non-zero entries\n- selectFractional(): Return entries with fractional values\n\n**Solution Sources:**\n- DcoSolutionTypeBounding: From node relaxation\n- DcoSolutionTypeHeuristic: From primal heuristics\n- DcoSolutionTypeStrong: From strong branching",
    "file": "DcoSolution",
    "library": "DisCO",
    "layer": "layer-3",
    "header": "src/DcoSolution.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "DcoLinearConGenerator": {
    "brief": "Wrapper for CGL linear cut generators\n\nDcoLinearConGenerator wraps CglCutGenerator objects to integrate\nstandard MILP cutting planes into DisCO's branch-and-cut.\n\n**Available CGL Generators:**\n- CglClique: Clique cuts\n- CglOddHole: Odd hole cuts\n- CglFlowCover: Flow cover cuts\n- CglKnapsackCover: Knapsack cover cuts\n- CglMixedIntegerRounding: MIR cuts\n- CglGomory: Gomory cuts\n- CglProbing: Probing cuts\n- CglTwomir: Two-MIR cuts\n\n**generateConstraints() Flow:**\n1. Call CglCutGenerator::generateCuts()\n2. Convert OsiCuts to DcoLinearConstraint objects\n3. Add to BcpsConstraintPool\n4. Update statistics",
    "file": "DcoLinearConGenerator",
    "library": "DisCO",
    "layer": "layer-3",
    "header": "src/DcoLinearConGenerator.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "DcoPresolve": {
    "brief": "Presolve/preprocessing for MISOCP problems\n\nDcoPresolve extends OsiPresolve to handle conic problems,\napplying reductions before branch-and-bound.\n\n**Supported Operations:**\n- Bound tightening (improve_bounds)\n- Redundant row/column removal (from OsiPresolve)\n- Problem scaling and reformulation\n\n**Two Modes (compile-time):**\n- OA mode (__OA__): Uses OsiSolverInterface\n- Direct mode: Uses OsiConicSolverInterface\n\n**Usage:**\n1. DcoPresolve(origModel) - Initialize with original model\n2. presolve() - Apply reductions, create presolvedModel_\n3. Solve presolved problem\n4. postsolve() - Restore solution to original space",
    "file": "DcoPresolve",
    "library": "DisCO",
    "layer": "layer-3",
    "header": "src/DcoPresolve.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "DcoMessage": {
    "brief": "Message codes and handler for DisCO logging\n\nDcoMessage extends CoinMessages to provide structured logging\nwith configurable verbosity and debug levels.\n\n**Message Categories (DISCO_Message):**\n- Gap/Cutoff: DISCO_CUTOFF_INC, DISCO_GAP_YES/NO\n- Cut stats: DISCO_CUT_STATS_FINAL, DISCO_CUT_GENERATED\n- Node logging: DISCO_NODE_LOG, DISCO_NODE_BRANCH\n- Input: DISCO_READ_NOINTS, DISCO_READ_NOCONES, DISCO_READ_MPSERROR\n- Solver: DISCO_SOLVER_STATUS, DISCO_SOLVER_FAILED\n- Heuristics: DISCO_HEUR_SOL_FOUND, DISCO_HEUR_STATS_FINAL\n- Branching: DISCO_PSEUDO_REPORT, DISCO_STRONG_REPORT\n\n**Debug Levels (DISCO_Debug_Level):**\n- DISCO_DLOG_BRANCH: Branching decisions\n- DISCO_DLOG_CUT: Cut generation\n- DISCO_DLOG_PROCESS: Node processing\n- DISCO_DLOG_GRUMPY: Visualization output",
    "file": "DcoMessage",
    "library": "DisCO",
    "layer": "layer-3",
    "header": "src/DcoMessage.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "DcoCbfIO": {
    "brief": "CBF (Conic Benchmark Format) file reader for DisCO\n\nDcoCbfIO reads and writes conic problems in the standard CBF format,\nwhich is a text-based format for conic optimization problems.\n\n**CONES Enum (CBF domain types):**\n- FREE_RANGE: Free variables (F)\n- POSITIVE_ORT: Nonnegative orthant (L+)\n- NEGATIVE_ORT: Nonpositive orthant (L-)\n- FIXPOINT_ZERO: Fixed to zero (L=)\n- QUAD_CONE: Lorentz/quadratic cone (Q): ||x_{2:n}|| <= x_1\n- RQUAD_CONE: Rotated quadratic cone (QR): 2*x_1*x_2 >= ||x_{3:n}||^2\n\n**File Structure (CBF format):**\n- VER: Version number\n- OBJSENSE: MIN or MAX\n- VAR: Number of variables and domains\n- INT: Integer variables\n- CON: Number of constraints and domains\n- OBJACOORD: Objective coefficients\n- ACOORD: Constraint matrix in coordinate format\n- BCOORD: Constraint bounds/fixed terms\n\n**Key Methods:**\n- readCbf(): Parse CBF file into internal structures\n- writeCbf(): Output problem in CBF format\n- getProblem(): Convert to standard form (colLB, colUB, rowLB, rowUB, matrix, cones)",
    "file": "DcoCbfIO",
    "library": "DisCO",
    "layer": "layer-3",
    "header": "src/DcoCbfIO.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "DcoLicense": {
    "brief": "DisCO license information\n\nEPL license text and copyright information.",
    "file": "DcoLicense",
    "library": "DisCO",
    "layer": "layer-3",
    "header": "src/DcoLicense.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "DcoBranchStrategyStrong": {
    "brief": "Strong branching variable selection strategy",
    "file": "DcoBranchStrategyStrong",
    "library": "DisCO",
    "layer": "layer-3",
    "header": "src/DcoBranchStrategyStrong.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "DcoTreeNode": {
    "brief": "Branch-and-bound tree node for MISOCP\n\nDcoTreeNode inherits BcpsTreeNode->AlpsTreeNode and implements\nthe core branch-and-cut loop for conic optimization.\n\n**Inheritance:** DcoTreeNode -> BcpsTreeNode -> AlpsTreeNode\n\n**Node Status (inherited from ALPS):**\n- Candidate: Fresh, unprocessed\n- Evaluated: Processed, may need more cuts\n- Pregnant: Ready to branch\n- Branched: Children created\n- Fathomed/Discarded: Pruned\n\n**Processing Flow:**\n1. process(): Main entry point called by ALPS\n2. installSubProblem(): Load bounds from node descriptor\n3. boundingLoop(): Iterate solve->cuts until done\n4. bound(): Solve conic/LP relaxation\n5. generateConstraints(): Add MILP and conic cuts\n6. branchConstrainOrPrice(): Decide next action\n7. branch(): Create child nodes\n\n**BcpStats Structure:**\nTracks cuts, bounds, and objective improvement per node.",
    "file": "DcoTreeNode",
    "library": "DisCO",
    "layer": "layer-3",
    "header": "src/DcoTreeNode.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "DcoLinearConstraint": {
    "brief": "Linear constraint (row) representation\n\nDcoLinearConstraint stores a linear constraint in sparse form:\nlb <= sum(values[i] * x[indices[i]]) <= ub\n\n**Data Members:**\n- size_: Number of nonzero coefficients\n- indices_: Variable indices with nonzero coefficients\n- values_: Coefficient values\n- Bounds inherited from DcoConstraint/BcpsObject\n\n**Usage:**\n- Core constraints from the original problem\n- MILP cutting planes (Gomory, MIR, etc.)\n- OA supports approximating conic constraints\n\n**Conversion:**\n- createOsiRowCut(): Convert to OsiRowCut for solver\n\n**Feasibility:**\n- infeasibility(): Returns constraint violation",
    "file": "DcoLinearConstraint",
    "library": "DisCO",
    "layer": "layer-3",
    "header": "src/DcoLinearConstraint.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "DcoConicConGenerator": {
    "brief": "Wrapper for conic outer approximation cut generators\n\nDcoConicConGenerator wraps CglConicCutGenerator to generate linear\ncuts that approximate conic constraints (Outer Approximation).\n\n**Conic Cut Types (DcoConicCutType):**\n- IPM: Interior point method based\n- IPMInt: Integer-aware IPM cuts\n- OA: Standard outer approximation\n- MIR: Conic MIR cuts\n- GD1: Gradient descent cuts\n\n**OA Algorithm:**\nFor a Lorentz cone ||x|| <= t, generate linear supports:\n- At current solution point x*, generate tangent hyperplane\n- a'x <= b where (a,b) defines supporting hyperplane\n\n**generateConstraints() Flow:**\n1. Call CglConicCutGenerator::generateCuts()\n2. Convert OsiConicCuts to DcoLinearConstraint objects\n3. Add to BcpsConstraintPool",
    "file": "DcoConicConGenerator",
    "library": "DisCO",
    "layer": "layer-3",
    "header": "src/DcoConicConGenerator.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "DcoConGenerator": {
    "brief": "Abstract base class for constraint/cut generators\n\nDcoConGenerator provides the interface for generating cutting planes\n(constraints) during the branch-and-cut algorithm.\n\n**Generator Hierarchy:**\n- DcoConGenerator (ABC)\n  - DcoLinearConGenerator: Wraps CglCutGenerator (MILP cuts)\n  - DcoConicConGenerator: Wraps CglConicCutGenerator (OA cuts)\n\n**Statistics (DcoConGeneratorStats):**\n- numConsGenerated_: Total cuts generated\n- numConsUsed_: Cuts that were actually added\n- time_: CPU time consumed\n- numCalls_: Times generator was invoked\n- numNoConsCalls_: Calls producing no cuts\n\n**Control Parameters:**\n- strategy_: None, Root, Auto, Periodic\n- frequency_: How often to call (1 = every node)\n\n**Pure Virtual:**\n- generateConstraints(): Populate BcpsConstraintPool",
    "file": "DcoConGenerator",
    "library": "DisCO",
    "layer": "layer-3",
    "header": "src/DcoConGenerator.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "DcoParams": {
    "brief": "DisCO algorithm parameters and configuration\n\nDcoParams extends AlpsParameterSet to provide MISOCP-specific\nparameters for controlling the branch-and-cut algorithm.\n\n**Parameter Categories:**\n\n**Boolean (chrParams):**\n- cutRampUp, presolve, shareConstraints/Variables\n- sharePseudocostRampUp/Search\n\n**Integer (intParams):**\n- branchStrategy: 0=MaxInf, 1=Pseudo, 2=Reliability, 3=Strong, 4=Bilevel\n- Cut strategies: cutCliqueStrategy, cutGomoryStrategy, etc.\n- Cut frequencies: cutCliqueFreq, cutGomoryFreq, etc.\n- Conic cuts: cutIpmStrategy, cutOaStrategy\n- heurStrategy, heurRoundStrategy\n- lookAhead, pseudoReliability, strongCandSize\n\n**Double (dblParams):**\n- cutFactor, cutoff, objTol, integerTol, coneTol\n- optimalRelGap, optimalAbsGap\n- pseudoWeight, tailOff\n- OA parameters: cutOaBeta, cutOaSlack1/2\n\n**Serialization:**\n- pack()/unpack(): Encode for parallel distribution",
    "file": "DcoParams",
    "library": "DisCO",
    "layer": "layer-3",
    "header": "src/DcoParams.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "DcoHeurRounding": {
    "brief": "Simple rounding heuristic for finding feasible solutions",
    "file": "DcoHeurRounding",
    "library": "DisCO",
    "layer": "layer-3",
    "header": "src/DcoHeurRounding.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "DcoBranchStrategyPseudo": {
    "brief": "Pseudocost branching variable selection",
    "file": "DcoBranchStrategyPseudo",
    "library": "DisCO",
    "layer": "layer-3",
    "header": "src/DcoBranchStrategyPseudo.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "Dco": {
    "brief": "Central header defining DisCO enums, types, and constants\n\nThis header defines all enumeration types used throughout DisCO\n(Discrete Conic Optimization), a Mixed-Integer Second-Order Cone\nProgramming (MISOCP) solver.\n\n**Constraint Types (DcoConstraintType):**\n- Core constraints from the original problem\n- MILP cuts: Clique, FlowCover, Gomory, Knapsack, MIR, OddHole, Probe, TwoMIR\n- Conic cuts: IPM, IPMint, OA (Outer Approximation), CMIR, GD1\n\n**Cone Types (DcoLorentzConeType):**\n- DcoLorentzCone: Standard ||x|| <= t\n- DcoRotatedLorentzCone: 2*x1*x2 >= ||x_rest||^2\n\n**Cut Strategies (DcoCutStrategy):**\n- None, Root only, Auto, Periodic\n\n**Branching Strategies (DcoBranchingStrategy):**\n- MaxInfeasibility, PseudoCost, Reliability, Strong, Bilevel",
    "file": "Dco",
    "library": "DisCO",
    "layer": "layer-3",
    "header": "src/Dco.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "DcoBranchStrategyMaxInf": {
    "brief": "Maximum infeasibility branching strategy",
    "file": "DcoBranchStrategyMaxInf",
    "library": "DisCO",
    "layer": "layer-3",
    "header": "src/DcoBranchStrategyMaxInf.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "DcoSubTree": {
    "brief": "Subtree representation for parallel search\n\nDcoSubTree extends BcpsSubTree to represent a portion of the\nbranch-and-bound tree for parallel distribution.\n\n**Inheritance:** DcoSubTree -> BcpsSubTree -> AlpsSubTree\n\n**Usage in Parallel:**\n- Subtrees are work units distributed to workers\n- Contains subset of tree nodes for processing\n- Supports encode/decode for network transmission\n\nNote: Currently minimal implementation - most logic in base class.",
    "file": "DcoSubTree",
    "library": "DisCO",
    "layer": "layer-3",
    "header": "src/DcoSubTree.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "DcoConfig": {
    "brief": "Build configuration header for DisCO\n\nStandard COIN-OR configuration pattern that selects appropriate\nconfig files based on build system and context.\n\n**Configuration Selection:**\n- With autotools (HAVE_CONFIG_H defined):\n  - Library build (DISCO_BUILD): uses config.h\n  - Client code: uses config_dco.h\n- Without autotools (e.g., Visual Studio):\n  - Library build: uses config_default.h\n  - Client code: uses config_dco_default.h",
    "file": "DcoConfig",
    "library": "DisCO",
    "layer": "layer-3",
    "header": "src/DcoConfig.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "DcoBranchObject": {
    "brief": "Branching decision for integer variable dichotomy\n\nDcoBranchObject stores the information needed to create two child\nnodes by branching on a fractional integer variable.\n\n**Branching Dichotomy:**\nFor variable x_i with fractional value v:\n- Down branch: x_i <= floor(v) (ubDownBranch_)\n- Up branch: x_i >= ceil(v) (lbUpBranch_)\n\n**Inherited from BcpsBranchObject:**\n- objectIndex_: Variable index being branched\n- score_: Branching score (from strategy)\n- value_: Current fractional value\n- direction_: Which branch to explore next\n\n**Key Methods:**\n- numBranches(): Returns 2 (binary branching)\n- branch(): Apply bound change to solver, return new bound",
    "file": "DcoBranchObject",
    "library": "DisCO",
    "layer": "layer-3",
    "header": "src/DcoBranchObject.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "OsiSymSolverParameters": {
    "brief": "SYMPHONY solver parameter enums\n\nParameter type enumerations for OsiSymSolverInterface.\nMaps Osi generic parameters to SYMPHONY-specific settings.",
    "file": "OsiSymSolverParameters",
    "library": "SYMPHONY",
    "layer": "layer-3",
    "header": "src/OsiSym/OsiSymSolverParameters.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "OsiSymConfig": {
    "brief": "SYMPHONY build configuration\n\nBuild configuration macros from autotools/cmake for OsiSym.",
    "file": "OsiSymConfig",
    "library": "SYMPHONY",
    "layer": "layer-3",
    "header": "src/OsiSym/OsiSymConfig.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "OsiSymSolverInterface": {
    "brief": "Osi interface for SYMPHONY MIP solver\n\nOsiSymSolverInterface wraps SYMPHONY (parallel MIP solver) with Osi\nabstraction. Enables SYMPHONY use with Cbc, Cgl, and other COIN-OR.\nSupports parallel branch-and-bound with warm start capability.",
    "file": "OsiSymSolverInterface",
    "library": "SYMPHONY",
    "layer": "layer-3",
    "header": "src/OsiSym/OsiSymSolverInterface.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "SymWarmStart": {
    "brief": "SYMPHONY warm start information\n\nSymWarmStart: stores basis and tree information for restarting\nSYMPHONY MIP solver from previous state. Enables incremental solving.",
    "file": "SymWarmStart",
    "library": "SYMPHONY",
    "layer": "layer-3",
    "header": "src/OsiSym/SymWarmStart.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "sym_prep": {
    "brief": "MIP preprocessing (presolve) for SYMPHONY\n\nPreprocessing reduces problem size before B&C by fixing variables,\nremoving redundant constraints, and tightening bounds.",
    "file": "sym_prep",
    "library": "SYMPHONY",
    "layer": "layer-3",
    "header": "include/sym_prep.h",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "sym_cp_params": {
    "brief": "Cut pool process parameters\n\nParameters for managing the global cut pool storage.\n\n**cp_params structure:**\n- verbosity: Output level\n- warm_start: Load cuts from file at start\n- warm_start_file_name: Saved cut pool file\n- logging: Save cut pool during solve\n- log_file_name: Cut pool log file\n\n**Size management:**\n- block_size: Allocation granularity\n- max_size: Maximum memory for cuts\n- max_number_of_cuts: Hard limit on cut count\n\n**Quality control:**\n- cuts_to_check: How many cuts to check for violations\n- delete_which: Deletion strategy (quality/touches)\n- touches_until_deletion: Inactivity threshold\n- min_to_delete: Minimum cuts to remove at once\n- check_which: Which cuts to check (level/touches)",
    "file": "sym_cp_params",
    "library": "SYMPHONY",
    "layer": "layer-3",
    "header": "include/sym_cp_params.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "sym_macros": {
    "brief": "Utility macros for SYMPHONY\n\nCommon macros for memory management, parameter parsing,\nPVM communication, and utility operations.\n\n**Random number generation:**\n- SRANDOM(seed): Seed generator (srand/srandom)\n- RANDOM(): Get random number (rand/random)\n\n**Memory allocation:**\n- REMALLOC(ptr, type, old, new, block): Realloc with free first\n- REALLOC(ptr, type, old, new, block): Standard realloc\n- FREE(p): Safe free with NULL check\n\n**PVM communication (parallel mode):**\n- READ_INT_DESC(): Read integer array descriptor\n- READ_CHAR_ARRAY_WITH_SIZE(): Read sized char array\n- READ_STR_LIST(): Read string list\n\n**Parameter file parsing:**\n- READ_INT_PAR(par): Parse integer parameter\n- READ_DBL_PAR(par): Parse double parameter\n- READ_STR_PAR(par): Parse string parameter\n- READ_STRINT_PAR(): Parse string-to-int mapping\n- READPAR_ERROR(x): Report parse error\n\n**Data copying:**\n- COPY_DBL_ARRAY_DESC(): Copy double array descriptor\n- COPY_ARRAY_DESC(): Copy integer array descriptor\n- COPY_STAT(): Copy status array\n\n**User function handling:**\n- CALL_USER_FUNCTION(f): Check USER_ERROR return\n- CALL_WRAPPER_FUNCTION(f): Check wrapper return\n\n**Standard utilities:**\n- PRINT(verb, thresh, args): Conditional print\n- MIN(a,b), MAX(a,b): Comparisons\n- isset(a,i), setbit(a,i): Bit array operations\n\n**OpenMP atomics:**\n- OPENMP_ATOMIC_WRITE: Thread-safe write\n- OPENMP_ATOMIC_UPDATE: Thread-safe update",
    "file": "sym_macros",
    "library": "SYMPHONY",
    "layer": "layer-3",
    "header": "include/sym_macros.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "sym_messages": {
    "brief": "PVM message tags for parallel SYMPHONY\n\nDefines message types for inter-process communication in parallel mode.\nUsed with PVM (Parallel Virtual Machine) for distributed solving.\n\n**Message numbering scheme:**\n- 1xx: General messages (lifecycle, bounds)\n- 2xx: Master process messages (data requests)\n- 3xx: Tree manager \u2194 LP messages\n- 4xx: LP process outgoing messages\n- 5xx: Cut/solution pool messages\n- 6xx: Cut packing messages\n- 7xx: Column packing messages\n\n**Lifecycle messages (1xx):**\n- YOU_CAN_DIE (100): Permission to terminate\n- I_AM_DEAD (101): Termination acknowledgment\n- UPPER_BOUND (103): New incumbent found\n- WRITE_LOG_FILE (105): Checkpoint request\n\n**Data request messages (2xx):**\n- REQUEST_FOR_LP_DATA/LP_DATA: LP worker setup\n- REQUEST_FOR_CG_DATA/CG_DATA: Cut generator setup\n- REQUEST_FOR_CP_DATA/CP_DATA: Cut pool setup\n- TM_DATA (210): Tree manager startup\n\n**Tree manager \u2194 LP (3xx):**\n- LP__NODE_DESCRIPTION (300): Node state to TM\n- LP__BRANCHING_INFO (301): Branching decision\n- LP__IS_FREE (302): Ready for new node\n- LP__ACTIVE_NODE_DATA (306): Node assignment\n- LP__DIVING_INFO (307): Dive/backtrack instruction\n\n**Solution messages (4xx):**\n- FEASIBLE_SOLUTION_NONZEROS (410): Sparse solution\n- LP_SOLUTION_NONZEROS (420): LP solution for cuts\n\n**Pool messages (5xx-6xx):**\n- POOL_YOU_ARE_USELESS (501): Pool shutdown\n- PACKED_CUT (600): Single cut\n- PACKED_CUTS_TO_CP (601): Cuts to pool\n- NO_MORE_CUTS (605): End of cut stream",
    "file": "sym_messages",
    "library": "SYMPHONY",
    "layer": "layer-3",
    "header": "include/sym_messages.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "sym_pack_array": {
    "brief": "Array serialization for PVM communication\n\nPack/unpack functions for SYMPHONY data structures in parallel mode.\n\n**Array packing:**\n- pack_array_desc(): Serialize array_desc (int list)\n- unpack_array_desc(): Deserialize array_desc\n- pack_double_array_desc(): Serialize with double stats\n- unpack_double_array_desc(): Deserialize double array\n\n**Basis packing:**\n- pack_basis(): Serialize basis_desc for warm start\n- unpack_basis(): Deserialize basis_desc",
    "file": "sym_pack_array",
    "library": "SYMPHONY",
    "layer": "layer-3",
    "header": "include/sym_pack_array.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "sym_master_u": {
    "brief": "User callbacks for master process\n\nDefines callbacks for customizing problem setup and solution handling.\nReturn USER_DEFAULT to use built-in behavior for standard MIP solving.\n\n**Initialization callbacks:**\n- user_usage(): Print custom command-line help\n- user_initialize(): Allocate user data structure\n- user_free_master(): Clean up user data\n- user_readparams(): Read custom parameters\n- user_io(): Custom problem input\n\n**Problem setup:**\n- user_initialize_root_node(): Define base problem\n  - Set base variables, base cuts, column gen strategy\n  - This is the main hook for problem definition\n- user_start_heurs(): Run initial heuristics for bounds\n- user_init_draw_graph(): Setup visualization\n\n**Solution handling:**\n- user_receive_feasible_solution(): Process new incumbent\n- user_display_solution(): Custom solution output\n- user_send_feas_sol(): Known feasible solution for warm start\n\n**Data distribution (parallel mode):**\n- user_send_lp_data(): Send data to LP workers\n- user_send_cg_data(): Send data to cut generators\n- user_send_cp_data(): Send data to cut pools\n\n**Warm start support:**\n- user_ws_update_cuts(): Update cuts for modified problem\n- user_process_own_messages(): Custom message handling",
    "file": "sym_master_u",
    "library": "SYMPHONY",
    "layer": "layer-3",
    "header": "include/sym_master_u.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "sym_master": {
    "brief": "Master process for SYMPHONY's parallel branch-and-cut\n\nThe master process coordinates the overall solve, managing problem\ndata, solution bounds, and communication with worker processes.",
    "file": "sym_master",
    "library": "SYMPHONY",
    "layer": "layer-3",
    "header": "include/sym_master.h",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "sym_dg": {
    "brief": "Draw Graph (DG) process for SYMPHONY visualization\n\nInteractive graphical display of solutions and search progress.\nCommunicates with Tcl/Tk-based GUI via pipes.\n\n**dg_prob structure:**\n- windows: Array of display windows\n- par: Visualization parameters\n- master: Master process tid\n\n**Window management:**\n- win_desc: Window display settings (size, fonts, scale)\n- dg_graph: Graph data (nodes, edges)\n- buf_fifo: Message buffer queue\n\n**dg_node:**\n- node_id, posx, posy: Identifier and position\n- radius, label, weight: Display properties\n- dash: Line pattern for node border\n\n**dg_edge:**\n- edge_id, tail, head: Identifier and endpoints\n- weight, dash: Display properties\n\n**Main functions:**\n- init_dgwin(): Create new window\n- display_graph_on_canvas(): Render graph\n- copy_window_structure(): Clone window\n- find_node(), find_edge(): Lookup elements\n- compress_graph(): Remove deleted elements\n\n**Communication:**\n- spprint(): Printf to pipe\n- start_child(): Launch GUI process\n- wait_for_you_can_die(): Graceful shutdown",
    "file": "sym_dg",
    "library": "SYMPHONY",
    "layer": "layer-3",
    "header": "include/sym_dg.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "symphony_api": {
    "brief": "Internal API header (legacy, includes sym_master.h)\n\nThis header provides the internal API declarations using the\nPROTO() macro for K&R C compatibility. Modern code should use\nsymphony.h which provides the same functions with standard\nANSI C prototypes.\n\n**Included headers:**\n- sym_proto.h: PROTO() macro definition\n- sym_master.h: Master process data structures\n- sym_messages.h: Message type definitions\n\n@note Prefer using symphony.h for new code",
    "file": "symphony_api",
    "library": "SYMPHONY",
    "layer": "layer-3",
    "header": "include/symphony_api.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "sym_proccomm": {
    "brief": "Process communication abstraction for parallel SYMPHONY\n\nWrapper functions for PVM (Parallel Virtual Machine) communication.\nProvides portable inter-process communication in distributed mode.\n\n**PVM integration:**\n- __PVM__ flag enables PVM3 library\n- DataInPlace = PvmDataRaw for efficient packing\n- PROCESS_OK = PvmOk for status checks\n\n**Process management:**\n- register_process(): Join PVM\n- spawn(): Start remote processes\n- pstat(): Check process status\n- kill_proc(): Terminate process\n- comm_exit(): Leave PVM\n\n**Message sending:**\n- init_send(): Initialize send buffer\n- send_char/int/dbl/float_array(): Pack arrays\n- send_str(): Pack string\n- send_msg(): Send to one recipient\n- msend_msg(): Multicast to multiple recipients\n\n**Message receiving:**\n- receive_msg(): Blocking receive\n- treceive_msg(): Timed receive\n- nreceive_msg(): Non-blocking receive\n- receive_char/int/dbl/float_array(): Unpack arrays\n- receive_str(): Unpack string\n\n**Buffer management:**\n- bufinfo(): Get buffer metadata\n- freebuf(): Release buffer\n- setsbuf(), setrbuf(): Set active buffers",
    "file": "sym_proccomm",
    "library": "SYMPHONY",
    "layer": "layer-3",
    "header": "include/sym_proccomm.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "sym_dg_params": {
    "brief": "Draw Graph parameters and message constants\n\nParameters for visualization and GUI communication constants.\n\n**dg_params structure:**\n- canvas_width/height: Drawing area size\n- viewable_width/height: Visible window size\n- disp_nodelabels/nodeweights/edgeweights: Show labels\n- node_radius: Default node size\n- scale_factor: Zoom level\n- *_font: Font specifications\n- interactive_mode: Enable user interaction\n- mouse_tracking: Track mouse position\n\n**Message protocols (CTOI_* = Client to Intermediary):**\n- CTOI_INITIALIZE_WINDOW: Create new window\n- CTOI_SET_GRAPH: Load graph data\n- CTOI_DRAW_GRAPH: Render current graph\n- CTOI_MODIFY_GRAPH: Update graph elements\n- CTOI_WAIT_FOR_CLICK_*: User interaction\n\n**Messages (ITOC_* = Intermediary to Client):**\n- ITOC_CLICK_HAPPENED: User clicked\n- ITOC_WINDOW_*: Window status responses\n\n**Modification types (MODIFY_*):**\n- ADD_NODES, DELETE_NODES: Node operations\n- ADD_EDGES, DELETE_EDGES: Edge operations\n- CHANGE_WEIGHTS_*: Update labels\n- CHANGE_DASH_*: Update line styles",
    "file": "sym_dg_params",
    "library": "SYMPHONY",
    "layer": "layer-3",
    "header": "include/sym_dg_params.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "sym_cg_params": {
    "brief": "Cut generator process parameters\n\nMinimal parameter structure for the cut generator process.\nMost cut generation parameters are in sym_lp_params.h (cgl_params).\n\n**cg_params:**\n- verbosity: Output level for cut generation\n- do_findcuts: Enable/disable user cut generation",
    "file": "sym_cg_params",
    "library": "SYMPHONY",
    "layer": "layer-3",
    "header": "include/sym_cg_params.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "sym_types": {
    "brief": "Core data structures for SYMPHONY's branch-and-cut\n\nDefines the fundamental data structures used throughout SYMPHONY\nfor representing problems, solutions, tree nodes, and cuts.\n\n**Problem representation:**\n- MIPdesc: Complete MIP in CSC format (matbeg, matind, matval)\n- MIPinfo: Problem statistics (var types, row types, density)\n\n**Tree node structures:**\n- bc_node: B&C tree node with bounds, solution, children\n- node_desc: Node description (basis, cuts, variables)\n- branch_obj: Branching decision (variable, children, bounds)\n- branch_desc: Single branch description (sense, rhs)\n\n**Cut structures:**\n- cut_data: Cut coefficients and metadata\n- row_data: Cut with effectiveness tracking\n- waiting_row: Pending cut with violation info\n\n**Solution structures:**\n- lp_sol: LP solution (sparse xind/xval format)\n- sp_solution: Solution pool entry\n- warm_start_desc: Complete warm start state\n\n**Statistics:**\n- problem_stat: Tree size, depth, diving stats\n- lp_stat_desc: LP calls, cuts generated by type\n- node_times: Timing breakdown per node\n\n**Presolve support:**\n- COLinfo: Column statistics and implications\n- ROWinfo: Row bounds, types, redundancy\n- IMPvar/IMPlist: Variable implication lists",
    "file": "sym_types",
    "library": "SYMPHONY",
    "layer": "layer-3",
    "header": "include/sym_types.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "sym_lp_params": {
    "brief": "LP solver process parameters for SYMPHONY\n\nParameters controlling LP relaxation solving, cut generation,\nbranching, and primal heuristics in each B&C node.\n\n**cgl_params (CGL cut generation):**\n- generate_cgl_*_cuts: Enable specific cut families\n- generate_cgl_*_cuts_freq: How often to generate (1=every node)\n- *_max_depth: Tree depth limit for each cut type\n- use_chain_strategy: Smart cut generation chain\n\n**lp_params structure sections:**\n\n**Matrix growth control:**\n- max_non_dual_feas_to_add_*: Limits on violated cuts added\n- mat_row/col_compress_*: When to compress matrix\n\n**Tailing off detection:**\n- tailoff_gap_backsteps/frac: Detect stalling LP progress\n- tailoff_obj_backsteps/frac: Objective improvement threshold\n\n**Branching control:**\n- strong_branching_cand_num_*: Candidates for strong branching\n- rel_br_threshold: Reliability branching parameters\n- use_sos_branching: Special ordered sets support\n\n**Primal heuristics:**\n- fp_*: Feasibility pump parameters\n- fr_*: Feasibility-based restricted search\n- rs_*: RINS (Relaxation Induced Neighborhood Search)\n- lb_*: Local branching\n- ds_*: Diving heuristics (fractional, guided, etc.)",
    "file": "sym_lp_params",
    "library": "SYMPHONY",
    "layer": "layer-3",
    "header": "include/sym_lp_params.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "sym_pack_cut": {
    "brief": "Cut serialization for PVM communication\n\nPack/unpack functions for cut_data in parallel mode.\n\n**Cut packing:**\n- pack_cut(): Serialize cut_data for transmission\n- unpack_cut(): Deserialize received cut_data",
    "file": "sym_pack_cut",
    "library": "SYMPHONY",
    "layer": "layer-3",
    "header": "include/sym_pack_cut.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "sym_proto": {
    "brief": "Function prototype and path length macros\n\nDefines the PROTO macro for ANSI C function prototypes\nand standard path/line length constants.\n\n**Length constants:**\n- MAX_FILE_NAME_LENGTH (255): File path buffer size\n- MACH_NAME_LENGTH (255): Machine name buffer size\n- MAX_LINE_LENGTH (255): Line buffer size\n\n**PROTO macro:**\n- PROTO(x) expands to x for ANSI C prototypes\n- Allows: `int foo PROTO((int a, int b));`\n- Legacy support for K&R C compilers (commented out)",
    "file": "sym_proto",
    "library": "SYMPHONY",
    "layer": "layer-3",
    "header": "include/sym_proto.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "sym_constants": {
    "brief": "Core constants and status codes for SYMPHONY\n\nDefines all numeric constants used throughout SYMPHONY including\nerror codes, status values, algorithm modes, and return codes.\n\n**Error codes (process_chain):**\n- ERROR__NO_BRANCHING_CANDIDATE, ERROR__ILLEGAL_RETURN_CODE\n- ERROR__NUMERICAL_INSTABILITY, ERROR__COMM_ERROR\n\n**Problem types:**\n- ZERO_ONE_PROBLEM, INTEGER_PROBLEM, MIXED_INTEGER_PROBLEM\n\n**Node status (NODE_STATUS__*):**\n- CANDIDATE, BRANCHED_ON, HELD, ROOT, PRUNED\n- TIME_LIMIT, ITERATION_LIMIT, WARM_STARTED\n\n**LP solver status:**\n- LP_OPTIMAL, LP_D_INFEASIBLE, LP_D_UNBOUNDED\n- LP_D_ITLIM, LP_D_OBJLIM, LP_TIME_LIMIT\n\n**Basis status:**\n- VAR_AT_LB, VAR_BASIC, VAR_AT_UB, VAR_FREE, VAR_FIXED\n\n**Cut source:**\n- INTERNAL_CUT_POOL, EXTERNAL_CUT_POOL\n- INTERNAL_CUT_GEN, EXTERNAL_CUT_GEN\n\n**CGL generators (CGL_*_GENERATOR):**\n- PROBING, KNAPSACK, CLIQUE, GOMORY, TWOMIR, FLOWCOVER, MIR\n\n**Branching actions:**\n- DO_BRANCH, DO_NOT_BRANCH, DO_NOT_BRANCH__FATHOMED\n- PRUNE_THIS_CHILD, RETURN_THIS_CHILD, KEEP_THIS_CHILD\n\n**Variable status flags:**\n- NOT_FIXED, TEMP_FIXED_TO_LB, PERM_FIXED_TO_LB\n- BASE_VARIABLE, VARIABLE_BRANCHED_ON, NOT_REMOVABLE\n\n**Column generation strategies:**\n- FATHOM__DO_NOT_GENERATE_COLS__DISCARD\n- FATHOM__GENERATE_COLS__RESOLVE\n- BEFORE_BRANCH__GENERATE_COLS__RESOLVE\n\n**VBC visualization (VBC_*):**\n- INTERIOR_NODE, PRUNED, ACTIVE_NODE, CAND_NODE, FEAS_SOL_FOUND\n\n**Diving heuristics:**\n- VLENGTH_DIVING, GUIDED_DIVING, CROSSOVER_DIVING\n- EUC_DIVING, RANK_DIVING, FRAC_DIVING\n\n**Presolve return codes:**\n- PREP_UNMODIFIED, PREP_MODIFIED, PREP_INFEAS, PREP_SOLVED",
    "file": "sym_constants",
    "library": "SYMPHONY",
    "layer": "layer-3",
    "header": "include/sym_constants.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "sym_lp": {
    "brief": "LP solver process for SYMPHONY's branch-and-cut\n\nThe LP process solves LP relaxations at each B&C node, manages\ncuts, and performs branching decisions.",
    "file": "sym_lp",
    "library": "SYMPHONY",
    "layer": "layer-3",
    "header": "include/sym_lp.h",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "sym_cp_u": {
    "brief": "User callbacks for cut pool process\n\nDefines callbacks for custom cut checking in the cut pool.\nCut pool stores cuts for reuse across B&C nodes.\n\n**User callbacks:**\n- user_receive_cp_data(): Receive problem-specific data\n- user_free_cp(): Clean up user data\n- user_receive_lp_solution_cp(): Custom solution handling\n\n**Cut checking protocol (three-phase):**\n1. user_prepare_to_check_cuts(): Initialize with LP solution\n2. user_check_cut(): Check single cut for violation\n   - Sets is_violated flag\n   - Optionally computes quality score\n3. user_finished_checking_cuts(): Cleanup after checking\n\n**Default behavior:**\nReturns USER_DEFAULT for built-in EXPLICIT_ROW handling.\nUser cuts need custom checking implementation.",
    "file": "sym_cp_u",
    "library": "SYMPHONY",
    "layer": "layer-3",
    "header": "include/sym_cp_u.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "sym_master_params": {
    "brief": "Master process parameters aggregating all component params\n\nTop-level parameter structure containing parameters for all\nSYMPHONY processes: master, TM, LP, CG, CP, DG, and preprocessing.\n\n**params structure contains:**\n- cp_par: Cut pool parameters\n- cg_par: Cut generator parameters\n- lp_par: LP solver parameters\n- tm_par: Tree manager parameters\n- dg_par: Draw graph parameters (visualization)\n- prep_par: Preprocessing parameters\n\n**Execution control:**\n- warm_start: Resume from saved state\n- verbosity: Global output level\n- random_seed: For reproducibility\n- do_branch_and_cut: Enable B&C algorithm\n- do_draw_graph: Enable visualization\n- use_permanent_cut_pools: Persistent cut storage\n\n**Input/output:**\n- infile: Problem file (MPS/LP/GMPL)\n- file_type: MPS_FORMAT, LP_FORMAT, GMPL_FORMAT\n- datafile: GMPL data file if needed\n- test_dir: Directory for test problems\n- obj_offset: Constant added to objective\n\n**Multi-criteria optimization:**\n- multi_criteria: Enable bi-objective mode\n- mc_search_order: Search strategy\n- mc_compare_solution_tolerance: Pareto comparison\n- mc_warm_start: Reuse solutions across objectives\n\n**Parallel configuration:**\n- tm_exe, dg_exe: Process executables\n- tm_machine, dg_machine: Machine assignments\n- pvm_trace: PVM debugging",
    "file": "sym_master_params",
    "library": "SYMPHONY",
    "layer": "layer-3",
    "header": "include/sym_master_params.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "sym_timemeas": {
    "brief": "Time measurement utilities for SYMPHONY\n\nPortable timing functions and timeval manipulation macros.\nUses Windows time on MSVC, sys/time.h otherwise.\n\n**Timing functions:**\n- start_time(): Start timer\n- used_time(): CPU time since last call\n- wall_clock(): Wall-clock elapsed time\n\n**timeval manipulation macros:**\n- TVCLEAR(tv): Zero a timeval\n- TVISSET(tv): Check if timeval is non-zero\n- TVXLTY(x,y): Compare x < y\n- TVXADDY(z,x,y): z = x + y\n- TVXSUBY(z,x,y): z = x - y\n- TVTODBL(tv): Convert to double seconds\n- DBLTOTV(d,tv): Convert double to timeval\n\n**VBC output macros:**\n- PRINT_TIME(tm, f): Print HH:MM:SS:MS format\n- PRINT_TIME2(tm, f): Print decimal seconds",
    "file": "sym_timemeas",
    "library": "SYMPHONY",
    "layer": "layer-3",
    "header": "include/sym_timemeas.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "sym_cg": {
    "brief": "Cut Generator process for SYMPHONY\n\nThe Cut Generator (CG) receives LP solutions and generates\nviolated cutting planes. Can run as separate process or\ncompiled into LP process (SYM_COMPILE_IN_CG).",
    "file": "sym_cg",
    "library": "SYMPHONY",
    "layer": "layer-3",
    "header": "include/sym_cg.h",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "sym_tm_params": {
    "brief": "Tree manager parameters for SYMPHONY\n\nParameters controlling the branch-and-cut search tree exploration.\n\n**Process configuration:**\n- lp_exe, cg_exe, cp_exe: Worker executables\n- lp/cg/cp_mach_num: Number of machines per type\n- lp/cg/cp_machs: Machine name arrays\n- max_active_nodes: Parallelism limit\n- max_cp_num: Maximum cut pools\n\n**Node selection (node_selection_rule):**\n- LOWEST_LP_FIRST: Best-bound search\n- DEPTH_FIRST_SEARCH: Deep diving\n- BREADTH_FIRST_SEARCH: Level-by-level\n- BEST_FIRST_SEARCH: Estimate-based\n\n**Diving strategy:**\n- unconditional_dive_frac: Always dive this fraction\n- diving_strategy: How to choose dive vs backtrack\n- diving_k, diving_threshold: Diving parameters\n\n**Termination criteria:**\n- time_limit: Maximum solve time\n- gap_limit: Optimality tolerance\n- node_limit: Maximum nodes to explore\n- find_first_feasible: Stop at first solution\n\n**Logging and warm start:**\n- logging, logging_interval: Progress logging\n- warm_start: Resume from saved state\n- warm_start_node_limit: Nodes to load\n- tree_log_file_name, cut_log_file_name: State files\n- vbc_emulation: Visualization output\n\n**Column generation:**\n- colgen_strat[2]: Strategy for two phases\n- price_in_root: Column generation at root\n\n**Solution pool:**\n- max_sp_size: Maximum solutions to keep",
    "file": "sym_tm_params",
    "library": "SYMPHONY",
    "layer": "layer-3",
    "header": "include/sym_tm_params.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "sym_primal_heuristics": {
    "brief": "Primal heuristics for finding feasible solutions\n\nCollection of heuristics to find feasible MIP solutions quickly.\nCalled during B&C to improve incumbent and provide bounds.",
    "file": "sym_primal_heuristics",
    "library": "SYMPHONY",
    "layer": "layer-3",
    "header": "include/sym_primal_heuristics.h",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "sym_prep_params": {
    "brief": "Preprocessing parameters for SYMPHONY\n\nParameters controlling MIP presolve operations.\n\n**prep_params structure:**\n- level: Preprocessing aggressiveness (0=off)\n- dive_level: Bound propagation depth\n- impl_dive_level: Implication chain depth\n- impl_limit: Max implications to explore\n- do_probe: Enable probing\n- verbosity: Output detail level\n- reduce_mip: Enable full problem reduction\n\n**Probing control:**\n- probe_verbosity: Probing output level\n- probe_level: Probing aggressiveness\n\n**Single-row relaxation:**\n- do_single_row_rlx: Enable SR bounds\n- single_row_rlx_ratio: Sparsity threshold\n- max_sr_cnt: Max rows to analyze\n\n**Aggregated row relaxation:**\n- do_aggregate_row_rlx: Combine rows for bounds\n- max_aggr_row_ratio: Density limit\n- max_aggr_row_cnt: Max aggregations\n\n**Resource limits:**\n- iteration_limit: Max preprocessing passes\n- time_limit: Preprocessing time budget\n- etol: Numerical tolerance\n\n**Output:**\n- display_stats: Show preprocessing summary\n- write_mps/write_lp: Save preprocessed problem",
    "file": "sym_prep_params",
    "library": "SYMPHONY",
    "layer": "layer-3",
    "header": "include/sym_prep_params.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "symphony": {
    "brief": "Main public API for SYMPHONY MILP solver\n\nSYMPHONY is a parallel branch-cut-price framework for solving\nMixed Integer Linear Programs (MILPs). Supports both shared-memory\nand distributed-memory (MPI) parallelism.",
    "file": "symphony",
    "library": "SYMPHONY",
    "layer": "layer-3",
    "header": "include/symphony.h",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "sym_cg_u": {
    "brief": "User callbacks for cut generator process\n\nDefines callbacks for custom cut generation in SYMPHONY.\nUsers implement problem-specific separation routines here.\n\n**Cut addition helpers (non-user):**\n- cg_add_explicit_cut(): Add cut with explicit coefficients\n- cg_add_user_cut(): Add packed user-defined cut\n- cg_send_cut(): Send cut to LP (internal)\n\n**User callbacks:**\n- user_receive_cg_data(): Receive problem-specific data\n- user_free_cg(): Clean up user data\n- user_find_cuts(): Main separation routine\n  - Called with LP solution (indices, values, objval)\n  - Populates cuts array via cg_add_* helpers\n- user_receive_lp_solution_cg(): Custom solution handling\n- user_check_validity_of_cut(): Debug validation (ifdef)\n\n**Example user_find_cuts implementation:**\n```c\nint user_find_cuts(void *user, int varnum, ...) {\n    // Check for violated inequalities\n    for (each inequality class) {\n        if (is_violated(values, ...)) {\n            cg_add_explicit_cut(nz, ind, val, rhs, 0.0,\n                                'L', TRUE, num_cuts, ...);\n        }\n    }\n    return USER_SUCCESS;\n}\n```",
    "file": "sym_cg_u",
    "library": "SYMPHONY",
    "layer": "layer-3",
    "header": "include/sym_cg_u.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "sym_lp_solver": {
    "brief": "LP solver abstraction layer for SYMPHONY\n\nProvides uniform interface to multiple LP solvers via OSI\n(Open Solver Interface) or native APIs.\n\n**Supported solvers (via compile flags):**\n- __OSI_CLP__: COIN-OR CLP (default, open source)\n- __OSI_CPLEX__: IBM CPLEX\n- __OSI_XPRESS__: FICO Xpress\n- __OSI_GLPK__: GNU Linear Programming Kit\n- __CPLEX__: Native CPLEX API\n- __OSL__: IBM OSL (legacy)\n\n**LPdata structure:**\n- si: OsiSolverInterface pointer (OSI mode)\n- lp: Native solver object (CPLEX/OSL mode)\n- n, m, nz: Columns, rows, nonzeros\n- x, dj, dualsol, slacks: Solution vectors\n- vars: Variable descriptors with bounds/status\n- mip: Original problem description\n- cgl: CGL cut generation parameters\n\n**Core LP operations:**\n- open/close_lp_solver(): Initialize/cleanup\n- load_lp_prob(): Load problem into solver\n- initial_lp_solve(): First solve from scratch\n- dual_simplex(): Resolve after modifications\n- solve_hotstart(): Quick re-solve with basis\n\n**Matrix modification:**\n- add_rows(), add_cols(): Extend problem\n- delete_rows(), delete_cols(): Remove elements\n- change_bounds(), change_rhs(): Modify constraints\n\n**Solution access:**\n- get_x(), get_dj_pi(), get_slacks(): Retrieve solutions\n- get_basis(), load_basis(): Basis manipulation\n\n**CGL cut generation:**\n- generate_cgl_cuts(): Call CGL generators\n- Supports: Gomory, MIR, Probing, Knapsack, Clique, etc.",
    "file": "sym_lp_solver",
    "library": "SYMPHONY",
    "layer": "layer-3",
    "header": "include/sym_lp_solver.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "SymConfig": {
    "brief": "Build configuration for SYMPHONY\n\nManages platform-specific configuration and symbol visibility.\n\n**Configuration modes:**\n- HAVE_CONFIG_H: Uses autoconf-generated config.h\n- Otherwise: Uses config_default.h / config_sym_default.h\n\n**Symbol visibility:**\n- SYMPHONYLIB_EXPORT: DLL export on Windows\n- __visibility__(\"default\"): GCC visibility for -fvisibility=hidden\n\n**Include hierarchy:**\n- SYMPHONYLIB_BUILD + HAVE_CONFIG_H \u2192 config.h\n- Client + HAVE_CONFIG_H \u2192 config_sym.h\n- SYMPHONYLIB_BUILD no autoconf \u2192 config_default.h\n- Client no autoconf \u2192 config_sym_default.h",
    "file": "SymConfig",
    "library": "SYMPHONY",
    "layer": "layer-3",
    "header": "include/SymConfig.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "sym_tm": {
    "brief": "Tree Manager for SYMPHONY's parallel B&C\n\nThe Tree Manager (TM) maintains the branch-and-cut search tree,\ndispatches nodes to LP workers, and coordinates cut generation.",
    "file": "sym_tm",
    "library": "SYMPHONY",
    "layer": "layer-3",
    "header": "include/sym_tm.h",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "sym_qsort": {
    "brief": "Quicksort variants and utility functions\n\nSpecialized quicksort implementations for common data patterns.\n\n**Quicksort variants:**\n- qsort_i(): Sort integer array\n- qsort_id(): Sort int array, permute double array\n- qsort_ic(): Sort int array, permute char array\n- qsort_ii(): Sort int array, permute second int array\n- qsort_di(): Sort double array, permute int array\n\n**Utility functions:**\n- sym_gcd(): Greatest common divisor\n- d_gap(): Compute optimality gap percentage",
    "file": "sym_qsort",
    "library": "SYMPHONY",
    "layer": "layer-3",
    "header": "include/sym_qsort.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "sym_dg_u": {
    "brief": "User callbacks for Draw Graph visualization\n\nDefines callbacks for custom visualization behavior.\n\n**User callbacks:**\n- user_initialize_dg(): Global DG initialization\n- user_free_dg(): Global DG cleanup\n- user_dg_init_window(): Per-window setup\n- user_dg_free_window(): Per-window cleanup\n- user_dg_process_message(): Handle custom messages\n- user_interpret_text(): Process text input",
    "file": "sym_dg_u",
    "library": "SYMPHONY",
    "layer": "layer-3",
    "header": "include/sym_dg_u.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "sym_lp_u": {
    "brief": "User callbacks for LP solver process\n\nDefines callbacks that users implement to customize LP solving.\nReturn USER_DEFAULT to use built-in behavior.\n\n**Data transfer:**\n- user_receive_lp_data(): Receive problem-specific data\n- user_free_lp(): Clean up user data\n\n**Feasibility checking:**\n- user_is_feasible(): Custom integrality check\n- user_send_feasible_solution(): Pack solution for master\n- user_display_lp_solution(): Custom solution display\n\n**Branching callbacks:**\n- user_shall_we_branch(): Decide whether to branch\n- user_select_candidates(): Choose branching candidates\n- user_compare_candidates(): Rank two candidates\n- user_select_child(): Choose child node to explore\n\n**Cut handling:**\n- user_unpack_cuts(): Convert packed cuts to rows\n- user_generate_cuts_in_lp(): Generate cuts in LP process\n- user_same_cuts(): Compare two cuts for equality\n\n**Column generation:**\n- user_generate_column(): Create new variables dynamically\n- user_create_subproblem(): Build restricted LP\n\n**Built-in selection rules:**\n- branch_close_to_half(): Fractional variables near 0.5\n- branch_close_to_half_and_expensive(): Combine with objective\n- branch_close_to_one_and_cheap(): Variables near 1 with low cost",
    "file": "sym_lp_u",
    "library": "SYMPHONY",
    "layer": "layer-3",
    "header": "include/sym_lp_u.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "config_default": {
    "brief": "Default build configuration for SYMPHONY library\n\nDefines package dependencies when not using autoconf.\nEdit this file to enable/disable optional solver backends.\n\n**Required packages (always enabled):**\n- COIN_HAS_CGL: CGL cut generators\n- COIN_HAS_CLP: CLP linear solver\n- COIN_HAS_COINUTILS: CoinUtils foundation\n- COIN_HAS_OSI: OSI solver interface\n\n**Optional packages (commented by default):**\n- COIN_HAS_CBC: Cbc MIP solver\n- COIN_HAS_VOL: Volume algorithm\n- COIN_HAS_CPX: CPLEX\n- COIN_HAS_GLPK: GLPK\n- COIN_HAS_MSK: Mosek\n- COIN_HAS_XPR: Xpress\n- COIN_DEBUG: Runtime sanity checks",
    "file": "config_default",
    "library": "SYMPHONY",
    "layer": "layer-3",
    "header": "include/config_default.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "sym_cp": {
    "brief": "Cut Pool process for SYMPHONY\n\nThe Cut Pool (CP) stores generated cuts for potential reuse\nacross multiple B&C nodes. Manages cut quality and deduplication.",
    "file": "sym_cp",
    "library": "SYMPHONY",
    "layer": "layer-3",
    "header": "include/sym_cp.h",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "sp_params": {
    "brief": "Solution/column pool parameters for decomposition\n\nParameters controlling column storage and management.\n\n**sp_params structure:**\n- verbosity: Output level\n- etol: Numerical tolerance\n- block_size: Allocation granularity\n- max_size: Maximum pool memory\n- max_number_of_sols: Hard limit on columns\n- min_to_delete: Minimum batch deletion size\n- touches_until_deletion: Inactivity threshold\n- compress_num/ratio: When to compress pool\n\n**Check strategies (check_which):**\n- CHECK_ALL_COLS: Check everything\n- CHECK_COL_LEVEL: By tree depth\n- CHECK_COL_TOUCHES: By activity\n- CHECK_COL_LEVEL_AND_TOUCHES: Combined\n\n**Delete strategies (delete_which):**\n- DELETE_DUPLICATE_COLS: Only duplicates\n- DELETE_DUPLICATE_AND_INEFFECTIVE_COLS: Also inactive",
    "file": "sp_params",
    "library": "SYMPHONY",
    "layer": "layer-3",
    "header": "include/decomp/sp_params.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "decomp_lp": {
    "brief": "LP interface for decomposition master problem\n\nLoad/unload functions for the restricted master LP.\n\n**Functions:**\n- load_decomp_lp(): Initialize master LP with initial columns\n- unload_decomp_lp(): Cleanup master LP",
    "file": "decomp_lp",
    "library": "SYMPHONY",
    "layer": "layer-3",
    "header": "include/decomp/decomp_lp.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "decomp": {
    "brief": "Decomposition-based column generation for SYMPHONY\n\nImplements column generation via Dantzig-Wolfe decomposition\nfor problems with special structure.\n\n**Core functions:**\n- decomp(): Main decomposition algorithm\n- create_initial_lp(): Build restricted master problem\n- generate_new_cols(): Solve pricing subproblem\n- generate_cuts(): Cut generation in master\n- add_dcmp_cols(): Add columns to master LP\n\n**Column management:**\n- receive_cols(): Receive columns from subproblems\n- get_cols_from_pool(): Retrieve from column pool\n- free_dcmp_col_set(): Cleanup column set\n\n**User callbacks:**\n- user_generate_new_cols(): Custom pricing routine\n- user_unpack_col(): Expand packed column\n- user_pack_col(): Compress column for storage\n- user_check_col(): Verify column validity\n- user_set_rhs(): Define subproblem RHS\n- user_send_to_sol_pool(): Store promising columns",
    "file": "decomp",
    "library": "SYMPHONY",
    "layer": "layer-3",
    "header": "include/decomp/decomp.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "decomp_types": {
    "brief": "Data structures for decomposition column generation\n\nTypes for representing columns in Dantzig-Wolfe decomposition.\n\n**col_data (packed column):**\n- size: Size of coef array\n- coef: Packed column data\n- level: Tree level where generated\n- touches: Inactivity counter for deletion\n\n**dcmp_col_set (column batch):**\n- lb, ub, obj: Column bounds and costs\n- matbeg, matind, matval: CSC format matrix\n- num_cols, nzcnt: Dimensions\n- bd_type, ubnd: Bound type info",
    "file": "decomp_types",
    "library": "SYMPHONY",
    "layer": "layer-3",
    "header": "include/decomp/decomp_types.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "SmiSmpsIO": {
    "brief": "SMPS (Stochastic MPS) file format reader and writer\n\nSmiSmpsIO extends CoinMpsIO to read/write the industry-standard SMPS\nformat for stochastic programming problems.\n\n**SMPS File Format (3 files):**\n- {name}.core: Core LP in MPS format (deterministic base problem)\n- {name}.time: Stage assignments (PERIODS section maps rows/cols to stages)\n- {name}.stoch: Stochastic data (SCENARIOS or INDEP sections)\n\n**SmiSectionType Enum:**\n- SMI_TIME_SECTION: PERIODS in time file\n- SMI_SCENARIOS_SECTION: SCENARIOS in stoch file\n- SMI_INDEPENDENT_SECTION: INDEP in stoch file\n\n**SmiSmpsType Enum:**\n- SMI_SC_CARD: SC card (scenario definition)\n- SMI_BL_CARD: BL card (branch location)\n- SMI_SMPS_COMBINE_ADD/REPLACE: Data combination rules\n\n**SmiSmpsCardReader Class:**\nExtends CoinMpsCardReader for SMPS-specific parsing:\n- periodName(): Stage name from time file\n- scenarioNew/Anc(): Scenario branching info\n- getProb(): Scenario probability\n\n**Key Methods:**\n- readTimeFile(): Parse stage assignments\n- readStochFile(): Parse stochastic data\n- writeSmps(): Output SMPS files",
    "file": "SmiSmpsIO",
    "library": "Smi",
    "layer": "layer-3",
    "header": "Smi/src/SmiSmpsIO.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "SmiMessage": {
    "brief": "Message handler and codes for Smi logging\n\nSmiMessage extends CoinMessages to provide structured logging\nfor the stochastic programming interface.\n\n**SMI_Message Enum:**\n- SMI_SCENARIO_FINISHED: Scenario processing complete\n- SMI_DUMMY_END: End marker\n\n**SmiMessage Class:**\nCoinMessages-based message handler:\n- Constructor sets up message text templates\n- Supports multiple languages (default us_en)",
    "file": "SmiMessage",
    "library": "Smi",
    "layer": "layer-3",
    "header": "Smi/src/SmiMessage.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "SmiScenarioTree": {
    "brief": "Scenario tree data structure for stochastic programming\n\nSmiScenarioTree is a template class for storing and navigating scenario\ntrees. Each root-to-leaf path represents one complete scenario.\n\n**SmiTreeNode<T> Template:**\nGeneric tree node with navigation:\n- parent_, child_, sibling_: Tree structure pointers\n- depth_: Distance from root (root = 0)\n- scen_: Scenario index for leaf nodes\n- child_labels_: Map for label-based child lookup\n\n**SmiScenarioTree<T> Template:**\nTree container with:\n- root_: Root node pointer\n- leaf_: Vector of leaf node pointers (one per scenario)\n- node_data: All node data in tree traversal order\n- scen_data: Temporary buffer for scenario path extraction\n\n**Key Operations:**\n- addPathtoLeaf(): Add new scenario path from branch point\n- find(scenario, stage): Get node at specific (scenario, stage)\n- find(labels): Get node by following label sequence\n- getScenario(s): Get vector of data along scenario s path\n\n**Tree Structure:**\n```\n      root (stage 0)\n     /    \\\n  node    node (stage 1)\n  / \\      |\nleaf leaf leaf (scenarios 0,1,2)\n```",
    "file": "SmiScenarioTree",
    "library": "Smi",
    "layer": "layer-3",
    "header": "Smi/src/SmiScenarioTree.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "SmiDiscreteDistribution": {
    "brief": "Discrete probability distributions for stochastic programming\n\nClasses for representing discrete random variables and their distributions,\nused to generate scenario trees from independent stochastic elements.\n\n**SmiDiscreteDistribution Class:**\nContainer for multiple discrete random variables:\n- smiDiscrete_: Vector of SmiDiscreteRV objects\n- core_: Link to core problem data\n- combineRule_: How to merge events with core\n\n**SmiDiscreteRV Class:**\nSingle discrete random variable at a specific stage:\n- events_: Vector of SmiDiscreteEvent outcomes\n- stg_: Stage index for this RV\n- prob_: Total probability across events\n- addEvent(): Add outcome with LP data and probability\n\n**SmiDiscreteEvent Class:**\nOne possible outcome (realization) of a random variable:\n- Inherits SmiLinearData: matrix, bounds, objective changes\n- prob_: Probability of this event\n\n**Usage Pattern:**\n```cpp\nSmiDiscreteDistribution dist(core, rule);\nSmiDiscreteRV* rv = new SmiDiscreteRV(stage);\nrv->addEvent(matrix, clo, cup, obj, rlo, rup, 0.5);  // 50% chance\nrv->addEvent(..., 0.5);  // 50% chance\ndist.addDiscreteRV(rv);\nsmiModel.processDiscreteDistributionIntoScenarios(&dist);\n```",
    "file": "SmiDiscreteDistribution",
    "library": "Smi",
    "layer": "layer-3",
    "header": "Smi/src/SmiDiscreteDistribution.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "SmiScnModel": {
    "brief": "Main scenario model class for stochastic linear/quadratic programming\n\nSmiScnModel is the central class for representing and solving scenario-based\nstochastic programs. It builds deterministic equivalent (DE) formulations\nfrom scenario trees.\n\n**Typical Usage:**\n```cpp\nSmiScnModel smi;\nsmi.readSmps(\"problem\");              // Read SMPS files\nsmi.setOsiSolverHandle(new OsiClpSolverInterface());\nOsiSolverInterface* osi = smi.loadOsiSolverData();  // Build DE\nosi->initialSolve();                  // Solve extensive form\n```\n\n**Key Methods:**\n- readSmps(): Parse SMPS files (core + time + stoch)\n- generateScenario(): Add scenario with probability and branching info\n- loadOsiSolverData(): Build deterministic equivalent LP\n- getColSolution(scenario): Extract solution for specific scenario\n\n**Solution Values:**\n- solveWS(): Wait-and-See solution (perfect information)\n- solveEV(): Expected Value solution (average scenario)\n- solveEEV(): Expected result of using EV solution\n\n**SmiScnNode Class:**\nRepresents a node in the scenario tree with:\n- Stage index, probability, parent link\n- Column/row offsets into DE matrix\n- Link to SmiNodeData for LP data",
    "file": "SmiScnModel",
    "library": "Smi",
    "layer": "layer-3",
    "header": "Smi/src/SmiScnModel.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "SmiQuadratic": {
    "brief": "Quadratic objective data for stochastic quadratic programming\n\nClasses for storing quadratic objective terms in stochastic QP problems.\nThe quadratic objective is: (1/2) x' Q x + c' x\n\n**SmiQuadraticData Class:**\nBase class storing Q matrix in compressed sparse column format:\n- _n: Number of columns\n- _starts: Column start indices (size n+1)\n- _indx: Row indices of nonzeros\n- _els: Values of nonzeros\n- _coff: Column offset for stage-based indexing\n- _hasData: Flag for valid data\n\n**CSC Format:**\nFor column j, nonzeros are at positions [starts[j], starts[j+1]):\n- Row indices: indx[starts[j]] ... indx[starts[j+1]-1]\n- Values: els[starts[j]] ... els[starts[j+1]-1]\n\n**SmiQuadraticDataDC Class:**\n\"Data Container\" subclass that owns its memory:\n- Constructor allocates arrays\n- Destructor frees arrays",
    "file": "SmiQuadratic",
    "library": "Smi",
    "layer": "layer-3",
    "header": "Smi/src/SmiQuadratic.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "SmiCoreCombineRule": {
    "brief": "Rules for combining core and stochastic data in SMPS\n\nIn SMPS, stochastic data is a \"diff\" from the core problem. This file\ndefines how to apply that diff (combine core + stochastic \u2192 scenario).\n\n**SmiCoreCombineRule (Abstract Base):**\nVirtual interface for combination rules:\n- Process(d1, offset, cpv): Modify dense array d1 using sparse cpv\n- Process(cpv1, cpv2): Combine two sparse vectors\n\n**SmiCoreCombineReplace (Singleton):**\nDefault SMPS rule - stochastic values REPLACE core values:\n- scenario[i] = stochastic[i] if defined, else core[i]\n- Use case: Changing a coefficient value entirely\n\n**SmiCoreCombineAdd (Singleton):**\nAlternative rule - stochastic values ADD to core values:\n- scenario[i] = core[i] + stochastic[i]\n- Use case: Perturbations, additive uncertainty\n\n**Singleton Pattern:**\nBoth concrete rules use singleton pattern for efficiency:\n- SmiCoreCombineReplace::Instance()\n- SmiCoreCombineAdd::Instance()\n\n**Usage:**\nRules are passed to generateScenario() or readSmps() to control\nhow scenario data is constructed from core + stochastic inputs.",
    "file": "SmiCoreCombineRule",
    "library": "Smi",
    "layer": "layer-3",
    "header": "Smi/src/SmiCoreCombineRule.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "SmiScnData": {
    "brief": "Core and node data classes for stochastic models\n\nContains SmiCoreData (deterministic base LP) and SmiNodeData (scenario\nmodifications) that together define stochastic linear programs.\n\n**SmiCoreData Class:**\nStores the deterministic \"core\" LP problem with stage structure:\n- nrow_, ncol_: Total rows/columns in core problem\n- nstag_: Number of stages (periods)\n- stageRowPtr_[t], stageColPtr_[t]: Row/col offsets for stage t\n- nRowInStage_[t], nColInStage_[t]: Counts per stage\n- nodes_[t]: Core SmiNodeData for each stage\n- Dense bound arrays: cdrlo_, cdrup_, cdclo_, cdcup_, cdobj_\n\n**SmiNodeData Class:**\nStores LP modifications for a tree node (scenario/stage):\n- Sparse delta data: matrix rows, bounds, objective\n- combineRule_: How to merge with core (replace/add)\n- Stage membership and core linkage\n- Dense row map for efficient access\n\n**SMPS Data Flow:**\n1. Core MPS \u2192 SmiCoreData (base LP with stage assignments)\n2. Stoch file \u2192 SmiNodeData (per-scenario modifications)\n3. Combine with rule \u2192 Full scenario LP data\n\n**Type Aliases:**\n- SmiCoreIndex, SmiScenarioIndex, SmiStageIndex: int aliases",
    "file": "SmiScnData",
    "library": "Smi",
    "layer": "layer-3",
    "header": "Smi/src/SmiScnData.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "SmiLinearData": {
    "brief": "Container for linear programming data (matrix + bounds + objective)\n\nSmiLinearData bundles all LP data needed to define a linear subproblem\nor modification in stochastic programming.\n\n**Data Members:**\n- matrix_: Constraint matrix (CoinPackedMatrix)\n- dclo_, dcup_: Column (variable) bounds\n- drlo_, drup_: Row (constraint) bounds\n- dobj_: Objective coefficients\n\n**Constructors:**\n- Default: Empty data\n- Copy: From another SmiLinearData\n- From components: matrix + 5 sparse vectors\n- From OSI: Extract from OsiSolverInterface\n\n**Accessors:**\n- getMatrix(), getColLower(), etc.: Const references\n- getMutableMatrix(), etc.: Non-const for modification\n\n**Usage:**\nUsed as base class for SmiDiscreteEvent and as a data container\nfor passing LP modifications around the Smi system.",
    "file": "SmiLinearData",
    "library": "Smi",
    "layer": "layer-3",
    "header": "Smi/src/SmiLinearData.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "nlopt": {
    "brief": "NLopt (Nonlinear Optimization) C API - bundled with oBB\n\nNLopt is a library for nonlinear optimization providing a common\ninterface to many algorithms. This is a subset bundled with oBB.\n\n**nlopt_algorithm Enum (in this subset):**\n- NLOPT_LD_SLSQP: Sequential Least Squares Programming (local, derivative)\n\n**nlopt_result Enum:**\n- NLOPT_SUCCESS: Generic success\n- NLOPT_STOPVAL_REACHED, FTOL_REACHED, XTOL_REACHED: Convergence\n- NLOPT_MAXEVAL_REACHED, MAXTIME_REACHED: Limits hit\n- NLOPT_FAILURE, INVALID_ARGS, OUT_OF_MEMORY: Errors\n\n**Object-Oriented API:**\n- nlopt_create(algorithm, n): Create optimizer for n dimensions\n- nlopt_set_min/max_objective(): Set objective function\n- nlopt_set_lower/upper_bounds(): Set variable bounds\n- nlopt_add_inequality/equality_constraint(): Add constraints\n- nlopt_set_ftol_rel/abs(), xtol_rel/abs(): Set tolerances\n- nlopt_optimize(opt, x, &f): Run optimization\n- nlopt_destroy(opt): Clean up\n\n**Function Types:**\n- nlopt_func: double f(n, x, grad, data) - objective/constraint\n- nlopt_mfunc: void f(m, result, n, x, grad, data) - vector constraint",
    "file": "nlopt",
    "library": "oBB",
    "layer": "layer-3",
    "header": "nlopt/nlopt.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "slsqp": {
    "brief": "SLSQP (Sequential Least Squares Programming) algorithm - bundled with oBB\n\nSLSQP is a gradient-based algorithm for constrained nonlinear optimization\nusing sequential quadratic programming with BFGS updates.\n\n**Algorithm (Kraft, 1988):**\n1. Solve QP subproblem: min (1/2)d'Bd + g'd s.t. linearized constraints\n2. Line search along direction d\n3. Update Hessian approximation B using BFGS\n4. Repeat until convergence\n\n**nlopt_slsqp() Parameters:**\n- n: Number of variables\n- f, f_data: Objective function (with gradient)\n- m, fc: Inequality constraints (m constraints, c(x) <= 0)\n- p, h: Equality constraints (p constraints, h(x) = 0)\n- lb, ub: Variable bounds\n- x: Initial point (modified in place)\n- minf: Output - optimal objective value\n- stop: Stopping criteria (nlopt_stopping struct)\n\n**Characteristics:**\n- Local, derivative-based optimization\n- Handles nonlinear equality and inequality constraints\n- Efficient for smooth, medium-scale problems\n- Used by oBB for local refinement in global optimization",
    "file": "slsqp",
    "library": "oBB",
    "layer": "layer-3",
    "header": "slsqp/slsqp.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "nlopt-util": {
    "brief": "NLopt utility functions and stopping criteria - bundled with oBB\n\nInternal utilities for NLopt algorithms including floating-point\nhelpers, timing, stopping criteria, and constraint handling.\n\n**Floating-Point Helpers:**\n- nlopt_isinf(), nlopt_isfinite(), nlopt_istiny(), nlopt_isnan()\n\n**Timing:**\n- nlopt_seconds(): Current time in seconds\n- nlopt_time_seed(): Seed based on current time\n\n**nlopt_stopping Struct:**\nStopping criteria state:\n- n: Problem dimension\n- minf_max: Stop if f <= minf_max\n- ftol_rel, ftol_abs: Function tolerance (relative/absolute)\n- xtol_rel, xtol_abs: Variable tolerance\n- nevals, maxeval: Evaluation count/limit\n- maxtime, start: Time limit and start time\n- force_stop: External stop signal\n\n**Stopping Tests:**\n- nlopt_stop_f(): Check function value convergence\n- nlopt_stop_x(), nlopt_stop_dx(): Check variable convergence\n- nlopt_stop_evals(), nlopt_stop_time(): Check limits\n\n**nlopt_constraint Struct:**\nConstraint representation (f <= 0 or f = 0):\n- m: Constraint dimension\n- f/mf: Scalar or vector constraint function\n- tol: Feasibility tolerance",
    "file": "nlopt-util",
    "library": "oBB",
    "layer": "layer-3",
    "header": "nlopt/nlopt-util.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "nlopt-internal": {
    "brief": "NLopt internal optimizer structure - bundled with oBB\n\nInternal header defining the nlopt_opt_s structure (opaque nlopt_opt).\nNot part of public API - used by algorithm implementations.\n\n**struct nlopt_opt_s (nlopt_opt):**\nComplete optimizer state:\n- algorithm, n: Algorithm type and dimension (immutable)\n- f, f_data: Objective function and user data\n- pre: Optional preconditioner\n- maximize: Nonzero if maximizing\n- lb, ub: Variable bounds (length n)\n- m, fc: Inequality constraints (m constraints)\n- p, h: Equality constraints (p constraints)\n- Stopping criteria: stopval, ftol_rel, ftol_abs, xtol_rel, xtol_abs, maxeval, maxtime\n- force_stop: External stop flag\n- local_opt: Nested local optimizer (for hybrid algorithms)\n- dx: Initial step sizes for derivative-free algorithms\n- work: Algorithm-specific workspace\n- errmsg: Error message buffer\n\n**Global Defaults (deprecated):**\n- nlopt_local_search_alg_deriv/nonderiv\n- nlopt_local_search_maxeval\n- nlopt_stochastic_population",
    "file": "nlopt-internal",
    "library": "oBB",
    "layer": "layer-3",
    "header": "nlopt/nlopt-internal.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "chooseblock": {
    "brief": "Constraint block selection for Creme RTR algorithm\n\nchoose_block(): Select a block of constraints for randomized\nrounding based on violation and satisfaction status.",
    "file": "chooseblock",
    "library": "Creme",
    "layer": "layer-4",
    "header": "Creme/src/Base/chooseblock.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "rtr": {
    "brief": "Randomized rounding algorithm for Creme LP solver\n\nImplements rtr() to find maximal feasible subsystems (MFS) using\nrandomized iterative rounding. USE_RTR/USE_LOCSRCH mode selection.",
    "file": "rtr",
    "library": "Creme",
    "layer": "layer-4",
    "header": "Creme/src/Base/rtr.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "linopt": {
    "brief": "One-variable local optimization for Creme\n\nImplements one_opt() for single-variable neighborhood search.",
    "file": "linopt",
    "library": "Creme",
    "layer": "layer-4",
    "header": "Creme/src/Base/linopt.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "move": {
    "brief": "Variable move operation for Creme local search\n\nmove(): Perform a single variable update in local search,\nadjusting primal values and updating constraint satisfaction.",
    "file": "move",
    "library": "Creme",
    "layer": "layer-4",
    "header": "Creme/src/Base/move.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "lpio": {
    "brief": "LP file I/O functions for Creme solver\n\nread_problem(): Parse LP problem from file into sparseLP structure.\nprintLP(): Display LP problem contents.\nclearLP(): Deallocate LP memory.",
    "file": "lpio",
    "library": "Creme",
    "layer": "layer-4",
    "header": "Creme/src/Base/lpio.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "misc": {
    "brief": "Miscellaneous utilities for Creme solver\n\nMemory allocation helpers (reallocate_double/int), bzip2 file I/O,\nmatrix transpose creation, and vector norm computation.",
    "file": "misc",
    "library": "Creme",
    "layer": "layer-4",
    "header": "Creme/src/Base/misc.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "isfeas": {
    "brief": "Feasibility checking for Creme LP solutions\n\nisFeas(): Verify if a point satisfies LP constraints.\nReturns number of satisfied constraints and updates satisfaction flags.",
    "file": "isfeas",
    "library": "Creme",
    "layer": "layer-4",
    "header": "Creme/src/Base/isfeas.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "locsrch": {
    "brief": "Local search algorithm for Creme LP solver\n\nImplements locsrch() with dvar (delta variable) and frontier structures.",
    "file": "locsrch",
    "library": "Creme",
    "layer": "layer-4",
    "header": "Creme/src/Base/locsrch.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "init": {
    "brief": "Solution initialization for Creme randomized LP solver\n\ninit_x(): Initialize primal variable values.\ninit_sat(): Initialize constraint satisfaction tracking (b-Ax, sat flags).\ncalc_lhs(): Compute left-hand side of constraints (with SIMD pragmas).",
    "file": "init",
    "library": "Creme",
    "layer": "layer-4",
    "header": "Creme/src/Base/init.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "cmdline": {
    "brief": "Command-line argument parsing for Creme solver\n\ntpar struct: Defines command-line options (short/long flags, types, defaults).\nreadargs(): Parse argc/argv against option definitions.\nprint_help(): Display usage information.",
    "file": "cmdline",
    "library": "Creme",
    "layer": "layer-4",
    "header": "Creme/src/Base/cmdline.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "GamsScip": {
    "brief": "GAMS interface to SCIP solver\n\nConnects GAMS to SCIP for constraint integer programming.\nSupports LP, MIP, MINLP, and general constraint optimization.",
    "file": "GamsScip",
    "library": "GAMSlinks",
    "layer": "layer-4",
    "header": "src/scip/GamsScip.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "GamsBonmin": {
    "brief": "GAMS interface to Bonmin MINLP solver\n\nConnects GAMS to COIN-OR Bonmin for mixed-integer nonlinear programming.",
    "file": "GamsBonmin",
    "library": "GAMSlinks",
    "layer": "layer-4",
    "header": "src/bonmin/GamsBonmin.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "GamsMINLP": {
    "brief": "Bonmin TMINLP implementation for GAMS models\n\nGamsMINLP: Implements Bonmin::TMINLP using GMO for MINLP evaluation.\nHandles variable types, SOS constraints, and branching priorities.",
    "file": "GamsMINLP",
    "library": "GAMSlinks",
    "layer": "layer-4",
    "header": "src/bonmin/GamsMINLP.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "GamsOsiHelper": {
    "brief": "GAMS-OSI data transfer utilities\n\nHelper functions for loading LP problems from GMO to OSI,\nstoring solutions from OSI to GMO, and writing problem files.",
    "file": "GamsOsiHelper",
    "library": "GAMSlinks",
    "layer": "layer-4",
    "header": "src/osi/GamsOsiHelper.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "GamsMessageHandler": {
    "brief": "CoinMessageHandler implementation for GAMS output\n\nRoutes COIN-OR messages through GAMS environment (gev) logging.\nThread-safe via shared mutex for concurrent solver access.",
    "file": "GamsMessageHandler",
    "library": "GAMSlinks",
    "layer": "layer-4",
    "header": "src/osi/GamsMessageHandler.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "GamsOsi": {
    "brief": "GAMS interface to OSI-compatible solvers\n\nConnects GAMS to commercial solvers (CPLEX, Gurobi, Mosek, Xpress)\nvia the COIN-OR Open Solver Interface.",
    "file": "GamsOsi",
    "library": "GAMSlinks",
    "layer": "layer-4",
    "header": "src/osi/GamsOsi.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "GamsNLP": {
    "brief": "Ipopt TNLP implementation for GAMS models\n\nGamsNLP: Implements Ipopt::TNLP using GMO (GAMS Modeling Object)\nfor objective/constraint evaluation, Jacobian sparsity, Hessian.",
    "file": "GamsNLP",
    "library": "GAMSlinks",
    "layer": "layer-4",
    "header": "src/ipopt/GamsNLP.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "GamsIpopt": {
    "brief": "GAMS interface to Ipopt NLP solver\n\nConnects GAMS modeling environment to COIN-OR Ipopt.\n\n**GamsIpopt Class:**\n- ipopt: SmartPtr to IpoptApplication\n- nlp: GamsNLP problem representation\n- Warmstart support for sequential solves",
    "file": "GamsIpopt",
    "library": "GAMSlinks",
    "layer": "layer-4",
    "header": "src/ipopt/GamsIpopt.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "GamsJournal": {
    "brief": "Ipopt Journal implementation for GAMS output\n\nRoutes Ipopt logging through GAMS environment (gev) routines.\nSupports configurable status file output levels.",
    "file": "GamsJournal",
    "library": "GAMSlinks",
    "layer": "layer-4",
    "header": "src/ipopt/GamsJournal.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "GamsCouenne": {
    "brief": "GAMS interface to Couenne global optimizer\n\nConnects GAMS to COIN-OR Couenne for global optimization of\nnon-convex MINLP problems via spatial branch-and-bound.",
    "file": "GamsCouenne",
    "library": "GAMSlinks",
    "layer": "layer-4",
    "header": "src/couenne/GamsCouenne.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "GamsOptionsSpecWriter": {
    "brief": "",
    "file": "GamsOptionsSpecWriter",
    "library": "GAMSlinks",
    "layer": "layer-4",
    "header": "src/utils/GamsOptionsSpecWriter.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "GamsSoPlex": {
    "brief": "GAMS interface to SoPlex LP solver\n\nConnects GAMS modeling environment to the ZIB SoPlex\nsimplex-based LP solver.",
    "file": "GamsSoPlex",
    "library": "GAMSlinks",
    "layer": "layer-4",
    "header": "src/soplex/GamsSoPlex.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "GamsCbcHeurSolveTrace": {
    "brief": "CBC heuristic for GAMS solve trace reporting\n\nCbcHeuristic implementation that reports bound progress\nto GAMS solve trace data structure for performance analysis.",
    "file": "GamsCbcHeurSolveTrace",
    "library": "GAMSlinks",
    "layer": "layer-4",
    "header": "src/cbc/GamsCbcHeurSolveTrace.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "GamsCbc": {
    "brief": "GAMS interface to CBC MIP solver\n\nConnects GAMS modeling environment to COIN-OR CBC.\n\n**GamsCbc Class:**\n- gmo/gev: GAMS modeling object and environment handles\n- setupProblem()/setupParameters(): Configure CBC from GAMS\n- Solve trace support for performance analysis",
    "file": "GamsCbc",
    "library": "GAMSlinks",
    "layer": "layer-4",
    "header": "src/cbc/GamsCbc.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "reader_gmo": {
    "brief": "GMO file reader",
    "file": "reader_gmo",
    "library": "GAMSlinks",
    "layer": "layer-4",
    "header": "src/scip/reader_gmo.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "event_solvetrace": {
    "brief": "event handler to write GAMS solve trace file",
    "file": "event_solvetrace",
    "library": "GAMSlinks",
    "layer": "layer-4",
    "header": "src/scip/event_solvetrace.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "convert_nl": {
    "brief": "",
    "file": "convert_nl",
    "library": "GAMSlinks",
    "layer": "layer-4",
    "header": "src/amplsolver/convert_nl.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "GamsLicensing": {
    "brief": "",
    "file": "GamsLicensing",
    "library": "GAMSlinks",
    "layer": "layer-4",
    "header": "src/utils/GamsLicensing.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "GamsSolveTrace": {
    "brief": "",
    "file": "GamsSolveTrace",
    "library": "GAMSlinks",
    "layer": "layer-4",
    "header": "src/utils/GamsSolveTrace.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "param": {
    "brief": "Parameters (data constants) indexed over sets\n\nParameters hold fixed data values used in optimization models.\n\n**param_ Base Class:**\n- _name: Parameter name\n- _id: Unique identifier\n- _indices: Index set this parameter is defined over\n- _intype: Internal storage type (double_, integer_, etc.)\n\n**Complex Number Support:**\n- _is_conjugate: Complex conjugate flag\n- _is_sqrmag: Magnitude squared\n- _is_angle: Phase angle\n- _real, _imag: Real/imaginary part pointers\n- _mag, _ang: Magnitude/angle pointers\n\n**Ipopt Integration:**\n- _l_dual, _u_dual: Dual values for bound constraints\n- _off: On/off flags per instance\n\n**param<type> Template Class:**\n- _val: Vector of values\n- _range: Min/max bounds\n- Indexed access via operator()\n\n**Usage:**\n```cpp\nparam<> cost(\"cost\");\ncost.in(Nodes);                    // Index over Nodes\ncost.set_val(node_costs);          // Set values\ncost(\"node1\");                     // Access by key\n```",
    "file": "param",
    "library": "Gravity",
    "layer": "layer-4",
    "header": "include/gravity/param.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "types": {
    "brief": "cuOpt GPU dual simplex component\n\nPart of CUDA-accelerated dual simplex LP solver.",
    "file": "types",
    "library": "cuopt",
    "layer": "layer-4",
    "header": "cpp/src/dual_simplex/types.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "GurobiProgram": {
    "brief": "Gurobi solver interface for LP/MIP/QP problems\n\nAdapts Gravity models to the Gurobi C++ API.\n\n**GurobiProgram Class:**\n- grb_env: Gurobi environment\n- grb_mod: Gurobi model\n- _grb_vars: Mapping from Gravity vars to GRBVar\n- _model: Pointer to Gravity Model\n\n**Model Building:**\n- prepare_model(): Initial conversion from Gravity\n- fill_in_grb_vmap(): Create GRBVar for each variable\n- create_grb_constraints(): Add constraints (linear/quadratic)\n- set_grb_objective(): Set objective function\n\n**Solving:**\n- solve(relax, mipgap): Optimize with optional LP relaxation\n- relax_model(): Remove integrality constraints\n- update_solution(): Copy solution back to Gravity model\n\n**Supported Problem Types:**\n- LP: Linear programming\n- MIP: Mixed-integer programming\n- QP: Quadratic programming (convex)\n- MIQP: Mixed-integer QP",
    "file": "GurobiProgram",
    "library": "Gravity",
    "layer": "layer-4",
    "header": "include/gravity/GurobiProgram.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "utils": {
    "brief": "Utility functions for timing, printing, and sign operations\n\nGeneral utilities used throughout the Gravity library.\n\n**Timing:**\n- get_wall_time(): Wall clock time in seconds\n- get_cpu_time(): CPU time in seconds\n\n**Printing:**\n- clean_print(): Format value with sign for display\n- RESET macro: Terminal color reset code\n\n**Parallelism:**\n- bounds(parts, mem): Split memory/indices into chunks\n  for parallel processing\n\n**Sign Arithmetic:**\n- reverse(Sign): Negate sign\n- sign_add(s1, s2): Result sign of sum\n- sign_product(s1, s2): Result sign of product\n\n**Time Indexing:**\n- time(p1, p2): Create time-indexed set [p1, p2]\n- time(idx1, ...): Variadic time index construction\n\n**Complex Number Support:**\n- Comparison operators for Cpx type",
    "file": "utils",
    "library": "Gravity",
    "layer": "layer-4",
    "header": "include/gravity/utils.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "constraint": {
    "brief": "Constraint classes with type, duals, and lazy evaluation\n\nConstraints are functions with a constraint type (<=, >=, ==) and bounds.",
    "file": "constraint",
    "library": "Gravity",
    "layer": "layer-4",
    "header": "include/gravity/constraint.h",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "Auxiliary": {
    "brief": "Base class for auxiliary network objects (generators, loads)\n\nProvides a base class for objects attached to network nodes.\n\n**aux Class:**\n- _active: Whether this auxiliary is active in the model\n- _name: Identifier string\n- _phases: Set of electrical phases (for power systems)\n\n**Phase Support:**\n- set_phases(str): Parse phase string (e.g., \"1,2,3\")\n- has_phase(ph): Check if auxiliary has given phase\n\n**Usage in Power Systems:**\n- Generators attached to buses\n- Loads at network nodes\n- Capacitors, transformers, etc.",
    "file": "Auxiliary",
    "library": "Gravity",
    "layer": "layer-4",
    "header": "include/gravity/Auxiliary.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "expr": {
    "brief": "Expression tree nodes for unary and binary operations\n\nExpressions are the building blocks for functions and constraints.",
    "file": "expr",
    "library": "Gravity",
    "layer": "layer-4",
    "header": "include/gravity/expr.h",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "Net": {
    "brief": "Graph/network data structure for power systems and network optimization\n\nRepresents graphs with nodes, arcs, and cycles for network-based models.\n\n**Net Class:**\n- nodes: Vector of Node pointers\n- arcs: All arcs (existing + potential)\n- _exist_arcs: Only existing arcs\n- conting_arcs: Contingency arcs (for N-1 analysis)\n\n**Indexing Structures:**\n- nodeID: Map from node name to Node*\n- arcID: Map from (src_name, dest_name) to Arc*\n- arcMap: Map from arc name to Arc*\n\n**Node Pairs (for SDP relaxations):**\n- _node_pairs: Bus pairs for standard formulation\n- _node_pairs_chord: Bus pairs in chordal completion\n\n**Cycle Basis (for Kirchhoff constraints):**\n- cycle_basis: Vector of Path* forming basis\n- horton_net: Subnetwork for Horton algorithm\n\n**Tree Decomposition:**\n- _bags: Cliques from chordal extension\n- Used for SDP rank-1 constraints\n\n**Graph Algorithms:**\n- clone(), clone_undirected(): Copy graphs\n- Cycle detection, shortest paths\n- Chordal completion",
    "file": "Net",
    "library": "Gravity",
    "layer": "layer-4",
    "header": "include/gravity/Net.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "IpoptProgram": {
    "brief": "Ipopt solver interface implementing TNLP callbacks\n\nAdapts Gravity models to Ipopt's TNLP (Templated NLP) interface.\n\n**IpoptProgram<type> Class:**\n- Inherits from Ipopt::TNLP and Program<type>\n- _model: Pointer to Gravity Model\n\n**Required TNLP Callbacks:**\n- get_nlp_info(): Return problem dimensions (n, m, nnz_jac, nnz_hess)\n- get_bounds_info(): Variable and constraint bounds\n- get_starting_point(): Initial x, z_L, z_U, lambda\n- eval_f(): Objective function value\n- eval_grad_f(): Objective gradient\n- eval_g(): Constraint values\n- eval_jac_g(): Jacobian values and structure\n- eval_h(): Hessian of Lagrangian\n- finalize_solution(): Copy solution back to model\n\n**Sparsity Pattern:**\n- First call to eval_jac_g/eval_h: return structure (iRow, jCol)\n- Subsequent calls: return values only\n- Gravity tracks via _first_call_jac, _first_call_hess\n\n**Solution Recovery:**\n- finalize_solution() copies x values to model variables\n- Retrieves dual values (lambda) for constraints\n- Retrieves bound multipliers (z_L, z_U)",
    "file": "IpoptProgram",
    "library": "Gravity",
    "layer": "layer-4",
    "header": "include/gravity/IpoptProgram.h",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "rapidcsv": {
    "brief": "Datastructure holding parameters controlling how invalid numbers (including\n           empty strings) should be handled.",
    "file": "rapidcsv",
    "library": "Gravity",
    "layer": "layer-4",
    "header": "include/gravity/rapidcsv.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "func": {
    "brief": "Expression functions with automatic differentiation and convexity tracking\n\nThe func class represents mathematical expressions with symbolic analysis.",
    "file": "func",
    "library": "Gravity",
    "layer": "layer-4",
    "header": "include/gravity/func.h",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "constant": {
    "brief": "Scalar and vector constants with type tracking\n\nBase constant class and typed constant templates for numeric values.\n\n**constant_ Base Class:**\n- _type: CType enum (binary_c, integer_c, double_c, complex_c, etc.)\n- _is_transposed: Transpose flag for matrix operations\n- _is_vector: True if vector/matrix\n- _dim[2]: Dimensions (rows, cols)\n- _polar: Complex polar representation flag\n\n**CType Classification:**\n- Scalar types: binary_c, short_c, integer_c, float_c, double_c, long_c\n- Special types: par_c (param), var_c (variable), func_c (function)\n- Expression types: uexp_c (unary), bexp_c (binary)\n\n**constant<type> Template:**\n- Holds single typed value\n- Implicit conversion from numeric types\n- String conversion with precision\n\n**Helper Functions:**\n- to_string_with_precision(): Format numbers\n- unit<type>(): Multiplicative identity (1)\n- zero<type>(): Additive identity (0)\n\n**Complex Support:**\n- Cpx typedef for complex<double>\n- Polar/rectangular representation",
    "file": "constant",
    "library": "Gravity",
    "layer": "layer-4",
    "header": "include/gravity/constant.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "CplexProgram": {
    "brief": "IBM CPLEX solver interface for LP/MIP/QP problems\n\nAdapts Gravity models to the IBM ILOG CPLEX C++ API.\n\n**CplexProgram Class:**\n- _cplex_env: IloEnv (CPLEX environment)\n- _cplex_model: IloModel (CPLEX model)\n- _cplex_vars: Mapping from Gravity vars to IloNumVarArray\n\n**Model Building:**\n- prepare_model(): Initial conversion from Gravity\n- fill_in_cplex_vars(): Create IloNumVar for each variable\n- create_cplex_constraints(): Add constraints\n- set_cplex_objective(): Set objective function\n\n**Solving:**\n- solve(relax, mipgap): Optimize with optional LP relaxation\n- warm_start(): Initialize from current solution\n- relax_model(): Remove integrality constraints\n\n**Callback Support:**\n- _cplex_contextmask: Context for callback location\n- create_callback(): Set up user callbacks",
    "file": "CplexProgram",
    "library": "Gravity",
    "layer": "layer-4",
    "header": "include/gravity/CplexProgram.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "Arc": {
    "brief": "Directed arc/edge for network optimization models\n\nRepresents an arc (edge) connecting two nodes in a graph.\n\n**Arc Class:**\n- _id: Numeric identifier\n- _name: String name\n- _src, _dest: Source and destination Node pointers\n- _weight: Arc weight/cost\n- _len: Arc length\n\n**Power System Attributes:**\n- _is_transformer: True if arc represents a transformer\n- _phases: Set of phases (for 3-phase systems)\n- _parallel: True if parallel arc exists\n\n**Planning Attributes:**\n- _active: Whether arc is active in model\n- _expansion: True if potential expansion arc\n- _imaginary: Imaginary arc for algorithm use\n\n**Graph Algorithm Support:**\n- in_cycle: True if arc is in a cycle\n- horton_path: Pointer to Horton path through this arc\n- _intersection: Common neighbors of src and dest\n- _intersection_clique: For clique tree algorithms\n\n**Methods:**\n- neighbour(Node* n): Get other endpoint\n- clone(): Deep copy arc",
    "file": "Arc",
    "library": "Gravity",
    "layer": "layer-4",
    "header": "include/gravity/Arc.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "MosekProgram": {
    "brief": "Mosek Fusion API interface for conic optimization\n\nAdapts Gravity models to Mosek's Fusion API for conic programming.\n\n**MosekProgram Class:**\n- _mosek_model: Mosek Fusion Model\n- _mosek_vars: Vector of Mosek Variable::t handles\n\n**Conic Capabilities:**\n- Second-order cone (SOCP)\n- Semidefinite programming (SDP)\n- Exponential cone\n\n**Expression Building:**\n- form_Fx(qterms): Build quadratic matrix form F*x\n- create_lin_expr(lterms, cst): Linear expression construction\n\n**Model Building:**\n- fill_in_mosek_vars(): Create Mosek variables\n- create_mosek_constraints(): Add conic constraints\n- set_mosek_objective(): Set objective\n\n@note Mosek Fusion is designed specifically for conic optimization,\n      making it ideal for SOCP and SDP problems in power systems.",
    "file": "MosekProgram",
    "library": "Gravity",
    "layer": "layer-4",
    "header": "include/gravity/MosekProgram.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "solver": {
    "brief": "cuOpt VRP solver\n\nMain VRP solver orchestrating metaheuristics.",
    "file": "solver",
    "library": "cuopt",
    "layer": "layer-4",
    "header": "cpp/src/routing/solver.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "var": {
    "brief": "Decision variables with bounds for optimization models\n\nVariables are parameters with lower and upper bounds that the solver optimizes.\n\n**var<type> Template Class:**\n- Inherits from param<type> (shares indexing, values storage)\n- Adds _lb, _ub as func<type> (bounds can be expressions)\n- Supports: double, int, bool (binary), complex<double>\n\n**Bound Types:**\n- Unbounded: var(\"x\") - uses numeric_limits\n- Non-negative: var(\"x\", non_neg_)\n- Non-positive: var(\"x\", non_pos_)\n- Bounded: var(\"x\", lb, ub)\n- Indexed bounds: var(\"x\", lb_param, ub_param) over indices\n\n**Lifted Variables:**\n- _lift flag for McCormick/RLT linearization\n- _original_vars: pointers to variables being lifted\n- _lift_lb, _lift_ub: whether lifted var needs bounding functions\n\n**Mosek/SDP Support:**\n- _in_q_cone: variable in quadratic cone\n- _psd: positive semidefinite matrix variable\n\n**Usage Example:**\n```cpp\nvar<> x(\"x\", 0, 1);           // x in [0,1]\nvar<int> y(\"y\", 0, 10);       // integer y in [0,10]\nvar<bool> z(\"z\");             // binary z\nx.in(Nodes);                   // x indexed over Nodes\n```",
    "file": "var",
    "library": "Gravity",
    "layer": "layer-4",
    "header": "include/gravity/var.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "model": {
    "brief": "HiGHS QP solver component\n\nPart of HiGHS quadratic programming active set solver.",
    "file": "model",
    "library": "HiGHS",
    "layer": "layer-4",
    "header": "extern/filereaderlp/model.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "Path": {
    "brief": "Graph path/cycle representation for network algorithms\n\nRepresents a sequence of nodes forming a path or cycle in a network.\n\n**Path Class:**\n- nodes: List of Node pointers in sequence\n\n**Methods:**\n- source_dest(n1, n2): Check if path connects n1 to n2\n- length(): Number of edges in path\n- cycle(): True if path is a closed cycle\n- clone(): Deep copy path\n- to_str(): String representation\n\n**Usage in Gravity:**\n- cycle_basis in Net: Fundamental cycles for Kirchhoff constraints\n- horton_path in Arc: Horton algorithm shortest paths\n- Power flow loop constraints",
    "file": "Path",
    "library": "Gravity",
    "layer": "layer-4",
    "header": "include/gravity/Path.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "Node": {
    "brief": "Graph node/vertex for network optimization models\n\nRepresents a node in network graphs (power systems, transportation, etc.).\n\n**Node Class:**\n- _name: Unique string identifier\n- _id: Numeric ID within container\n- _type_name: \"Nodes\" (for indexing)\n- _active: Whether node is active in model\n\n**Connectivity:**\n- branches: Vector of incident Arc pointers\n- degree(): Number of incident arcs\n- addArc(), removeArc(): Modify adjacency\n\n**Graph Algorithms:**\n- explored: BFS/DFS traversal flag\n- cycle: True if node is in a cycle\n- predecessor: Parent in BFS tree\n- distance: Distance from source in BFS\n- fill_in: Edges needed to make neighbors a clique\n\n**Power System Extensions:**\n- _phases: Set of phases (for 3-phase systems)",
    "file": "Node",
    "library": "Gravity",
    "layer": "layer-4",
    "header": "include/gravity/Node.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "HiGHSProgram": {
    "brief": "HiGHS solver interface for LP/MIP problems\n\nAdapts Gravity models to the HiGHS open-source LP/MIP solver.\n\n**HiGHSProgram Class:**\n- Highs_mod: HighsModel (HiGHS model container)\n- Highs_inst: Highs solver instance\n\n**Model Building:**\n- prepare_model(): Initial conversion from Gravity\n- fill_in_var_map(): Create variable mappings\n- create_constraints(): Add linear constraints\n- set_objective(): Set linear objective\n\n**Solving:**\n- solve(relax, mipgap): Optimize with optional LP relaxation\n- update_solution(): Copy solution back to Gravity model\n- relax_model(): Remove integrality constraints\n\n**Supported Problem Types:**\n- LP: Linear programming\n- MIP: Mixed-integer programming\n\n@note HiGHS is an open-source solver that excels at large-scale LP\n      and MIP problems with state-of-the-art performance.",
    "file": "HiGHSProgram",
    "library": "Gravity",
    "layer": "layer-4",
    "header": "include/gravity/HiGHSProgram.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "presolve": {
    "brief": "cuOpt LP presolve\n\nBound tightening and constraint reduction for LP.",
    "file": "presolve",
    "library": "cuopt",
    "layer": "layer-4",
    "header": "cpp/src/dual_simplex/presolve.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "PardisoLoader": {
    "brief": "",
    "file": "PardisoLoader",
    "library": "Gravity",
    "layer": "layer-4",
    "header": "thirdparty/Ipopt/include/coin/PardisoLoader.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "HSLLoader": {
    "brief": "",
    "file": "HSLLoader",
    "library": "Gravity",
    "layer": "layer-4",
    "header": "thirdparty/Ipopt/include/coin/HSLLoader.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "catch": {
    "brief": "HiGHS QP solver component\n\nPart of HiGHS quadratic programming active set solver.",
    "file": "catch",
    "library": "HiGHS",
    "layer": "layer-4",
    "header": "extern/catch.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "CLI11": {
    "brief": "HiGHS QP solver component\n\nPart of HiGHS quadratic programming active set solver.",
    "file": "CLI11",
    "library": "HiGHS",
    "layer": "layer-4",
    "header": "app/CLI11.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "matrix_multiplication": {
    "brief": "HiGHS QP solver component\n\nPart of HiGHS quadratic programming active set solver.",
    "file": "matrix_multiplication",
    "library": "HiGHS",
    "layer": "layer-4",
    "header": "check/matrix_multiplication.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "devexpricing": {
    "brief": "HiGHS Devex pricing for QP active set method\n\nDevex pricing strategy: approximate steepest edge using\nreference framework with periodic weight updates.",
    "file": "devexpricing",
    "library": "HiGHS",
    "layer": "layer-4",
    "header": "highs/qpsolver/devexpricing.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "pricing": {
    "brief": "HiGHS QP pricing base class\n\nAbstract pricing strategy interface for QP active set method.\nSelects entering variable for basis change.",
    "file": "pricing",
    "library": "HiGHS",
    "layer": "layer-4",
    "header": "highs/qpsolver/pricing.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "reducedcosts": {
    "brief": "HiGHS QP reduced costs\n\nReduced cost computation for QP active set algorithm.\nManages gradient projection onto feasible directions.",
    "file": "reducedcosts",
    "library": "HiGHS",
    "layer": "layer-4",
    "header": "highs/qpsolver/reducedcosts.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "factor": {
    "brief": "HiGHS QP reduced Hessian Cholesky factorization\n\nBasis factorization for QP solver. Cholesky decomposition\nof reduced Hessian Z'QZ for efficient direction computation.",
    "file": "factor",
    "library": "HiGHS",
    "layer": "layer-4",
    "header": "highs/qpsolver/factor.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "a_quass": {
    "brief": "HiGHS QUASS QP algorithm\n\nQUASS (QUadratic Active Set Solver) main algorithm.\nPrimal active set method for convex QP.",
    "file": "a_quass",
    "library": "HiGHS",
    "layer": "layer-4",
    "header": "highs/qpsolver/a_quass.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "feasibility_highs": {
    "brief": "HiGHS QP feasibility restoration via LP\n\nFeasibility restoration using HiGHS LP solver.\nHandles infeasible iterates during QP solving.",
    "file": "feasibility_highs",
    "library": "HiGHS",
    "layer": "layer-4",
    "header": "highs/qpsolver/feasibility_highs.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "devexharrispricing": {
    "brief": "HiGHS Devex-Harris hybrid pricing\n\nCombined Devex and Harris ratio test for QP pricing.\nBalances accuracy and numerical stability.",
    "file": "devexharrispricing",
    "library": "HiGHS",
    "layer": "layer-4",
    "header": "highs/qpsolver/devexharrispricing.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "matrix": {
    "brief": "HiGHS QP matrix operations\n\nSparse matrix utilities for QP solver. Row/column access,\nproducts, and basis matrix maintenance.",
    "file": "matrix",
    "library": "HiGHS",
    "layer": "layer-4",
    "header": "highs/qpsolver/matrix.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "steepestedgepricing": {
    "brief": "HiGHS steepest edge pricing for QP active set method\n\nSteepest edge pricing for QP active set. Exact edge weights\nfor optimal variable selection (more expensive than Devex).",
    "file": "steepestedgepricing",
    "library": "HiGHS",
    "layer": "layer-4",
    "header": "highs/qpsolver/steepestedgepricing.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "eventhandler": {
    "brief": "HiGHS QP event handler\n\nCallback interface for QP solver events. Iteration callbacks,\nlogging, and early termination hooks.",
    "file": "eventhandler",
    "library": "HiGHS",
    "layer": "layer-4",
    "header": "highs/qpsolver/eventhandler.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "basis": {
    "brief": "Basis management for IPX interior point solver\n\nManages simplex-style basis for IPM preconditioning and crossover.\n\n**BasicStatus Enum:**\n- NONBASIC_FIXED: Fixed at bound, never enters basis\n- NONBASIC: At bound, may enter basis\n- BASIC: In basis, may leave\n- BASIC_FREE: In basis, never leaves\n\n**Basis Storage:**\n- basis_[p]: Column index at position p (0 <= p < m)\n- map2basis_[j]: Position of variable j, or -1/-2 if nonbasic\n- StatusOf(), PositionOf(), IsBasic(): Query methods\n\n**Linear Algebra Operations:**\n- Factorize(): LU factorization with stability check\n- SolveDense(): FTRAN/BTRAN for dense RHS\n- SolveForUpdate(): Prepare for basis exchange\n- TableauRow(): Compute simplex tableau row\n- ExchangeIfStable(): Pivot with stability check\n\n**Basis Construction:**\n- SetToSlackBasis(): Initialize to identity\n- Load(): Load user-provided basis\n- ConstructBasisFromWeights(): Crash procedure\n- CrashBasis(): Fast weighted crash\n- Repair(): Fix singularities with slack columns\n\n**Statistics:**\n- factorizations(), updates_total(): Counts\n- frac_ftran_sparse(), frac_btran_sparse(): Sparsity metrics\n- mean_fill(), max_fill(): LU fill factors",
    "file": "basis",
    "library": "HiGHS",
    "layer": "layer-4",
    "header": "highs/ipm/ipx/basis.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "reducedgradient": {
    "brief": "HiGHS QP reduced gradient",
    "file": "reducedgradient",
    "library": "HiGHS",
    "layer": "layer-4",
    "header": "highs/qpsolver/reducedgradient.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "perturbation": {
    "brief": "HiGHS QP perturbation\n\nPerturbation for handling degeneracy in QP.\nAdds small shifts to ensure unique optima.",
    "file": "perturbation",
    "library": "HiGHS",
    "layer": "layer-4",
    "header": "highs/qpsolver/perturbation.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "feasibility_bounded": {
    "brief": "HiGHS QP bounded feasibility\n\nBounded feasibility subroutine for QP.\nHandles box constraints during active set updates.",
    "file": "feasibility_bounded",
    "library": "HiGHS",
    "layer": "layer-4",
    "header": "highs/qpsolver/feasibility_bounded.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "qpvector": {
    "brief": "HiGHS QP vector utilities\n\nDense vector operations for QP solver.\nBasic linear algebra with QP-specific optimizations.",
    "file": "qpvector",
    "library": "HiGHS",
    "layer": "layer-4",
    "header": "highs/qpsolver/qpvector.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "settings": {
    "brief": "HiGHS QP solver settings\n\nParameter settings for QUASS QP solver.\nTolerances, iteration limits, and algorithm options.",
    "file": "settings",
    "library": "HiGHS",
    "layer": "layer-4",
    "header": "highs/qpsolver/settings.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "snippets": {
    "brief": "HiGHS QP code snippets\n\nUtility code snippets for QP solver implementation.\nCommon patterns and helper macros.",
    "file": "snippets",
    "library": "HiGHS",
    "layer": "layer-4",
    "header": "highs/qpsolver/snippets.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "crashsolution": {
    "brief": "HiGHS QP crash solution\n\nInitial solution heuristic for QP solver.\nGenerates starting point for active set method.",
    "file": "crashsolution",
    "library": "HiGHS",
    "layer": "layer-4",
    "header": "highs/qpsolver/crashsolution.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "runtime": {
    "brief": "HiGHS QP runtime data\n\nRuntime state for QUASS algorithm.\nStores iteration counts, timers, and status.",
    "file": "runtime",
    "library": "HiGHS",
    "layer": "layer-4",
    "header": "highs/qpsolver/runtime.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "gradient": {
    "brief": "HiGHS QP gradient maintenance\n\nIncremental gradient updates for QP active set method.",
    "file": "gradient",
    "library": "HiGHS",
    "layer": "layer-4",
    "header": "highs/qpsolver/gradient.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "qpconst": {
    "brief": "HiGHS QP solver component\n\nPart of HiGHS quadratic programming active set solver.",
    "file": "qpconst",
    "library": "HiGHS",
    "layer": "layer-4",
    "header": "highs/qpsolver/qpconst.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "a_asm": {
    "brief": "HiGHS QP solver component\n\nPart of HiGHS quadratic programming active set solver.",
    "file": "a_asm",
    "library": "HiGHS",
    "layer": "layer-4",
    "header": "highs/qpsolver/a_asm.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "quass": {
    "brief": "HiGHS QP solver component\n\nPart of HiGHS quadratic programming active set solver.",
    "file": "quass",
    "library": "HiGHS",
    "layer": "layer-4",
    "header": "highs/qpsolver/quass.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "statistics": {
    "brief": "HiGHS QP solver component\n\nPart of HiGHS quadratic programming active set solver.",
    "file": "statistics",
    "library": "HiGHS",
    "layer": "layer-4",
    "header": "highs/qpsolver/statistics.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "dantzigpricing": {
    "brief": "HiGHS QP Dantzig pricing rule\n\nClassic Dantzig pricing: select constraint with largest dual infeasibility.",
    "file": "dantzigpricing",
    "library": "HiGHS",
    "layer": "layer-4",
    "header": "highs/qpsolver/dantzigpricing.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "scaling": {
    "brief": "cuOpt matrix preprocessing\n\nScaling and permutation for numerical stability.",
    "file": "scaling",
    "library": "cuopt",
    "layer": "layer-4",
    "header": "cpp/src/dual_simplex/scaling.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "instance": {
    "brief": "HiGHS QP solver component\n\nPart of HiGHS quadratic programming active set solver.",
    "file": "instance",
    "library": "HiGHS",
    "layer": "layer-4",
    "header": "highs/qpsolver/instance.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "zstr": {
    "brief": "HiGHS QP solver component\n\nPart of HiGHS quadratic programming active set solver.",
    "file": "zstr",
    "library": "HiGHS",
    "layer": "layer-4",
    "header": "extern/zstr/zstr.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "strict_fstream": {
    "brief": "HiGHS QP solver component\n\nPart of HiGHS quadratic programming active set solver.",
    "file": "strict_fstream",
    "library": "HiGHS",
    "layer": "layer-4",
    "header": "extern/zstr/strict_fstream.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "builder": {
    "brief": "HiGHS QP solver component\n\nPart of HiGHS quadratic programming active set solver.",
    "file": "builder",
    "library": "HiGHS",
    "layer": "layer-4",
    "header": "extern/filereaderlp/builder.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "reader": {
    "brief": "HiGHS QP solver component\n\nPart of HiGHS quadratic programming active set solver.",
    "file": "reader",
    "library": "HiGHS",
    "layer": "layer-4",
    "header": "extern/filereaderlp/reader.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "def": {
    "brief": "HiGHS QP solver component\n\nPart of HiGHS quadratic programming active set solver.",
    "file": "def",
    "library": "HiGHS",
    "layer": "layer-4",
    "header": "extern/filereaderlp/def.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "Highs": {
    "brief": "Main HiGHS solver class - high-performance LP/MIP/QP optimization\n\nHiGHS (High-performance Interior point and Gradient descent Solvers) is\nan open-source solver for LP, MIP, and convex QP problems.\n\n**Highs Class (Main API):**\nPrimary interface for model input, solving, and solution retrieval:\n- passModel(): Load LP/QP/MIP from HighsModel, HighsLp, or raw arrays\n- run(): Solve the incumbent model\n- getSolution(), getBasis(): Retrieve solution and basis\n- getModelStatus(): Check optimization result\n\n**Solving Capabilities:**\n- LP: Dual/primal simplex (HEkk) or interior point (IPX)\n- MIP: Branch-and-cut with presolve, cuts, and heuristics\n- QP: Convex quadratic programming via interior point or active set\n\n**Model Modification:**\n- addCol/addRow, deleteCols/deleteRows: Incremental model building\n- changeColBounds, changeRowBounds, changeColCost: Hot-start friendly\n- changeCoeff: Modify individual matrix coefficients\n\n**Basis Operations:**\n- getBasisInverseRow/Col: Access B^{-1} for advanced use\n- getBasisSolve/getBasisTransposeSolve: Solve B*x=b or B'*x=b\n- getReducedRow/Col: Compute B^{-1}*A columns\n\n**Options and Info:**\n- setOptionValue/getOptionValue: Configure solver behavior\n- getInfo: Retrieve solve statistics (iterations, time, etc.)",
    "file": "Highs",
    "library": "HiGHS",
    "layer": "layer-4",
    "header": "highs/Highs.h",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "Avgas": {
    "brief": "Utilities for tests with AVGAS",
    "file": "Avgas",
    "library": "HiGHS",
    "layer": "layer-4",
    "header": "check/Avgas.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "SpecialLps": {
    "brief": "Utilities for tests with special LPs",
    "file": "SpecialLps",
    "library": "HiGHS",
    "layer": "layer-4",
    "header": "check/SpecialLps.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "highs_c_api": {
    "brief": "Pure C interface to HiGHS solver\n\nProvides C-compatible API for LP/MIP/QP solving without C++ dependencies.\n\n**Quick-Start Functions:**\n- Highs_lpCall(): Solve LP in one call with solution returned\n- Highs_mipCall(): Solve MIP in one call\n- Highs_qpCall(): Solve QP in one call\n\n**Full API (via Highs pointer):**\n- Highs_create()/Highs_destroy(): Instance management\n- Highs_passLp()/Highs_passMip(): Pass model data\n- Highs_run(): Solve current model\n- Highs_getSolution()/Highs_getBasis(): Retrieve results\n- Highs_setOption*(): Configure solver options\n- Highs_getInfo*(): Query solver statistics\n\n**Status Constants:**\n- kHighsStatus{Ok,Warning,Error}: Return codes\n- kHighsModelStatus*: Optimal, Infeasible, Unbounded, etc.\n- kHighsBasisStatus*: Lower, Basic, Upper, Zero, Nonbasic\n\n**Type Constants:**\n- kHighsVarType*: Continuous, Integer, SemiContinuous, etc.\n- kHighsOptionType*: Bool, Int, Double, String\n- kHighsMatrixFormat*: Colwise, Rowwise",
    "file": "highs_c_api",
    "library": "HiGHS",
    "layer": "layer-4",
    "header": "highs/interfaces/highs_c_api.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "CupdlpWrapper": {
    "brief": "Wrapper for CUPDLP first-order LP solver\n\nIntegrates CUPDLP (CUDA/CPU Primal-Dual LP) solver into HiGHS.\nCUPDLP uses first-order methods (PDHG) for LP solving without pivoting.\n\n**Main Functions:**\n- solveLpCupdlp(): Solve LP using CUPDLP algorithm\n- formulateLP_highs(): Convert HighsLp to CUPDLP format (CSC, rhs, bounds)\n- getCupdlpLogLevel(): Map HiGHS verbosity to CUPDLP log level\n\n**Problem Setup:**\n- problem_create()/problem_alloc(): Allocate CUPDLP problem structure\n- data_alloc(): Allocate matrix data (supports GPU if CUPDLP_GPU defined)\n\n**Memory Macros:**\n- cupdlp_init_*: Allocation helpers for int, double, work, problem, data\n- cupdlp_copy_vec: CPU vector copy (GPU uses CUDA memcpy)\n\n**GPU Support:**\nCompile with CUPDLP_GPU for CUDA acceleration via cuPDLP backend.",
    "file": "CupdlpWrapper",
    "library": "HiGHS",
    "layer": "layer-4",
    "header": "highs/pdlp/CupdlpWrapper.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "HighsLpUtils": {
    "brief": "Utility functions for LP manipulation, I/O, and validation\n\nCollection of free functions operating on HighsLp and related structures.\n\n**Basis I/O:**\n- writeBasisFile(): Export basis to file\n- readBasisFile()/readBasisStream(): Import basis from file/stream\n\n**Index/Name Lookup:**\n- getIndexFromName(): Resolve variable/constraint name to index\n\n**LP Assessment:**\n- assessLp(): Validate LP data consistency\n- lpDimensionsOk(): Check matrix dimensions\n- assessCosts(): Validate objective coefficients\n- assessBounds(): Validate variable/constraint bounds\n- applyScalingToLp()/applyScalingToLpCol/Row(): Apply scaling factors\n\n**LP Modification:**\n- appendColsToLp(), appendRowsToLp(): Extend LP\n- transformIntoEqualityProblem(): Convert to standard form\n\n**Solution Utilities:**\n- getLpCosts(), analyseObjective(): Cost analysis\n- writeSolution(): Export solution to file",
    "file": "HighsLpUtils",
    "library": "HiGHS",
    "layer": "layer-4",
    "header": "highs/lp_data/HighsLpUtils.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "HighsIis": {
    "brief": "Irreducible Infeasible Set (IIS) computation for infeasible LPs\n\nIdentifies minimal subset of constraints that cannot be satisfied.\n\n**IIS Definition:**\n- Minimal infeasible subsystem: removing any constraint makes it feasible\n- Helps diagnose why an LP is infeasible\n- Also identifies which variable bounds participate\n\n**IisBoundStatus:**\n- kDropped: Bound removed from IIS\n- kNull: Not yet classified\n- kFree: Variable is free (not in IIS)\n- kLower/kUpper/kBoxed: Which bound(s) are in IIS\n\n**Algorithm:**\n- compute(): Main IIS computation using simplex iterations\n- trivial(): Check for obviously infeasible (single row/col)\n- rowValueBounds(): Check row activity vs bounds\n\n**Strategy:**\n- kIisStrategyMin: Minimize IIS size (more iterations)\n- Iteratively removes constraints until minimal set remains\n\n**Output:**\n- col_index_/row_index_: Variables/constraints in IIS\n- col_bound_/row_bound_: Which bounds contribute\n- info_: Simplex stats per iteration",
    "file": "HighsIis",
    "library": "HiGHS",
    "layer": "layer-4",
    "header": "highs/lp_data/HighsIis.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "HighsAnalysis": {
    "brief": "Timer clock aggregation for performance analysis\n\nGroups named timer clocks for measuring algorithm phases.\n\n**HighsTimerClock:**\n- timer_pointer_: Reference to parent HighsTimer\n- clock_[]: Vector of clock indices for this group\n\n**Usage:**\n- Simplex phases (pricing, ratio test, update)\n- IPM iterations\n- MIP operations (cuts, branching, heuristics)",
    "file": "HighsAnalysis",
    "library": "HiGHS",
    "layer": "layer-4",
    "header": "highs/lp_data/HighsAnalysis.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "HighsLp": {
    "brief": "Linear programming model data structure\n\n**HighsLp Class:**\nCore LP representation: min/max c'x s.t. row_lower <= Ax <= row_upper,\ncol_lower <= x <= col_upper\n\n**Data Members:**\n- num_col_, num_row_: Problem dimensions\n- col_cost_: Objective coefficients (c)\n- col_lower_, col_upper_: Variable bounds\n- row_lower_, row_upper_: Constraint bounds\n- a_matrix_: Constraint matrix A (HighsSparseMatrix, CSC or CSR)\n- sense_: Minimize (1) or Maximize (-1)\n- offset_: Constant objective offset\n- integrality_: Variable types (continuous, integer, semi-continuous, etc.)\n\n**Naming:**\n- col_names_, row_names_: Optional variable/constraint names\n- col_hash_, row_hash_: Name lookup hash tables\n\n**Scaling:**\n- scale_: Row/column scaling factors\n- is_scaled_: Whether scaling has been applied",
    "file": "HighsLp",
    "library": "HiGHS",
    "layer": "layer-4",
    "header": "highs/lp_data/HighsLp.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "HighsRanging": {
    "brief": "Sensitivity analysis (ranging) for LP optimal solutions\n\nComputes allowable ranges for objective coefficients and bounds.\n\n**HighsRangingRecord:**\n- value_[]: New coefficient/bound value at range limit\n- objective_[]: Objective value at range limit\n- in_var_[]: Variable entering basis at limit\n- ou_var_[]: Variable leaving basis at limit\n\n**HighsRanging Structure:**\n- col_cost_up/dn: Objective coefficient increase/decrease\n- col_bound_up/dn: Variable bound increase/decrease\n- row_bound_up/dn: Constraint RHS increase/decrease\n\n**Sensitivity Analysis:**\n- For costs: Range where current basis remains optimal\n- For bounds: Range where current basis remains primal feasible\n- Shadow prices from dual variables",
    "file": "HighsRanging",
    "library": "HiGHS",
    "layer": "layer-4",
    "header": "highs/lp_data/HighsRanging.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "HighsSolve": {
    "brief": "Top-level LP solve dispatch and special case handling\n\nEntry points for solving LPs with solver selection and preprocessing.\n\n**Main Solve Functions:**\n- solveLp(): Primary entry point dispatching to simplex/IPM\n- solveUnconstrainedLp(): Handle LPs with no constraints\n\n**Solver Selection:**\n- useIpm(): Check if IPM should be used based on options\n- useHipo(): Check if parallel HIPO IPM is appropriate\n  - Considers problem size, structure, and options\n\n**Preprocessing:**\n- assessExcessiveObjectiveBoundScaling(): Detect numerical issues\n  - Warns if objective/bound ratio is extreme\n  - Populates user_scale_data for remediation\n\n**Dispatch Logic:**\n1. Check for special cases (unconstrained, trivially infeasible)\n2. Select solver (simplex vs IPM vs HIPO)\n3. Call appropriate solver with prepared solver object",
    "file": "HighsSolve",
    "library": "HiGHS",
    "layer": "layer-4",
    "header": "highs/lp_data/HighsSolve.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "HighsModelUtils": {
    "brief": "Utility functions for model analysis and solution output\n\nFree functions for analyzing models and writing solution files.\n\n**Model Analysis:**\n- analyseModelBounds(): Report statistics on variable/constraint bounds\n- hasNamesWithSpaces(): Check for problematic whitespace in names\n\n**Solution Output:**\n- writeModelBoundSolution(): Write variable/constraint solution to file\n- writeModelObjective(): Write objective function evaluation\n- writeLpObjective(): Write LP objective evaluation\n- writeObjectiveValue(): Write scalar objective value\n- writePrimalSolution()/writeDualSolution(): Export primal/dual values\n- writeSolutionFile(): Write complete solution to file\n\n**Model Status:**\n- utilModelStatusToString(): Convert HighsModelStatus to string\n- utilBasisStatusToString(): Convert HighsBasisStatus to string",
    "file": "HighsModelUtils",
    "library": "HiGHS",
    "layer": "layer-4",
    "header": "highs/lp_data/HighsModelUtils.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "HStruct": {
    "brief": "Core data structures for HiGHS solver\n\nDefines fundamental structs used throughout HiGHS.\n\n**Solution/Basis Structs:**\n- HighsSolution: Primal values (col_value, row_value) and duals (col_dual, row_dual)\n- HighsBasis: Column/row basis status (Lower, Basic, Upper, Zero, Nonbasic)\n- HighsObjectiveSolution: Objective value with column values (for MIP solutions)\n\n**Scaling Structs:**\n- HighsScale: Row/column scaling factors (strategy, col[], row[], cost)\n- HighsUserScaleData: User-specified objective/bound scaling parameters\n\n**Model Modification Structs:**\n- HighsLpMods: Tracks modifications for semi-variables and infinite costs\n- HighsLinearObjective: Multi-objective support (weight, offset, coefficients, priority)\n\n**Utility Structs:**\n- HighsFiles: File paths for reading/writing solutions, bases, models\n- HighsNameHash: Hash table for name-to-index lookup\n- RefactorInfo/HotStart: Basis refactorization data (deprecated HotStart)\n\n**Logging/Statistics:**\n- HighsPresolveRuleLog/HighsPresolveLog: Presolve rule application counts\n- HighsSimplexStats: Iteration count, invert frequency, density statistics\n- HighsIllConditioning: Records for ill-conditioned basis detection\n- HighsSubSolverCallTime: Sub-solver timing breakdown",
    "file": "HStruct",
    "library": "HiGHS",
    "layer": "layer-4",
    "header": "highs/lp_data/HStruct.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "HConst": {
    "brief": "Constants, enums, and type definitions for HiGHS\n\nCentral definitions for HiGHS types and enumerations.\n\n**Numeric Constants:**\n- kHighsInf: Infinity value (std::numeric_limits<double>::infinity())\n- kHighsIInf: Integer infinity (max HighsInt)\n- kHighsTiny, kHighsMacheps, kHighsZero: Numerical tolerances\n\n**Core Enums:**\n- HighsModelStatus: Optimization result (kOptimal, kInfeasible, kUnbounded, etc.)\n- HighsVarType: Variable types (kContinuous, kInteger, kSemiContinuous, etc.)\n- HighsBasisStatus: Basis state (kLower, kBasic, kUpper, kZero, kNonbasic)\n- ObjSense: Minimize (+1) or Maximize (-1)\n\n**Format Enums:**\n- MatrixFormat: kColwise (CSC), kRowwise (CSR), kRowwisePartitioned\n- HessianFormat: kTriangular, kSquare\n\n**Status Enums:**\n- HighsPresolveStatus: Presolve outcomes\n- SolutionStatus: kNone, kInfeasible, kFeasible\n- BasisValidity: kInvalid, kValid\n\n**Callback Types:**\n- HighsCallbackType: Logging, interrupt, MIP solution events\n\n**Presolve Rules:**\n- PresolveRuleType: EmptyRow, SingletonRow, FixedCol, ForcingRow, etc.",
    "file": "HConst",
    "library": "HiGHS",
    "layer": "layer-4",
    "header": "highs/lp_data/HConst.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "HighsDebug": {
    "brief": "",
    "file": "HighsDebug",
    "library": "HiGHS",
    "layer": "layer-4",
    "header": "highs/lp_data/HighsDebug.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "HighsSolutionDebug": {
    "brief": "",
    "file": "HighsSolutionDebug",
    "library": "HiGHS",
    "layer": "layer-4",
    "header": "highs/lp_data/HighsSolutionDebug.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "HighsSolution": {
    "brief": "Solution validation and KKT condition checking utilities\n\nProvides functions to validate solutions and compute optimality metrics.\n\n**KKT Failure Analysis:**\n- getKktFailures(): Compute primal/dual infeasibilities for LP/QP\n- getLpKktFailures(): LP-specific KKT checking\n- getVariableKktFailures(): Per-variable bound/dual violations\n\n**Error Tracking (HighsError, HighsPrimalDualErrors):**\n- Absolute/relative primal infeasibility\n- Absolute/relative dual infeasibility\n- Nonzero basic duals, off-bound nonbasics\n- Glpsol-compatible residual output\n\n**Solution Utilities:**\n- computeObjectiveValue(): Evaluate c'x\n- computeDualObjectiveValue(): Dual objective for LP/QP\n- getComplementarityViolations(): x_i * s_i deviations\n- refineBasis(): Improve basis from solution values\n\n**IPX Integration:**\n- ipxSolutionToHighsSolution(): Convert IPX (interior point) solution\n- ipxBasicSolutionToHighsBasicSolution(): Convert IPX basis + crossover result",
    "file": "HighsSolution",
    "library": "HiGHS",
    "layer": "layer-4",
    "header": "highs/lp_data/HighsSolution.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "HighsInfo": {
    "brief": "Solver output information and statistics\n\nProvides typed info records for solver statistics accessible via API.\n\n**InfoRecord Hierarchy:**\n- InfoRecord: Base class (type, name, description, advanced)\n- InfoRecordInt64: 64-bit integer info (mip_node_count)\n- InfoRecordInt: Integer info (iteration counts, status codes)\n- InfoRecordDouble: Double info (objective, infeasibilities)\n\n**HighsInfoStruct/HighsInfo:**\n- Iteration counts: simplex, ipm, crossover, pdlp, qp\n- Solution status: primal_solution_status, dual_solution_status\n- Objective: objective_function_value\n- MIP statistics: mip_node_count, mip_dual_bound, mip_gap\n- Infeasibility metrics: num/max/sum primal/dual infeasibilities\n- Residuals: primal/dual residual errors (absolute and relative)\n- Complementarity: violation counts and max violation\n\n**Functions:**\n- getInfoIndex(): Look up info by name\n- getLocalInfoValue(): Retrieve int/int64/double values\n- writeInfoToFile()/reportInfo(): Output info records",
    "file": "HighsInfo",
    "library": "HiGHS",
    "layer": "layer-4",
    "header": "highs/lp_data/HighsInfo.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "HighsCallbackStruct": {
    "brief": "",
    "file": "HighsCallbackStruct",
    "library": "HiGHS",
    "layer": "layer-4",
    "header": "highs/lp_data/HighsCallbackStruct.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "HighsLpSolverObject": {
    "brief": "Aggregation of all objects needed for LP solving\n\n**HighsLpSolverObject:**\nBundles references to all components needed to solve an LP:\n- lp_: The LP model data (HighsLp)\n- basis_: Current simplex basis (HighsBasis)\n- solution_: Primal/dual solution vectors (HighsSolution)\n- highs_info_: Solver statistics and output (HighsInfo)\n- ekk_instance_: Edinburgh simplex kernel (HEkk)\n- callback_: User callback handler (HighsCallback)\n- options_: Solver options (HighsOptions)\n- timer_: Performance timer (HighsTimer)\n- sub_solver_call_time_: Timing breakdown for sub-solvers\n- model_status_: Current model status (kNotset, kOptimal, etc.)\n\nUsed to pass solver context between functions without long parameter lists.",
    "file": "HighsLpSolverObject",
    "library": "HiGHS",
    "layer": "layer-4",
    "header": "highs/lp_data/HighsLpSolverObject.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "HighsOptions": {
    "brief": "Solver configuration options system\n\n**OptionRecord Hierarchy:**\nBase class with derived types for each option type:\n- OptionRecordBool: Boolean options\n- OptionRecordInt: Integer options with bounds\n- OptionRecordDouble: Double options with bounds\n- OptionRecordString: String options\n\n**HighsOptions Class:**\nContainer holding all solver options:\n- records: Vector of OptionRecord pointers\n- Options by category: solving, tolerances, output, limits, etc.\n\n**Key Option Categories:**\n- Solver selection: solver (\"simplex\", \"ipm\", \"choose\"), run_crossover\n- Tolerances: primal_feasibility_tolerance, dual_feasibility_tolerance\n- Limits: time_limit, iteration_limit, solution_limit\n- Output: output_flag, log_to_console, log_file\n- Presolve: presolve (\"on\", \"off\", \"choose\")\n- Simplex: simplex_strategy, simplex_scale_strategy\n- IPM: ipm_iteration_limit\n- MIP: mip_max_nodes, mip_abs_gap, mip_rel_gap",
    "file": "HighsOptions",
    "library": "HiGHS",
    "layer": "layer-4",
    "header": "highs/lp_data/HighsOptions.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "HighsCallback": {
    "brief": "Callback mechanism for solver events and user interaction\n\nEnables user code to receive solver events and inject solutions.\n\n**HighsCallbackOutput:**\nData provided to callback during solver execution:\n- running_time, iteration counts (simplex, ipm, pdlp)\n- objective_function_value\n- MIP data: node_count, primal/dual bounds, gap, incumbent solution\n- Cut pool data for callback-based cuts\n\n**HighsCallbackInput:**\nData provided by user callback:\n- user_interrupt: Signal early termination\n- user_solution: Provide heuristic solution to MIP\n- setSolution(): Set solution (dense or sparse)\n- repairSolution(): Fix partial solution to feasibility\n\n**HighsCallback:**\nMain callback container:\n- user_callback: std::function for C++/Python\n- c_callback: C function pointer\n- active[]: Bitmask of enabled callback types\n- callbackAction(): Trigger callback and process response\n\n**Callback Types (from HighsCallbackStruct.h):**\nLogging, SimplexInterrupt, IpmInterrupt, MipSolution, MipLogging, etc.",
    "file": "HighsCallback",
    "library": "HiGHS",
    "layer": "layer-4",
    "header": "highs/lp_data/HighsCallback.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "HighsStatus": {
    "brief": "Return status enum for HiGHS API calls\n\n**HighsStatus enum:**\n- kError (-1): Operation failed\n- kOk (0): Operation succeeded\n- kWarning (1): Operation succeeded with warnings\n\n**Functions:**\n- highsStatusToString(): Convert status to string\n- interpretCallStatus(): Combine call and return status with logging\n- worseStatus(): Return max(status0, status1) for status propagation",
    "file": "HighsStatus",
    "library": "HiGHS",
    "layer": "layer-4",
    "header": "highs/lp_data/HighsStatus.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "HighsInfoDebug": {
    "brief": "",
    "file": "HighsInfoDebug",
    "library": "HiGHS",
    "layer": "layer-4",
    "header": "highs/lp_data/HighsInfoDebug.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "HSimplexNla": {
    "brief": "Numerical linear algebra interface for simplex\n\nWraps HFactor with scaling, product-form updates, and iterate storage.\n\n**ProductFormUpdate:**\nStores basis updates as explicit \u03b7-vectors when HFactor update fails:\n- pivot_index/value[]: Pivot positions and values\n- start/index/value[]: Eta-file sparse storage\n- btran/ftran(): Apply product form to vectors\n- Allows continued solve after HFactor becomes unstable\n\n**SimplexIterate:**\nCheckpoint storage for basis state:\n- basis_: Basis column indices and status\n- invert_: Factorization representation\n- dual_edge_weight_[]: DSE weights for restoration\n\n**Scaling Operations:**\n- btranInScaledSpace/ftranInScaledSpace(): Solve in scaled coordinates\n- applyBasisMatrixColScale/RowScale(): Transform vectors\n- variableScaleFactor(): Individual column/row scales\n\n**Key Methods:**\n- invert(): Refactorize basis via HFactor\n- btran(): B^(-T) * rhs (row pricing)\n- ftran(): B^(-1) * rhs (column evaluation)\n- update(): Basis update with pivot\n- putInvert/getInvert(): Save/restore iterate state\n\n**Debug Support:**\n- debugCheckInvert(): Verify factorization accuracy\n- debugInvertResidualError(): Measure solution error",
    "file": "HSimplexNla",
    "library": "HiGHS",
    "layer": "layer-4",
    "header": "highs/simplex/HSimplexNla.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "SimplexConst": {
    "brief": "Constants and enums for HiGHS simplex solvers\n\n**SimplexStrategy Enum:**\n- kSimplexStrategyDual: Serial dual simplex\n- kSimplexStrategyDualTasks: SIP parallel dual\n- kSimplexStrategyDualMulti: PAMI parallel dual\n- kSimplexStrategyPrimal: Primal simplex\n\n**SimplexSolvePhase Enum:**\n- kSolvePhase1: Finding feasible basis\n- kSolvePhase2: Optimizing objective\n- kSolvePhaseOptimalCleanup: Removing perturbations\n\n**EdgeWeightMode Enum:**\n- kDantzig: Original pricing\n- kDevex: Approximate steepest edge\n- kSteepestEdge: Exact steepest edge\n\n**RebuildReason Enum:**\nReasons to reinvert basis matrix (INVERT):\n- kRebuildReasonUpdateLimitReached: Too many eta factors\n- kRebuildReasonSyntheticClockSaysInvert: Time-based trigger\n- kRebuildReasonPossiblyOptimal: Check optimality\n\n**Nonbasic Status Constants:**\n- kNonbasicMoveUp/Dn/Ze: Variable movement directions\n- kNonbasicFlagTrue/False: Basic/nonbasic indicator",
    "file": "SimplexConst",
    "library": "HiGHS",
    "layer": "layer-4",
    "header": "highs/simplex/SimplexConst.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "HEkk": {
    "brief": "Edinburgh simplex kernel - high-performance LP solver core\n\nHEkk (Edinburgh Kernel) is the main simplex implementation in HiGHS,\nsupporting both dual and primal simplex methods.\n\n**HEkk Class:**\nCentral simplex solver managing LP data, basis, and solve state:\n- solve(): Run simplex algorithm (auto-selects dual/primal)\n- setBasis(): Initialize from HighsBasis\n- getSolution(): Extract primal/dual solution\n\n**Key Components:**\n- lp_: The LP being solved (may be scaled/dualized copy)\n- basis_: SimplexBasis with basic variable indices and status\n- simplex_nla_: Numeric linear algebra (factorization)\n- dual_edge_weight_: Steepest edge or Devex weights\n\n**Simplex Operations:**\n- btran/ftran: Backward/forward transformation with basis\n- pivotColumnFtran: Compute pivot column for ratio test\n- unitBtran: Compute row of B^{-1}\n\n**Transformations:**\n- dualize/undualize: Convert LP to/from dual form\n- permute/unpermute: Reorder LP for efficiency\n\n**Parallelism:**\n- chooseSimplexStrategyThreads(): Configure parallel strategy",
    "file": "HEkk",
    "library": "HiGHS",
    "layer": "layer-4",
    "header": "highs/simplex/HEkk.h",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "HSimplexReport": {
    "brief": "Simplex iteration progress reporting\n\nFunctions for logging simplex solve progress.\n\n**reportSimplexPhaseIterations():**\nReports iteration counts and phase transitions:\n- iteration_count: Total simplex iterations\n- info: HighsSimplexInfo with infeasibility counts\n- initialise: Reset counters for new phase\n\n**Output Includes:**\n- Phase 1/2 transition points\n- Iteration milestones\n- Infeasibility reduction progress",
    "file": "HSimplexReport",
    "library": "HiGHS",
    "layer": "layer-4",
    "header": "highs/simplex/HSimplexReport.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "HEkkPrimal": {
    "brief": "Phase 2 primal simplex solver for HiGHS",
    "file": "HEkkPrimal",
    "library": "HiGHS",
    "layer": "layer-4",
    "header": "highs/simplex/HEkkPrimal.h",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "HEkkDualRHS": {
    "brief": "Dual simplex optimality test for HiGHS",
    "file": "HEkkDualRHS",
    "library": "HiGHS",
    "layer": "layer-4",
    "header": "highs/simplex/HEkkDualRHS.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "HSimplex": {
    "brief": "Simplex utility functions\n\nStandalone functions for simplex basis and scaling operations.\n\n**Basis Extension:**\n- appendNonbasicColsToBasis(): Add new columns as nonbasic\n- appendBasicRowsToBasis(): Add new rows as basic (slack variables)\nWorks with both HighsBasis and SimplexBasis.\n\n**Solution Status:**\n- getUnscaledInfeasibilities(): Compute infeasibilities in original space\n- setSolutionStatus(): Set primal/dual solution status in HighsInfo\n\n**Scaling:**\n- scaleSimplexCost(): Scale objective coefficients\n- unscaleSimplexCost(): Reverse objective scaling\n\n**Validation:**\n- isBasisRightSize(): Check SimplexBasis dimensions match LP",
    "file": "HSimplex",
    "library": "HiGHS",
    "layer": "layer-4",
    "header": "highs/simplex/HSimplex.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "SimplexTimer": {
    "brief": "Timer clock indices for profiling simplex operations\n\nDefines clock identifiers for fine-grained simplex timing.\n\n**iClockSimplex Enum:**\nClock indices for HighsTimer used by simplex:\n\n**Top-Level Clocks:**\n- SimplexTotalClock: Total simplex time\n- SimplexDualPhase1/2Clock: Dual simplex phases\n- SimplexPrimalPhase1/2Clock: Primal simplex phases\n\n**Iteration Clocks:**\n- IterateClock: Per-iteration timing\n- IterateChuzrClock: CHUZR (row selection)\n- IterateChuzcClock: CHUZC (column selection)\n- IterateFtranClock: FTRAN operations\n- IterateDualClock: Dual value updates\n- IteratePrimalClock: Primal value updates\n\n**Infrastructure Clocks:**\n- InvertClock: Basis factorization\n- BasisConditionClock: Condition estimation\n- DseIzClock: DSE weight initialization",
    "file": "SimplexTimer",
    "library": "HiGHS",
    "layer": "layer-4",
    "header": "highs/simplex/SimplexTimer.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "HSimplexDebug": {
    "brief": "Debug utilities for simplex algorithm validation\n\nFunctions to detect numerical issues and algorithm failures.\n\n**CHUZC Failure Diagnosis:**\n- debugDualChuzcFailNorms(): Compute norms for failure analysis\n- debugDualChuzcFailQuad0/1(): Check quadratic pricing failures\n- debugDualChuzcFailHeap(): Check heap-based pricing failures\n\n**Basis Validation:**\n- debugNonbasicFlagConsistent(): Verify nonbasicFlag matches basis\n\n**Usage:**\nCalled when simplex encounters unexpected conditions:\n- Ratio test returns no candidate\n- Basis becomes numerically unstable\n- Iteration cycling detected\n\n**Return Type:**\nHighsDebugStatus indicates severity:\n- kOk: No issues detected\n- kWarning: Potential numerical concern\n- kError: Algorithmic failure",
    "file": "HSimplexDebug",
    "library": "HiGHS",
    "layer": "layer-4",
    "header": "highs/simplex/HSimplexDebug.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "HEkkDual": {
    "brief": "Dual simplex solver for HiGHS\n\nImplements dual simplex algorithm with CHUZR (row selection), PRICE\n(pivot row computation), CHUZC (column selection), and basis update.\n\n**Parallelization Strategies:**\n- Plain: Serial dual simplex (kSimplexStrategyDualPlain)\n- SIP: Suboptimization with Independent Parallelism (Tasks)\n- PAMI: Parallel Minor Iterations (Multi)\n\n**Key Phases:**\n- Phase 1: Minimize sum of infeasibilities to find feasible basis\n- Phase 2: Optimize objective maintaining dual feasibility\n\n**Edge Weight Modes:**\n- Dantzig: Simple pricing\n- Devex: Approximate steepest edge\n- Steepest Edge: Exact steepest edge with DSE vector updates\n\n**PAMI Data Structures:**\n- MChoice: Multiple row candidates from CHUZR\n- MFinish: Minor iteration data for parallel updates\n- slice_*: Partitioned matrix for parallel PRICE",
    "file": "HEkkDual",
    "library": "HiGHS",
    "layer": "layer-4",
    "header": "highs/simplex/HEkkDual.h",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "HighsSimplexAnalysis": {
    "brief": "Analyse simplex iterations, both for run-time control and data\ngathering",
    "file": "HighsSimplexAnalysis",
    "library": "HiGHS",
    "layer": "layer-4",
    "header": "highs/simplex/HighsSimplexAnalysis.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "SimplexStruct": {
    "brief": "Core data structures for HiGHS simplex solvers\n\n**SimplexBasis:**\nLow-level basis representation:\n- basicIndex_[row]: Variable index of basic variable in each row\n- nonbasicFlag_[var]: 0=basic, 1=nonbasic\n- nonbasicMove_[var]: Direction to move (-1=lower, +1=upper, 0=fixed/free)\n- hash: Basis fingerprint for debugging\n\n**HighsSimplexStatus:**\nSimplex solver state flags:\n- has_basis, has_ar_matrix, has_nla, has_invert\n- has_dual_steepest_edge_weights\n- is_dualized, is_permuted (problem transformations)\n\n**HighsSimplexInfo:**\nWorking data for simplex iterations:\n- workCost_/workDual_/workShift_: Objective and dual values\n- workLower_/workUpper_/workRange_/workValue_: Nonbasic variable bounds\n- baseLower_/baseUpper_/baseValue_: Basic variable data\n- Perturbation flags: costs_perturbed, bounds_perturbed\n- Infeasibility counts: num_primal/dual_infeasibilities\n- Backtracking data for singular basis recovery\n- DSE (Dual Steepest Edge) control parameters\n\n**HighsSimplexBadBasisChangeRecord:**\nTracks tabooed pivot operations to avoid cycling.\n\n**HighsRayRecord:**\nStores primal/dual ray for unbounded/infeasible detection.",
    "file": "SimplexStruct",
    "library": "HiGHS",
    "layer": "layer-4",
    "header": "highs/simplex/SimplexStruct.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "HEkkDualRow": {
    "brief": "Dual simplex ratio test for HiGHS",
    "file": "HEkkDualRow",
    "library": "HiGHS",
    "layer": "layer-4",
    "header": "highs/simplex/HEkkDualRow.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "HighsParallel": {
    "brief": "High-level parallel execution API with spawn/sync pattern\n\nTask-based parallelism modeled on Intel TBB / Cilk Plus semantics.\n\n**Initialization:**\n- initialize_scheduler(): Set up thread pool\n  - Default: hardware_concurrency/2 threads\n  - HIGHS_NO_DEFAULT_THREADS: Force single-threaded\n\n**Spawn/Sync Pattern:**\n- spawn(f): Push task to local deque, may be stolen\n- sync(): Wait for most recent spawn to complete\n- Child stealing: spawned tasks run depth-first or stolen\n\n**TaskGroup:**\n- RAII wrapper for spawn/sync blocks\n- taskWait(): Wait for all spawned tasks\n- cancel(): Mark pending tasks as cancelled\n- Destructor ensures cleanup\n\n**Parallel Loops:**\n- for_each(start, end, f, grainSize): Recursive binary splitting\n  - Splits until range <= grainSize\n  - Spawns right half, executes left half\n  - Task parallelism with load balancing\n\n**Thread Info:**\n- num_threads(): Total worker count\n- thread_num(): Current worker ID",
    "file": "HighsParallel",
    "library": "HiGHS",
    "layer": "layer-4",
    "header": "highs/parallel/HighsParallel.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "HighsTask": {
    "brief": "Fixed-size task for work-stealing scheduler\n\nInline callable storage with atomic state for task synchronization.\n\n**Memory Layout:**\n- taskData[]: 64-sizeof(Metadata) bytes for callable storage\n- metadata.stealer: Atomic for stealer pointer + status flags\n- Total: kMaxTaskSize = 64 bytes (cache line sized)\n\n**Status Flags (packed in stealer pointer):**\n- kFinishedFlag: Task execution completed\n- kCancelFlag: Task marked for cancellation\n- Pointer bits: Which worker stole this task\n\n**Callable Storage:**\n- Type-erased via virtual CallableBase interface\n- Placement new into taskData buffer\n- Requires trivially destructible callables\n\n**State Transitions:**\n- setTaskData(): Initialize with callable, stealer=0\n- run() by owner: Execute if not cancelled\n- run(stealer): Execute and mark stealer, return owner to notify\n- markAsFinished(): Set finished flag, return waiting owner\n- cancel(): Set cancel flag atomically\n\n**Interrupt Handling:**\n- HighsTask::Interrupt exception for task cancellation\n- Propagates up through task tree on cancel",
    "file": "HighsTask",
    "library": "HiGHS",
    "layer": "layer-4",
    "header": "highs/parallel/HighsTask.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "HighsSplitDeque": {
    "brief": "Chase-Lev work-stealing deque with split point optimization\n\nLock-free concurrent deque enabling efficient task-parallel execution.\n\n**Chase-Lev Deque:**\n- Owner pushes/pops from head (LIFO for locality)\n- Thieves steal from tail (FIFO for load balancing)\n- Single-word CAS for conflict resolution\n\n**Split Point Optimization:**\n- tail/split packed in 64-bit atomic (ts)\n- Split divides deque: [tail, split) available for stealing\n- Owner controls split growth via growShared()/shrinkShared()\n- Reduces contention when deque not fully shared\n\n**Memory Layout (Cache-Aligned):**\n- OwnerData (64B): head, split copy, workers, RNG\n- splitRequest (64B): Flag for thieves requesting more work\n- StealerData (64B): semaphore, injectedTask, ts atomic\n- WorkerBunkData (64B): nextSleeper for sleep stack\n- taskArray: 8192 task slots\n\n**WorkerBunk:**\n- Global sleep/wake coordination across workers\n- Lock-free sleeper stack with ABA-safe CAS\n- publishWork(): Wake sleepers when work available\n\n**Pop Status:**\n- kEmpty: No tasks\n- kStolen: Task was stolen, need sync\n- kWork: Task available for execution\n- kOverflown: Queue full, task executed inline",
    "file": "HighsSplitDeque",
    "library": "HiGHS",
    "layer": "layer-4",
    "header": "highs/parallel/HighsSplitDeque.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "HighsCacheAlign": {
    "brief": "Cache-line aligned memory allocation for parallel performance\n\nPrevents false sharing by ensuring separate objects reside on different cache lines.\n\n**cache_aligned Struct:**\nStatic utilities for aligned allocation:\n- alignment() \u2192 64 bytes (typical cache line size)\n- alloc(size): Allocate with 64-byte alignment\n- free(ptr): Deallocate aligned memory\n\n**Implementation:**\n- Over-allocates by alignment bytes\n- Stores original pointer before aligned address\n- Retrieves original pointer for deallocation\n\n**Smart Pointer Support:**\n- Deleter<T>: Custom deleter calling destructor + free\n- unique_ptr<T>: Alias with custom deleter\n- make_unique<T>(): Factory function\n- make_unique_array<T>(n): Array allocation\n\n**Usage:**\nWrap thread-local data in cache_aligned::unique_ptr to prevent\nperformance degradation from false sharing in parallel algorithms.",
    "file": "HighsCacheAlign",
    "library": "HiGHS",
    "layer": "layer-4",
    "header": "highs/parallel/HighsCacheAlign.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "HighsSpinMutex": {
    "brief": "Lightweight spin lock for short critical sections\n\nBusy-waits instead of blocking, ideal for short-held locks.\n\n**HighsSpinMutex Class:**\nSimple test-and-set spin lock:\n- flag: Atomic bool (false = unlocked)\n- try_lock(): Non-blocking lock attempt\n- lock(): Spin until acquired\n- unlock(): Release with release semantics\n\n**Spinning Strategy:**\n- yieldProcessor(): CPU hint during spin wait\n  - x86: _mm_pause() (reduces power, prevents pipeline stalls)\n  - Others: std::this_thread::yield()\n\n**TTAS Pattern:**\nTest-and-Test-and-Set for reduced bus traffic:\n1. Exchange to try acquiring\n2. If failed, spin on load (cache-local)\n3. Only retry exchange when flag appears free\n\n**When to Use:**\nPrefer over std::mutex when critical sections are very short\nand contention is low. Avoids syscall overhead.",
    "file": "HighsSpinMutex",
    "library": "HiGHS",
    "layer": "layer-4",
    "header": "highs/parallel/HighsSpinMutex.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "HighsCombinable": {
    "brief": "Thread-local storage with reduction for parallel algorithms\n\nPer-thread copies that are lazily initialized and can be combined.\n\n**Design (similar to TBB combinable):**\n- One T instance per worker thread\n- Cache-line aligned to prevent false sharing\n- Lazy initialization on first access\n\n**Construction:**\n- Default: T() for each thread's copy\n- Custom: Callable returning T for each thread\n\n**Access:**\n- local(): Get/create this thread's copy\n- Thread ID from HighsTaskExecutor::getThisWorkerDeque()\n\n**Reduction:**\n- combine_each(f): Apply f to each initialized copy\n- combine(f): Reduce all copies with binary operation f\n  - Returns combined result by move\n\n**Usage Pattern:**\n```cpp\nHighsCombinable<int> sum;\nparallel::for_each([&](int i, int j) {\n  sum.local() += compute(i, j);\n});\nint total = sum.combine(std::plus<int>());\n```",
    "file": "HighsCombinable",
    "library": "HiGHS",
    "layer": "layer-4",
    "header": "highs/parallel/HighsCombinable.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "HighsTaskExecutor": {
    "brief": "Work-stealing thread pool for task parallelism\n\nManages worker threads and coordinates task execution via work stealing.\n\n**Thread Pool:**\n- Main thread (worker 0) + N-1 spawned workers\n- Each worker has own HighsSplitDeque for local tasks\n- Thread-local storage for current worker's deque\n\n**Work Stealing Loop:**\n- random_steal_loop(): Try stealing from random victims\n  - Exponential backoff with microsecond timing\n  - Falls back to global sync after timeout\n- Workers sleep when no work available (WorkerBunk)\n\n**Stolen Task Sync:**\n- sync_stolen_task(): Wait for task stolen by another worker\n  - Leapfrog stealing: steal from the stealer\n  - Spin wait with exponential backoff\n  - Sleep with notification when timeout exceeded\n\n**Lifecycle:**\n- initialize(): Create executor singleton\n- shutdown(): Stop all workers, join or detach threads\n- ExecutorHandle: RAII cleanup on thread exit",
    "file": "HighsTaskExecutor",
    "library": "HiGHS",
    "layer": "layer-4",
    "header": "highs/parallel/HighsTaskExecutor.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "HighsRaceTimer": {
    "brief": "Lock-free timer for parallel algorithm racing\n\nAllows multiple threads to race, with early termination when limit reached.\n\n**HighsRaceTimer<T> Class:**\nAtomic limit value that can only decrease:\n- Constructor: Initialize limit to max value (no limit)\n- decreaseLimit(newLimit): Atomically reduce limit (CAS loop)\n- limitReached(currentTime): Check if time exceeds limit\n\n**Memory Ordering:**\nUses relaxed ordering since:\n- Only one direction (decrease) of updates\n- Eventual consistency sufficient for early termination\n- No happens-before relationships required\n\n**Usage:**\nMultiple solvers race; first to find solution decreases limit.\nSlower solvers check limitReached() and abort early.",
    "file": "HighsRaceTimer",
    "library": "HiGHS",
    "layer": "layer-4",
    "header": "highs/parallel/HighsRaceTimer.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "HighsHessianUtils": {
    "brief": "Utility functions for Hessian matrix manipulation\n\nFree functions for validating, transforming, and operating on Hessian matrices.\n\n**Validation:**\n- assessHessian(): Comprehensive Hessian validation\n- assessHessianDimensions(): Check dimension consistency\n- okHessianDiagonal(): Verify positive diagonal for convexity\n\n**Transformation:**\n- normaliseHessian(): Standardize Hessian format\n- extractTriangularHessian(): Convert to lower-triangular storage\n- triangularToSquareHessian(): Expand to full symmetric matrix\n- completeHessianDiagonal(): Add missing diagonal entries\n- completeHessian(): Extend to full variable dimension\n\n**Scaling:**\n- userScaleHessian(): Apply/remove user-provided scaling factors\n\n**Reporting:**\n- reportHessian(): Print Hessian structure and values",
    "file": "HighsHessianUtils",
    "library": "HiGHS",
    "layer": "layer-4",
    "header": "highs/model/HighsHessianUtils.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "HighsModel": {
    "brief": "Combined LP/QP model container\n\n**HighsModel Class:**\nCombines HighsLp (linear constraints/objective) with HighsHessian (quadratic terms).\n\n**Data Members:**\n- lp_: Linear program data (constraints, bounds, linear objective)\n- hessian_: Quadratic objective term Q for QP: min 0.5*x'Qx + c'x\n\n**Model Type Detection:**\n- isQp(): Returns true if hessian_.dim_ != 0\n- isMip(): Delegates to lp_.isMip() (checks integrality constraints)\n- isEmpty(): True if num_col_ == 0 and num_row_ == 0\n\n**Objective Evaluation:**\n- objectiveValue(): Compute c'x + 0.5*x'Qx\n- objectiveGradient(): Compute c + Qx",
    "file": "HighsModel",
    "library": "HiGHS",
    "layer": "layer-4",
    "header": "highs/model/HighsModel.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "HighsHessian": {
    "brief": "Sparse Hessian matrix for QP objective\n\n**HighsHessian Class:**\nStores quadratic objective term Q for QP: min 0.5*x'Qx + c'x\n\n**Sparse Storage (CSC-like):**\n- dim_: Number of variables (Q is dim_ x dim_)\n- format_: kTriangular (lower triangle) or kSquare (full matrix)\n- start_[]: Column start indices\n- index_[]: Row indices\n- value_[]: Non-zero values\n\n**Operations:**\n- product(): Compute Qx (Hessian-vector product)\n- objectiveValue(): Compute 0.5*x'Qx\n- objectiveCDoubleValue(): High-precision objective using HighsCDouble\n- deleteCols(): Remove columns/rows for presolve",
    "file": "HighsHessian",
    "library": "HiGHS",
    "layer": "layer-4",
    "header": "highs/model/HighsHessian.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "IpxWrapper": {
    "brief": "Wrapper for IPX interior point solver\n\nProvides interface between HiGHS and the IPX interior point solver.\n\n**Main Functions:**\n- solveLpIpx(): Solve LP using IPX with optional crossover to basis\n- fillInIpxData(): Convert HighsLp to IPX's input format\n- getHighsNonVertexSolution(): Extract non-vertex (interior) solution\n\n**Status Reporting:**\n- reportIpxSolveStatus(): Convert IPX status to HighsStatus\n- reportIpxIpmCrossoverStatus(): Report IPM/crossover termination\n- ipxStatusError(): Handle IPX error conditions\n- reportIpmNoProgress(): Log stalled IPM iterations\n\n**HIPO Support (optional):**\nParallel interior point variant (compile-time flag HIPO):\n- solveLpHipo(): High-performance IPM solver\n- getHipoNonVertexSolution(): Extract HIPO solution",
    "file": "IpxWrapper",
    "library": "HiGHS",
    "layer": "layer-4",
    "header": "highs/ipm/IpxWrapper.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "IpxSolution": {
    "brief": "IPX interior point solution container\n\nStores primal/dual solution and basis status from IPX solver.\n\n**IpxSolution Struct:**\nSolution data in IPX's native format for transfer to HiGHS:\n- num_col, num_row: Problem dimensions\n- ipx_col_value[], ipx_row_value[]: Primal solution (x, slacks)\n- ipx_col_dual[], ipx_row_dual[]: Dual solution (reduced costs, duals)\n- ipx_col_status[], ipx_row_status[]: Basis status for crossover\n\n**Status Values:**\nIPX uses its own status encoding (see ipx_status.h):\n- Basic, AtLower, AtUpper, Free for variables\n- Converted to HighsBasisStatus in IpxWrapper\n\n**Usage:**\n1. IPX populates after solve\n2. IpxWrapper extracts to HighsSolution/HighsBasis\n3. Crossover uses basis status for simplex warm start",
    "file": "IpxSolution",
    "library": "HiGHS",
    "layer": "layer-4",
    "header": "highs/ipm/IpxSolution.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "HighsPrimalHeuristics": {
    "brief": "Primal heuristics for finding MIP feasible solutions\n\nCollection of primal heuristics to discover incumbent solutions.",
    "file": "HighsPrimalHeuristics",
    "library": "HiGHS",
    "layer": "layer-4",
    "header": "highs/mip/HighsPrimalHeuristics.h",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "HighsRedcostFixing": {
    "brief": "Reduced cost fixing and lurking bounds for MIP\n\nUses LP reduced costs to fix variable bounds based on cutoff.\n\n**Reduced Cost Fixing:**\nIf fixing variable j to its bound would increase objective beyond cutoff,\nthe opposite bound becomes valid. For minimization:\n- If reduced_cost[j] > 0 and x[j] = lb: fixing to ub proves lb valid\n- If reduced_cost[j] < 0 and x[j] = ub: fixing to lb proves ub valid\n\n**Lurking Bounds:**\nBounds that become valid at specific objective values:\n- lurkingColUpper[col]: (objective_threshold, bound_value) pairs\n- lurkingColLower[col]: Maps threshold to tighter bound\n- getLurkingBounds(): Extract bounds valid at current cutoff\n\n**Propagation Methods:**\n- propagateRootRedcost(): Apply fixings at root using stored costs\n- propagateRedCost(): Apply fixings at any node using LP reduced costs\n- addRootRedcost(): Store root LP reduced costs for later use\n\n**Integration:**\n- Called when incumbent improves (new cutoff enables more fixings)\n- Provides global domain tightening from LP dual information",
    "file": "HighsRedcostFixing",
    "library": "HiGHS",
    "layer": "layer-4",
    "header": "highs/mip/HighsRedcostFixing.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "HighsDebugSol": {
    "brief": "Debug solution tracking for MIP solver validation\n\nConditionally compiled (HIGHS_DEBUGSOL) facility to verify MIP solver\ncorrectness against a known optimal solution.\n\n**When HIGHS_DEBUGSOL Defined:**\n- debugSolution[]: Known optimal solution values\n- debugSolObjective: Optimal objective value\n- conflictingBounds: Tracks domain changes inconsistent with debug solution\n\n**Validation Methods:**\n- checkCut(): Verify cut doesn't exclude debug solution\n- checkRow(): Verify row bounds contain debug solution\n- checkClique(): Verify clique is satisfied by debug solution\n- checkVub/Vlb(): Verify variable bounds contain debug solution\n- nodePruned(): Alert if node containing debug solution is pruned\n\n**Domain Tracking:**\n- registerDomain(): Track a HighsDomain instance\n- boundChangeAdded/Removed(): Monitor bound changes\n- resetDomain(): Clear domain tracking\n\n**Conflict Analysis:**\n- checkConflictReasonFrontier(): Verify conflict derivation\n- checkConflictReconvergenceFrontier(): Verify reconvergence\n\n**When HIGHS_DEBUGSOL Not Defined:**\nAll methods become empty stubs with zero overhead.",
    "file": "HighsDebugSol",
    "library": "HiGHS",
    "layer": "layer-4",
    "header": "highs/mip/HighsDebugSol.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "HighsSearch": {
    "brief": "Branch-and-bound tree search for MIP solver\n\nImplements depth-first search with backtracking and node evaluation.",
    "file": "HighsSearch",
    "library": "HiGHS",
    "layer": "layer-4",
    "header": "highs/mip/HighsSearch.h",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "HighsTableauSeparator": {
    "brief": "Gomory mixed-integer cuts from LP tableau\n\nGenerates cuts by applying MIR procedure to simplex tableau rows.\n\n**Gomory Cut Generation:**\nFor each fractional basic integer variable:\n1. Extract tableau row: x_B[i] = f_0 - sum(a_j * x_N[j])\n2. Apply mixed-integer rounding (MIR)\n3. Produce cut: sum(floor(a_j) * x_j) \u2264 floor(f_0) (simplified)\n\n**Separation Flow:**\n1. Get fractional integer variables from LP relaxation\n2. For each candidate, extract tableau row via BTRAN\n3. Transform using HighsTransformedLp (bound substitution)\n4. Apply MIR strengthening\n5. Add valid cuts to cut pool\n\n**Implementation:**\n- numTries: Counter for separation attempts (controls effort)\n- Uses kTableauSepaString identifier for statistics\n- Inherits run() timing from HighsSeparator base class",
    "file": "HighsTableauSeparator",
    "library": "HiGHS",
    "layer": "layer-4",
    "header": "highs/mip/HighsTableauSeparator.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "HighsGFkSolve": {
    "brief": "Linear system solver over finite field GF(k)\n\nSolves congruence systems for mod-k cut generation.\n\n**HighsGFk<k> Template:**\nCompile-time multiplicative inverse via Fermat's little theorem:\n- inverse(a) = a^(k-2) mod k (when k prime)\n- powk(): Recursive repeated squaring for a^k\n- Specializations for k=2,3 (trivial inverses)\n\n**HighsGFkSolve Class:**\nSparse LU factorization in GF(k):\n\n**Storage:**\n- Triplet format: Arow[], Acol[], Avalue[] (mod k)\n- Column-wise linked list: colhead, Anext, Aprev\n- Row-wise splay tree: rowroot, ARleft, ARright\n\n**Factorization:**\n- Markowitz-style pivot selection (min row \u00d7 col size)\n- factorColPerm/factorRowPerm: Pivot order recording\n- colBasisStatus/rowUsed: Track basic columns and used rows\n\n**Solution:**\n- solve<k>(): Enumerate basic solutions\n- SolutionEntry: (index, weight) for solution vector\n- Reports multiple solutions via basis swapping\n\n**Usage:**\n1. fromCSC<k>(): Load constraint matrix modulo k\n2. setRhs<k>(): Set right-hand side (k-1 for mod-k MIR)\n3. solve<k>(): Find row weights yielding maximally violated cuts",
    "file": "HighsGFkSolve",
    "library": "HiGHS",
    "layer": "layer-4",
    "header": "highs/mip/HighsGFkSolve.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "HighsCutPool": {
    "brief": "Cutting plane storage and separation for MIP solver\n\n**HighsCutSet:**\nContainer for cuts to add to LP relaxation:\n- cutindices: Indices into cut pool\n- ARstart_/ARindex_/ARvalue_: CSR storage for cut coefficients\n- lower_/upper_: Cut bounds (typically -inf, rhs)\n\n**HighsCutPool:**\nManages all generated cutting planes:\n- matrix_: HighsDynamicRowMatrix storing all cuts\n- rhs_[]: Right-hand sides\n- ages_[]: Cut age (incremented when not binding, reset when used)\n- hashToCutMap: Duplicate detection via row hashing\n\n**Cut Lifecycle:**\n- addCut(): Add new cut with duplicate detection and clique extraction\n- separate(): Select violated cuts for LP (scoring + density limits)\n- performAging(): Increment ages, remove old cuts (age > agelim_)\n- lpCutRemoved(): Called when cut leaves LP\n\n**Cut Propagation:**\n- propagationDomains: Registered domains for cut-based bound tightening\n- propRows: Active propagation rows",
    "file": "HighsCutPool",
    "library": "HiGHS",
    "layer": "layer-4",
    "header": "highs/mip/HighsCutPool.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "HighsMipSolver": {
    "brief": "Branch-and-cut MIP solver",
    "file": "HighsMipSolver",
    "library": "HiGHS",
    "layer": "layer-4",
    "header": "highs/mip/HighsMipSolver.h",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "HighsDynamicRowMatrix": {
    "brief": "Dynamic row matrix with efficient column-sign iteration\n\nSparse row-wise matrix supporting efficient row add/remove with\nseparate iteration over positive and negative column entries.\n\n**Row Storage:**\n- ARrange_[row]: (start, end) range in ARindex_/ARvalue_\n- ARindex_[]/ARvalue_[]: Column indices and values\n- ARrowindex_[]: Row index for each nonzero position\n\n**Column Iteration by Sign:**\nSeparate doubly-linked lists for positive and negative entries:\n- AheadPos_[col], AnextPos_[], AprevPos_[]: Positive entry list\n- AheadNeg_[col], AnextNeg_[], AprevNeg_[]: Negative entry list\n\n**Template Iterators:**\n- forEachPositiveColumnEntry(): Iterate positive entries in column\n- forEachNegativeColumnEntry(): Iterate negative entries in column\n- Useful for implication detection (sign determines bound type)\n\n**Dynamic Operations:**\n- addRow(): Insert row, reusing deleted space from freespaces_ set\n- removeRow(): Remove row, add index to deletedrows_ for reuse\n- unlinkColumns(): Disconnect row from column lists",
    "file": "HighsDynamicRowMatrix",
    "library": "HiGHS",
    "layer": "layer-4",
    "header": "highs/mip/HighsDynamicRowMatrix.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "HighsTransformedLp": {
    "brief": "LP bound transformations for cutting plane separation\n\nTransforms LP rows into single-row relaxations suitable for cut generation\nby substituting bounds and handling complementation.\n\n**Bound Substitution Types (BoundType enum):**\n- kSimpleLb/kSimpleUb: Direct variable bounds (x \u2265 lb, x \u2264 ub)\n- kVariableLb/kVariableUb: VLB/VUB from implications (x \u2265 a*y + b)\n\n**Bound Selection:**\n- bestVlb/bestVub[]: Tightest variable bound for each column\n- simpleLbDist/simpleUbDist[]: Distance of LP value from simple bounds\n- lbDist/ubDist[]: Distance considering all bound types\n- boundDist[]: Minimum distance (used for coefficient strengthening)\n\n**Transform Operations:**\n- transform(): Convert row to standard form for cut generation\n  - Substitutes bounds to get non-negative variables\n  - Tracks which bound type used per variable\n  - Returns integralPositive flag for MIR applicability\n- untransform(): Reverse transformation to original space\n\n**Cut Generation Flow:**\n1. Aggregate LP rows (via HighsLpAggregator)\n2. Transform to standard form (substitute bounds)\n3. Apply cut procedure (Gomory, MIR, etc.)\n4. Untransform back to original variables",
    "file": "HighsTransformedLp",
    "library": "HiGHS",
    "layer": "layer-4",
    "header": "highs/mip/HighsTransformedLp.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "MipTimer": {
    "brief": "Indices of mip iClocks",
    "file": "MipTimer",
    "library": "HiGHS",
    "layer": "layer-4",
    "header": "highs/mip/MipTimer.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "HighsMipSolverData": {
    "brief": "Central data container for MIP solver state\n\nAggregates all MIP solver components and statistics.\n\n**MipSolutionSource enum:**\nTracks origin of solutions for statistics:\n- B: Branching, C: CentralRounding, F: FeasibilityPump\n- H: Heuristic, J: FeasibilityJump, L: SubMip\n- R: RandomizedRounding, S: SolveLp, X: UserSolution, Z: ZiRound\n\n**HighsPrimaDualIntegral:**\nTracks primal-dual gap integral for solution quality metric.\n\n**HighsMipSolverData Components:**\n\n*Core Structures:*\n- cutpool: Global cut storage\n- conflictPool: Learned conflict constraints\n- domain: Global domain with bounds and propagation\n- lp: LP relaxation solver\n- nodequeue: B&B tree node priority queue\n\n*Inference:*\n- cliquetable: Binary variable cliques\n- implications: Variable implications (VUB/VLB)\n- pseudocost: Branching score history\n- redcostfixing: Reduced cost-based bound fixing\n\n*Heuristics:*\n- heuristics: Primal heuristic controller\n- objectiveFunction: Objective analysis for probing\n\n*Symmetry:*\n- symmetries/globalOrbits: Symmetry detection/handling\n- SymmetryDetectionData: Async symmetry computation\n\n*Statistics:*\n- num_nodes/num_leaves: Tree exploration counts\n- total_lp_iterations: LP iteration counters by type\n- lower_bound/upper_bound: Best bounds\n- incumbent: Best solution vector\n\n**Key Methods:**\n- init/runSetup(): Initialize solver state\n- evaluateRootNode(): Root node processing\n- trySolution/addIncumbent(): Solution handling\n- performRestart(): Restart MIP search",
    "file": "HighsMipSolverData",
    "library": "HiGHS",
    "layer": "layer-4",
    "header": "highs/mip/HighsMipSolverData.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "HighsObjectiveFunction": {
    "brief": "Objective function analysis for MIP solving\n\nAnalyzes objective structure to enable specialized bound propagation.\n\n**Objective Structure:**\n- objectiveNonzeros[]: Columns with nonzero objective (binaries first)\n- objectiveVals[]: Packed objective coefficients\n- numBinary/numIntegral: Variable counts by type\n\n**Integrality Detection:**\n- objIntScale: Scale factor making all integer coefficients integral\n- isIntegral(): True if objective is integer for integer solutions\n- checkIntegrality(): Verify/update integrality with epsilon\n- Enables objective cutoff rounding\n\n**Clique Partitioning:**\nPartitions binary objective variables into cliques:\n- cliquePartitionStart[]: Start indices per partition\n- colToPartition[]: Maps column to its partition\n- At most one variable per clique can be 1\n- Enables tighter objective bounds from clique constraints\n\n**Usage:**\n- Objective bound computation during propagation\n- Detecting integral objectives for cutoff strengthening\n- Clique-based objective probing",
    "file": "HighsObjectiveFunction",
    "library": "HiGHS",
    "layer": "layer-4",
    "header": "highs/mip/HighsObjectiveFunction.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "HighsModkSeparator": {
    "brief": "Class for separating maximally violated mod-k MIR cuts",
    "file": "HighsModkSeparator",
    "library": "HiGHS",
    "layer": "layer-4",
    "header": "highs/mip/HighsModkSeparator.h",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "HighsPseudocost": {
    "brief": "Pseudocost branching for MIP variable selection\n\nEstimates objective change from branching based on historical observations.\n\n**Score Components:**\n- pseudocostup/down[col]: Average unit objective change per direction\n- inferencesup/down[col]: Average domain reductions (bound tightenings)\n- ncutoffsup/down[col]: Count of subtree cutoffs per direction\n- conflictscoreup/down[col]: Conflict analysis contribution\n\n**Reliability:**\n- nsamplesup/down[col]: Number of observations per direction\n- minreliable: Threshold for reliable pseudocost estimate\n- isReliable(): True when min(up_samples, down_samples) >= minreliable\n- Unreliable estimates blend with global average (cost_total)\n\n**Scoring (getScore):**\nCombines multiple signals into branching score:\n- costScore: Pseudocost product (up * down) / avg^2\n- inferenceScore: Domain reduction product\n- cutoffScore: Historical cutoff frequency\n- conflictScore: Conflict analysis contribution\n- degeneracyFactor: Adjusts weighting for degenerate LPs\n\n**Key Methods:**\n- addObservation(): Record objective change from branching\n- addInferenceObservation(): Record domain reductions\n- getPseudocostUp/Down(): Get estimated change for given fraction",
    "file": "HighsPseudocost",
    "library": "HiGHS",
    "layer": "layer-4",
    "header": "highs/mip/HighsPseudocost.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "HighsMipAnalysis": {
    "brief": "Analyse MIP iterations, both for run-time control and data\ngathering",
    "file": "HighsMipAnalysis",
    "library": "HiGHS",
    "layer": "layer-4",
    "header": "highs/mip/HighsMipAnalysis.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "HighsCutGeneration": {
    "brief": "Class that generates cuts from single row relaxations",
    "file": "HighsCutGeneration",
    "library": "HiGHS",
    "layer": "layer-4",
    "header": "highs/mip/HighsCutGeneration.h",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "HighsDomain": {
    "brief": "Bound tracking, propagation, and conflict analysis for MIP\n\n**HighsDomain Class:**\nManages variable bounds during MIP branch-and-bound with:\n- col_lower_[], col_upper_[]: Current variable bounds\n- domchgstack_[]: Stack of bound changes (for backtracking)\n- domchgreason_[]: Reason for each bound change (branching, row, clique)\n\n**Bound Propagation:**\n- propagate(): Deduce implied bounds from constraints\n- activitymin_[]/activitymax_[]: Row activity bounds for propagation\n- markPropagate(): Queue row for propagation\n- ObjectivePropagation: Deduce bounds from objective cutoff\n\n**Reason Tracking:**\nEach bound change records its cause:\n- kBranching: B&B branching decision\n- kModelRowUpper/Lower: Implied by constraint\n- kCliqueTable: Clique conflict\n- kObjective: Objective bound\n- cut(pool,index): Cut from cut pool\n\n**Conflict Analysis (ConflictSet):**\nLearns from infeasibility:\n- conflictAnalysis(): Build conflict clause from infeasibility proof\n- reasonSideFrontier: Domain changes causing infeasibility\n- Generates learned conflicts for HighsConflictPool\n\n**Cut Pool Integration (CutpoolPropagation):**\n- Tracks activity of cuts for cut-based propagation\n- Updates when bounds change\n\n**Backtracking:**\n- backtrack(): Undo bound changes\n- backtrackToGlobal(): Reset to root node bounds\n- branchPos_[]: Positions of branching decisions in stack",
    "file": "HighsDomain",
    "library": "HiGHS",
    "layer": "layer-4",
    "header": "highs/mip/HighsDomain.h",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "HighsSeparation": {
    "brief": "Cut generation orchestration for MIP solver",
    "file": "HighsSeparation",
    "library": "HiGHS",
    "layer": "layer-4",
    "header": "highs/mip/HighsSeparation.h",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "HighsLpAggregator": {
    "brief": "Row aggregation for cut generation\n\nCombines LP rows with weights to create mixed-integer Gomory source rows.\n\n**Core Operations:**\n- addRow(): Add weighted LP row to current aggregation\n- getCurrentAggregation(): Extract combined row as sparse vector\n- clear(): Reset for next aggregation\n\n**Aggregation Format:**\nResult includes slack variables making it an equation with RHS = 0:\n  sum(a_ij * x_j) + s_i = b_i  \u2192  aggregated as equality\n\n**Implementation:**\n- Uses HighsSparseVectorSum for efficient sparse combination\n- Tracks nonzero indices incrementally\n- negate parameter for sign flip (row sense conversion)\n\n**Cut Generation Context:**\n1. Start from LP tableau row (basis row)\n2. Aggregate additional rows to eliminate non-integer variables\n3. Pass to HighsTransformedLp for bound substitution\n4. Generate Gomory mixed-integer cuts",
    "file": "HighsLpAggregator",
    "library": "HiGHS",
    "layer": "layer-4",
    "header": "highs/mip/HighsLpAggregator.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "HighsSeparator": {
    "brief": "Abstract base class for cut separators",
    "file": "HighsSeparator",
    "library": "HiGHS",
    "layer": "layer-4",
    "header": "highs/mip/HighsSeparator.h",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "HighsPathSeparator": {
    "brief": "Path aggregation cuts from network structure",
    "file": "HighsPathSeparator",
    "library": "HiGHS",
    "layer": "layer-4",
    "header": "highs/mip/HighsPathSeparator.h",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "HighsCliqueTable": {
    "brief": "Clique detection and storage for MIP solver",
    "file": "HighsCliqueTable",
    "library": "HiGHS",
    "layer": "layer-4",
    "header": "highs/mip/HighsCliqueTable.h",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "HighsConflictPool": {
    "brief": "Storage for learned conflict constraints\n\nManages nogood constraints derived from infeasible subproblems.\n\n**Conflict Storage:**\n- conflictEntries_[]: Domain changes forming each conflict\n- conflictRanges_[]: {start, end} pairs indexing entries\n- Each conflict: set of HighsDomainChange that together are infeasible\n\n**Aging System:**\n- ages_[]: Tracks how long since conflict was active\n- ageDistribution_[]: Count of conflicts at each age\n- performAging(): Increment ages, remove old conflicts\n- resetAge(): Reset age when conflict becomes active\n- agelim_: Maximum age before deletion\n\n**Memory Management:**\n- freeSpaces_: Ordered set of reusable entry ranges\n- deletedConflicts_: Reusable conflict indices\n- softlimit_: Target maximum conflicts\n\n**Key Methods:**\n- addConflictCut(): Store conflict from infeasibility analysis\n- addReconvergenceCut(): Store conflict with reconvergence point\n- removeConflict(): Delete conflict and free space\n\n**Propagation Integration:**\n- propagationDomains[]: Domains using conflicts for propagation\n- modification_[]: Version counter for conflict updates",
    "file": "HighsConflictPool",
    "library": "HiGHS",
    "layer": "layer-4",
    "header": "highs/mip/HighsConflictPool.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "HighsImplications": {
    "brief": "Implication graphs and variable bound relationships for MIP",
    "file": "HighsImplications",
    "library": "HiGHS",
    "layer": "layer-4",
    "header": "highs/mip/HighsImplications.h",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "HighsLpRelaxation": {
    "brief": "LP relaxation management for MIP branch-and-bound\n\nManages the LP relaxation at each B&B node with cut handling.\n\n**Status enum:**\n- kOptimal: LP solved to optimality\n- kInfeasible: LP is infeasible (node can be pruned)\n- kUnscaledDualFeasible: Dual feasible (valid bound)\n- kUnscaledPrimalFeasible: Primal feasible (valid solution)\n- kUnbounded/kError: Problem states\n\n**LpRow Tracking:**\n- origin: kModel (original constraint) or kCutPool (added cut)\n- index: Row index in model or cut pool\n- age: Iterations since cut was binding (for aging/removal)\n\n**Key Operations:**\n- run(): Solve LP relaxation\n- addCuts(): Add cuts from HighsCutSet\n- flushDomain(): Apply bound changes from HighsDomain\n- performAging(): Age cuts, remove old non-binding cuts\n- removeObsoleteRows(): Delete aged-out cuts\n\n**Solution Access:**\n- getObjective(): LP objective value\n- getSolution(): Primal/dual values\n- getFractionalIntegers(): Integer vars with fractional values\n- integerFeasible(): True if LP solution is MIP-feasible\n\n**Dual Proofs:**\n- computeDualProof(): Derive valid inequality from LP dual\n- storeDualInfProof(): Store proof when LP is infeasible\n- getDualProof(): Retrieve stored proof for conflict analysis\n\n**Playground (nested class):**\nRAII wrapper for temporary LP modifications (e.g., strong branching).",
    "file": "HighsLpRelaxation",
    "library": "HiGHS",
    "layer": "layer-4",
    "header": "highs/mip/HighsLpRelaxation.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "HighsNodeQueue": {
    "brief": "Priority queue for branch-and-bound nodes",
    "file": "HighsNodeQueue",
    "library": "HiGHS",
    "layer": "layer-4",
    "header": "highs/mip/HighsNodeQueue.h",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "stringutil": {
    "brief": "String manipulation utilities for file parsing\n\nHelper functions for trimming, case conversion, and tokenization.\n\n**Case Conversion:**\n- tolower(): Convert string to lowercase in-place\n- toupper(): Convert string to uppercase in-place\n\n**Trimming:**\n- ltrim(): Remove leading whitespace\n- rtrim(): Remove trailing whitespace\n- trim(): Remove leading and trailing whitespace\n- default_non_chars: Standard whitespace characters\n\n**Predicates:**\n- is_empty(): Check if string contains only whitespace\n- is_end(): Check if position is at end of content\n\n**Tokenization:**\n- first_word(): Extract first word from position\n- first_word_end(): Find end position of first word\n\n**Usage:**\nUsed by MPS/LP parsers for section and field extraction.",
    "file": "stringutil",
    "library": "HiGHS",
    "layer": "layer-4",
    "header": "highs/util/stringutil.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "HighsUtils": {
    "brief": "Index collections, sparse transpose, and statistical utilities\n\nMiscellaneous utility types and functions used across HiGHS.\n\n**HighsIndexCollection:**\nFlexible index specification for API operations:\n- interval: Range [from_, to_]\n- set: Explicit index array\n- mask: Boolean array\n\n**Sparse Matrix Operations:**\n- highsSparseTranspose(): CSC to CSR conversion\n\n**Value Distribution:**\n- HighsValueDistribution: Histogram for analyzing value ranges\n- HighsScatterData: Scatter plot data for analysis\n\n**Index Collection Status:**\n- kIndexCollectionCreateOk: Valid collection\n- kIndexCollectionCreateIllegalInterval/Set/Mask: Error codes",
    "file": "HighsUtils",
    "library": "HiGHS",
    "layer": "layer-4",
    "header": "highs/util/HighsUtils.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "HSet": {
    "brief": "O(1) integer set with fast membership test and removal\n\nUnordered set of distinct non-negative integers with O(1) operations.\n\n**Data Structure:**\n- entry_[]: Dense array of current entries\n- pointer_[]: Sparse array mapping entry \u2192 position in entry_[]\n- count_: Number of elements\n\n**Operations (all O(1)):**\n- add(entry): Append to entry_[], record position in pointer_[]\n- remove(entry): Swap with last, update swapped entry's pointer\n- in(entry): Check pointer_[] for valid position\n\n**Design:**\n- Similar to \"swap and pop\" deletion pattern\n- pointer_[i] = no_pointer (-1) means i not in set\n- Trades O(max_entry) space for O(1) operations\n\n**Usage:**\n- Track active row/column indices in simplex\n- Maintain sets of candidates during pricing",
    "file": "HSet",
    "library": "HiGHS",
    "layer": "layer-4",
    "header": "highs/util/HSet.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "HighsInt": {
    "brief": "The definition for the integer type to use",
    "file": "HighsInt",
    "library": "HiGHS",
    "layer": "layer-4",
    "header": "highs/util/HighsInt.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "HighsHashTree": {
    "brief": "Adaptive hash-array mapped trie (HAMT) container\n\nCache-efficient hash map using trie structure with occupation bitmaps.\n\n**Node Types:**\n- InnerLeaf<SizeClass>: Leaf with 6-54 entries (4 size classes)\n- BranchNode: Internal node with 64-way branching via hash chunks\n- ListLeaf: Collision list at maximum depth (rare)\n\n**Hash Structure:**\n- 6 bits per level \u2192 64-way branching (kBranchFactor)\n- Up to 9 depth levels (54 bits of 64-bit hash)\n- Occupation bitmap tracks which children exist\n\n**InnerLeaf Features:**\n- Linear probing within leaf for hash collisions\n- 16-bit hash prefix for fast filtering\n- Size class promotion/demotion on insert/erase\n\n**Burst Behavior:**\n- Leaf bursts to branch when exceeding kLeafBurstThreshold (54)\n- Branch merges back to leaf when children fit in threshold\n\n**Key Methods:**\n- insert/insert_or_get(): Add entry, return value pointer\n- find(): Lookup by key\n- erase(): Remove entry\n- find_common(): Find intersection with another tree\n- for_each(): Iterate all entries\n\n**Usage:**\nUsed for lifting opportunities in presolve (HPresolve.liftingOpportunities)",
    "file": "HighsHashTree",
    "library": "HiGHS",
    "layer": "layer-4",
    "header": "highs/util/HighsHashTree.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "HighsSparseMatrix": {
    "brief": "Sparse matrix in CSC or CSR format\n\n**HighsSparseMatrix Class:**\nStores constraint matrix A for LP/QP in compressed format.\n\n**Storage Format (MatrixFormat):**\n- kColwise (CSC): start_[col], index_[]/value_[] are row indices and values\n- kRowwise (CSR): start_[row], index_[]/value_[] are column indices and values\n- p_end_[]: Optional end pointers for partitioned/incremental updates\n\n**Format Conversion:**\n- ensureColwise()/ensureRowwise(): Convert to desired format\n- createColwise()/createRowwise(): Create from existing matrix\n- setFormat(): Set target format\n\n**Operations:**\n- product()/productTranspose(): Ax, A'x multiplication\n- productQuad(): Quad-precision multiplication\n- alphaProductPlusY(): y += alpha*Ax\n\n**Simplex PRICE Operations:**\n- priceByColumn()/priceByRow(): Compute pi'A\n- priceByRowWithSwitch(): Switch strategy based on density\n- createRowwisePartitioned(): Partition for hyper-sparse PRICE\n\n**Modification:**\n- addCols()/addRows(): Extend matrix\n- deleteCols()/deleteRows(): Remove columns/rows\n- scaleCol()/scaleRow(): Apply scaling",
    "file": "HighsSparseMatrix",
    "library": "HiGHS",
    "layer": "layer-4",
    "header": "highs/util/HighsSparseMatrix.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "HighsSparseVectorSum": {
    "brief": "Accumulator for sparse vector linear combinations\n\nEfficient accumulation of multiple sparse vectors with quad precision.\n\n**Hybrid Storage:**\n- values[]: Full-length HighsCDouble array for accumulation\n- nonzeroinds[]: Packed indices of nonzero entries\n- O(nnz) iteration with O(1) random access\n\n**Key Operations:**\n- add(): Accumulate value at index, track new nonzeros\n  - Uses DBL_MIN sentinel to distinguish zero from never-set\n- getNonzeros(): Return accumulated nonzero indices\n- getValue(): Extract accumulated value at index\n- clear(): Reset (O(nnz) or O(n) based on density)\n\n**Template Methods:**\n- partition(): Partition nonzeros by predicate\n- cleanup(): Remove entries satisfying isZero predicate\n\n**Usage:**\nRow aggregation for cut generation (HighsLpAggregator uses this)",
    "file": "HighsSparseVectorSum",
    "library": "HiGHS",
    "layer": "layer-4",
    "header": "highs/util/HighsSparseVectorSum.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "FactorTimer": {
    "brief": "Indices of factor iClocks",
    "file": "FactorTimer",
    "library": "HiGHS",
    "layer": "layer-4",
    "header": "highs/util/FactorTimer.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "HighsRbTree": {
    "brief": "Array-based Red-Black tree with CRTP interface\n\nSelf-balancing BST using indices instead of pointers for cache efficiency.\n\n**CRTP Pattern:**\n- RbTreeTraits<Impl>: Define KeyType and LinkType\n- Impl::getRbTreeLinks(): Return reference to RbTreeLinks\n- Impl::getKey(): Return comparable key value\n\n**RbTreeLinks Structure:**\n- child[2]: Left/right child indices\n- parentAndColor: Parent packed with color bit (saves storage)\n- Works with both integer and pointer LinkTypes\n\n**Tree Operations:**\n- link(): Insert node, rebalance via red-black rotations\n- unlink(): Remove node with transplant and fixup\n- find(): Search returning (node, exact_match) pair\n- first()/last(): Minimum/maximum in subtree\n- successor()/predecessor(): In-order traversal\n\n**CacheMinRbTree Variant:**\n- Maintains cached pointer to minimum element\n- O(1) access to first() for priority queue usage\n\n**Usage in HiGHS:**\n- HighsNodeQueue: Priority queue for B&B nodes by bound\n- Efficient ordered containers with O(log n) operations",
    "file": "HighsRbTree",
    "library": "HiGHS",
    "layer": "layer-4",
    "header": "highs/util/HighsRbTree.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "HighsMatrixPic": {
    "brief": "Class-independent utilities for HiGHS",
    "file": "HighsMatrixPic",
    "library": "HiGHS",
    "layer": "layer-4",
    "header": "highs/util/HighsMatrixPic.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "HighsLinearSumBounds": {
    "brief": "Row activity bounds for bound tightening (FBBT)\n\nIncrementally maintains min/max activity bounds for linear constraints.\n\n**Activity Computation:**\nFor row sum = \u03a3(a_i * x_i):\n- sumLower: Minimum activity using a_i>0 with lb_i, a_i<0 with ub_i\n- sumUpper: Maximum activity using a_i>0 with ub_i, a_i<0 with lb_i\n- numInfSumLower/Upper: Count of infinite contributions\n\n**Original vs Implied Bounds:**\n- sumLowerOrig/sumUpperOrig: Using original variable bounds only\n- sumLower/sumUpper: Using tightest of original and implied bounds\n- implVarLower/implVarUpper: Implied bounds from other constraints\n- Source tracking: implVarLowerSource[] for circular dependency detection\n\n**Incremental Updates:**\n- add(): Add variable contribution to sum\n- remove(): Remove variable contribution from sum\n- updatedVarLower/Upper(): Update after bound tightening\n- updatedImplVarLower/Upper(): Update after implied bound discovery\n\n**Residual Computation:**\n- getResidualSumLower/Upper(): Activity excluding specific variable\n  - Used for FBBT: derive x_i bounds from row \u2264 rhs - residual\n  - Optional boundVar parameter for conditional bounds\n\n**Quad Precision:**\nUses HighsCDouble for activity sums to avoid numerical issues.",
    "file": "HighsLinearSumBounds",
    "library": "HiGHS",
    "layer": "layer-4",
    "header": "highs/util/HighsLinearSumBounds.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "HVectorBase": {
    "brief": "Template sparse vector for simplex operations\n\nHybrid-storage vector supporting both sparse and dense access patterns.\n\n**Storage Model:**\n- array[]: Full-length value storage (dense access)\n- index[]: Packed nonzero indices (sparse iteration)\n- count: Number of nonzeros\n- Enables O(nnz) operations while allowing O(1) element access\n\n**Core Operations:**\n- setup(): Initialize to dimension\n- clear(): Reset all values and count\n- saxpy(): y += alpha * x (sparse BLAS-1)\n- pack(): Compress to packIndex/packValue arrays\n- reIndex(): Rebuild index[] from array[] (after cancellation)\n- norm2(): Squared 2-norm computation\n\n**Packing System:**\n- packFlag: Enable/disable packing\n- packIndex/packValue: Compressed representation\n- tight(): Zero small values exceeding kHighsTiny\n\n**PAMI Support:**\n- next: Link pointer for parallel minor iteration chains\n- cwork/iwork: Scratch buffers for UPDATE operations\n- synthetic_tick: Profiling counter for operation costs",
    "file": "HVectorBase",
    "library": "HiGHS",
    "layer": "layer-4",
    "header": "highs/util/HVectorBase.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "HighsTimer": {
    "brief": "Profiling facility for HiGHS computational components\n\n**HighsTimer Class:**\nWall-clock timing with named clocks for performance profiling.\n\n**Clock Management:**\n- clock_def(): Define a named clock, returns clock index\n- start()/stop(): Start/stop a clock (asserts proper pairing)\n- read(): Get elapsed time (handles running clocks)\n- running(): Check if clock is running\n- numCall(): Get number of times clock was stopped\n\n**Built-in Clocks:**\n- Clock 0: \"Run HiGHS\" (total time)\n- presolve_clock, solve_clock, postsolve_clock: Phase timings\n\n**Reporting:**\n- report(): Print timing breakdown for clock list (grep-friendly format)\n- reportOnTolerance(): Only report clocks above percentage threshold\n- writeAllClocks(): Dump all clock times\n\n**Implementation:**\nUses std::chrono::high_resolution_clock. Clock start stores negative\nwall time; positive indicates stopped. This enables running/stopped detection.",
    "file": "HighsTimer",
    "library": "HiGHS",
    "layer": "layer-4",
    "header": "highs/util/HighsTimer.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "HighsRandom": {
    "brief": "Deterministic random number generator for HiGHS\n\nXorshift-based PRNG with strongly universal hash output functions.\n\n**State Management:**\n- 64-bit state with xorshift advance\n- initialise(): Seed with mixing to avoid weak states\n- Deterministic for reproducible optimization\n\n**Output Methods:**\n- integer(): Random in [0, 2^31-1] or [0, sup) or [min, sup)\n- fraction(): Open interval (0, 1)\n- closedFraction(): Closed interval [0, 1]\n- real(a, b): Uniform in [a, b]\n- bit(): Random boolean\n- shuffle(): Fisher-Yates shuffle\n\n**Uniform Range Algorithm:**\nUses rejection sampling with hash function outputs:\n- Multiple hash outputs per state (up to 32)\n- Minimizes state advances for bounded integers\n\n**Hash-Based Mixing:**\nApplies HighsHashHelpers::pair_hash to state for high-quality output\nin both high and low bits (unlike raw xorshift).",
    "file": "HighsRandom",
    "library": "HiGHS",
    "layer": "layer-4",
    "header": "highs/util/HighsRandom.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "HighsHash": {
    "brief": "Hash functions and hash table for HiGHS\n\nProvides high-quality hashing with Mersenne prime arithmetic.\n\n**HighsHashHelpers:**\n- hash<T>(): Fast hash for trivially copyable types (up to 64 bytes)\n- vector_hash(): Hash for vectors using pair_hash with random constants\n- sparse_combine(): Order-independent hash for sparse vectors\n- multiply_modM61(): Multiply mod Mersenne prime 2^61-1\n- double_hash_code(): Hash for doubles handling epsilon equality\n\n**Sparse Hashing (for symmetry detection):**\nEvaluates polynomial over finite field GF(2^61-1):\n- sparse_combine(hash, index, value): Add term to polynomial\n- sparse_inverse_combine(): Remove term (for partition refinement)\n- Enables order-independent hashing of sparse vectors\n\n**HighsHashTable<K,V>:**\nRobin Hood hashing with linear probing:\n- 7-bit hash stored in metadata for fast comparison\n- Automatic grow/shrink at 7/8 and 1/4 load factors\n- Steals positions from entries closer to ideal slot\n\n**HighsHashTableEntry<K,V>:**\n- Specialized for void value (set behavior)\n- key(), value() accessors\n- forward() for functional-style iteration",
    "file": "HighsHash",
    "library": "HiGHS",
    "layer": "layer-4",
    "header": "highs/util/HighsHash.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "HFactorDebug": {
    "brief": "",
    "file": "HFactorDebug",
    "library": "HiGHS",
    "layer": "layer-4",
    "header": "highs/util/HFactorDebug.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "HighsSplay": {
    "brief": "Splay tree operations for array-based binary search trees\n\nTop-down splay tree using indices instead of pointers for cache efficiency.\n\n**Splay Operation:**\n- highs_splay(): Move accessed node to root via rotations\n- Amortized O(log n) operations through self-adjusting\n- Zig-zig and zig-zag rotations for balanced restructuring\n\n**Tree Operations:**\n- highs_splay_link(): Insert new node, splay to root\n- highs_splay_unlink(): Remove node, restructure tree\n\n**Lambda Interface:**\nTemplate parameters for flexible storage:\n- GetLeft: lambda(index) \u2192 reference to left child index\n- GetRight: lambda(index) \u2192 reference to right child index\n- GetKey: lambda(index) \u2192 comparable key value\n\n**Usage in HiGHS:**\n- HPresolve: Row-wise nonzero storage (ARleft, ARright, rowroot)\n- HighsGFkSolve: Sparse storage for GF(k) systems\n- Efficient O(1) access to recently accessed elements",
    "file": "HighsSplay",
    "library": "HiGHS",
    "layer": "layer-4",
    "header": "highs/util/HighsSplay.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "HighsCDouble": {
    "brief": "Compensated double for quad precision arithmetic\n\nImplements quad precision using error-free transformations (Knuth/Rump).\n\n**Representation:**\n- hi: Primary double value\n- lo: Compensation term (error from previous operations)\n- Value = hi + lo with |lo| << |hi|\n\n**Error-Free Transformations:**\n- two_sum(x,y,a,b): Exact a+b=x+y with x=double(a+b), 6 FLOPs\n- two_product(x,y,a,b): Exact a*b=x+y with x=double(a*b), 17 FLOPs\n- split(x,y,a): Split 53-bit mantissa into two 26-bit parts\n\n**Supported Operations:**\n- +, -, *, / with double and HighsCDouble operands\n- Comparison operators (using double(hi+lo))\n- abs(), sqrt(), floor(), ceil(), round(), ldexp()\n- renormalize(): Restore |lo| << |hi| invariant\n\n**Usage:**\nCritical for accurate summation in LP (objective, constraint activity)\nand avoiding catastrophic cancellation in bound computations.",
    "file": "HighsCDouble",
    "library": "HiGHS",
    "layer": "layer-4",
    "header": "highs/util/HighsCDouble.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "HighsDataStack": {
    "brief": "Type-erased byte stack for presolve reduction storage\n\nLIFO storage for heterogeneous data with compile-time type safety.\n\n**Design:**\n- Stores arbitrary trivially-copyable types as raw bytes\n- push<T>(): Append value to stack\n- pop<T>(): Remove and return value from top\n- Vectors stored with trailing size for self-describing pops\n\n**Presolve Integration:**\n- HighsPostsolveStack uses this for reduction storage\n- Each presolve reduction pushes undo data\n- Postsolve pops in reverse order to restore solution\n- Compact binary format (no per-element overhead)\n\n**Memory Layout:**\n- Scalar: |--value bytes--|\n- Vector: |--element bytes--|--size_t count--|\n- Position tracks pop location; data.size() for push\n\n**Type Safety:**\n- IS_TRIVIALLY_COPYABLE enforces memcpy-safe types\n- Compatible with GCC < 5 via __has_trivial_copy",
    "file": "HighsDataStack",
    "library": "HiGHS",
    "layer": "layer-4",
    "header": "highs/util/HighsDataStack.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "HighsSort": {
    "brief": "Heap-based sorting routines for HiGHS\n\nIn-place heapsort implementations for indices and value-index pairs.\n\n**Algorithm:**\n- Build max-heap in O(n) via buildMaxheap()\n- Extract elements in O(n log n) via maxHeapsort()\n- Result: increasing order (max-heap yields ascending sort)\n\n**Functions:**\n- maxheapsort(): Combined build + sort\n- buildMaxheap() + maxHeapsort(): Separate phases\n- maxHeapify(): Sift-down operation\n\n**Overloads:**\n- (HighsInt*): Sort indices only\n- (double*, HighsInt*): Sort values with corresponding indices\n- (HighsInt*, HighsInt*): Sort HighsInt values with indices\n\n**Decreasing Heap Utilities:**\n- addToDecreasingHeap(): Insert into bounded min-heap\n- sortDecreasingHeap(): Extract in decreasing order\n\n**Validation:**\n- increasingSetOk(): Check sorted order and bounds\n- sortSetData(): Sort indices and reorder associated data arrays\n\n@note Arrays use 1-based indexing: heap[1..n]",
    "file": "HighsSort",
    "library": "HiGHS",
    "layer": "layer-4",
    "header": "highs/util/HighsSort.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "HighsMatrixUtils": {
    "brief": "Class-independent utilities for HiGHS",
    "file": "HighsMatrixUtils",
    "library": "HiGHS",
    "layer": "layer-4",
    "header": "highs/util/HighsMatrixUtils.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "HighsDisjointSets": {
    "brief": "Union-Find data structure for disjoint sets\n\nEfficient partition management with path compression and union-by-size.\n\n**Template Parameter:**\n- kMinimalRepresentative: If true, smaller index becomes representative\n  (useful for symmetry detection where order matters)\n\n**Data Structure:**\n- sets[]: Parent pointers (self-loop = representative)\n- sizes[]: Set sizes for union-by-size\n- linkCompressionStack: Workspace for path compression\n\n**Operations:**\n- getSet(): Find representative with path compression\n  - Amortized O(\u03b1(n)) via iterative compression\n- merge(): Union two sets\n  - Union-by-size keeps tree balanced\n  - Or union-by-min-index if kMinimalRepresentative\n- getSetSize(): Size of set containing item\n\n**Usage in HiGHS:**\n- Symmetry detection: orbit computation (HighsSymmetry)\n- Clique merging (HighsCliqueTable)\n- Connected component identification",
    "file": "HighsDisjointSets",
    "library": "HiGHS",
    "layer": "layer-4",
    "header": "highs/util/HighsDisjointSets.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "HVector": {
    "brief": "Sparse vector types for HiGHS simplex operations\n\nType aliases for HVectorBase with different precision.\n\n**Types:**\n- HVector: HVectorBase<double> - Standard precision sparse vector\n- HVectorQuad: HVectorBase<HighsCDouble> - Quad precision for accuracy\n- HVector_ptr, HVectorQuad_ptr: Pointer types for array storage\n\n**HVectorBase Features (from HVectorBase.h):**\n- Sparse representation: index[] + array[] with count\n- Dense operations: clear(), setup(), collectDense()\n- SAXPY: Add scalar multiple of another vector\n- Packed format for BLAS-style operations",
    "file": "HVector",
    "library": "HiGHS",
    "layer": "layer-4",
    "header": "highs/util/HVector.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "HighsComponent": {
    "brief": "The HiGHS class",
    "file": "HighsComponent",
    "library": "HiGHS",
    "layer": "layer-4",
    "header": "highs/util/HighsComponent.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "HFactorConst": {
    "brief": "Constants for basis matrix factorization, update and solves for HiGHS",
    "file": "HFactorConst",
    "library": "HiGHS",
    "layer": "layer-4",
    "header": "highs/util/HFactorConst.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "HighsMatrixSlice": {
    "brief": "Polymorphic iterators for sparse matrix storage formats\n\nSTL-compatible iterators over matrix rows/columns regardless of storage.\n\n**Storage Format Specializations:**\n- HighsEmptySlice: Zero nonzeros (null iterators)\n- HighsCompressedSlice: CSC/CSR format (index[], value[], len)\n- HighsIndexedSlice: Sparse index + dense values (hybrid storage)\n- HighsTripletListSlice: Linked list via next[] array\n- HighsTripletTreeSliceInOrder: BST traversal (sorted iteration)\n- HighsTripletTreeSlicePreOrder: BST pre-order (fast iteration)\n- HighsTripletPositionSlice: Position array indirection\n\n**Iterator Interface:**\n- HighsSliceNonzero: (index, value) pair via index()/value()\n- Forward iterator with begin()/end()\n- Compatible with range-based for loops\n\n**Usage Pattern:**\n```cpp\nfor (auto nz : HighsCompressedSlice(idx, val, len)) {\n  process(nz.index(), nz.value());\n}\n```\n\n**Usage in HiGHS:**\n- HPresolve: Unified iteration over row/column storage\n- Generic algorithms independent of underlying format\n- Splay tree and linked list iteration in presolve",
    "file": "HighsMatrixSlice",
    "library": "HiGHS",
    "layer": "layer-4",
    "header": "highs/util/HighsMatrixSlice.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "HFactor": {
    "brief": "Basis matrix factorization, update and solves for HiGHS",
    "file": "HFactor",
    "library": "HiGHS",
    "layer": "layer-4",
    "header": "highs/util/HFactor.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "HighsIntegers": {
    "brief": "Integer arithmetic utilities for cut generation\n\nNumber-theoretic functions critical for MIP cut generation.\n\n**Basic Operations:**\n- mod(): Proper modulo (always non-negative result)\n- gcd(): Euclidean algorithm for GCD\n- nearestInteger(): Round to nearest int64\n- isIntegral(): Test if double is within eps of integer\n\n**Modular Arithmetic:**\n- modularInverse(): Extended Euclidean algorithm for a^{-1} mod m\n  - Used in mod-k cut generation (GF(k) arithmetic)\n\n**Rational Approximation:**\n- denominator(): Continued fraction algorithm to find\n  smallest denominator d such that |x - p/d| < eps\n  - Used for detecting integer structure in coefficients\n\n**Integral Scaling:**\n- integralScale(): Find multiplier to make all values integral\n  - Combines continued fractions with GCD reduction\n  - Used for strengthening MIR/GMI cuts\n  - Returns 0 if no small denominator exists\n\n**Usage in HiGHS:**\n- HighsGFkSolve: Modular inverse for GF(k) systems\n- HighsTableauSeparator: Finding integral structure in cuts\n- Cut coefficient strengthening",
    "file": "HighsIntegers",
    "library": "HiGHS",
    "layer": "layer-4",
    "header": "highs/util/HighsIntegers.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "HighsMemoryAllocation": {
    "brief": "Utilities for memory allocation that return true if successful",
    "file": "HighsMemoryAllocation",
    "library": "HiGHS",
    "layer": "layer-4",
    "header": "highs/util/HighsMemoryAllocation.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "HMpsFF": {
    "brief": "Free-format MPS file parser with full section support\n\nComprehensive MPS reader supporting LP, QP, MIP, and extensions.\n\n**MPS Sections Parsed:**\n- NAME, OBJSENSE: Problem metadata and optimization direction\n- ROWS: Constraint types (N=free, L/G/E=bounds)\n- COLUMNS: Variable coefficients, integrality markers\n- RHS: Right-hand sides for constraints\n- RANGES: Two-sided constraint bounds\n- BOUNDS: Variable bounds (LO/UP/FX/FR/MI/PL/BV/LI/UI)\n\n**Quadratic Extensions:**\n- QSECTION, QMATRIX, QUADOBJ: Objective Hessian\n- QCMATRIX: Quadratic constraints (per-row)\n\n**Additional Sections:**\n- SOS: Special ordered sets (Type 1, Type 2)\n- CSECTION: Conic constraints (MOSEK format)\n- INDICATORS: Indicator constraints (ignored)\n\n**Parsing Features:**\n- Triplet matrix accumulation, then CSC conversion\n- Duplicate row/column name detection\n- Timeout support for large files\n- Fixed-format detection and fallback\n\n**Data Flow:**\n- loadProblem() \u2192 parse() \u2192 fillMatrix()/fillHessian()\n- Populates HighsModel with LP/QP/MIP data",
    "file": "HMpsFF",
    "library": "HiGHS",
    "layer": "layer-4",
    "header": "highs/io/HMpsFF.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "Filereader": {
    "brief": "Abstract file reader/writer interface for optimization models\n\nPolymorphic I/O with format detection from file extension.\n\n**Supported Formats:**\n- MPS: Mathematical Programming System (fixed/free format)\n- LP: CPLEX LP format (human-readable)\n- EMS: HiGHS extended model format\n\n**Factory Pattern:**\n- getFilereader(): Returns appropriate reader for extension\n  - \".mps\", \".mps.gz\" \u2192 FilereaderMps\n  - \".lp\" \u2192 FilereaderLp\n  - \".ems\" \u2192 FilereaderEms\n\n**Return Codes:**\n- kOk: Success\n- kFileNotFound: File doesn't exist\n- kParserError: Malformed input\n- kNotImplemented: Format not supported for operation\n- kTimeout: Read exceeded time limit",
    "file": "Filereader",
    "library": "HiGHS",
    "layer": "layer-4",
    "header": "highs/io/Filereader.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "FilereaderMps": {
    "brief": "MPS format file reader/writer wrapper\n\nImplements Filereader interface for MPS format (industry standard).\n\n**FilereaderMps Class:**\nThin wrapper delegating to HMpsFF (free-format) or HMPSIO (fixed-format):\n- readModelFromFile(): Detect format, parse MPS into HighsModel\n- writeModelToFile(): Export HighsModel to MPS format\n\n**MPS Format Support:**\n- Standard sections: ROWS, COLUMNS, RHS, BOUNDS, RANGES\n- Extensions: OBJSENSE, QSECTION, SOS, integer markers\n- Both free-format and fixed-format variants\n\n**Read Flow:**\n1. Attempts free-format parse (HMpsFF)\n2. Falls back to fixed-format (HMPSIO) if needed\n3. Handles QP and MIP extensions",
    "file": "FilereaderMps",
    "library": "HiGHS",
    "layer": "layer-4",
    "header": "highs/io/FilereaderMps.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "HMPSIO": {
    "brief": "Fixed-format MPS file parser (legacy format)\n\nParses classic fixed-column MPS format from IBM's MP/360.\n\n**Fixed-Format Layout:**\nColumns are at fixed character positions:\n- field_1_start (1): Indicator field (row type, bound type)\n- field_2_start (4): Name field (8 chars)\n- field_3_start (14): Name field 2 (8 chars)\n- field_4_start (24): Value field (12 chars)\n- field_5_start (39): Name field 3 (8 chars)\n- field_6_start (49): Value field 2 (12 chars)\n\n**Row Type Constants:**\n- MPS_ROW_TY_N: Free row (objective)\n- MPS_ROW_TY_E: Equality constraint\n- MPS_ROW_TY_L: Less-than-or-equal\n- MPS_ROW_TY_G: Greater-than-or-equal\n\n**readMps():**\nMain parsing function extracting:\n- Constraint matrix (Astart, Aindex, Avalue)\n- Bounds and costs\n- Integrality constraints\n- Quadratic terms (Qstart, Qindex, Qvalue)",
    "file": "HMPSIO",
    "library": "HiGHS",
    "layer": "layer-4",
    "header": "highs/io/HMPSIO.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "LoadOptions": {
    "brief": "Load solver options from file\n\nParses options files into HighsOptions structure.\n\n**HighsLoadOptionsStatus:**\n- kError: Parse failure or invalid option\n- kOk: Options loaded successfully\n- kEmpty: File exists but contains no options\n\n**loadOptionsFromFile():**\nReads option file with key=value pairs:\n- Recognizes all HighsOptions fields\n- Validates option names and value types\n- Logs warnings for unknown options\n\n**File Format:**\nSimple text format with one option per line:\n```\npresolve = on\ntime_limit = 3600.0\nmip_rel_gap = 0.01\n```",
    "file": "LoadOptions",
    "library": "HiGHS",
    "layer": "layer-4",
    "header": "highs/io/LoadOptions.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "FilereaderEms": {
    "brief": "EMS format file reader/writer (internal HiGHS format)\n\nImplements Filereader interface for EMS format.\n\n**EMS Format:**\nHiGHS internal text format for model serialization:\n- Compact representation of LP/MIP data\n- Preserves all model metadata\n- Used for debugging and testing\n\n**FilereaderEms Class:**\n- readModelFromFile(): Parse EMS file into HighsModel\n- writeModelToFile(): Export HighsModel to EMS format\n\n**Compared to MPS/LP:**\n- Less standardized but more compact\n- Primarily for internal use\n- Full round-trip fidelity with HighsModel",
    "file": "FilereaderEms",
    "library": "HiGHS",
    "layer": "layer-4",
    "header": "highs/io/FilereaderEms.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "FilereaderLp": {
    "brief": "CPLEX LP format file reader/writer\n\nImplements Filereader interface for LP format (human-readable).\n\n**LP Format:**\nCPLEX-style format with sections:\n- Minimize/Maximize: Objective function\n- Subject To: Linear constraints\n- Bounds: Variable bounds\n- General/Binary: Integer/binary declarations\n- End: File terminator\n\n**FilereaderLp Class:**\n- readModelFromFile(): Parse LP file into HighsModel\n- writeModelToFile(): Export HighsModel to LP format\n\n**Writing Utilities:**\n- writeToFile(): Buffered output with line-length management\n- writeToFileValue(): Format numeric coefficients\n- writeToFileVar(): Output variable names (quotes if needed)\n- writeToFileMatrixRow(): Output constraint row\n\n**Constants:**\n- LP_MAX_LINE_LENGTH (560): Maximum line length\n- LP_MAX_NAME_LENGTH (255): Maximum identifier length",
    "file": "FilereaderLp",
    "library": "HiGHS",
    "layer": "layer-4",
    "header": "highs/io/FilereaderLp.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "HighsIO": {
    "brief": "Logging and output utilities for HiGHS\n\nProvides structured logging with log levels and callbacks.\n\n**Log Levels (LogDevLevel):**\n- kHighsLogDevLevelNone: No output\n- kHighsLogDevLevelInfo: Standard progress info\n- kHighsLogDevLevelDetailed: More detailed info\n- kHighsLogDevLevelVerbose: Maximum detail\n\n**Log Types (HighsLogType):**\nTagged output: WARNING, ERROR, etc. (see HighsLogTypeTag[])\n\n**HighsLogOptions:**\nConfiguration for logging destination and callbacks:\n- log_stream: FILE* for output (nullptr = stdout)\n- output_flag/log_to_console: Enable/disable flags\n- user_log_callback: Custom logging callback\n- user_callback: Full callback with HighsCallbackOutput\n\n**Logging Functions:**\n- highsLogUser(): Single-line user messages with type tag\n- highsLogDev(): Development logging (respects log_dev_level)\n- highsLogHeader(): Print version and copyright\n- highsReportDevInfo(): Development info (accepts null log_options)\n\n**File Types (HighsFileType):**\nkMinimal, kFull, kMps, kLp, kMd for output format selection.",
    "file": "HighsIO",
    "library": "HiGHS",
    "layer": "layer-4",
    "header": "highs/io/HighsIO.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "ICrashUtil": {
    "brief": "Low-level utilities for ICrash algorithms",
    "file": "ICrashUtil",
    "library": "HiGHS",
    "layer": "layer-4",
    "header": "highs/presolve/ICrashUtil.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "HPresolve": {
    "brief": "LP/MIP presolve engine\n\n**HPresolve Class:**\nReduces problem size and tightens bounds before solving.\n\n**Matrix Storage:**\nTriplet format with linked list (column) and splay tree (row) for fast access:\n- Avalue[], Arow[], Acol[]: Non-zero storage\n- colhead[], Anext[], Aprev[]: Column-wise linked list\n- rowroot[], ARleft[], ARright[]: Row-wise splay tree\n- rowsize[], colsize[]: Current row/column lengths\n\n**Bound Tracking:**\n- implColLower[]/implColUpper[]: Implied variable bounds\n- rowDualLower[]/rowDualUpper[]: Dual bounds\n- impliedRowBounds, impliedDualRowBounds: Row activity bounds\n\n**Presolve Techniques (Result enum):**\n- singletonRow()/singletonCol(): Remove singleton rows/columns\n- emptyCol(): Remove columns with no constraints\n- doubletonEq(): Eliminate doubleton equalities\n- dominatedColumns(): Remove dominated variables\n- aggregator(): Aggregate rows/columns\n- runProbing(): Probing for integer variables\n- sparsify(): Reduce matrix density\n- detectParallelRowsAndCols(): Remove parallel constraints/variables",
    "file": "HPresolve",
    "library": "HiGHS",
    "layer": "layer-4",
    "header": "highs/presolve/HPresolve.h",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "ICrash": {
    "brief": "Iterative crash procedure for LP starting points",
    "file": "ICrash",
    "library": "HiGHS",
    "layer": "layer-4",
    "header": "highs/presolve/ICrash.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "HPresolveAnalysis": {
    "brief": "Presolve statistics and rule control\n\nTracks presolve reductions and controls which rules are enabled.\n\n**HPresolveAnalysis Class:**\n- model, options: References to problem being presolved\n- allow_rule_[]: Per-rule enable flags (from options->presolve_rule_off)\n- numDeletedRows, numDeletedCols: Reduction counts\n- presolve_log_: Detailed reduction history\n\n**Rule Control:**\n- setup(): Initialize rule flags from options\n- allow_rule_[]: Boolean array indexed by PresolveRuleType\n- Disabled rules are skipped during presolve passes\n\n**Logging:**\n- allow_logging_/logging_on_: Control verbosity\n- startPresolveRuleLog()/stopPresolveRuleLog(): Bracket rule execution\n- analysePresolveRuleLog(): Summarize effectiveness of rules\n- presolveReductionTypeToString(): Convert rule type to name\n\n**Statistics:**\n- original_num_col_/row_: Problem size before presolve\n- num_deleted_rows0_/cols0_: Running deletion counts",
    "file": "HPresolveAnalysis",
    "library": "HiGHS",
    "layer": "layer-4",
    "header": "highs/presolve/HPresolveAnalysis.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "HighsPostsolveStack": {
    "brief": "Postsolve stack to recover original-space solutions\n\nRecords all presolve transformations to enable solution recovery.\n\n**HighsPostsolveStack Class:**\nStack of reduction operations that can be undone in reverse order.\n\n**Reduction Types (ReductionType enum):**\nEach presolve operation has a corresponding undo:\n- kLinearTransform: x = scale * x' + constant\n- kFreeColSubstitution: Free variable substituted via equation\n- kDoubletonEquation: Two-variable equation eliminated\n- kSingletonRow/kFixedCol: Single-entry row or fixed column\n- kRedundantRow/kForcingRow: Redundant or forcing constraints\n- kDuplicateRow/kDuplicateColumn: Parallel rows/columns merged\n\n**Index Mapping:**\n- origColIndex[], origRowIndex[]: Map reduced indices to original\n- compressIndexMaps(): Update after columns/rows removed\n\n**Postsolve Operations:**\n- undo(): Reverse all reductions (primal, dual, basis)\n- undoPrimal(): Reverse only primal solution\n- getReducedPrimalSolution(): Map original solution to reduced space\n\n**Data Storage:**\n- reductionValues: HighsDataStack for reduction parameters\n- reductions[]: Vector of (type, stack_position) pairs\n- rowValues[], colValues[]: Temporary storage for sparse vectors",
    "file": "HighsPostsolveStack",
    "library": "HiGHS",
    "layer": "layer-4",
    "header": "highs/presolve/HighsPostsolveStack.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "ICrashX": {
    "brief": "Crossover from interior point to basic solution\n\nProvides simplex crossover after IPM solve to obtain vertex solution.\n\n**callCrossover():**\nConverts interior point solution to basic feasible solution:\n- Input: IPM solution (may be interior to polytope)\n- Output: Basis + vertex solution for post-processing\n\n**Why Crossover:**\n- IPM returns interior solutions, not vertices\n- Basic solutions needed for warm-starting, sensitivity analysis\n- Crossover pushes solution to vertex via simplex pivots\n\n**Process:**\n1. Identify near-bound variables\n2. Construct initial basis from binding constraints\n3. Run simplex cleanup to reach vertex",
    "file": "ICrashX",
    "library": "HiGHS",
    "layer": "layer-4",
    "header": "highs/presolve/ICrashX.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "PresolveComponent": {
    "brief": "Presolve component for HiGHS pipeline integration\n\nEncapsulates presolve as a modular component with data and statistics.\n\n**PresolveComponentData:**\nState managed by presolve component:\n- reduced_lp_: Presolved LP (smaller problem)\n- postSolveStack: Operations to undo presolve\n- recovered_solution_/recovered_basis_: Original-space solution\n- presolve_log_: Reduction history\n\n**PresolveComponentInfo:**\nStatistics exposed for reporting:\n- n_rows_removed, n_cols_removed, n_nnz_removed: Reduction counts\n- Timing information from HighsComponentInfo base\n\n**PresolveComponentOptions:**\nComponent-specific settings (extends HighsComponentOptions):\n- iteration_limit: Maximum presolve passes\n- Timeout and other controls\n\n**PresolveComponent Class:**\nMain component implementing HighsComponent interface:\n- init(): Setup with options\n- run(): Execute presolve\n- has_run_: Track execution state",
    "file": "PresolveComponent",
    "library": "HiGHS",
    "layer": "layer-4",
    "header": "highs/presolve/PresolveComponent.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "HighsSymmetry": {
    "brief": "Symmetry detection and orbital fixing for MIP",
    "file": "HighsSymmetry",
    "library": "HiGHS",
    "layer": "layer-4",
    "header": "highs/presolve/HighsSymmetry.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "cupdlp_solver": {
    "brief": "PDHG (Primal-Dual Hybrid Gradient) Solver for Linear Programming\n\nImplements the PDLP (Primal-Dual Linear Programming) algorithm using\nfirst-order optimization methods instead of traditional simplex or IPM.",
    "file": "cupdlp_solver",
    "library": "HiGHS",
    "layer": "layer-4",
    "header": "highs/pdlp/cupdlp/cupdlp_solver.h",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "iterate": {
    "brief": "IPM Iterate Management with Variable States\n\nManages the primal-dual iterate for interior point methods, including\nvariable states (fixed/free/barrier) and convergence monitoring.",
    "file": "iterate",
    "library": "HiGHS",
    "layer": "layer-4",
    "header": "highs/ipm/ipx/iterate.h",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "forrest_tomlin": {
    "brief": "Forrest-Tomlin LU Update for Basis Maintenance\n\nImplements the Forrest-Tomlin update to maintain LU factorization when\na single column of the basis matrix changes (basis exchange/pivot).",
    "file": "forrest_tomlin",
    "library": "HiGHS",
    "layer": "layer-4",
    "header": "highs/ipm/ipx/forrest_tomlin.h",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "crossover": {
    "brief": "cuOpt GPU dual simplex component\n\nPart of CUDA-accelerated dual simplex LP solver.",
    "file": "crossover",
    "library": "cuopt",
    "layer": "layer-4",
    "header": "cpp/src/dual_simplex/crossover.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "ipm": {
    "brief": "Mehrotra's Predictor-Corrector Interior Point Method\n\nImplements an interior point method (IPM) for linear programming using\nMehrotra's predictor-corrector technique with two KKT solves per iteration.",
    "file": "ipm",
    "library": "HiGHS",
    "layer": "layer-4",
    "header": "highs/ipm/ipx/ipm.h",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "kkt_solver": {
    "brief": "KKT System Solver Interface for Interior Point Methods\n\nDefines the interface for solving the augmented system (KKT system) that\narises in each iteration of primal-dual interior point methods.",
    "file": "kkt_solver",
    "library": "HiGHS",
    "layer": "layer-4",
    "header": "highs/ipm/ipx/kkt_solver.h",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "lp_solver": {
    "brief": "IPX interior point LP solver main class\n\nImplements primal-dual interior point method with crossover to basic solution.\n\n**Model Loading:**\n- LoadModel(): LP in standard form (c, lb, ub, A, rhs, constr_type)\n- LoadIPMStartingPoint(): User-provided initial point (x, xl, xu, y, zl, zu)\n\n**Solution Methods:**\n- Solve(): Run IPM + optional crossover to basis\n- CrossoverFromStartingPoint(): Convert complementary point to basis\n\n**Solution Access:**\n- GetInfo(): Solver status and statistics\n- GetInteriorSolution(): IPM iterate (primal, slack, dual)\n- GetBasicSolution(): Basic solution with basis status (vbasis, cbasis)\n\n**IPM Pipeline (InteriorPointSolve):**\n1. RunInitialIPM(): Initial centering iterations\n2. BuildStartingBasis(): Construct basis from weighted columns\n3. RunMainIPM(): Main IPM iterations with basis preconditioning\n4. RunCrossover(): Push to basis via dual/primal pushes\n\n**Key Components:**\n- control_: Parameters and logging\n- model_: Preprocessed LP data\n- iterate_: Current IPM point (x, y, z, slacks)\n- basis_: Basis for preconditioning and crossover",
    "file": "lp_solver",
    "library": "HiGHS",
    "layer": "layer-4",
    "header": "highs/ipm/ipx/lp_solver.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "conjugate_residuals": {
    "brief": "Conjugate Residuals Method for Symmetric Positive Definite Systems\n\nImplements preconditioned Conjugate Residuals (CR) for iteratively solving\nthe KKT system in interior point methods.",
    "file": "conjugate_residuals",
    "library": "HiGHS",
    "layer": "layer-4",
    "header": "highs/ipm/ipx/conjugate_residuals.h",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "OSReferenced": {
    "brief": "OS reference counting base class\n\nReference-counted base class for OS objects.\nEnables automatic memory management via smart pointers.",
    "file": "OSReferenced",
    "library": "OS",
    "layer": "layer-4",
    "header": "OS/src/OSUtils/OSReferenced.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "OSSmartPtr": {
    "brief": "OS smart pointer implementation\n\nIntrusive smart pointer for OSReferenced objects.\nSimilar to Ipopt SmartPtr for reference counting.",
    "file": "OSSmartPtr",
    "library": "OS",
    "layer": "layer-4",
    "header": "OS/src/OSUtils/OSSmartPtr.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "OSgams2osil": {
    "brief": "GAMS to OSiL model converter\n\nConverts GAMS optimization models to OS Instance Language (OSiL).\nReads GAMS .gms files and produces XML-based OSiL representation.",
    "file": "OSgams2osil",
    "library": "OS",
    "layer": "layer-4",
    "header": "OS/src/OSModelInterfaces/OSgams2osil.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "OSosrl2gams": {
    "brief": "OSrL to GAMS solution converter\n\nConverts OS Result Language (OSrL) to GAMS solution format.\nWrites solution back to GAMS for post-processing.",
    "file": "OSosrl2gams",
    "library": "OS",
    "layer": "layer-4",
    "header": "OS/src/OSModelInterfaces/OSosrl2gams.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "OSParseosil.tab": {
    "brief": "OSiL XML parser (bison-generated)\n\nBison-generated parser for OS Instance Language (OSiL).\nParses XML optimization problem instances.",
    "file": "OSParseosil.tab",
    "library": "OS",
    "layer": "layer-4",
    "header": "OS/src/OSParsers/OSParseosil.tab.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "OSParseosol.tab": {
    "brief": "OSoL XML parser (bison-generated)\n\nBison-generated parser for OS Option Language (OSoL).\nParses solver options in XML format.",
    "file": "OSParseosol.tab",
    "library": "OS",
    "layer": "layer-4",
    "header": "OS/src/OSParsers/OSParseosol.tab.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "OSParseosrl.tab": {
    "brief": "OSrL XML parser (bison-generated)\n\nBison-generated parser for OS Result Language (OSrL).\nParses optimization results in XML format.",
    "file": "OSParseosrl.tab",
    "library": "OS",
    "layer": "layer-4",
    "header": "OS/src/OSParsers/OSParseosrl.tab.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "OSDecompSolverFactory": {
    "brief": "",
    "file": "OSDecompSolverFactory",
    "library": "OS",
    "layer": "layer-4",
    "header": "OS/applications/columnGen/code/OSDecompSolverFactory.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "OSBearcatSolverXij": {
    "brief": "",
    "file": "OSBearcatSolverXij",
    "library": "OS",
    "layer": "layer-4",
    "header": "OS/applications/columnGen/code/OSBearcatSolverXij.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "OSNode": {
    "brief": "",
    "file": "OSNode",
    "library": "OS",
    "layer": "layer-4",
    "header": "OS/applications/columnGen/code/OSNode.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "OSColGenApp": {
    "brief": "",
    "file": "OSColGenApp",
    "library": "OS",
    "layer": "layer-4",
    "header": "OS/applications/columnGen/code/OSColGenApp.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "OSDecompSolver": {
    "brief": "",
    "file": "OSDecompSolver",
    "library": "OS",
    "layer": "layer-4",
    "header": "OS/applications/columnGen/code/OSDecompSolver.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "OSDecompParam": {
    "brief": "",
    "file": "OSDecompParam",
    "library": "OS",
    "layer": "layer-4",
    "header": "OS/applications/columnGen/code/OSDecompParam.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "OSBearcatSolverXkij": {
    "brief": "",
    "file": "OSBearcatSolverXkij",
    "library": "OS",
    "layer": "layer-4",
    "header": "OS/applications/columnGen/code/OSBearcatSolverXkij.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "OSDecompFactoryInitializer": {
    "brief": "",
    "file": "OSDecompFactoryInitializer",
    "library": "OS",
    "layer": "layer-4",
    "header": "OS/applications/columnGen/code/OSDecompFactoryInitializer.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "OSWSUtil": {
    "brief": "",
    "file": "OSWSUtil",
    "library": "OS",
    "layer": "layer-4",
    "header": "OS/src/OSAgent/OSWSUtil.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "OSSolverAgent": {
    "brief": "",
    "file": "OSSolverAgent",
    "library": "OS",
    "layer": "layer-4",
    "header": "OS/src/OSAgent/OSSolverAgent.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "OShL": {
    "brief": "",
    "file": "OShL",
    "library": "OS",
    "layer": "layer-4",
    "header": "OS/src/OSAgent/OShL.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "OSBase64": {
    "brief": "",
    "file": "OSBase64",
    "library": "OS",
    "layer": "layer-4",
    "header": "OS/src/OSUtils/OSBase64.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "OSFileUtil": {
    "brief": "",
    "file": "OSFileUtil",
    "library": "OS",
    "layer": "layer-4",
    "header": "OS/src/OSUtils/OSFileUtil.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "OSErrorClass": {
    "brief": "",
    "file": "OSErrorClass",
    "library": "OS",
    "layer": "layer-4",
    "header": "OS/src/OSUtils/OSErrorClass.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "OSMathUtil": {
    "brief": "",
    "file": "OSMathUtil",
    "library": "OS",
    "layer": "layer-4",
    "header": "OS/src/OSUtils/OSMathUtil.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "OSDataStructures": {
    "brief": "",
    "file": "OSDataStructures",
    "library": "OS",
    "layer": "layer-4",
    "header": "OS/src/OSUtils/OSDataStructures.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "OSParameters": {
    "brief": "",
    "file": "OSParameters",
    "library": "OS",
    "layer": "layer-4",
    "header": "OS/src/OSUtils/OSParameters.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "OSOutput": {
    "brief": "",
    "file": "OSOutput",
    "library": "OS",
    "layer": "layer-4",
    "header": "OS/src/OSUtils/OSOutput.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "OSdtoa": {
    "brief": "",
    "file": "OSdtoa",
    "library": "OS",
    "layer": "layer-4",
    "header": "OS/src/OSUtils/OSdtoa.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "OSStringUtil": {
    "brief": "",
    "file": "OSStringUtil",
    "library": "OS",
    "layer": "layer-4",
    "header": "OS/src/OSUtils/OSStringUtil.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "OSmps2OS": {
    "brief": "",
    "file": "OSmps2OS",
    "library": "OS",
    "layer": "layer-4",
    "header": "OS/src/OSModelInterfaces/OSmps2OS.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "OSmps2osil": {
    "brief": "",
    "file": "OSmps2osil",
    "library": "OS",
    "layer": "layer-4",
    "header": "OS/src/OSModelInterfaces/OSmps2osil.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "OSnl2OS": {
    "brief": "",
    "file": "OSnl2OS",
    "library": "OS",
    "layer": "layer-4",
    "header": "OS/src/OSModelInterfaces/OSnl2OS.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "OSosrl2ampl": {
    "brief": "",
    "file": "OSosrl2ampl",
    "library": "OS",
    "layer": "layer-4",
    "header": "OS/src/OSModelInterfaces/OSosrl2ampl.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "OSMatlabSolver": {
    "brief": "",
    "file": "OSMatlabSolver",
    "library": "OS",
    "layer": "layer-4",
    "header": "OS/src/OSSolverInterfaces/OSMatlabSolver.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "OSDefaultSolver": {
    "brief": "",
    "file": "OSDefaultSolver",
    "library": "OS",
    "layer": "layer-4",
    "header": "OS/src/OSSolverInterfaces/OSDefaultSolver.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "OSLindoSolver": {
    "brief": "",
    "file": "OSLindoSolver",
    "library": "OS",
    "layer": "layer-4",
    "header": "OS/src/OSSolverInterfaces/OSLindoSolver.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "OSKnitroSolver": {
    "brief": "",
    "file": "OSKnitroSolver",
    "library": "OS",
    "layer": "layer-4",
    "header": "OS/src/OSSolverInterfaces/OSKnitroSolver.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "OSCsdpSolver": {
    "brief": "",
    "file": "OSCsdpSolver",
    "library": "OS",
    "layer": "layer-4",
    "header": "OS/src/OSSolverInterfaces/OSCsdpSolver.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "OSBonminSolver": {
    "brief": "",
    "file": "OSBonminSolver",
    "library": "OS",
    "layer": "layer-4",
    "header": "OS/src/OSSolverInterfaces/OSBonminSolver.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "OSIpoptSolver": {
    "brief": "",
    "file": "OSIpoptSolver",
    "library": "OS",
    "layer": "layer-4",
    "header": "OS/src/OSSolverInterfaces/OSIpoptSolver.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "OSCouenneSolver": {
    "brief": "",
    "file": "OSCouenneSolver",
    "library": "OS",
    "layer": "layer-4",
    "header": "OS/src/OSSolverInterfaces/OSCouenneSolver.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "OSRunSolver": {
    "brief": "",
    "file": "OSRunSolver",
    "library": "OS",
    "layer": "layer-4",
    "header": "OS/src/OSSolverInterfaces/OSRunSolver.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "OSCoinSolver": {
    "brief": "",
    "file": "OSCoinSolver",
    "library": "OS",
    "layer": "layer-4",
    "header": "OS/src/OSSolverInterfaces/OSCoinSolver.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "OSnLNode": {
    "brief": "",
    "file": "OSnLNode",
    "library": "OS",
    "layer": "layer-4",
    "header": "OS/src/OSCommonInterfaces/OSnLNode.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "OSCommandLine": {
    "brief": "",
    "file": "OSCommandLine",
    "library": "OS",
    "layer": "layer-4",
    "header": "OS/src/OSCommonInterfaces/OSCommandLine.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "OSrLWriter": {
    "brief": "",
    "file": "OSrLWriter",
    "library": "OS",
    "layer": "layer-4",
    "header": "OS/src/OSCommonInterfaces/OSrLWriter.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "OSrLReader": {
    "brief": "",
    "file": "OSrLReader",
    "library": "OS",
    "layer": "layer-4",
    "header": "OS/src/OSCommonInterfaces/OSrLReader.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "OSMatrix": {
    "brief": "",
    "file": "OSMatrix",
    "library": "OS",
    "layer": "layer-4",
    "header": "OS/src/OSCommonInterfaces/OSMatrix.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "OSoLWriter": {
    "brief": "",
    "file": "OSoLWriter",
    "library": "OS",
    "layer": "layer-4",
    "header": "OS/src/OSCommonInterfaces/OSoLWriter.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "OSoLReader": {
    "brief": "",
    "file": "OSoLReader",
    "library": "OS",
    "layer": "layer-4",
    "header": "OS/src/OSCommonInterfaces/OSoLReader.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "OSExpressionTree": {
    "brief": "",
    "file": "OSExpressionTree",
    "library": "OS",
    "layer": "layer-4",
    "header": "OS/src/OSCommonInterfaces/OSExpressionTree.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "OSResult": {
    "brief": "",
    "file": "OSResult",
    "library": "OS",
    "layer": "layer-4",
    "header": "OS/src/OSCommonInterfaces/OSResult.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "OSOption": {
    "brief": "",
    "file": "OSOption",
    "library": "OS",
    "layer": "layer-4",
    "header": "OS/src/OSCommonInterfaces/OSOption.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "OSGeneral": {
    "brief": "",
    "file": "OSGeneral",
    "library": "OS",
    "layer": "layer-4",
    "header": "OS/src/OSCommonInterfaces/OSGeneral.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "OSInstance": {
    "brief": "",
    "file": "OSInstance",
    "library": "OS",
    "layer": "layer-4",
    "header": "OS/src/OSCommonInterfaces/OSInstance.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "OSgLWriter": {
    "brief": "",
    "file": "OSgLWriter",
    "library": "OS",
    "layer": "layer-4",
    "header": "OS/src/OSCommonInterfaces/OSgLWriter.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "OSiLWriter": {
    "brief": "",
    "file": "OSiLWriter",
    "library": "OS",
    "layer": "layer-4",
    "header": "OS/src/OSCommonInterfaces/OSiLWriter.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "OSiLReader": {
    "brief": "",
    "file": "OSiLReader",
    "library": "OS",
    "layer": "layer-4",
    "header": "OS/src/OSCommonInterfaces/OSiLReader.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "OSCommandLineReader": {
    "brief": "",
    "file": "OSCommandLineReader",
    "library": "OS",
    "layer": "layer-4",
    "header": "OS/src/OSCommonInterfaces/OSCommandLineReader.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "OSrLParserData": {
    "brief": "",
    "file": "OSrLParserData",
    "library": "OS",
    "layer": "layer-4",
    "header": "OS/src/OSParsers/OSrLParserData.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "OSiLParserData": {
    "brief": "",
    "file": "OSiLParserData",
    "library": "OS",
    "layer": "layer-4",
    "header": "OS/src/OSParsers/OSiLParserData.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "OSoLParserData": {
    "brief": "",
    "file": "OSoLParserData",
    "library": "OS",
    "layer": "layer-4",
    "header": "OS/src/OSParsers/OSoLParserData.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "OSgLParserData": {
    "brief": "",
    "file": "OSgLParserData",
    "library": "OS",
    "layer": "layer-4",
    "header": "OS/src/OSParsers/OSgLParserData.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "OSnLParserData": {
    "brief": "",
    "file": "OSnLParserData",
    "library": "OS",
    "layer": "layer-4",
    "header": "OS/src/OSParsers/OSnLParserData.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "OSOptionsStruc": {
    "brief": "",
    "file": "OSOptionsStruc",
    "library": "OS",
    "layer": "layer-4",
    "header": "OS/src/OSParsers/OSOptionsStruc.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "tmodel": {
    "brief": "Taylor Model Arithmetic for Rigorous Bound Propagation",
    "file": "tmodel",
    "library": "SHOT",
    "layer": "layer-4",
    "header": "ThirdParty/mc++/include/tmodel.hpp",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "ref": {
    "brief": "Contains a reference to an object of type `T`.\n\n `reference_wrapper` is primarily used to \"feed\" references to\n function templates (algorithms) that take their parameter by\n value. It provides an implicit conversion to `T&`, which\n usually allows the function templates to work on references\n unmodified.",
    "file": "ref",
    "library": "SHOT",
    "layer": "layer-4",
    "header": "ThirdParty/boost/boost/core/ref.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "EventHandler": {
    "brief": "Observer pattern for algorithm events and callbacks\n\nAllows external code to respond to solver events.\n\n**Event Types (E_EventType):**\n- NewPrimalSolution: New feasible solution found\n- UserTerminationCheck: Allow user to request termination\n\n**Callback Registration:**\n- registerCallback(event, callback): Register handler\n- Callback signature: void()\n- Multiple callbacks per event supported\n\n**Event Notification:**\n- notify(event): Invoke all registered callbacks\n- Called by solver at appropriate points\n\n**Usage Example:**\n```cpp\neventHandler->registerCallback(E_EventType::NewPrimalSolution,\n    [&]() { std::cout << \"New solution found!\" << std::endl; });\n```",
    "file": "EventHandler",
    "library": "SHOT",
    "layer": "layer-4",
    "header": "src/EventHandler.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "Results": {
    "brief": "Solution results storage and optimality gap tracking\n\nCentral repository for primal/dual solutions and algorithm progress.\n\n**Primal Solutions:**\n- primalSolutions: All found feasible points\n- addPrimalSolution(): Submit new incumbent\n- getPrimalBound(): Best objective value\n- primalSolutionSourceStatistics: Track solution origins\n\n**Dual Solutions:**\n- dualSolutions: Lower/upper bounds from MIP\n- getCurrentDualBound(), getGlobalDualBound()\n- setDualBound(): Update relaxation bound\n\n**Optimality Gap:**\n- getAbsoluteGlobalObjectiveGap(): |primal - dual|\n- getRelativeGlobalObjectiveGap(): |gap| / |primal|\n- isRelativeObjectiveGapToleranceMet(): Termination check\n\n**Iteration Tracking:**\n- iterations: Per-iteration state snapshots\n- createIteration(), getCurrentIteration()\n\n**Output Formats:**\n- getResultsOSrL(): XML Optimization Services format\n- getResultsTrace(): GAMS trace format\n- getResultsSol(): AMPL .sol format",
    "file": "Results",
    "library": "SHOT",
    "layer": "layer-4",
    "header": "src/Results.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "Settings": {
    "brief": "Solver configuration and option management\n\nHierarchical settings system for SHOT algorithm parameters.\n\n**Settings Categories:**\n- Termination: TimeLimit, IterationLimit, ObjectiveGap\n- Subsolver: MIP backend, NLP backend\n- Algorithm: Cut generation, reformulation options\n- Output: Verbosity, logging levels\n\n**Exception Classes:**\n- SettingKeyNotFoundException: Unknown setting key\n- SettingSetWrongTypeException: Type mismatch on set\n- SettingGetWrongTypeException: Type mismatch on get\n\n**Settings Types:**\n- E_SettingType: Integer, Double, String, Boolean, Enum\n\n**File Formats:**\n- OSoL XML format (Options Service Language)\n- Simple key=value format",
    "file": "Settings",
    "library": "SHOT",
    "layer": "layer-4",
    "header": "src/Settings.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "Environment": {
    "brief": "Shared state container for SHOT solver components\n\nCentral hub connecting all solver subsystems.\n\n**Environment Class Members:**\n- problem: Original problem formulation\n- reformulatedProblem: Convexified/linearized version\n- modelingSystem: GAMS/AMPL/OSiL interface\n\n**Solver Components:**\n- dualSolver: MIP solver for dual problem (CPLEX/Gurobi/CBC)\n- primalSolver: NLP solver for primal bounds (Ipopt)\n- rootsearchMethod: Line search for hyperplanes\n\n**Infrastructure:**\n- settings: Solver configuration parameters\n- results: Solution and statistics\n- output: Logging via spdlog\n- timing: Performance profiling\n- events: Callback event handler\n- tasks: Asynchronous task manager",
    "file": "Environment",
    "library": "SHOT",
    "layer": "layer-4",
    "header": "src/Environment.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "Structs": {
    "brief": "Core data structures and type definitions for SHOT\n\nFundamental types, forward declarations, and helper structures.\n\n**Constants:**\n- SHOT_DBL_MIN/MAX/INF/EPS: Double precision limits\n- SHOT_INT_MAX, SHOT_LONG_MAX: Integer limits\n\n**Smart Pointer Typedefs:**\n- ProblemPtr, SettingsPtr, ResultsPtr, etc.\n- Shared ownership via std::shared_ptr\n\n**Solution Structures:**\n- PrimalSolution: Variable values + objective + source\n- DualSolution: Dual bound + iteration + source\n- SolutionPoint: Point with constraint deviation\n\n**Hyperplane Structures:**\n- Hyperplane: Supporting hyperplane cut\n- GeneratedHyperplane: Hyperplane with metadata\n- IntegerCut: No-good cut for integer variables\n\n**Utility Types:**\n- VectorDouble, VectorInteger, VectorString\n- PairIndexValue: (index, value) pair",
    "file": "Structs",
    "library": "SHOT",
    "layer": "layer-4",
    "header": "src/Structs.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "Solver": {
    "brief": "Main solver interface for convex MINLP problems\n\nPrimary entry point for the SHOT optimizer.",
    "file": "Solver",
    "library": "SHOT",
    "layer": "layer-4",
    "header": "src/Solver.h",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "Timer": {
    "brief": "High-resolution stopwatch for performance measurement\n\nLightweight timer using std::chrono::high_resolution_clock.\n\n**Timer Class:**\n- start()/stop(): Pause/resume timing\n- restart(): Reset to zero and start\n- elapsed(): Get cumulative time in seconds\n\n**Properties:**\n- name: Timer identifier (for Timing registry)\n- description: Human-readable label\n\n**Usage:**\nTimer t(\"SolveMIP\", \"MIP solver time\");\nt.start();\n// ... computation ...\nt.stop();\ndouble seconds = t.elapsed();",
    "file": "Timer",
    "library": "SHOT",
    "layer": "layer-4",
    "header": "src/Timer.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "PrimalSolver": {
    "brief": "NLP-based primal bound computation and solution repair\n\nFinds feasible solutions and improves the primal bound.",
    "file": "PrimalSolver",
    "library": "SHOT",
    "layer": "layer-4",
    "header": "src/PrimalSolver.h",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "Timing": {
    "brief": "Named timer registry for profiling solver phases\n\nCollection of named timers for performance analysis.\n\n**Timing Class:**\n- createTimer(): Register new timer with name/description\n- startTimer()/stopTimer(): Control by name\n- getElapsedTime(): Query accumulated time\n\n**Typical Timers:**\n- \"Total\": Overall solve time\n- \"DualMIP\": MIP solver calls\n- \"PrimalNLP\": NLP subproblem solves\n- \"Reformulation\": Problem transformation\n\n**Thread Safety:**\n- Timers are not thread-safe\n- Use in single-threaded solver context",
    "file": "Timing",
    "library": "SHOT",
    "layer": "layer-4",
    "header": "src/Timing.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "TaskHandler": {
    "brief": "Task scheduling and execution control\n\nOrchestrates the modular task-based algorithm workflow.\n\n**Task Management:**\n- addTask(): Register task with string identifier\n- getTask(): Retrieve task by ID\n- clearTasks(): Reset for new solve\n\n**Execution Control:**\n- getNextTask(): Dequeue next task to run\n- setNextTask(): Jump to specific task (for goto/branching)\n- terminate(): Signal algorithm termination\n- isTerminated(): Check termination flag\n\n**Workflow Pattern:**\n1. SolutionStrategy adds tasks in order\n2. Solver calls getNextTask() in loop\n3. Tasks execute and may setNextTask() for control flow\n4. Termination tasks set terminate()\n\n**Task ID Naming:**\n- \"InitializeIteration\", \"SolveIteration\"\n- \"CheckTimeLimit\", \"CheckAbsoluteGap\"\n- \"SelectHyperplanes\", \"AddHyperplanes\"",
    "file": "TaskHandler",
    "library": "SHOT",
    "layer": "layer-4",
    "header": "src/TaskHandler.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "Report": {
    "brief": "Formatted console output for solver progress\n\nGenerates iteration tables and summary reports.\n\n**Report Class:**\n- outputSolverHeader(): Version and license info\n- outputOptionsReport(): Active settings summary\n- outputProblemInstanceReport(): Problem statistics\n\n**Iteration Reporting:**\n- outputIterationDetailHeader(): Column headers\n- outputIterationDetail(): Per-iteration progress line\n- Shows: iteration, time, cuts, bounds, gap\n\n**Solution Reporting:**\n- outputSolutionReport(): Final summary\n- outputPrimalSolutionDetailedReport(): Full solution\n\n**Output Control:**\n- Tracks last values to avoid redundant output\n- Respects ES_IterationOutputDetail setting",
    "file": "Report",
    "library": "SHOT",
    "layer": "layer-4",
    "header": "src/Report.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "Utilities": {
    "brief": "Helper functions for vectors, hashing, and I/O\n\nStandalone utility functions in SHOT::Utilities namespace.\n\n**Vector Operations:**\n- L2Norm(): Euclidean distance between points\n- calculateCenterPoint(): Centroid of point set\n- displayVector(): Debug output for vectors\n\n**Hashing:**\n- calculateHash(): Hash function for duplicate detection\n- Used by hyperplane/integer cut deduplication\n\n**File I/O:**\n- writeStringToFile(), getFileAsString()\n- saveVariablePointVectorToFile(): Solution output\n\n**Numeric:**\n- isAlmostEqual(), isAlmostZero(): Tolerance comparisons\n- isInteger(): Check for integer values\n\n**Sparse Containers:**\n- SparseVariableVector: Variable\u2192coefficient map\n- SparseVariableMatrix: (Variable,Variable)\u2192coefficient\n- combineSparseVariable*(): Merge operations",
    "file": "Utilities",
    "library": "SHOT",
    "layer": "layer-4",
    "header": "src/Utilities.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "DualSolver": {
    "brief": "MIP-based dual bound computation via supporting hyperplanes\n\nManages the linearization-based dual problem.",
    "file": "DualSolver",
    "library": "SHOT",
    "layer": "layer-4",
    "header": "src/DualSolver.h",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "Output": {
    "brief": "Logging infrastructure using spdlog\n\nCentralized logging with console and file sinks.\n\n**Output Class:**\n- outputCritical/Error/Warning/Info/Debug/Trace(): Log methods\n- setLogLevels(): Configure console and file verbosity\n- setConsoleSink(): Custom console output\n- setFileSink(): Enable file logging\n\n**E_LogLevel (Enums.h):**\n- Off, Critical, Error, Warning, Info, Debug, Trace\n\n**OutputStream Class:**\n- std::ostream wrapper for solver output redirection\n- Routes external solver output through SHOT logging\n- Used by CPLEX, Gurobi, Ipopt adapters\n\n**Implementation:**\n- Uses spdlog library for fast, thread-safe logging\n- consoleSink: stdout sink\n- fileSink: basic_file_sink for persistence",
    "file": "Output",
    "library": "SHOT",
    "layer": "layer-4",
    "header": "src/Output.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "Iteration": {
    "brief": "Per-iteration state snapshot for algorithm progress tracking\n\nCaptures the state of the solver at each outer approximation iteration.\n\n**Problem State:**\n- dualProblemClass: LP, QP, MIP, MIQP, etc.\n- isDualProblemDiscrete: Whether MIP or LP relaxation\n- solutionStatus: Optimal, Feasible, Infeasible, etc.\n\n**Solution Data:**\n- solutionPoints: All solutions from MIP solution pool\n- objectiveValue: Best objective value\n- currentObjectiveBounds: (dual, primal) bounds\n\n**Constraint Violation:**\n- constraintDeviations: Per-constraint violations\n- maxDeviation, maxDeviationConstraint: Worst violation\n- usedConstraintTolerance: Tolerance for this iteration\n\n**Hyperplane Statistics:**\n- numHyperplanesAdded: Cuts added this iteration\n- totNumHyperplanes: Cumulative cuts\n- hyperplanePoints: Generation points\n\n**Node Statistics:**\n- numberOfExploredNodes, numberOfOpenNodes: B&B tree\n\n**Helper Methods:**\n- getSolutionPointWithSmallestDeviation()\n- isMIP(): Check if discrete problem",
    "file": "Iteration",
    "library": "SHOT",
    "layer": "layer-4",
    "header": "src/Iteration.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "Enums": {
    "brief": "Enumeration types for SHOT solver states and options\n\nComprehensive enums for algorithm configuration and status tracking.\n\n**Problem Classification:**\n- E_Convexity: Linear, Convex, Concave, Nonconvex, Unknown\n- E_DualProblemClass: LP, QP, QCQP, MIP, MIQP, MIQCQP\n\n**Auxiliary Variable Types:**\n- E_AuxiliaryVariableType: NonlinearObjectiveFunction (epigraph),\n  BilinearTerms, MonomialPartitioning, etc.\n\n**Hyperplane Sources (E_HyperplaneSource):**\n- MIPOptimalRootsearch, MIPSolutionPoolRootsearch\n- LPRelaxedRootsearch, InteriorPointSearch\n- PrimalSolutionSearch, ObjectiveCuttingPlane\n\n**Event Types (E_EventType):**\n- NewPrimalSolution: New incumbent found\n- UserTerminationCheck: Allow user termination\n\n**Termination Reasons (E_TerminationReason):**\n- Optimal, ObjectiveGapTolerance, TimeLimit\n- IterationLimit, InfeasibleProblem, NoDualCutsAdded",
    "file": "Enums",
    "library": "SHOT",
    "layer": "layer-4",
    "header": "src/Enums.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "ModelingSystemOSiL": {
    "brief": "OSiL XML format reader for optimization problems\n\nReads Optimization Services instance Language (OSiL) files.\n\n**ModelingSystemOSiL Class:**\n- createProblem(): Parse OSiL XML into Problem\n- augmentSettings(): Add OSiL-specific options\n- finalizeSolution(): Write OSrL result format\n\n**OSiL Format:**\n- XML-based optimization instance representation\n- <instanceData> contains variables, objectives, constraints\n- <nonlinearExpressions> for NLP terms (OSnL format)\n\n**XML Parsing:**\n- Uses tinyxml2 for XML processing\n- convertNonlinearNode(): OSnL to SHOT expression conversion\n\n@note OSiL is part of COIN-OR Optimization Services",
    "file": "ModelingSystemOSiL",
    "library": "SHOT",
    "layer": "layer-4",
    "header": "src/ModelingSystem/ModelingSystemOSiL.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "ModelingSystemGAMS": {
    "brief": "GAMS interface for optimization problem input\n\nReads GAMS models via GMO/GEV API.\n\n**ModelingSystemGAMS Class:**\n- setModelingObject(): Accept gmoHandle_t from GAMS\n- createProblem(): Convert GMO model to SHOT Problem\n- finalizeSolution(): Return solution to GAMS\n\n**GAMS Integration:**\n- gmoHandle_t: GAMS Model Object (GMO)\n- gevHandle_t: GAMS Environment (GEV)\n- palHandle_t: GAMS Audit Licensing (PAL)\n\n**Model Conversion:**\n- copyVariables/Constraints/ObjectiveFunction()\n- parseGamsInstructions(): Bytecode to expression conversion\n\n**GamsOutputSink:**\n- spdlog sink routing to GAMS log\n- gevLogPChar() for normal messages\n- gevLogStatPChar() for warnings/errors",
    "file": "ModelingSystemGAMS",
    "library": "SHOT",
    "layer": "layer-4",
    "header": "src/ModelingSystem/ModelingSystemGAMS.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "IModelingSystem": {
    "brief": "Abstract interface for problem input formats\n\nBase interface for parsing optimization problem files.\n\n**E_ProblemCreationStatus Enum:**\n- NormalCompletion: Problem loaded successfully\n- FileDoesNotExist, ErrorInFile: I/O errors\n- ErrorInVariables/Constraints/Objective: Parse errors\n- CapabilityProblem: Unsupported problem features\n\n**IModelingSystem Interface:**\n- augmentSettings(): Add format-specific settings\n- updateSettings(): Extract settings from problem file\n- finalizeSolution(): Write solution back to format\n\n**Implementations:**\n- ModelingSystemOSiL: XML OSiL format (Optimization Services)\n- ModelingSystemAMPL: .nl format from AMPL\n- ModelingSystemGAMS: GAMS interface\n- ModelingSystemOS: Optimization Services framework",
    "file": "IModelingSystem",
    "library": "SHOT",
    "layer": "layer-4",
    "header": "src/ModelingSystem/IModelingSystem.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "ModelingSystemOS": {
    "brief": "Optimization Services library integration\n\nFull OS library integration for OSiL and AMPL files.\n\n**ModelingSystemOS Class:**\n- createProblem(filename, format): Read OSiL or nl files\n- createProblem(OSInstance): Use existing OS instance\n- finalizeSolution(): Generate OSrL output\n\n**File Formats:**\n- E_OSInputFileFormat::OSiL: XML format\n- E_OSInputFileFormat::Ampl: nl binary via OSnl2OS\n\n**OS Library Classes:**\n- OSiLReader: Parse OSiL XML\n- OSInstance: In-memory problem representation\n- OSnl2OS: Convert nl to OSInstance\n- OSnLNode: Nonlinear expression tree nodes\n\n**Expression Conversion:**\n- convertOSNonlinearNode(): OSnLNode to SHOT expression\n- Preserves convexity annotations if available\n\n@note Uses COIN-OR OS library (github.com/coin-or/OS)",
    "file": "ModelingSystemOS",
    "library": "SHOT",
    "layer": "layer-4",
    "header": "src/ModelingSystem/ModelingSystemOS.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "ModelingSystemAMPL": {
    "brief": "AMPL nl-file format reader for optimization problems\n\nReads AMPL .nl (nonlinear) binary problem files.\n\n**ModelingSystemAMPL Class:**\n- createProblem(): Parse .nl file into Problem\n- augmentSettings(): Add AMPL-specific options\n- finalizeSolution(): Write .sol solution file\n\n**AMPL nl Format:**\n- Binary format for optimization instances\n- Contains variables, bounds, constraints, expressions\n- Used by AMPL-compatible solvers\n\n**Usage:**\n- Standalone: SHOT problem.nl\n- Via AMPL: option solver shot; solve;",
    "file": "ModelingSystemAMPL",
    "library": "SHOT",
    "layer": "layer-4",
    "header": "src/ModelingSystem/ModelingSystemAMPL.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "NLPSolverIpoptRelaxed": {
    "brief": "Ipopt solver for continuous relaxation problems\n\nSolves NLP with integer variables relaxed to continuous.\n\n**NLPSolverIpoptRelaxed Class:**\n- Multiple inheritance: NLPSolverBase + NLPSolverIpoptBase\n- setSolverSpecificInitialSettings(): Configure for relaxed solve\n- getSolution(): Return continuous solution values\n\n**Use Case:**\n- Find interior points for ESH algorithm\n- Check feasibility of relaxed problem\n- Generate starting points for primal heuristics",
    "file": "NLPSolverIpoptRelaxed",
    "library": "SHOT",
    "layer": "layer-4",
    "header": "src/NLPSolver/NLPSolverIpoptRelaxed.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "NLPSolverCuttingPlaneMinimax": {
    "brief": "Cutting-plane solver for minimax LP problems\n\nBuilt-in LP-based solver for simple minimax problems.\n\n**NLPSolverCuttingPlaneMinimax Class:**\n- Uses MIP solver (CPLEX/Gurobi/Cbc) as LP engine\n- Iteratively adds cutting planes\n- No external NLP solver dependency\n\n**Minimax Problem Form:**\n- min t\n- s.t. f_i(x) <= t for all i\n\n**Use Case:**\n- Finding interior points when Ipopt unavailable\n- Solving auxiliary minimax subproblems",
    "file": "NLPSolverCuttingPlaneMinimax",
    "library": "SHOT",
    "layer": "layer-4",
    "header": "src/NLPSolver/NLPSolverCuttingPlaneMinimax.h",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "INLPSolver": {
    "brief": "Abstract interface for NLP solver backends\n\nPure virtual interface for primal bound NLP solvers.\n\n**Starting Point:**\n- setStartingPoint(): Initialize solver from MIP solution\n- clearStartingPoint(): Reset to default\n\n**Variable Fixing:**\n- fixVariables(): Fix integer variables for NLP subproblem\n- unfixVariables(): Restore full problem\n\n**Solution Methods:**\n- solveProblem(): Execute NLP solver\n- getSolution(): Retrieve primal point\n- getObjectiveValue(): Primal objective value\n\n**Bound Management:**\n- getVariableLowerBounds(), getVariableUpperBounds()\n- updateVariableLowerBound(), updateVariableUpperBound()\n\n**Implementations:**\n- NLPSolverIpoptBase: Ipopt interior point solver\n- NLPSolverGAMS: GAMS NLP solvers\n- NLPSolverSHOT: Recursive SHOT for NLP",
    "file": "INLPSolver",
    "library": "SHOT",
    "layer": "layer-4",
    "header": "src/NLPSolver/INLPSolver.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "NLPSolverBase": {
    "brief": "Base implementation for NLP solver interface\n\nProvides shared solve logic for all NLP solvers.\n\n**NLPSolverBase Class:**\n- solveProblem(): Template method calling solveProblemInstance()\n- Derived classes implement solveProblemInstance() hook\n\n**Inheritance:**\n- Virtually inherits from INLPSolver\n- Used with multiple inheritance (NLPSolverIpoptRelaxed)",
    "file": "NLPSolverBase",
    "library": "SHOT",
    "layer": "layer-4",
    "header": "src/NLPSolver/NLPSolverBase.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "NLPSolverIpoptBase": {
    "brief": "Ipopt implementation of INLPSolver interface\n\nProvides NLP solving for SHOT's primal problem using Ipopt interior point.\n\n**IpoptProblem Class (Ipopt::TNLP):**\n- Implements Ipopt's TNLP interface\n- Provides callbacks for function/gradient/Hessian evaluation\n- Sparse Jacobian/Hessian via index placement maps\n\n**TNLP Callbacks:**\n- get_nlp_info(): Problem dimensions and sparsity\n- get_bounds_info(): Variable and constraint bounds\n- eval_f(): Objective function value\n- eval_grad_f(): Objective gradient\n- eval_g(): Constraint function values\n- eval_jac_g(): Constraint Jacobian (sparse)\n- eval_h(): Lagrangian Hessian (sparse)\n- finalize_solution(): Store optimal point\n\n**NLPSolverIpoptBase Class:**\n- Wraps IpoptApplication for solve control\n- Variable fixing for integer-fixed NLP subproblems\n- Starting point management\n\n**IpoptJournal:**\n- Routes Ipopt output through SHOT logging system\n\n@note Used for fixed-integer NLP subproblems in primal bound computation",
    "file": "NLPSolverIpoptBase",
    "library": "SHOT",
    "layer": "layer-4",
    "header": "src/NLPSolver/NLPSolverIpoptBase.h",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "NLPSolverSHOT": {
    "brief": "SHOT as NLP solver for convex subproblems\n\nRecursive use of SHOT to solve fixed-integer NLP.\n\n**NLPSolverSHOT Class:**\n- Creates nested SHOT solver instance\n- Solves convex NLP after fixing integer variables\n- Useful when Ipopt is unavailable\n\n**Fixed-Integer NLP:**\n- fixVariables(): Fix discrete variables to integer values\n- solveProblemInstance(): Solve continuous subproblem\n- getSolution(): Return primal solution\n\n**Nested Architecture:**\n- Outer SHOT: Full MINLP (uses this as primal solver)\n- Inner SHOT: Convex NLP (fixed integers)\n\n@note Self-referential design for solver-agnostic NLP solving",
    "file": "NLPSolverSHOT",
    "library": "SHOT",
    "layer": "layer-4",
    "header": "src/NLPSolver/NLPSolverSHOT.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "NLPSolverGAMS": {
    "brief": "GAMS-based NLP solver for fixed-integer subproblems\n\nUses GAMS modeling system to call NLP solvers.\n\n**NLPSolverGAMS Class:**\n- Uses gmoHandle_t from GAMS modeling system\n- Calls user-selected NLP solver (CONOPT, IPOPT, etc.)\n- Manages variable bounds and starting points\n\n**GAMS Handles:**\n- modelingObject: GMO for problem data\n- modelingEnvironment: GEV for GAMS environment\n\n**Solver Configuration:**\n- nlpsolver: Solver name (e.g., \"CONOPT\", \"IPOPT\")\n- timelimit, iterlimit: Resource limits\n- solvelink: Execution mode\n\n@note Requires GAMS license for commercial NLP solvers",
    "file": "NLPSolverGAMS",
    "library": "SHOT",
    "layer": "layer-4",
    "header": "src/NLPSolver/NLPSolverGAMS.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "TaskSelectHyperplanePointsObjectiveFunction": {
    "brief": "Hyperplane selection for nonlinear objective\n\nGenerates cuts for epigraph of nonlinear objective.\n\n**TaskSelectHyperplanePointsObjectiveFunction Class:**\n- run(): Process objective at current solutions\n- run(solPoints): Process specific solution points\n\n**Epigraph Linearization:**\n- Nonlinear objective reformulated as: min t, f(x) <= t\n- Generates cuts to approximate f(x) <= t constraint",
    "file": "TaskSelectHyperplanePointsObjectiveFunction",
    "library": "SHOT",
    "layer": "layer-4",
    "header": "src/Tasks/TaskSelectHyperplanePointsObjectiveFunction.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "TaskRepairableBase": {
    "brief": "Base class for tasks that can repair failures\n\nExtension point for failure recovery logic.\n\n**TaskRepairableBase Class:**\n- repair(): Attempt to fix failed task\n\n**Usage:**\n- Subclassed by tasks that can recover from errors\n- Called when initial run() fails",
    "file": "TaskRepairableBase",
    "library": "SHOT",
    "layer": "layer-4",
    "header": "src/Tasks/TaskRepairableBase.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "TaskPerformBoundTightening": {
    "brief": "Tighten variable bounds via optimization\n\nUses optimization-based bound tightening (OBBT).\n\n**TaskPerformBoundTightening Class:**\n- POASolver: Polyhedral outer approximation solver\n- createPOA(): Build relaxed problem for bound tightening\n\n**OBBT Algorithm:**\n- For each variable: min/max subject to relaxation\n- Tightens bounds beyond constraint propagation\n- Improves relaxation quality",
    "file": "TaskPerformBoundTightening",
    "library": "SHOT",
    "layer": "layer-4",
    "header": "src/Tasks/TaskPerformBoundTightening.h",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "TaskPrintIterationReport": {
    "brief": "Output iteration progress to console\n\nFormatted progress line for each iteration.\n\n**TaskPrintIterationReport Class:**\n- lastNumHyperplane: Track hyperplanes added\n- run(): Format and print iteration status\n\n**Report Contents:**\n- Iteration number, elapsed time\n- Primal bound, dual bound, gap\n- Number of hyperplanes added",
    "file": "TaskPrintIterationReport",
    "library": "SHOT",
    "layer": "layer-4",
    "header": "src/Tasks/TaskPrintIterationReport.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "TaskSimple": {
    "brief": "Lightweight task wrapper for lambda functions\n\nAdapts arbitrary callable to task interface.\n\n**TaskSimple Class:**\n- setFunction(fn): Set callable to execute\n- run(): Invoke the stored function\n\n**Usage:**\n- Quick inline tasks without subclassing\n- Adapts existing functions to task framework",
    "file": "TaskSimple",
    "library": "SHOT",
    "layer": "layer-4",
    "header": "src/Tasks/TaskSimple.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "TaskTerminate": {
    "brief": "Signals end of optimization algorithm\n\nFinal task that stops the main loop.\n\n**TaskTerminate Class:**\n- run(): Set termination flag in TaskHandler\n\n**Called When:**\n- Optimal solution found (gap closed)\n- Resource limit exceeded (time, iteration)\n- Infeasibility proven",
    "file": "TaskTerminate",
    "library": "SHOT",
    "layer": "layer-4",
    "header": "src/Tasks/TaskTerminate.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "TaskInitializeIteration": {
    "brief": "Per-iteration setup and housekeeping\n\nPrepares state for new iteration cycle.\n\n**TaskInitializeIteration Class:**\n- run(): Reset iteration-local state\n\n**Initialization Steps:**\n- Increment iteration counter\n- Clear iteration-specific storage\n- Update timing information",
    "file": "TaskInitializeIteration",
    "library": "SHOT",
    "layer": "layer-4",
    "header": "src/Tasks/TaskInitializeIteration.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "TaskCheckIterationError": {
    "brief": "Detect errors during iteration\n\nHandles solver failures and numerical issues.\n\n**TaskCheckIterationError Class:**\n- taskIDIfTrue: Jump target when error detected\n- run(): Check for MIP solver errors, infeasibility, etc.\n\n**Error Types:**\n- MIP solver failure or timeout\n- Numerical issues in cut generation\n- Unexpected infeasibility",
    "file": "TaskCheckIterationError",
    "library": "SHOT",
    "layer": "layer-4",
    "header": "src/Tasks/TaskCheckIterationError.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "TaskSelectPrimalCandidatesFromSolutionPool": {
    "brief": "Check MIP solution pool for feasible MINLP solutions\n\nExtracts primal candidates from MIP solver's solution pool.\n\n**TaskSelectPrimalCandidatesFromSolutionPool Class:**\n- run(): Iterate through MIP solution pool\n- Check each solution for original constraint feasibility\n\n**Primal Candidate Processing:**\n- MIP solution may violate nonlinear constraints\n- Feasible solutions update primal bound\n- Infeasible solutions generate hyperplanes",
    "file": "TaskSelectPrimalCandidatesFromSolutionPool",
    "library": "SHOT",
    "layer": "layer-4",
    "header": "src/Tasks/TaskSelectPrimalCandidatesFromSolutionPool.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "TaskCreateDualProblem": {
    "brief": "Build MIP relaxation from reformulated problem\n\nTranslates SHOT's problem representation to MIP solver format.\n\n**TaskCreateDualProblem Class:**\n- run(): Create initial MIP in DualSolver\n- createProblem(): Transfer variables, constraints, objective\n\n**MIP Construction:**\n- Linear constraints: Added directly\n- Quadratic constraints: Added if solver supports MIQCQP\n- Nonlinear constraints: Omitted (handled via hyperplanes)\n- Integer variables: Marked as such in MIP",
    "file": "TaskCreateDualProblem",
    "library": "SHOT",
    "layer": "layer-4",
    "header": "src/Tasks/TaskCreateDualProblem.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "TaskCheckAbsoluteGap": {
    "brief": "Termination check for absolute optimality gap\n\nTerminates when |primal - dual| < tolerance.\n\n**TaskCheckAbsoluteGap Class:**\n- taskIDIfTrue: Jump target when gap closed\n- run(): Check |bestPrimal - bestDual| < AbsoluteGapTol\n\n**Optimality Gap:**\n- Primal bound: Best feasible solution value\n- Dual bound: Relaxation optimal value\n- Gap closed = provably optimal",
    "file": "TaskCheckAbsoluteGap",
    "library": "SHOT",
    "layer": "layer-4",
    "header": "src/Tasks/TaskCheckAbsoluteGap.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "TaskPresolve": {
    "brief": "Initial problem simplification\n\nApplies presolve techniques before main algorithm.\n\n**TaskPresolve Class:**\n- isPresolved: Track if presolve completed\n- run(): Apply presolve routines\n\n**Presolve Techniques:**\n- Bound propagation\n- Fixed variable removal\n- Redundant constraint detection\n- Expression simplification",
    "file": "TaskPresolve",
    "library": "SHOT",
    "layer": "layer-4",
    "header": "src/Tasks/TaskPresolve.h",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "TaskCheckIterationLimit": {
    "brief": "Termination check for iteration count limit\n\nPart of termination check sequence.\n\n**TaskCheckIterationLimit Class:**\n- taskIDIfTrue: Jump target when limit reached\n- run(): Compare iteration count vs Settings.IterationLimit\n\n**Behavior:**\n- If exceeded: Jump to termination task\n- If not: Continue to next task",
    "file": "TaskCheckIterationLimit",
    "library": "SHOT",
    "layer": "layer-4",
    "header": "src/Tasks/TaskCheckIterationLimit.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "TaskSelectPrimalCandidatesFromNLP": {
    "brief": "Solve fixed-integer NLP for primal candidates\n\nUses NLP solver (Ipopt) with fixed integer variables.\n\n**TaskSelectPrimalCandidatesFromNLP Class:**\n- solveFixedNLP(): Fix integers, solve continuous NLP\n- createInfeasibilityCut(): Handle infeasible NLP\n- createIntegerCut(): Exclude tested integer assignment\n\n**Fixed-Integer NLP:**\n- Take MIP solution's integer values\n- Solve continuous relaxation with fixed integers\n- Provides locally optimal primal candidates\n\n**Usage:**\n- Triggered by primal stagnation\n- May improve primal bound significantly",
    "file": "TaskSelectPrimalCandidatesFromNLP",
    "library": "SHOT",
    "layer": "layer-4",
    "header": "src/Tasks/TaskSelectPrimalCandidatesFromNLP.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "TaskClearFixedPrimalCandidates": {
    "brief": "Clear pending fixed-integer NLP candidates\n\nResets candidate queue between iterations.\n\n**TaskClearFixedPrimalCandidates Class:**\n- run(): Empty the fixed-NLP candidate list\n\n**Usage:**\n- Called at start of each iteration\n- Ensures fresh candidate selection each cycle",
    "file": "TaskClearFixedPrimalCandidates",
    "library": "SHOT",
    "layer": "layer-4",
    "header": "src/Tasks/TaskClearFixedPrimalCandidates.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "TaskAddPrimalReductionCut": {
    "brief": "Add objective cutoff based on incumbent\n\nUses primal bound to tighten MIP relaxation.\n\n**TaskAddPrimalReductionCut Class:**\n- currentLowerBoundForReductionCut: Current cutoff value\n- run(): Update objective bound constraint\n\n**Cutoff Strategy:**\n- Adds constraint: objective <= bestPrimal - epsilon\n- Forces MIP to find improving solutions only\n- Updated when primal bound improves",
    "file": "TaskAddPrimalReductionCut",
    "library": "SHOT",
    "layer": "layer-4",
    "header": "src/Tasks/TaskAddPrimalReductionCut.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "TaskCheckDualStagnation": {
    "brief": "Detect stalled dual bound improvement\n\nTriggers countermeasures when dual bound stops improving.\n\n**TaskCheckDualStagnation Class:**\n- taskIDIfTrue: Jump target when stagnation detected\n- run(): Check if dual bound unchanged for N iterations\n\n**Stagnation Recovery:**\n- May trigger stronger cuts or reformulation\n- Indicates outer approximation isn't tightening",
    "file": "TaskCheckDualStagnation",
    "library": "SHOT",
    "layer": "layer-4",
    "header": "src/Tasks/TaskCheckDualStagnation.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "TaskCheckConstraintTolerance": {
    "brief": "Termination check for constraint feasibility\n\nVerifies primal solution satisfies all constraints.\n\n**TaskCheckConstraintTolerance Class:**\n- taskIDIfTrue: Jump target when feasible\n- run(): Check max constraint violation < ConstraintTolerance\n\n**Usage:**\n- Validates feasibility of best primal solution\n- Required for declaring optimality",
    "file": "TaskCheckConstraintTolerance",
    "library": "SHOT",
    "layer": "layer-4",
    "header": "src/Tasks/TaskCheckConstraintTolerance.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "TaskInitializeRootsearch": {
    "brief": "Setup rootsearch method for ESH\n\nOne-time initialization of boundary finding algorithm.\n\n**TaskInitializeRootsearch Class:**\n- run(): Create and configure rootsearch method\n\n**Rootsearch Setup:**\n- Select algorithm (TOMS 748, bisection)\n- Configure tolerances and iteration limits\n- Required for ESH hyperplane generation",
    "file": "TaskInitializeRootsearch",
    "library": "SHOT",
    "layer": "layer-4",
    "header": "src/Tasks/TaskInitializeRootsearch.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "TaskSequential": {
    "brief": "Container task that runs subtasks in sequence\n\nComposite pattern for building task workflows.\n\n**TaskSequential Class:**\n- addTask()/addTasks(): Build task list\n- run(): Execute all subtasks in order\n\n**Usage in SHOT:**\n- Main iteration loop as sequential task chain\n- Groups related operations (all termination checks)",
    "file": "TaskSequential",
    "library": "SHOT",
    "layer": "layer-4",
    "header": "src/Tasks/TaskSequential.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "TaskInitializeDualSolver": {
    "brief": "Configure and create MIP solver instance\n\nOne-time setup for MIP solver before main loop.\n\n**TaskInitializeDualSolver Class:**\n- useLazyStrategy: Single-tree (true) or multi-tree (false)\n- run(): Create appropriate MIP solver type\n\n**Solver Selection:**\n- CPLEX: MIPSolverCplex or MIPSolverCplexSingleTree\n- Gurobi: MIPSolverGurobi or MIPSolverGurobiSingleTree\n- CBC: MIPSolverCbc (multi-tree only)",
    "file": "TaskInitializeDualSolver",
    "library": "SHOT",
    "layer": "layer-4",
    "header": "src/Tasks/TaskInitializeDualSolver.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "TaskExecuteRelaxationStrategy": {
    "brief": "Execute LP/MIP relaxation strategy step\n\nControls transition from LP to MIP solving.\n\n**TaskExecuteRelaxationStrategy Class:**\n- run(): Invoke current relaxation strategy\n\n**Strategy Control:**\n- Calls IRelaxationStrategy to decide LP vs MIP\n- May enable/disable integer constraints\n- Affects DualSolver solve behavior",
    "file": "TaskExecuteRelaxationStrategy",
    "library": "SHOT",
    "layer": "layer-4",
    "header": "src/Tasks/TaskExecuteRelaxationStrategy.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "TaskConditional": {
    "brief": "Branching task based on runtime condition\n\nIf-then-else logic for task workflows.\n\n**TaskConditional Class:**\n- setCondition(fn): Boolean predicate to evaluate\n- setTaskIfTrue/False(): Branch targets\n- run(): Evaluate condition and execute appropriate branch\n\n**Usage in SHOT:**\n- Branch on problem type (MINLP vs NLP)\n- Skip tasks based on solver state",
    "file": "TaskConditional",
    "library": "SHOT",
    "layer": "layer-4",
    "header": "src/Tasks/TaskConditional.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "TaskCalculateSolutionChangeNorm": {
    "brief": "Compute solution movement between iterations\n\nTracks convergence via solution change magnitude.\n\n**TaskCalculateSolutionChangeNorm Class:**\n- run(): Compute ||x_new - x_old|| norm\n\n**Usage:**\n- Detect solution stagnation\n- Used in convergence criteria\n- May trigger algorithm strategy changes",
    "file": "TaskCalculateSolutionChangeNorm",
    "library": "SHOT",
    "layer": "layer-4",
    "header": "src/Tasks/TaskCalculateSolutionChangeNorm.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "TaskSelectPrimalCandidatesFromRootsearch": {
    "brief": "Extract primal candidates from ESH rootsearch\n\nByproduct of boundary finding: feasible points near boundary.\n\n**TaskSelectPrimalCandidatesFromRootsearch Class:**\n- run(): Check rootsearch intermediate points\n- run(solPoints): Process specific solution points\n\n**Rootsearch Byproduct:**\n- ESH rootsearch traverses from infeasible to interior\n- Intermediate points may be feasible primal candidates\n- Cheap way to discover feasible solutions",
    "file": "TaskSelectPrimalCandidatesFromRootsearch",
    "library": "SHOT",
    "layer": "layer-4",
    "header": "src/Tasks/TaskSelectPrimalCandidatesFromRootsearch.h",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "TaskSelectPrimalFixedNLPPointsFromSolutionPool": {
    "brief": "Select MIP solutions for fixed-integer NLP solving\n\nChooses promising candidates for NLP refinement.\n\n**TaskSelectPrimalFixedNLPPointsFromSolutionPool Class:**\n- run(): Select best candidates from solution pool\n\n**Selection Criteria:**\n- Prioritize solutions close to feasibility\n- Avoid already-tested integer assignments\n- Respect NLP solve budget",
    "file": "TaskSelectPrimalFixedNLPPointsFromSolutionPool",
    "library": "SHOT",
    "layer": "layer-4",
    "header": "src/Tasks/TaskSelectPrimalFixedNLPPointsFromSolutionPool.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "TaskAddHyperplanes": {
    "brief": "Add generated hyperplanes to MIP relaxation\n\nTransfers cuts from hyperplane pool to MIP solver.\n\n**TaskAddHyperplanes Class:**\n- run(): Add pending hyperplanes to dual problem\n- itersWithoutAddedHPs: Track stagnation\n\n**Cut Management:**\n- Filters duplicate/dominated cuts\n- Respects cut limit per iteration\n- May trigger lazy vs pool constraint handling",
    "file": "TaskAddHyperplanes",
    "library": "SHOT",
    "layer": "layer-4",
    "header": "src/Tasks/TaskAddHyperplanes.h",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "TaskUpdateInteriorPoint": {
    "brief": "Update interior point during optimization\n\nImproves ESH quality by updating interior point.\n\n**TaskUpdateInteriorPoint Class:**\n- run(): Recompute or update interior point\n\n**Update Strategy:**\n- Use new primal solutions as interior candidates\n- Average with existing interior point\n- Improves cut quality as algorithm progresses",
    "file": "TaskUpdateInteriorPoint",
    "library": "SHOT",
    "layer": "layer-4",
    "header": "src/Tasks/TaskUpdateInteriorPoint.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "TaskGoto": {
    "brief": "Jump to labeled task in workflow\n\nEnables non-linear control flow in task sequences.\n\n**TaskGoto Class:**\n- gotoTaskID: Target task identifier\n- run(): Signal TaskHandler to jump to target\n\n**Usage in SHOT:**\n- Loop back to iteration start\n- Jump to termination on error",
    "file": "TaskGoto",
    "library": "SHOT",
    "layer": "layer-4",
    "header": "src/Tasks/TaskGoto.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "TaskCheckTimeLimit": {
    "brief": "Termination check for wall-clock time limit\n\nPart of termination check sequence.\n\n**TaskCheckTimeLimit Class:**\n- taskIDIfTrue: Jump target when limit exceeded\n- run(): Compare elapsed vs Settings.TimeLimit\n\n**Behavior:**\n- If exceeded: Jump to termination task\n- If not: Continue to next task",
    "file": "TaskCheckTimeLimit",
    "library": "SHOT",
    "layer": "layer-4",
    "header": "src/Tasks/TaskCheckTimeLimit.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "TaskException": {
    "brief": "Exception types for task framework errors\n\nSpecialized exceptions for task-related failures.\n\n**Exception Classes:**\n- TaskException: General task error\n- TaskExceptionFunctionNotDefined: Missing run() implementation\n- TaskExceptionNotFound: Invalid task ID in goto/jump\n\n**Usage:**\n- Thrown by TaskHandler and individual tasks\n- Caught and handled in main solve loop",
    "file": "TaskException",
    "library": "SHOT",
    "layer": "layer-4",
    "header": "src/Tasks/TaskException.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "TaskCheckRelativeGap": {
    "brief": "Termination check for relative optimality gap\n\nTerminates when |primal - dual| / |primal| < tolerance.\n\n**TaskCheckRelativeGap Class:**\n- taskIDIfTrue: Jump target when gap closed\n- run(): Check (|bestPrimal - bestDual| / max(1, |bestPrimal|)) < RelativeGapTol\n\n**Usage:**\n- More common than absolute gap for practical problems\n- Scales with solution magnitude",
    "file": "TaskCheckRelativeGap",
    "library": "SHOT",
    "layer": "layer-4",
    "header": "src/Tasks/TaskCheckRelativeGap.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "TaskAddIntegerCuts": {
    "brief": "Add integer cuts to exclude visited solutions\n\nPrevents revisiting same integer assignment.\n\n**TaskAddIntegerCuts Class:**\n- run(): Generate cut excluding current integer solution\n\n**Integer Cut Types:**\n- No-good cuts: Exclude exact binary assignment\n- Local branching: Limit Hamming distance\n\n**Usage:**\n- Multi-tree strategy uses these extensively\n- Prevents cycling through same MIP solutions",
    "file": "TaskAddIntegerCuts",
    "library": "SHOT",
    "layer": "layer-4",
    "header": "src/Tasks/TaskAddIntegerCuts.h",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "TaskCheckUserTermination": {
    "brief": "Check for external termination request\n\nAllows user to interrupt solver gracefully.\n\n**TaskCheckUserTermination Class:**\n- taskIDIfTrue: Jump target when user requests stop\n- run(): Check for CTRL+C, callback termination, etc.\n\n**Usage:**\n- Called every iteration to check for interrupts\n- Returns best solution found so far",
    "file": "TaskCheckUserTermination",
    "library": "SHOT",
    "layer": "layer-4",
    "header": "src/Tasks/TaskCheckUserTermination.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "TaskSelectHyperplanePointsESH": {
    "brief": "Extended Supporting Hyperplane point selection\n\nCore ESH algorithm: finds boundary points for hyperplane generation.\n\n**TaskSelectHyperplanePointsESH Class:**\n- run(): Process current MIP solutions\n- run(solPoints): Process specific solution points\n\n**ESH Algorithm:**\n1. Take infeasible MIP solution point\n2. Use rootsearch to find boundary with feasible region\n3. Generate supporting hyperplane at boundary\n\n**Extends ECP:**\n- ESH uses interior point + rootsearch\n- ECP generates cuts at infeasible point directly",
    "file": "TaskSelectHyperplanePointsESH",
    "library": "SHOT",
    "layer": "layer-4",
    "header": "src/Tasks/TaskSelectHyperplanePointsESH.h",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "TaskCheckPrimalStagnation": {
    "brief": "Detect stalled primal bound improvement\n\nTriggers NLP solves when primal bound stops improving.\n\n**TaskCheckPrimalStagnation Class:**\n- taskIDIfTrue/False: Branch targets for stagnation state\n- run(): Check if primal bound unchanged for N iterations\n\n**Stagnation Recovery:**\n- May trigger fixed-integer NLP to find better solutions\n- Indicates MIP solutions aren't improving primal",
    "file": "TaskCheckPrimalStagnation",
    "library": "SHOT",
    "layer": "layer-4",
    "header": "src/Tasks/TaskCheckPrimalStagnation.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "TaskBase": {
    "brief": "Base class for modular algorithm tasks\n\nFoundation for task-based algorithm composition.\n\n**TaskBase Class:**\n- isActive(), activate(), deactivate(): Enable/disable tasks\n- initialize(): Setup before first run\n- run(): Execute the task logic\n- getType(): Task identifier for debugging\n\n**Task Categories:**\n- Termination: TimeLimit, IterationLimit, Gap checks\n- Hyperplane: SelectHyperplanePointsESH/ECP, AddHyperplanes\n- Primal: SelectPrimalCandidates, NLP solving\n- Dual: SolveIteration, CreateDualProblem\n- Control: Sequential, Conditional, Goto\n\n**Task Composition:**\n- TaskSequential: Run tasks in order\n- TaskConditional: Branch on conditions\n- TaskGoto: Jump to labeled task",
    "file": "TaskBase",
    "library": "SHOT",
    "layer": "layer-4",
    "header": "src/Tasks/TaskBase.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "TaskExecuteSolutionLimitStrategy": {
    "brief": "Control MIP solution pool size dynamically\n\nAdjusts how many MIP solutions are collected per iteration.\n\n**TaskExecuteSolutionLimitStrategy Class:**\n- solutionLimitStrategy: Strategy implementation\n- previousSolLimit: Track limit changes\n- run(): Apply current solution limit\n\n**Strategy Control:**\n- Start with small limit for fast iterations\n- Increase when MIP optimal to explore pool\n- Balance speed vs solution diversity",
    "file": "TaskExecuteSolutionLimitStrategy",
    "library": "SHOT",
    "layer": "layer-4",
    "header": "src/Tasks/TaskExecuteSolutionLimitStrategy.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "TaskSolveIteration": {
    "brief": "Solve MIP relaxation for current iteration\n\nCore MIP solve step in outer approximation loop.\n\n**TaskSolveIteration Class:**\n- run(): Call DualSolver to solve MIP with current cuts\n\n**Iteration Flow:**\n1. MIP has linear approximation of nonlinear constraints\n2. Solve gives candidate solution + dual bound\n3. Candidate checked for feasibility\n4. New cuts generated at infeasible points",
    "file": "TaskSolveIteration",
    "library": "SHOT",
    "layer": "layer-4",
    "header": "src/Tasks/TaskSolveIteration.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "TaskSelectHyperplanePointsECP": {
    "brief": "Extended Cutting Plane point selection\n\nClassic outer approximation: linearize at infeasible points.\n\n**TaskSelectHyperplanePointsECP Class:**\n- run(): Process current MIP solutions\n- run(solPoints): Process specific solution points\n\n**ECP Algorithm:**\n- Generate gradient cut at infeasible solution\n- Simpler than ESH but may converge slower\n- Used as fallback when ESH rootsearch fails",
    "file": "TaskSelectHyperplanePointsECP",
    "library": "SHOT",
    "layer": "layer-4",
    "header": "src/Tasks/TaskSelectHyperplanePointsECP.h",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "TaskFindInteriorPoint": {
    "brief": "Find strictly feasible interior point for ESH\n\nCritical for ESH: rootsearch needs interior point endpoint.\n\n**TaskFindInteriorPoint Class:**\n- NLPSolvers: Solvers for finding interior\n- run(): Attempt to find strictly feasible point\n\n**Interior Point Methods:**\n- Solve feasibility problem with slack maximization\n- Use NLP solver (Ipopt) with modified objective\n- Required for ESH rootsearch to work",
    "file": "TaskFindInteriorPoint",
    "library": "SHOT",
    "layer": "layer-4",
    "header": "src/Tasks/TaskFindInteriorPoint.h",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "TaskReformulateProblem": {
    "brief": "Transform problem for efficient outer approximation\n\nKey preprocessing: converts problem to reformulated form.\n\n**TaskReformulateProblem Class:**\n- reformulateObjectiveFunction(): Handle nonlinear objective\n- reformulateConstraint(): Process each constraint type\n- createEpigraphConstraint(): Epigraph reformulation\n\n**Reformulation Techniques:**\n- Bilinear terms: McCormick envelopes (addBilinearMcCormickEnvelope)\n- Integer products: Binary expansion\n- Eigenvalue decomposition: Convexify quadratics\n- Term extraction: Separate linear/quadratic/monomial/signomial\n\n**Auxiliary Variables:**\n- Created for bilinear products, squares, absolute values\n- Tracked in squareAuxVariables, bilinearAuxVariables maps",
    "file": "TaskReformulateProblem",
    "library": "SHOT",
    "layer": "layer-4",
    "header": "src/Tasks/TaskReformulateProblem.h",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "TaskCheckMaxNumberOfPrimalReductionCuts": {
    "brief": "Limit number of objective cutoff updates\n\nPrevents excessive cutoff constraint modifications.\n\n**TaskCheckMaxNumberOfPrimalReductionCuts Class:**\n- taskIDIfTrue: Jump target when limit reached\n- run(): Check cutoff update count\n\n**Usage:**\n- Limit objective bound updates per iteration\n- Avoid MIP solver overhead from repeated bound changes",
    "file": "TaskCheckMaxNumberOfPrimalReductionCuts",
    "library": "SHOT",
    "layer": "layer-4",
    "header": "src/Tasks/TaskCheckMaxNumberOfPrimalReductionCuts.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "TaskRepairInfeasibleDualProblem": {
    "brief": "Recover from infeasible MIP relaxation\n\nAttempts to restore feasibility when cuts cause infeasibility.\n\n**TaskRepairInfeasibleDualProblem Class:**\n- mainRepairTries, totRepairTries: Repair attempt counters\n- run(): Attempt repair strategies\n\n**Repair Strategies:**\n- Remove recently added cuts\n- Relax cut coefficients\n- Remove dominated cuts\n\n**When Called:**\n- MIP solver returns infeasible\n- May indicate numerical issues with cuts",
    "file": "TaskRepairInfeasibleDualProblem",
    "library": "SHOT",
    "layer": "layer-4",
    "header": "src/Tasks/TaskRepairInfeasibleDualProblem.h",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "NonlinearExpressions": {
    "brief": "Expression tree nodes for nonlinear functions\n\nDAG-based representation of nonlinear expressions with convexity analysis.\n\n**E_NonlinearExpressionTypes:**\n- Constant, Variable: Leaf nodes\n- Unary: Negate, Invert, SquareRoot, Log, Exp, Square, Sin, Cos, etc.\n- Binary: Divide, Power\n- N-ary: Sum, Product\n\n**NonlinearExpression Base Class:**\n- calculate(point): Evaluate at numeric point\n- calculate(intervals): Interval arithmetic evaluation\n- getFactorableFunction(): CppAD automatic differentiation\n- getConvexity(): Analyze convexity via composition rules\n- getMonotonicity(): Analyze monotonicity\n- tightenBounds(): FBBT bound propagation\n\n**Expression Subclasses:**\n- ExpressionConstant, ExpressionVariable\n- ExpressionNegate, ExpressionSquare, ExpressionSquareRoot\n- ExpressionLog, ExpressionExp\n- ExpressionSin, ExpressionCos\n- ExpressionSum, ExpressionProduct\n- ExpressionDivide, ExpressionPower\n\n**Convexity Rules:**\n- Based on composition theorems (e.g., convex \u2218 nondecreasing convex = convex)\n- Interval bounds inform sign-dependent rules\n\n@note Convexity analysis influenced by SUSPECT library",
    "file": "NonlinearExpressions",
    "library": "SHOT",
    "layer": "layer-4",
    "header": "src/Model/NonlinearExpressions.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "AuxiliaryVariables": {
    "brief": "Variables introduced during problem reformulation\n\nVariables created to linearize or convexify expressions.\n\n**AuxiliaryVariable Class:**\n- Extends Variable with expression components\n- calculate(): Evaluate auxiliary from original variables\n- Properties: constant, linear/quadratic/monomial/signomial terms\n\n**Auxiliary Variable Types (E_AuxiliaryVariableType):**\n- NonlinearObjectiveFunction: Epigraph reformulation\n- BilinearTerms: McCormick relaxation variables\n- MonomialPartitioning: Product term linearization\n- EigenvalueDecomposition: Convexification variables\n\n**AuxiliaryVariables Collection:**\n- Vector of AuxiliaryVariablePtr with Problem ownership\n- sortByIndex(): Order by variable index",
    "file": "AuxiliaryVariables",
    "library": "SHOT",
    "layer": "layer-4",
    "header": "src/Model/AuxiliaryVariables.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "Problem": {
    "brief": "Core problem representation with variables, constraints, and objective\n\nCentral data structure holding the optimization problem definition.\n\n**ProblemProperties Struct:**\n- Convexity classification (Convex, Nonconvex, NotSet)\n- Problem type flags (MINLP, MIQP, MILP, NLP, etc.)\n- Variable counts by type (real, binary, integer, auxiliary)\n- Constraint counts by type (linear, quadratic, nonlinear)\n\n**SpecialOrderedSet Struct:**\n- SOS1 (at most one variable nonzero) or SOS2 (contiguous nonzeros)\n- Variables and optional weights\n\n**Problem Class:**\n- allVariables, realVariables, binaryVariables, etc.\n- linearConstraints, quadraticConstraints, nonlinearConstraints\n- objectiveFunction (linear, quadratic, or nonlinear)\n- Sparsity patterns for Jacobian and Hessian\n- Feasibility bound propagation (FBBT) for tightening bounds\n\n**Key Methods:**\n- add(): Add variables, constraints, objective\n- finalize(): Compute properties and sparsity patterns\n- getMostDeviatingNumericConstraint(): Find worst violation\n- createCopy(): Clone for reformulation",
    "file": "Problem",
    "library": "SHOT",
    "layer": "layer-4",
    "header": "src/Model/Problem.h",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "Variables": {
    "brief": "Decision variable representation with bounds and types\n\nVariable classes for MINLP problem modeling.\n\n**VariableProperties Struct:**\n- type: Real, Binary, Integer, Semicontinuous, Semiinteger\n- auxiliaryType: Tracks origin of reformulation variables\n- Context flags: inObjectiveFunction, inLinearConstraints, etc.\n- Bound tightening status\n\n**Variable Class:**\n- index, name: Problem identifier\n- lowerBound, upperBound: Variable domain\n- semiBound: For semicontinuous/semiinteger types\n- calculate(): Evaluate at a point\n- getBound(): Interval arithmetic bounds\n- tightenBounds(): FBBT bound update\n\n**Variables Collection:**\n- Vector wrapper with ownership tracking\n- sortByIndex(): Reorder for solver compatibility\n\n**Interval Arithmetic (CppAD):**\n- Uses mc::Interval for bound propagation\n- FactorableFunction for automatic differentiation",
    "file": "Variables",
    "library": "SHOT",
    "layer": "layer-4",
    "header": "src/Model/Variables.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "ObjectiveFunction": {
    "brief": "Objective function hierarchy with derivative computation\n\nObjective function classes mirroring the constraint hierarchy.\n\n**ObjectiveFunctionProperties:**\n- direction: Minimize or Maximize\n- classification: Linear, Quadratic, Signomial, Nonlinear\n- convexity: Convex, Concave, Linear, Nonconvex\n- Term presence flags for structure detection\n\n**ObjectiveFunction Base:**\n- calculateValue(): Evaluate at point or interval\n- calculateGradient(), calculateHessian(): Derivatives\n- getGradientSparsityPattern(): Nonzero structure\n\n**LinearObjectiveFunction:**\n- linearTerms + constant\n- isDualUnbounded(): Unboundedness detection\n\n**QuadraticObjectiveFunction:**\n- + quadraticTerms\n- Inherits from LinearObjectiveFunction\n\n**NonlinearObjectiveFunction:**\n- + monomialTerms, signomialTerms, nonlinearExpression\n- factorableFunction: CppAD automatic differentiation\n- Inherits from QuadraticObjectiveFunction\n\n@note For minimization with nonlinear objective, SHOT uses\n      epigraph reformulation: min t s.t. f(x) <= t",
    "file": "ObjectiveFunction",
    "library": "SHOT",
    "layer": "layer-4",
    "header": "src/Model/ObjectiveFunction.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "Simplifications": {
    "brief": "Expression tree simplification and term extraction\n\nAlgebraic simplification and structured term extraction.\n\n**Simplification Functions:**\n- simplify(): Recursive expression simplification\n- simplifyExpression(ExprType): Type-specific handlers\n- Constant folding, negation cancellation, identity removal\n\n**Term Extraction:**\n- extractTermsAndConstant(): Decompose expression into:\n  LinearTerms, QuadraticTerms, MonomialTerms, SignomialTerms,\n  NonlinearExpression remainder, and constant\n\n**Conversion Functions:**\n- convertProductToLinearTerm/QuadraticTerm/MonomialTerm()\n- convertPowerToLinearTerm/QuadraticTerm()\n- convertToSignomialTerm(): Extract signomial structure\n\n**Use Case:**\n- Problem reformulation for better convexity analysis\n- Extract quadratics for QCQP solvers\n- Identify linear/quadratic substructure in NLP",
    "file": "Simplifications",
    "library": "SHOT",
    "layer": "layer-4",
    "header": "src/Model/Simplifications.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "Terms": {
    "brief": "Term hierarchy for linear, quadratic, monomial, and signomial expressions\n\nBuilding blocks for constraint and objective function representation.\n\n**Term Base Class:**\n- coefficient: Scaling factor\n- calculate(): Evaluate at point or interval\n- getConvexity(): Linear, Convex, Concave, Nonconvex\n- getMonotonicity(): Nondecreasing, Nonincreasing, Constant\n\n**LinearTerm:** coeff * x\n- Always linear convexity\n- Monotonicity depends on coefficient sign\n\n**QuadraticTerm:** coeff * x1 * x2\n- isSquare: x1 == x2 (convex if coeff > 0)\n- isBilinear: x1 != x2 (nonconvex)\n- isBinary, isInteger: Type detection for reformulation\n\n**QuadraticTerms Collection:**\n- Eigenvalue analysis via Eigen for convexity\n- allSquares, allPositive flags for structure detection\n\n**MonomialTerm:** coeff * x1 * x2 * ... * xn\n- isBinary: All variables binary (linearizable)\n- Generally nonconvex\n\n**SignomialTerm:** coeff * x1^p1 * x2^p2 * ... * xn^pn\n- SignomialElement: (variable, power) pair\n- Convexity rules based on power signs and sums\n\n**Gradient/Hessian Methods:**\n- calculateGradient(): Sparse first derivatives\n- calculateHessian(): Upper triangular second derivatives",
    "file": "Terms",
    "library": "SHOT",
    "layer": "layer-4",
    "header": "src/Model/Terms.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "ISolutionStrategy": {
    "brief": "Abstract interface for solution strategies\n\nBase interface for algorithm selection.\n\n**Strategy Interface:**\n- initializeStrategy(): Configure tasks and solvers\n- solveProblem(): Execute the solution algorithm\n\n**Strategy Implementations:**\n- SolutionStrategyMultiTree: Iterative outer approximation\n  - Solve MIP, add cuts, repeat\n- SolutionStrategySingleTree: Lazy constraint callback\n  - Single MIP with callback cut injection\n- SolutionStrategyNLP: Pure NLP (no integer variables)\n- SolutionStrategyMIQP/MIQCQP: Direct quadratic solving\n\n**Selection Logic:**\n- Problem classification determines best strategy\n- Convex MINLP \u2192 ESH (multi-tree or single-tree)\n- QP/QCQP \u2192 Direct solver if supported\n- NLP \u2192 Interior point only",
    "file": "ISolutionStrategy",
    "library": "SHOT",
    "layer": "layer-4",
    "header": "src/SolutionStrategy/ISolutionStrategy.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "SolutionStrategyMIQCQP": {
    "brief": "Direct MIQCQP solver for convex quadratic problems\n\nBypasses ESH for problems solvable by CPLEX/Gurobi MIQCQP.\n\n**SolutionStrategyMIQCQP Class:**\n- initializeStrategy(): Configure for direct MIQCQP solve\n- solveProblem(): Single solver call, no outer approximation\n\n**Use Case:**\n- Convex MIQCQP (quadratic constraints, convex)\n- CPLEX and Gurobi support convex QCQP natively\n- Faster than iterative linearization for small problems\n\n**Problem Classification:**\n- All constraints must be convex quadratic\n- Solver must support QCQP (supportsQuadraticConstraints)",
    "file": "SolutionStrategyMIQCQP",
    "library": "SHOT",
    "layer": "layer-4",
    "header": "src/SolutionStrategy/SolutionStrategyMIQCQP.h",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "SolutionStrategySingleTree": {
    "brief": "Lazy constraint callback strategy (single-tree)\n\nCallback-based outer approximation within single B&B tree.\n\n**Algorithm Pattern:**\n1. Solve MIP with lazy constraint callback\n2. Callback checks integer solutions for feasibility\n3. Generate hyperplanes for violated constraints\n4. Add as lazy constraints, solver continues\n\n**Task Flow (initializeStrategy):**\n- CreateDualProblem \u2192 ConfigureCallback \u2192 SolveProblem\n- (cuts added via callback during solve)\n\n**Advantages:**\n- Single B&B tree exploration\n- Potentially fewer node evaluations\n- Better integration with MIP solver\n\n**Disadvantages:**\n- Requires solver callback support\n- Limited to CPLEX/Gurobi\n- More complex debugging",
    "file": "SolutionStrategySingleTree",
    "library": "SHOT",
    "layer": "layer-4",
    "header": "src/SolutionStrategy/SolutionStrategySingleTree.h",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "SolutionStrategyMultiTree": {
    "brief": "Iterative outer approximation strategy (multi-tree)\n\nClassic outer approximation loop for convex MINLP.\n\n**Algorithm Pattern:**\n1. Solve MIP relaxation to get candidate point\n2. Generate supporting hyperplanes at violated points\n3. Add cuts to MIP and resolve\n4. Repeat until convergence or termination\n\n**Task Flow (initializeStrategy):**\n- CreateDualProblem \u2192 SolveIteration \u2192 SelectHyperplanes\n- AddHyperplanes \u2192 CheckTermination \u2192 loop\n\n**Advantages:**\n- No callback complexity\n- Can use any MIP solver\n- Easier debugging/logging\n\n**Disadvantages:**\n- Multiple MIP solves\n- May regenerate same B&B tree work",
    "file": "SolutionStrategyMultiTree",
    "library": "SHOT",
    "layer": "layer-4",
    "header": "src/SolutionStrategy/SolutionStrategyMultiTree.h",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "SolutionStrategyNLP": {
    "brief": "Direct NLP solver for continuous problems\n\nBypasses ESH for purely continuous NLP problems.\n\n**SolutionStrategyNLP Class:**\n- initializeStrategy(): Configure for direct NLP solve\n- solveProblem(): Single NLP solver call (Ipopt)\n\n**Use Case:**\n- Problems with no integer variables\n- Convex NLP where outer approximation is unnecessary\n- Falls back to standard NLP solvers (Ipopt)\n\n**When Selected:**\n- Problem type is NLP (no discrete variables)\n- Simpler than ESH for continuous problems",
    "file": "SolutionStrategyNLP",
    "library": "SHOT",
    "layer": "layer-4",
    "header": "src/SolutionStrategy/SolutionStrategyNLP.h",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "IRootsearchMethod": {
    "brief": "Interface for constraint boundary rootsearch algorithms\n\nFinds points on constraint boundaries for ESH hyperplane generation.\n\n**Purpose:**\nGiven interior point A and exterior point B, find point on boundary\nwhere constraint function equals zero (feasibility boundary).\n\n**Constraint Rootsearch:**\n- findZero(ptA, ptB, ...): Search along line segment A\u2192B\n- Returns (boundary point, exterior point) pair\n- lambdaTol: Tolerance on line parameter\n- constrTol: Tolerance on constraint violation\n\n**Objective Rootsearch:**\n- findZero(pt, objLB, objUB, ...): Find objective level set\n- Used for objective function cuts\n\n**Algorithm:**\n- Uses bisection or hybrid methods (TOMS 748)\n- Requires f(A) < 0 (feasible) and f(B) > 0 (infeasible)\n\n**Implementations:**\n- RootsearchMethodBoost: Boost.Math TOMS 748 or bisection",
    "file": "IRootsearchMethod",
    "library": "SHOT",
    "layer": "layer-4",
    "header": "src/RootsearchMethod/IRootsearchMethod.h",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "RootsearchMethodBoost": {
    "brief": "Boost.Math rootfinding for constraint boundaries\n\nFinds constraint boundary points using TOMS 748 or bisection.\n\n**RootsearchMethodBoost Class:**\n- findZero(ptA, ptB, constraints): Find boundary between points\n- findZero(pt, objLB, objUB, objective): Objective rootsearch\n\n**Helper Classes:**\n- Test: Functor for constraint max-violation evaluation\n- TestObjective: Functor for objective function evaluation\n- TerminationCondition: Convergence criterion\n\n**Algorithm:**\n- TOMS 748: Optimal bracketing algorithm (4th order)\n- Bisection: Fallback for difficult cases\n- Returns boundary point for hyperplane generation",
    "file": "RootsearchMethodBoost",
    "library": "SHOT",
    "layer": "layer-4",
    "header": "src/RootsearchMethod/RootsearchMethodBoost.h",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "MIPSolverCplexSingleTreeLegacy": {
    "brief": "Legacy CPLEX callback API for single-tree ESH\n\nUses older callback API (pre-CPLEX 12.10 generic callbacks).\n\n**Legacy Callback Classes:**\n- HCallbackI: Heuristic callback for primal solutions\n- InfoCallbackI: Progress information callback\n- CtCallbackI: Lazy constraint callback for hyperplanes\n\n**MIPSolverCplexSingleTreeLegacy Class:**\n- Inherits MIPSolverCplex for base functionality\n- Uses IloCplex::LazyConstraintCallbackI/HeuristicCallbackI\n\n@deprecated Prefer MIPSolverCplexSingleTree with generic callbacks",
    "file": "MIPSolverCplexSingleTreeLegacy",
    "library": "SHOT",
    "layer": "layer-4",
    "header": "src/MIPSolver/MIPSolverCplexSingleTreeLegacy.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "IRelaxationStrategy": {
    "brief": "Interface for LP relaxation control strategies\n\nManages when to solve LP relaxation vs full MIP.\n\n**IRelaxationStrategy Interface:**\n- executeStrategy(): Apply relaxation decision\n- setActive()/setInactive(): Enable/disable strategy\n- setInitial(): Reset to initial state\n\n**Implementations:**\n- RelaxationStrategyStandard: Periodic LP solves\n- RelaxationStrategyNone: Always solve full MIP\n\n**Use Case:**\n- LP relaxations generate more hyperplanes quickly\n- MIP solves provide better candidate points\n- Strategy balances cut generation vs exploration",
    "file": "IRelaxationStrategy",
    "library": "SHOT",
    "layer": "layer-4",
    "header": "src/MIPSolver/IRelaxationStrategy.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "MIPSolverGurobi": {
    "brief": "Gurobi implementation of IMIPSolver interface\n\nProvides MIP solving for SHOT's dual problem using Gurobi C++ API.\n\n**MIPSolverGurobi Class:**\n- Implements full IMIPSolver interface\n- Uses GRBModel for problem representation\n- Supports LP, MIP, QP, MIQP, QCQP problem types\n\n**Key Data Structures:**\n- gurobiModel: Shared GRBModel pointer\n- objectiveLinearExpression, objectiveQuadraticExpression\n- constraintLinearExpression, constraintQuadraticExpression\n\n**GurobiCallbackMultiTree:**\n- GRBCallback for multi-tree algorithm\n- Handles termination checks during solve\n\n**Quadratic Support:**\n- supportsQuadraticObjective(): Yes\n- supportsQuadraticConstraints(): Yes (QCQP)\n\n@note Requires Gurobi C++ headers",
    "file": "MIPSolverGurobi",
    "library": "SHOT",
    "layer": "layer-4",
    "header": "src/MIPSolver/MIPSolverGurobi.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "MIPSolverCallbackBase": {
    "brief": "Shared logic for single-tree callback handlers\n\nBase class for CPLEX and Gurobi callback implementations.\n\n**MIPSolverCallbackBase Class:**\n- addLazyConstraint(): Generate and add ESH cuts\n- checkFixedNLPStrategy(): Decide if NLP should be called\n- checkIterationLimit()/checkUserTermination(): Termination checks\n- printIterationReport(): Console output in callback\n\n**Task Objects:**\n- taskSelectPrimNLPOriginal/Reformulated: Fixed-integer NLP\n- taskSelectHPPts: ESH/ECP hyperplane selection\n- taskSelectPrimalSolutionFromRootsearch: Rootsearch primal\n- tUpdateInteriorPoint: Interior point maintenance",
    "file": "MIPSolverCallbackBase",
    "library": "SHOT",
    "layer": "layer-4",
    "header": "src/MIPSolver/MIPSolverCallbackBase.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "IMIPSolutionLimitStrategy": {
    "brief": "Interface for MIP solution pool limit strategies\n\nControls how many solutions MIP solver collects per iteration.\n\n**IMIPSolutionLimitStrategy Interface:**\n- updateLimit(): Adjust limit based on progress\n- getNewLimit(): Current solution limit value\n- getInitialLimit(): Starting limit\n\n**Implementations:**\n- MIPSolutionLimitStrategyIncrease: Grow limit over time\n- MIPSolutionLimitStrategyUnlimited: No limit\n- MIPSolutionLimitStrategyAdaptive: Adjust based on gap\n\n**Purpose:**\n- Balance cut generation vs solver time per iteration\n- More solutions = more hyperplane generation points\n- Fewer solutions = faster MIP solves",
    "file": "IMIPSolutionLimitStrategy",
    "library": "SHOT",
    "layer": "layer-4",
    "header": "src/MIPSolver/IMIPSolutionLimitStrategy.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "MIPSolverGurobiSingleTree": {
    "brief": "Gurobi with lazy constraint callback for single-tree ESH\n\nExtends MIPSolverGurobi with callback-based cut generation.\n\n**GurobiCallbackSingleTree Class:**\n- Inherits GRBCallback + MIPSolverCallbackBase\n- callback(): Called at candidate solution points\n- createHyperplane()/createIntegerCut(): Add lazy constraints\n- addLazyConstraint(): Generate ESH cuts from solution\n\n**MIPSolverGurobiSingleTree Class:**\n- solveProblem(): Single MIP solve with callbacks enabled\n- isCallbackInitialized: Track callback registration\n\n**Node Information:**\n- lastExploredNodes/lastOpenNodes: B&B tree progress\n- Used for iteration reporting within callback",
    "file": "MIPSolverGurobiSingleTree",
    "library": "SHOT",
    "layer": "layer-4",
    "header": "src/MIPSolver/MIPSolverGurobiSingleTree.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "RelaxationStrategyStandard": {
    "brief": "Standard LP-to-MIP relaxation strategy\n\nImplements the default relaxation phase behavior.\n\n**RelaxationStrategyStandard Class:**\n- executeStrategy(): Decide LP vs MIP solve\n- setActive()/setInactive(): Control strategy state\n- setInitial(): Reset for new problem\n\n**LP Phase Termination:**\n- isIterationLimitReached(): Max LP iterations\n- isTimeLimitReached(): LP time budget\n- isLPStepFinished(): Convergence detection\n- isObjectiveStagnant(): No bound improvement\n\n**Algorithm:**\n- Initial iterations solve LP for fast hyperplanes\n- Switch to MIP after LP phase completion\n- LPFinished flag tracks phase transition",
    "file": "RelaxationStrategyStandard",
    "library": "SHOT",
    "layer": "layer-4",
    "header": "src/MIPSolver/RelaxationStrategyStandard.h",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "MIPSolverCplexSingleTree": {
    "brief": "CPLEX with lazy constraint callback for single-tree ESH\n\nExtends MIPSolverCplex with callback-based cut generation.\n\n**MIPSolverCplexSingleTree Class:**\n- solveProblem(): Single MIP solve with callbacks enabled\n- Uses generic callback API (Context-based)\n\n**CplexCallback Class:**\n- Inherits IloCplex::Callback::Function + MIPSolverCallbackBase\n- invoke(): Called at candidate solution points\n- createHyperplane()/createIntegerCut(): Add lazy constraints\n- addLazyConstraint(): Generate ESH cuts from solution\n\n**Threading:**\n- callbackMutex: Protect shared state in multi-threaded solve\n- CPLEX invokes callbacks from multiple threads",
    "file": "MIPSolverCplexSingleTree",
    "library": "SHOT",
    "layer": "layer-4",
    "header": "src/MIPSolver/MIPSolverCplexSingleTree.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "MIPSolutionLimitStrategyIncrease": {
    "brief": "Solution limit strategy with gradual increase\n\nIncreases MIP solution pool limit over iterations.\n\n**MIPSolutionLimitStrategyIncrease Class:**\n- updateLimit(): Increase limit when MIP finds optimal\n- getNewLimit()/getInitialLimit(): Current and start values\n\n**State Tracking:**\n- lastIterSolLimIncreased: When limit was last raised\n- numSolLimIncremented: Total increases performed\n- lastIterOptimal: Last iteration with optimal MIP\n\n**Algorithm:**\n- Start with low limit for fast initial iterations\n- Increase when solver proves optimality\n- More solutions = more hyperplane generation points",
    "file": "MIPSolutionLimitStrategyIncrease",
    "library": "SHOT",
    "layer": "layer-4",
    "header": "src/MIPSolver/MIPSolutionLimitStrategyIncrease.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "MIPSolverCplex": {
    "brief": "IBM CPLEX implementation of IMIPSolver interface\n\nProvides MIP solving for SHOT's dual problem using CPLEX Concert API.\n\n**MIPSolverCplex Class:**\n- Implements full IMIPSolver interface\n- Uses IloModel, IloCplex for problem representation\n- Supports LP, MIP, QP, MIQP, QCQP problem types\n\n**Key Data Structures:**\n- cplexModel: IloModel for optimization model\n- cplexInstance: IloCplex solver instance\n- cplexVars: Variable array\n- cplexConstrs: Constraint array\n\n**Quadratic Support:**\n- supportsQuadraticObjective(): Yes\n- supportsQuadraticConstraints(): Yes (QCQP)\n\n**UserTerminationCallbackI:**\n- MIP info callback for user termination\n- Allows early termination on events\n\n@note Requires CPLEX Concert Technology headers",
    "file": "MIPSolverCplex",
    "library": "SHOT",
    "layer": "layer-4",
    "header": "src/MIPSolver/MIPSolverCplex.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "MIPSolutionLimitStrategyUnlimited": {
    "brief": "No limit on MIP solution pool size\n\nAllows solver to collect all feasible solutions.\n\n**MIPSolutionLimitStrategyUnlimited Class:**\n- getInitialLimit(): Returns maximum integer\n- updateLimit(): No-op (always unlimited)\n\n**Use Case:**\n- Thorough exploration of solution space\n- May slow down iterations",
    "file": "MIPSolutionLimitStrategyUnlimited",
    "library": "SHOT",
    "layer": "layer-4",
    "header": "src/MIPSolver/MIPSolutionLimitStrategyUnlimited.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "MIPSolutionLimitStrategyAdaptive": {
    "brief": "Adaptive solution limit based on solver progress\n\nAdjusts limit based on optimization state.\n\n**MIPSolutionLimitStrategyAdaptive Class:**\n- lastIterSolLimIncreased: Track when limit changed\n- numSolLimIncremented: Count of increases\n\n**Adaptive Logic:**\n- Increase when finding good solutions\n- Decrease when solver is struggling\n- Balances exploration vs speed",
    "file": "MIPSolutionLimitStrategyAdaptive",
    "library": "SHOT",
    "layer": "layer-4",
    "header": "src/MIPSolver/MIPSolutionLimitStrategyAdaptive.h",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "RelaxationStrategyNone": {
    "brief": "No-op relaxation strategy (always MIP)\n\nDisables LP relaxation phase, always solves full MIP.\n\n**RelaxationStrategyNone Class:**\n- executeStrategy(): No-op (MIP always active)\n- setActive()/setInactive()/setInitial(): State management\n\n**Use Case:**\n- Problems where LP phase doesn't help\n- When integer solutions are needed immediately\n- Benchmarking MIP-only performance\n\n**Behavior:**\n- Every iteration solves full MIP problem\n- No LP warm-start phase for hyperplane generation",
    "file": "RelaxationStrategyNone",
    "library": "SHOT",
    "layer": "layer-4",
    "header": "src/MIPSolver/RelaxationStrategyNone.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "MIPSolverCbc": {
    "brief": "COIN-OR Cbc implementation of IMIPSolver interface\n\nProvides open-source MIP solving using Cbc branch-and-cut solver.\n\n**MIPSolverCbc Class:**\n- Implements IMIPSolver interface\n- Uses OsiClpSolverInterface for LP subproblems\n- CbcModel for branch-and-cut\n- CoinModel for problem construction\n\n**Key Data Structures:**\n- osiInterface: OSI LP solver (Clp)\n- cbcModel: MIP solver model\n- coinModel: Problem builder\n- objectiveLinearExpression: CoinPackedVector\n\n**CbcMessageHandler:**\n- Custom message handler for SHOT logging\n- Routes Cbc output through SHOT's Output system\n\n**Limitations:**\n- supportsQuadraticObjective(): No\n- supportsQuadraticConstraints(): No\n- LP/MIP only (no MIQP/QCQP)\n\n@note Default open-source MIP solver, no license required",
    "file": "MIPSolverCbc",
    "library": "SHOT",
    "layer": "layer-4",
    "header": "src/MIPSolver/MIPSolverCbc.h",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "IMIPSolver": {
    "brief": "Abstract interface for MIP solver backends\n\nPure virtual interface for dual problem MIP solvers.\n\n**Problem Construction:**\n- initializeProblem(), finalizeProblem(): Setup/teardown\n- addVariable(): With type, bounds, and semi-bounds\n- addLinearTermToObjective/Constraint(): Build incrementally\n- addQuadraticTermToObjective/Constraint(): For MIQP/MIQCQP\n\n**Solution Methods:**\n- solveProblem(): Execute MIP solver\n- repairInfeasibility(): Attempt feasibility repair\n- getObjectiveValue(), getDualObjectiveValue(): Bounds\n- getVariableSolution(), getAllVariableSolutions(): Points\n\n**Hyperplane/Cut Management:**\n- createHyperplane(): Add supporting hyperplane linearization\n- createInteriorHyperplane(): Interior point cuts\n- createIntegerCut(): No-good cuts for integer variables\n\n**Bound Management:**\n- setCutOff(): Objective cutoff for pruning\n- fixVariable(), unfixVariables(): For integer fixing\n- presolveAndUpdateBounds(): Bound tightening\n\n**Implementations:**\n- MIPSolverCplex, MIPSolverGurobi, MIPSolverCbc\n- SingleTree variants for callback-based cut addition",
    "file": "IMIPSolver",
    "library": "SHOT",
    "layer": "layer-4",
    "header": "src/MIPSolver/IMIPSolver.h",
    "algorithms": 1,
    "methods": 0,
    "has_pass2": true
  },
  "MIPSolverBase": {
    "brief": "Common base class for MIP solver implementations\n\nShared functionality for CPLEX, Gurobi, and Cbc backends.\n\n**Problem State:**\n- numberOfVariables, numberOfConstraints: Problem size\n- variableTypes, variableLowerBounds, variableUpperBounds\n- isMinimizationProblem, isProblemDiscrete\n\n**Hyperplane Creation:**\n- createHyperplane(): Add supporting hyperplane cut\n- createInteriorHyperplane(): Interior point cut\n- createHyperplaneTerms(): Compute cut coefficients\n- getConstraintIdentifier(): Named constraint IDs\n\n**Variable Fixing:**\n- fixVariable(), fixVariables(): Fix for NLP subproblem\n- unfixVariables(): Restore original bounds\n- updateVariableBound(): Dynamic bound update\n\n**Relaxation Strategy:**\n- relaxationStrategy: LP relaxation handling\n- executeRelaxationStrategy(): Apply relaxation\n\n**Dual Auxiliary Variable:**\n- Tracks epigraph variable for nonlinear objective\n- hasDualAuxiliaryObjectiveVariable(), getDualAuxiliaryObjectiveVariableIndex()",
    "file": "MIPSolverBase",
    "library": "SHOT",
    "layer": "layer-4",
    "header": "src/MIPSolver/MIPSolverBase.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "RelaxationStrategyBase": {
    "brief": "Shared helper methods for relaxation strategies\n\nCommon termination checks for LP/MIP relaxation control.\n\n**RelaxationStrategyBase Class:**\n- isRelaxedSolutionInterior(): Check if LP solution is interior\n- isConstraintToleranceReached(): Feasibility achieved\n- isGapReached(): Optimality gap tolerance met\n\n**Use Case:**\n- Determines when to stop LP phase and switch to MIP\n- Checks convergence criteria during relaxation",
    "file": "RelaxationStrategyBase",
    "library": "SHOT",
    "layer": "layer-4",
    "header": "src/MIPSolver/RelaxationStrategyBase.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "GamsNLinstr": {
    "brief": "GAMS nonlinear instruction opcodes and function codes\n\nDefines GAMS bytecode for nonlinear expressions.\n\n**GamsOpCode Enum:**\n- Stack operations: nlPushV, nlPushI, nlStore\n- Arithmetic: nlAdd, nlSub, nlMul, nlDiv, nlUMin\n- Function calls: nlCallArg1, nlCallArg2, nlCallArgN\n\n**GamsFuncCode Enum:**\n- Math functions: fnexp, fnlog, fnsqrt, fnabs, fnsin, fncos\n- Comparison: fnmin, fnmax, fnifthen\n- Special: fnpower, fnsignpower, fnentropy\n\n@warning Bytecode format may change without notice",
    "file": "GamsNLinstr",
    "library": "SHOT",
    "layer": "layer-4",
    "header": "src/GAMS/GamsNLinstr.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "SyclMemoryModel": {
    "brief": "Returns an accessor to the buffer of the given virtual pointer",
    "file": "SyclMemoryModel",
    "library": "SHOT",
    "layer": "layer-4",
    "header": "ThirdParty/eigen/Eigen/src/Core/arch/SYCL/SyclMemoryModel.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "Helpers": {
    "brief": "Core wrapper infrastructure for Sonnet .NET bindings\n\nTemplate base classes for C++/CLI wrappers around native COIN-OR objects.\nWrapperAbstractBase<T> and WrapperBase<T> handle ownership and lifetime.",
    "file": "Helpers",
    "library": "Sonnet",
    "layer": "layer-4",
    "header": "src/SonnetWrapper/Helpers.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "benchmark_helper": {
    "brief": "cuOpt linear programming component\n\nPart of GPU-accelerated LP solver.",
    "file": "benchmark_helper",
    "library": "cuopt",
    "layer": "layer-4",
    "header": "benchmarks/linear_programming/cuopt/benchmark_helper.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "initial_solution_reader": {
    "brief": "cuOpt LP solution storage\n\nPrimal/dual solution and basis information.",
    "file": "initial_solution_reader",
    "library": "cuopt",
    "layer": "layer-4",
    "header": "benchmarks/linear_programming/cuopt/initial_solution_reader.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "initial_problem_check": {
    "brief": "cuOpt LP problem representation\n\nSparse matrix storage for LP constraints.",
    "file": "initial_problem_check",
    "library": "cuopt",
    "layer": "layer-4",
    "header": "benchmarks/linear_programming/cuopt/initial_problem_check.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "solution_writer": {
    "brief": "cuOpt optimization utilities\n\nCommon utilities for mathematical optimization.",
    "file": "solution_writer",
    "library": "cuopt",
    "layer": "layer-4",
    "header": "cpp/src/math_optimization/solution_writer.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "solution_reader": {
    "brief": "cuOpt optimization utilities\n\nCommon utilities for mathematical optimization.",
    "file": "solution_reader",
    "library": "cuopt",
    "layer": "layer-4",
    "header": "cpp/src/math_optimization/solution_reader.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "distance": {
    "brief": "cuOpt distance computation\n\nDistance/time matrix computation for routing.\nHaversine, Euclidean, and graph-based distances.",
    "file": "distance",
    "library": "cuopt",
    "layer": "layer-4",
    "header": "cpp/src/distance/distance.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "routing_details": {
    "brief": "cuOpt vehicle routing component\n\nPart of GPU-accelerated VRP solver.",
    "file": "routing_details",
    "library": "cuopt",
    "layer": "layer-4",
    "header": "cpp/src/routing/routing_details.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "vehicle_info": {
    "brief": "cuOpt VRP vehicle/fleet model\n\nVehicle capacity, time windows, and fleet constraints.",
    "file": "vehicle_info",
    "library": "cuopt",
    "layer": "layer-4",
    "header": "cpp/src/routing/vehicle_info.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "structures": {
    "brief": "cuOpt vehicle routing component\n\nPart of GPU-accelerated VRP solver.",
    "file": "structures",
    "library": "cuopt",
    "layer": "layer-4",
    "header": "cpp/src/routing/structures.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "fleet_order_info": {
    "brief": "cuOpt VRP vehicle/fleet model\n\nVehicle capacity, time windows, and fleet constraints.",
    "file": "fleet_order_info",
    "library": "cuopt",
    "layer": "layer-4",
    "header": "cpp/src/routing/fleet_order_info.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "fleet_order_constraints": {
    "brief": "cuOpt VRP vehicle/fleet model\n\nVehicle capacity, time windows, and fleet constraints.",
    "file": "fleet_order_constraints",
    "library": "cuopt",
    "layer": "layer-4",
    "header": "cpp/src/routing/fleet_order_constraints.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "hyper_params": {
    "brief": "cuOpt vehicle routing component\n\nPart of GPU-accelerated VRP solver.",
    "file": "hyper_params",
    "library": "cuopt",
    "layer": "layer-4",
    "header": "cpp/src/routing/hyper_params.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "order_info": {
    "brief": "cuOpt vehicle routing component\n\nPart of GPU-accelerated VRP solver.",
    "file": "order_info",
    "library": "cuopt",
    "layer": "layer-4",
    "header": "cpp/src/routing/order_info.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "arc_value": {
    "brief": "cuOpt vehicle routing component\n\nPart of GPU-accelerated VRP solver.",
    "file": "arc_value",
    "library": "cuopt",
    "layer": "layer-4",
    "header": "cpp/src/routing/arc_value.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "fleet_info": {
    "brief": "cuOpt VRP vehicle/fleet model\n\nVehicle capacity, time windows, and fleet constraints.",
    "file": "fleet_info",
    "library": "cuopt",
    "layer": "layer-4",
    "header": "cpp/src/routing/fleet_info.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "pseudo_costs": {
    "brief": "cuOpt GPU dual simplex component\n\nPart of CUDA-accelerated dual simplex LP solver.",
    "file": "pseudo_costs",
    "library": "cuopt",
    "layer": "layer-4",
    "header": "cpp/src/dual_simplex/pseudo_costs.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "initial_basis": {
    "brief": "cuOpt dual simplex basis management\n\nLU factorization and basis updates for GPU simplex.",
    "file": "initial_basis",
    "library": "cuopt",
    "layer": "layer-4",
    "header": "cpp/src/dual_simplex/initial_basis.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "folding": {
    "brief": "cuOpt GPU dual simplex component\n\nPart of CUDA-accelerated dual simplex LP solver.",
    "file": "folding",
    "library": "cuopt",
    "layer": "layer-4",
    "header": "cpp/src/dual_simplex/folding.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "random": {
    "brief": "cuOpt GPU dual simplex component\n\nPart of CUDA-accelerated dual simplex LP solver.",
    "file": "random",
    "library": "cuopt",
    "layer": "layer-4",
    "header": "cpp/src/dual_simplex/random.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "logger": {
    "brief": "Logging infrastructure for cuOpt based on rapids_logger\n\nProvides configurable logging for cuOpt operations.\n\n**Configuration:**\n- CUOPT_DEBUG_LOG_FILE env var: Log to file instead of stderr\n- Log levels: trace, debug, info, warn, error, critical\n\n**Functions:**\n- default_logger(): Get/create the global cuOpt logger\n- reset_default_logger(): Reset to default configuration\n- default_sink(): Get file or stderr sink\n- default_pattern(): Timestamp format string",
    "file": "logger",
    "library": "cuopt",
    "layer": "layer-4",
    "header": "cpp/include/cuopt/logger.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "user_problem": {
    "brief": "cuOpt GPU dual simplex component\n\nPart of CUDA-accelerated dual simplex LP solver.",
    "file": "user_problem",
    "library": "cuopt",
    "layer": "layer-4",
    "header": "cpp/src/dual_simplex/user_problem.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "phase2": {
    "brief": "cuOpt GPU dual simplex component\n\nPart of CUDA-accelerated dual simplex LP solver.",
    "file": "phase2",
    "library": "cuopt",
    "layer": "layer-4",
    "header": "cpp/src/dual_simplex/phase2.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "triangle_solve": {
    "brief": "cuOpt GPU dual simplex component\n\nPart of CUDA-accelerated dual simplex LP solver.",
    "file": "triangle_solve",
    "library": "cuopt",
    "layer": "layer-4",
    "header": "cpp/src/dual_simplex/triangle_solve.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "branch_and_bound": {
    "brief": "cuOpt GPU dual simplex component\n\nPart of CUDA-accelerated dual simplex LP solver.",
    "file": "branch_and_bound",
    "library": "cuopt",
    "layer": "layer-4",
    "header": "cpp/src/dual_simplex/branch_and_bound.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "conjugate_gradient": {
    "brief": "cuOpt GPU dual simplex component\n\nPart of CUDA-accelerated dual simplex LP solver.",
    "file": "conjugate_gradient",
    "library": "cuopt",
    "layer": "layer-4",
    "header": "cpp/src/dual_simplex/conjugate_gradient.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "phase1": {
    "brief": "cuOpt GPU dual simplex component\n\nPart of CUDA-accelerated dual simplex LP solver.",
    "file": "phase1",
    "library": "cuopt",
    "layer": "layer-4",
    "header": "cpp/src/dual_simplex/phase1.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "dense_vector": {
    "brief": "cuOpt GPU dual simplex component\n\nPart of CUDA-accelerated dual simplex LP solver.",
    "file": "dense_vector",
    "library": "cuopt",
    "layer": "layer-4",
    "header": "cpp/src/dual_simplex/dense_vector.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "iterative_refinement": {
    "brief": "cuOpt GPU dual simplex component\n\nPart of CUDA-accelerated dual simplex LP solver.",
    "file": "iterative_refinement",
    "library": "cuopt",
    "layer": "layer-4",
    "header": "cpp/src/dual_simplex/iterative_refinement.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "barrier": {
    "brief": "cuOpt GPU dual simplex component\n\nPart of CUDA-accelerated dual simplex LP solver.",
    "file": "barrier",
    "library": "cuopt",
    "layer": "layer-4",
    "header": "cpp/src/dual_simplex/barrier.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "basis_updates": {
    "brief": "cuOpt dual simplex basis management\n\nLU factorization and basis updates for GPU simplex.",
    "file": "basis_updates",
    "library": "cuopt",
    "layer": "layer-4",
    "header": "cpp/src/dual_simplex/basis_updates.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "dense_matrix": {
    "brief": "cuOpt GPU dual simplex component\n\nPart of CUDA-accelerated dual simplex LP solver.",
    "file": "dense_matrix",
    "library": "cuopt",
    "layer": "layer-4",
    "header": "cpp/src/dual_simplex/dense_matrix.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "sparse_vector": {
    "brief": "cuOpt GPU dual simplex component\n\nPart of CUDA-accelerated dual simplex LP solver.",
    "file": "sparse_vector",
    "library": "cuopt",
    "layer": "layer-4",
    "header": "cpp/src/dual_simplex/sparse_vector.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "primal": {
    "brief": "cuOpt GPU dual simplex component\n\nPart of CUDA-accelerated dual simplex LP solver.",
    "file": "primal",
    "library": "cuopt",
    "layer": "layer-4",
    "header": "cpp/src/dual_simplex/primal.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "tic_toc": {
    "brief": "cuOpt GPU dual simplex component\n\nPart of CUDA-accelerated dual simplex LP solver.",
    "file": "tic_toc",
    "library": "cuopt",
    "layer": "layer-4",
    "header": "cpp/src/dual_simplex/tic_toc.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "singletons": {
    "brief": "cuOpt GPU dual simplex component\n\nPart of CUDA-accelerated dual simplex LP solver.",
    "file": "singletons",
    "library": "cuopt",
    "layer": "layer-4",
    "header": "cpp/src/dual_simplex/singletons.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "mip_node": {
    "brief": "cuOpt GPU dual simplex component\n\nPart of CUDA-accelerated dual simplex LP solver.",
    "file": "mip_node",
    "library": "cuopt",
    "layer": "layer-4",
    "header": "cpp/src/dual_simplex/mip_node.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "right_looking_lu": {
    "brief": "cuOpt GPU dual simplex component\n\nPart of CUDA-accelerated dual simplex LP solver.",
    "file": "right_looking_lu",
    "library": "cuopt",
    "layer": "layer-4",
    "header": "cpp/src/dual_simplex/right_looking_lu.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "vector_math": {
    "brief": "cuOpt GPU dual simplex component\n\nPart of CUDA-accelerated dual simplex LP solver.",
    "file": "vector_math",
    "library": "cuopt",
    "layer": "layer-4",
    "header": "cpp/src/dual_simplex/vector_math.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "sparse_matrix": {
    "brief": "cuOpt GPU dual simplex component\n\nPart of CUDA-accelerated dual simplex LP solver.",
    "file": "sparse_matrix",
    "library": "cuopt",
    "layer": "layer-4",
    "header": "cpp/src/dual_simplex/sparse_matrix.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "solution": {
    "brief": "cuOpt GPU dual simplex component\n\nPart of CUDA-accelerated dual simplex LP solver.",
    "file": "solution",
    "library": "cuopt",
    "layer": "layer-4",
    "header": "cpp/src/dual_simplex/solution.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "pinned_host_allocator": {
    "brief": "cuOpt GPU dual simplex component\n\nPart of CUDA-accelerated dual simplex LP solver.",
    "file": "pinned_host_allocator",
    "library": "cuopt",
    "layer": "layer-4",
    "header": "cpp/src/dual_simplex/pinned_host_allocator.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "cusparse_info": {
    "brief": "cuOpt GPU dual simplex component\n\nPart of CUDA-accelerated dual simplex LP solver.",
    "file": "cusparse_info",
    "library": "cuopt",
    "layer": "layer-4",
    "header": "cpp/src/dual_simplex/cusparse_info.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "simplex_solver_settings": {
    "brief": "cuOpt GPU dual simplex component\n\nPart of CUDA-accelerated dual simplex LP solver.",
    "file": "simplex_solver_settings",
    "library": "cuopt",
    "layer": "layer-4",
    "header": "cpp/src/dual_simplex/simplex_solver_settings.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "cusparse_view": {
    "brief": "cuOpt linear programming component\n\nPart of GPU-accelerated LP solver.",
    "file": "cusparse_view",
    "library": "cuopt",
    "layer": "layer-4",
    "header": "cpp/src/linear_programming/cusparse_view.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "basis_solves": {
    "brief": "cuOpt dual simplex basis management\n\nLU factorization and basis updates for GPU simplex.",
    "file": "basis_solves",
    "library": "cuopt",
    "layer": "layer-4",
    "header": "cpp/src/dual_simplex/basis_solves.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "translate": {
    "brief": "cuOpt linear programming component\n\nPart of GPU-accelerated LP solver.",
    "file": "translate",
    "library": "cuopt",
    "layer": "layer-4",
    "header": "cpp/src/linear_programming/translate.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "pdlp_constants": {
    "brief": "cuOpt linear programming component\n\nPart of GPU-accelerated LP solver.",
    "file": "pdlp_constants",
    "library": "cuopt",
    "layer": "layer-4",
    "header": "cpp/src/linear_programming/pdlp_constants.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "saddle_point": {
    "brief": "cuOpt linear programming component\n\nPart of GPU-accelerated LP solver.",
    "file": "saddle_point",
    "library": "cuopt",
    "layer": "layer-4",
    "header": "cpp/src/linear_programming/saddle_point.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "pdhg": {
    "brief": "cuOpt linear programming component\n\nPart of GPU-accelerated LP solver.",
    "file": "pdhg",
    "library": "cuopt",
    "layer": "layer-4",
    "header": "cpp/src/linear_programming/pdhg.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "mip_constants": {
    "brief": "cuOpt MIP solver component\n\nPart of GPU-accelerated mixed-integer solver.",
    "file": "mip_constants",
    "library": "cuopt",
    "layer": "layer-4",
    "header": "cpp/src/mip/mip_constants.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "omp_helpers": {
    "brief": "cuOpt utility functions\n\nCommon utilities for cuOpt library.",
    "file": "omp_helpers",
    "library": "cuopt",
    "layer": "layer-4",
    "header": "cpp/src/utilities/omp_helpers.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "unique_pinned_ptr": {
    "brief": "cuOpt utility functions\n\nCommon utilities for cuOpt library.",
    "file": "unique_pinned_ptr",
    "library": "cuopt",
    "layer": "layer-4",
    "header": "cpp/src/utilities/unique_pinned_ptr.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "double_buffer": {
    "brief": "cuOpt utility functions\n\nCommon utilities for cuOpt library.",
    "file": "double_buffer",
    "library": "cuopt",
    "layer": "layer-4",
    "header": "cpp/src/utilities/double_buffer.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "strided_span": {
    "brief": "cuOpt utility functions\n\nCommon utilities for cuOpt library.",
    "file": "strided_span",
    "library": "cuopt",
    "layer": "layer-4",
    "header": "cpp/src/utilities/strided_span.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "timer": {
    "brief": "cuOpt timing utilities\n\nPerformance timing and profiling.",
    "file": "timer",
    "library": "cuopt",
    "layer": "layer-4",
    "header": "cpp/src/utilities/timer.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "version_info": {
    "brief": "cuOpt utility functions\n\nCommon utilities for cuOpt library.",
    "file": "version_info",
    "library": "cuopt",
    "layer": "layer-4",
    "header": "cpp/src/utilities/version_info.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "scope_guard": {
    "brief": "cuOpt utility functions\n\nCommon utilities for cuOpt library.",
    "file": "scope_guard",
    "library": "cuopt",
    "layer": "layer-4",
    "header": "cpp/src/utilities/scope_guard.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "copy_helpers": {
    "brief": "cuOpt utility functions\n\nCommon utilities for cuOpt library.",
    "file": "copy_helpers",
    "library": "cuopt",
    "layer": "layer-4",
    "header": "cpp/src/utilities/copy_helpers.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "high_res_timer": {
    "brief": "cuOpt timing utilities\n\nPerformance timing and profiling.",
    "file": "high_res_timer",
    "library": "cuopt",
    "layer": "layer-4",
    "header": "cpp/src/utilities/high_res_timer.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "helpers": {
    "brief": "cuOpt VRP diversity management\n\nPopulation diversity for evolutionary VRP.\nPrevents premature convergence.",
    "file": "helpers",
    "library": "cuopt",
    "layer": "layer-4",
    "header": "cpp/src/routing/diversity/helpers.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "diversity_config": {
    "brief": "cuOpt MIP solver component\n\nPart of GPU-accelerated mixed-integer solver.",
    "file": "diversity_config",
    "library": "cuopt",
    "layer": "layer-4",
    "header": "cpp/src/mip/diversity/diversity_config.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "macros": {
    "brief": "cuOpt VRP diversity management\n\nPopulation diversity for evolutionary VRP.\nPrevents premature convergence.",
    "file": "macros",
    "library": "cuopt",
    "layer": "layer-4",
    "header": "cpp/src/routing/diversity/macros.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "population": {
    "brief": "cuOpt VRP diversity management\n\nPopulation diversity for evolutionary VRP.\nPrevents premature convergence.",
    "file": "population",
    "library": "cuopt",
    "layer": "layer-4",
    "header": "cpp/src/routing/diversity/population.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "injection_info": {
    "brief": "cuOpt VRP diversity management\n\nPopulation diversity for evolutionary VRP.\nPrevents premature convergence.",
    "file": "injection_info",
    "library": "cuopt",
    "layer": "layer-4",
    "header": "cpp/src/routing/diversity/injection_info.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "diverse_solver": {
    "brief": "cuOpt VRP diversity management\n\nPopulation diversity for evolutionary VRP.\nPrevents premature convergence.",
    "file": "diverse_solver",
    "library": "cuopt",
    "layer": "layer-4",
    "header": "cpp/src/routing/diversity/diverse_solver.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "generator": {
    "brief": "cuOpt public API header\n\nPublic interface for NVIDIA cuOpt optimization library.",
    "file": "generator",
    "library": "cuopt",
    "layer": "layer-4",
    "header": "cpp/include/cuopt/routing/cython/generator.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "ab_cycle": {
    "brief": "cuOpt VRP genetic crossover\n\nCrossover operators for evolutionary VRP algorithm.\nEAX (edge assembly), OX (order crossover), etc.",
    "file": "ab_cycle",
    "library": "cuopt",
    "layer": "layer-4",
    "header": "cpp/src/routing/crossovers/ab_cycle.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "eax_recombiner": {
    "brief": "cuOpt VRP genetic crossover\n\nCrossover operators for evolutionary VRP algorithm.\nEAX (edge assembly), OX (order crossover), etc.",
    "file": "eax_recombiner",
    "library": "cuopt",
    "layer": "layer-4",
    "header": "cpp/src/routing/crossovers/eax_recombiner.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "inversion_recombiner": {
    "brief": "cuOpt VRP genetic crossover\n\nCrossover operators for evolutionary VRP algorithm.\nEAX (edge assembly), OX (order crossover), etc.",
    "file": "inversion_recombiner",
    "library": "cuopt",
    "layer": "layer-4",
    "header": "cpp/src/routing/crossovers/inversion_recombiner.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "set_covering": {
    "brief": "cuOpt VRP genetic crossover\n\nCrossover operators for evolutionary VRP algorithm.\nEAX (edge assembly), OX (order crossover), etc.",
    "file": "set_covering",
    "library": "cuopt",
    "layer": "layer-4",
    "header": "cpp/src/routing/crossovers/set_covering.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "ox_graph": {
    "brief": "cuOpt VRP genetic crossover\n\nCrossover operators for evolutionary VRP algorithm.\nEAX (edge assembly), OX (order crossover), etc.",
    "file": "ox_graph",
    "library": "cuopt",
    "layer": "layer-4",
    "header": "cpp/src/routing/crossovers/ox_graph.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "dispose": {
    "brief": "cuOpt VRP genetic crossover\n\nCrossover operators for evolutionary VRP algorithm.\nEAX (edge assembly), OX (order crossover), etc.",
    "file": "dispose",
    "library": "cuopt",
    "layer": "layer-4",
    "header": "cpp/src/routing/crossovers/dispose.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "srex_recombiner": {
    "brief": "cuOpt VRP genetic crossover\n\nCrossover operators for evolutionary VRP algorithm.\nEAX (edge assembly), OX (order crossover), etc.",
    "file": "srex_recombiner",
    "library": "cuopt",
    "layer": "layer-4",
    "header": "cpp/src/routing/crossovers/srex_recombiner.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "constants": {
    "brief": "cuOpt vehicle routing component\n\nPart of GPU-accelerated VRP solver.",
    "file": "constants",
    "library": "cuopt",
    "layer": "layer-4",
    "header": "cpp/src/routing/utilities/constants.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "check_input": {
    "brief": "cuOpt vehicle routing component\n\nPart of GPU-accelerated VRP solver.",
    "file": "check_input",
    "library": "cuopt",
    "layer": "layer-4",
    "header": "cpp/src/routing/utilities/check_input.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "env_utils": {
    "brief": "cuOpt vehicle routing component\n\nPart of GPU-accelerated VRP solver.",
    "file": "env_utils",
    "library": "cuopt",
    "layer": "layer-4",
    "header": "cpp/src/routing/utilities/env_utils.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "md_utils": {
    "brief": "cuOpt vehicle routing component\n\nPart of GPU-accelerated VRP solver.",
    "file": "md_utils",
    "library": "cuopt",
    "layer": "layer-4",
    "header": "cpp/src/routing/utilities/md_utils.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "device_bitset": {
    "brief": "cuOpt VRP local search\n\nLocal search moves for route improvement.\n2-opt, Or-opt, swap, relocate operators.",
    "file": "device_bitset",
    "library": "cuopt",
    "layer": "layer-4",
    "header": "cpp/src/routing/local_search/cycle_finder/device_bitset.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "cycle_graph": {
    "brief": "cuOpt VRP local search\n\nLocal search moves for route improvement.\n2-opt, Or-opt, swap, relocate operators.",
    "file": "cycle_graph",
    "library": "cuopt",
    "layer": "layer-4",
    "header": "cpp/src/routing/local_search/cycle_finder/cycle_graph.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "cycle": {
    "brief": "cuOpt VRP local search\n\nLocal search moves for route improvement.\n2-opt, Or-opt, swap, relocate operators.",
    "file": "cycle",
    "library": "cuopt",
    "layer": "layer-4",
    "header": "cpp/src/routing/local_search/cycle_finder/cycle.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "cycle_finder": {
    "brief": "cuOpt VRP local search\n\nLocal search moves for route improvement.\n2-opt, Or-opt, swap, relocate operators.",
    "file": "cycle_finder",
    "library": "cuopt",
    "layer": "layer-4",
    "header": "cpp/src/routing/local_search/cycle_finder/cycle_finder.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "weighted_average_solution": {
    "brief": "cuOpt LP solution storage\n\nPrimal/dual solution and basis information.",
    "file": "weighted_average_solution",
    "library": "cuopt",
    "layer": "layer-4",
    "header": "cpp/src/linear_programming/restart_strategy/weighted_average_solution.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "localized_duality_gap_container": {
    "brief": "cuOpt linear programming component\n\nPart of GPU-accelerated LP solver.",
    "file": "localized_duality_gap_container",
    "library": "cuopt",
    "layer": "layer-4",
    "header": "cpp/src/linear_programming/restart_strategy/localized_duality_gap_container.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "termination_strategy": {
    "brief": "cuOpt linear programming component\n\nPart of GPU-accelerated LP solver.",
    "file": "termination_strategy",
    "library": "cuopt",
    "layer": "layer-4",
    "header": "cpp/src/linear_programming/termination_strategy/termination_strategy.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "infeasibility_information": {
    "brief": "cuOpt linear programming component\n\nPart of GPU-accelerated LP solver.",
    "file": "infeasibility_information",
    "library": "cuopt",
    "layer": "layer-4",
    "header": "cpp/src/linear_programming/termination_strategy/infeasibility_information.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "convergence_information": {
    "brief": "cuOpt linear programming component\n\nPart of GPU-accelerated LP solver.",
    "file": "convergence_information",
    "library": "cuopt",
    "layer": "layer-4",
    "header": "cpp/src/linear_programming/termination_strategy/convergence_information.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "adaptive_step_size_strategy": {
    "brief": "cuOpt linear programming component\n\nPart of GPU-accelerated LP solver.",
    "file": "adaptive_step_size_strategy",
    "library": "cuopt",
    "layer": "layer-4",
    "header": "cpp/src/linear_programming/step_size_strategy/adaptive_step_size_strategy.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "logger_init": {
    "brief": "cuOpt linear programming component\n\nPart of GPU-accelerated LP solver.",
    "file": "logger_init",
    "library": "cuopt",
    "layer": "layer-4",
    "header": "cpp/src/linear_programming/utilities/logger_init.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "local_search_config": {
    "brief": "cuOpt MIP solver component\n\nPart of GPU-accelerated mixed-integer solver.",
    "file": "local_search_config",
    "library": "cuopt",
    "layer": "layer-4",
    "header": "cpp/src/mip/local_search/local_search_config.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "third_party_presolve": {
    "brief": "cuOpt MIP solver component\n\nPart of GPU-accelerated mixed-integer solver.",
    "file": "third_party_presolve",
    "library": "cuopt",
    "layer": "layer-4",
    "header": "cpp/src/mip/presolve/third_party_presolve.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "gf2_presolve": {
    "brief": "cuOpt MIP solver component\n\nPart of GPU-accelerated mixed-integer solver.",
    "file": "gf2_presolve",
    "library": "cuopt",
    "layer": "layer-4",
    "header": "cpp/src/mip/presolve/gf2_presolve.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "recombiner_configs": {
    "brief": "cuOpt MIP solver component\n\nPart of GPU-accelerated mixed-integer solver.",
    "file": "recombiner_configs",
    "library": "cuopt",
    "layer": "layer-4",
    "header": "cpp/src/mip/diversity/recombiners/recombiner_configs.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "recombiner_stats": {
    "brief": "cuOpt MIP solver component\n\nPart of GPU-accelerated mixed-integer solver.",
    "file": "recombiner_stats",
    "library": "cuopt",
    "layer": "layer-4",
    "header": "cpp/src/mip/diversity/recombiners/recombiner_stats.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "error": {
    "brief": "cuOpt MPS file parser\n\nReads LP/MIP problems in MPS format.\nHandles fixed and free format MPS files.",
    "file": "error",
    "library": "cuopt",
    "layer": "layer-4",
    "header": "cpp/libmps_parser/src/utilities/error.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "data_model_view": {
    "brief": "cuOpt public API header\n\nPublic interface for NVIDIA cuOpt optimization library.",
    "file": "data_model_view",
    "library": "cuopt",
    "layer": "layer-4",
    "header": "cpp/libmps_parser/include/mps_parser/data_model_view.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "routing_structures": {
    "brief": "Core data structures for VRP problem specification\n\nEnums and helper classes for VRP constraint modeling.\n\n**Objective Types (objective_t):**\n- COST: Total route cost from cost matrix\n- TRAVEL_TIME: Total driving time (excluding waits)\n- VARIANCE_ROUTE_SIZE: Balance route lengths\n- VARIANCE_ROUTE_SERVICE_TIME: Balance service times\n- PRIZE: Sum of collected order prizes\n- VEHICLE_FIXED_COST: Per-vehicle usage cost\n\n**Node Types (node_type_t):**\n- DEPOT: Start/end location for vehicles\n- PICKUP: Pickup location for PDP\n- DELIVERY: Delivery location for PDP\n- BREAK: Driver break location\n\n**Internal Detail Classes:**\n- break_dimension_t: Uniform break constraints\n- vehicle_break_t: Per-vehicle break constraints\n- capacity_t: Capacity dimension (demand/capacity pair)\n- order_time_window_t: Time window bounds\n- vehicle_time_window_t: Vehicle availability bounds",
    "file": "routing_structures",
    "library": "cuopt",
    "layer": "layer-4",
    "header": "cpp/include/cuopt/routing/routing_structures.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "solver_settings": {
    "brief": "Mixed-integer programming solver configuration\n\nSettings for GPU-accelerated MIP solver.\n\n**mip_solver_settings_t Class:**\n- set_mip_callback(): User callback for incumbent solutions\n- set_time_limit(): Maximum solve time\n- set_mip_gap(): Optimality gap tolerance\n- set_verbosity(): Output level control\n\n**MIP Algorithm:**\n- Branch-and-bound with GPU LP relaxations\n- Population-based heuristics\n- Recombination operators for primal improvement",
    "file": "solver_settings",
    "library": "cuopt",
    "layer": "layer-4",
    "header": "cpp/include/cuopt/linear_programming/mip/solver_settings.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "assignment": {
    "brief": "VRP solution output container with routes and timing\n\nContainer for Vehicle Routing Problem solver output.\n\n**assignment_t Class:**\n- Optimized routes stored in GPU device memory\n- Arrival times, truck assignments, node types\n- Objective values and solution status\n\n**Solution Data:**\n- get_route(): Ordered sequence of node IDs\n- get_truck_id(): Vehicle assignment per stop\n- get_arrival_stamp(): Arrival time at each stop\n- get_unserviced_nodes(): Orders not serviced (if any)\n\n**Solution Status (solution_status_t):**\n- SUCCESS: Feasible solution found\n- INFEASIBLE: No feasible solution exists\n- TIMEOUT: Time limit reached\n- EMPTY: Solver did not run\n- ERROR: Runtime error occurred\n\n**host_assignment_t:**\n- Host-side copy for CPU access\n- std::vector storage for routes and stamps",
    "file": "assignment",
    "library": "cuopt",
    "layer": "layer-4",
    "header": "cpp/include/cuopt/routing/assignment.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "optimization_problem": {
    "brief": "GPU-resident linear/integer programming problem representation\n\nContainer for LP/MIP optimization problems stored in GPU memory.\n\n**optimization_problem_t Class:**\n- Represents: min/max c'x s.t. Ax \u2264/=/\u2265 b, l \u2264 x \u2264 u\n- Constraint matrix A in CSR (Compressed Sparse Row) format\n- GPU device memory via rmm::device_uvector\n\n**Problem Components:**\n- set_csr_constraint_matrix(): Sparse constraint matrix\n- set_constraint_bounds(): RHS values (b)\n- set_objective_coefficients(): Cost vector (c)\n- set_variable_lower/upper_bounds(): Variable bounds\n- set_variable_types(): CONTINUOUS or INTEGER\n\n**Variable Types:**\n- var_t::CONTINUOUS: Real-valued variable\n- var_t::INTEGER: Integer-valued variable\n\n**Problem Categories:**\n- LP: All continuous variables\n- MIP: Mixed integer and continuous\n- IP: All integer variables",
    "file": "optimization_problem",
    "library": "cuopt",
    "layer": "layer-4",
    "header": "cpp/include/cuopt/linear_programming/optimization_problem.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "timestamp_utils": {
    "brief": "cuOpt public API header\n\nPublic interface for NVIDIA cuOpt optimization library.",
    "file": "timestamp_utils",
    "library": "cuopt",
    "layer": "layer-4",
    "header": "cpp/include/cuopt/utilities/timestamp_utils.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "waypoint_matrix": {
    "brief": "cuOpt public API header\n\nPublic interface for NVIDIA cuOpt optimization library.",
    "file": "waypoint_matrix",
    "library": "cuopt",
    "layer": "layer-4",
    "header": "cpp/include/cuopt/routing/distance_engine/waypoint_matrix.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "cython": {
    "brief": "cuOpt public API header\n\nPublic interface for NVIDIA cuOpt optimization library.",
    "file": "cython",
    "library": "cuopt",
    "layer": "layer-4",
    "header": "cpp/include/cuopt/routing/cython/cython.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "pdlp_warm_start_data": {
    "brief": "cuOpt GPU linear programming API\n\nPublic API for GPU-accelerated linear programming.\nCUDA-based simplex and interior point methods.",
    "file": "pdlp_warm_start_data",
    "library": "cuopt",
    "layer": "layer-4",
    "header": "cpp/include/cuopt/linear_programming/pdlp/pdlp_warm_start_data.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "solver_solution": {
    "brief": "cuOpt public API header\n\nPublic interface for NVIDIA cuOpt optimization library.",
    "file": "solver_solution",
    "library": "cuopt",
    "layer": "layer-4",
    "header": "cpp/include/cuopt/linear_programming/mip/solver_solution.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "solver_stats": {
    "brief": "cuOpt public API header\n\nPublic interface for NVIDIA cuOpt optimization library.",
    "file": "solver_stats",
    "library": "cuopt",
    "layer": "layer-4",
    "header": "cpp/include/cuopt/linear_programming/mip/solver_stats.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "callbacks_implems": {
    "brief": "cuOpt public API header\n\nPublic interface for NVIDIA cuOpt optimization library.",
    "file": "callbacks_implems",
    "library": "cuopt",
    "layer": "layer-4",
    "header": "cpp/include/cuopt/linear_programming/utilities/callbacks_implems.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "internals": {
    "brief": "cuOpt public API header\n\nPublic interface for NVIDIA cuOpt optimization library.",
    "file": "internals",
    "library": "cuopt",
    "layer": "layer-4",
    "header": "cpp/include/cuopt/linear_programming/utilities/internals.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "cython_solve": {
    "brief": "cuOpt public API header\n\nPublic interface for NVIDIA cuOpt optimization library.",
    "file": "cython_solve",
    "library": "cuopt",
    "layer": "layer-4",
    "header": "cpp/include/cuopt/linear_programming/utilities/cython_solve.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "mps_parser": {
    "brief": "cuOpt MPS file parser\n\nReads LP/MIP problems in MPS format.\nHandles fixed and free format MPS files.",
    "file": "mps_parser",
    "library": "cuopt",
    "layer": "layer-4",
    "header": "cpp/libmps_parser/src/mps_parser.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "parser": {
    "brief": "cuOpt public API header\n\nPublic interface for NVIDIA cuOpt optimization library.",
    "file": "parser",
    "library": "cuopt",
    "layer": "layer-4",
    "header": "cpp/libmps_parser/include/mps_parser/parser.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "writer": {
    "brief": "cuOpt public API header\n\nPublic interface for NVIDIA cuOpt optimization library.",
    "file": "writer",
    "library": "cuopt",
    "layer": "layer-4",
    "header": "cpp/libmps_parser/include/mps_parser/writer.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "mps_writer": {
    "brief": "cuOpt public API header\n\nPublic interface for NVIDIA cuOpt optimization library.",
    "file": "mps_writer",
    "library": "cuopt",
    "layer": "layer-4",
    "header": "cpp/libmps_parser/include/mps_parser/mps_writer.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "mps_data_model": {
    "brief": "cuOpt public API header\n\nPublic interface for NVIDIA cuOpt optimization library.",
    "file": "mps_data_model",
    "library": "cuopt",
    "layer": "layer-4",
    "header": "cpp/libmps_parser/include/mps_parser/mps_data_model.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "cython_mps_parser": {
    "brief": "cuOpt public API header\n\nPublic interface for NVIDIA cuOpt optimization library.",
    "file": "cython_mps_parser",
    "library": "cuopt",
    "layer": "layer-4",
    "header": "cpp/libmps_parser/include/mps_parser/utilities/cython_mps_parser.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "span": {
    "brief": "cuOpt public API header\n\nPublic interface for NVIDIA cuOpt optimization library.",
    "file": "span",
    "library": "cuopt",
    "layer": "layer-4",
    "header": "cpp/libmps_parser/include/mps_parser/utilities/span.hpp",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  },
  "cuopt_c": {
    "brief": "A ``cuOptOptimizationProblem`` object contains a representation of\nan LP or MIP. It is created by ``cuOptCreateProblem`` or ``cuOptCreateRangedProblem``.\nIt is passed to ``cuOptSolve``. It should be destroyed using ``cuOptDestroyProblem``.",
    "file": "cuopt_c",
    "library": "cuopt",
    "layer": "layer-4",
    "header": "cpp/include/cuopt/linear_programming/cuopt_c.h",
    "algorithms": 0,
    "methods": 0,
    "has_pass2": false
  }
}